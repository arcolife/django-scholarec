[{"a": ["Sameer Agarwal", "Noah Snavely", "Ian Simon", "Steven Seitz", "Richard Szeliski"], "c": [39261565, 13995468, 39261210, 13994911, 13995278, 13995276, 39261323, 50988747, 39261302, 39321391, 51067869, 13992287, 14375552, 39261244, 13995212, 13995291, 13995392, 14146559, 27812935, 27812937, 51098554, 51108160, 13995024, 13995350, 14083969, 39229313, 39230006, 39261608, 39262415, 39282597, 40169505, 57019482, 57172316, 39236328, 39263856, 39277596, 39326590, 47925415, 51041592, 51080325, 51080356, 51098511, 51098513, 51099932, 51107998, 51108155, 51108176, 51108231, 51110261, 51118068, 51159418, 13980859, 13988433, 13995361, 39256517, 39256540, 39256606, 39261340, 39261394, 39261501, 39262420, 39277519, 39292915, 39297783, 48871443, 50919735, 50986297, 50994080, 51001401, 61402281, 15271299, 48455104, 48605263, 48696941], "b": "We present a system that can match and reconstruct 3D scenes from extremely large collections of photographs such as those found by searching for a given city (e.g., Rome) on Internet photo sharing sites. Our system uses a collection of novel parallel distributed matching and reconstruction algorithms, designed to maximize parallelism at each stage in the pipeline and minimize serialization", "cn": 74, "i": 39266032, "tw": ["image", "images", "matching", "connected", "system", "match", "reconstruction", "data", "feature", "set", "components", "node", "query", "skeletal", "matches", "pairs", "graph", "algorithm", "number", "points", "component", "size", "distributed", "expansion", "large", "network", "features", "sets", "vocabulary", "largest", "bundle", "nodes", "tracks", "tree", "photographs", "problem", "detailed", "time", "cluster", "collections", "sift", "sfm", "adjustment", "three", "photo", "stage", "associated", "small", "based", "approach", "second", "consider", "larger", "process", "verify", "parallel", "merge", "frequency", "master", "track", "tfidf", "well", "scale", "compute", "rounds", "computing", "matrix", "22505", "36587", "61450", "36586", "55763", "55760", "41377", "55764", "92654", "5412", "43870", "vector", "40017", "40018", "round", "64871", "1628", "27282", "2543", "14757", "rome", "53569", "34321", "88549", "1231", "101945", "75015", "55720", "104", "694", "step", "amount", "14470"], "k": ["Parallel Computer", "Photo Sharing", "Reconstruction Algorithm"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459148", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459148", "http://research.microsoft.com/apps/pubs/default.aspx?id=101029", "http://research.microsoft.com/pubs/101029/Agarwal-ICCV09.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459148", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#AgarwalSSSS09"], "r": [1942580, 1318048, 607785, 2167392, 2175137, 4115842, 4112268, 4116856, 4389476, 307732, 1714709, 4117954, 4253676, 4771561, 30509, 4704942, 4253852], "t": "Building Rome in a day", "v": "ICCV", "y": 2009, "rn": 17, "h": ["resources/39266032/thumb-0.png", "resources/39266032/thumb-1.png", "resources/39266032/thumb-2.png", "resources/39266032/thumb-3.png", "resources/39266032/thumb-4.png", "resources/39266032/thumb-5.png", "resources/39266032/thumb-6.png", "resources/39266032/thumb-7.png"]}, {"a": ["Yasutaka Furukawa", "Brian Curless", "Steven Seitz", "Richard Szeliski"], "c": [13995468, 13992287, 14375552, 39262452, 51000605, 51108243, 51147849, 39232624, 39297783, 51001401, 51015817, 61402281, 48396525], "b": "This paper introduces an approach for enabling existing multi-view stereo methods to operate on extremely large unstructured photo collections. The main idea is to decompose the collection into a set of overlapping sets of photos that can be processed in parallel, and to merge the resulting reconstructions. This overlapping clustering problem is formulated as a constrained optimization and solved iteratively.", "cn": 13, "i": 39261565, "tw": ["mvs", "image", "images", "points", "cluster", "sfm", "reconstruction", "point", "set", "clusters", "visibility", "algorithm", "depth", "view", "algorithms", "reconstructed", "figure", "quality", "clustering", "number", "large", "merging", "filter", "selection", "input", "parallel", "note", "photo", "overlapping", "reconstructions", "map", "accuracy", "stereo", "approach", "rendering", "coverage", "time", "entire", "memory", "merge", "size", "proposed", "constraint", "visible", "maps", "mesh", "multi-view", "pmvs", "multiple", "surface", "running", "steps", "small", "step", "camera", "high", "designed", "redundant", "constraints", "system", "pair", "handle", "reconstruct", "out-of-core", "methods", "enforce", "measures", "internet", "reference", "actions", "goesele", "action", "accurate", "dense", "neighbors", "global", "dubrovnik", "merged", "serial", "times", "pixel", "propose", "renderings", "san", "extracted", "covered", "robust", "execution", "node", "software", "computational", "count", "datasets", "associated", "formulation", "repeat", "models", "variation", "resolution", "division"], "k": ["3d reconstruction", "Algorithm Design", "Constrained Optimization", "large dataset", "multi-view stereo", "Photo Collection"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539802", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539802", "http://research.microsoft.com/apps/pubs/default.aspx?id=131807", "http://research.microsoft.com/pubs/131807/Furukawa-CVPR10.pdf", "http://dx.doi.org/10.1109/CVPR.2010.5539802", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#FurukawaCSS10"], "r": [1942580, 799939, 321498, 115264, 107294, 2167171, 3582575, 2145613, 1872555, 1789051, 4389476, 4404151, 4114741, 39266032, 2503389, 13313906, 1775195, 4247946, 4271345, 6076411, 4704947, 4704643, 4114744, 6368088], "t": "Towards Internet-scale multi-view stereo", "v": "CVPR", "y": 2010, "rn": 24, "h": ["resources/39261565/thumb-0.png", "resources/39261565/thumb-1.png", "resources/39261565/thumb-2.png", "resources/39261565/thumb-3.png", "resources/39261565/thumb-4.png", "resources/39261565/thumb-5.png", "resources/39261565/thumb-6.png", "resources/39261565/thumb-7.png"]}, {"a": ["Jan-Michael Frahm", "Pierre Georgel", "David Gallup", "Tim Johnson", "Rahul Raguram", "Changchang Wu", "Yi-Hung Jen", "Enrique Dunn", "Brian Clipp", "Svetlana Lazebnik", "Marc Pollefeys"], "c": [51067869, 51108215, 51100540, 51108160, 48000085, 51080325, 51108231, 56904787], "b": "This paper introduces an approach for dense 3D reconstruction from unregistered Internet-scale photo collections with about 3 million of images within the span of a day on a single PC (\\cloudless\"). Our method advances image clustering, stereo, stereo fusion and structure from motion to achieve high computational performance. We leverage geometric and appearance constraints to obtain a highly parallel implementation", "cn": 8, "i": 13995468, "tw": ["images", "iconic", "image", "cluster", "reconstruction", "photo", "rome", "scene", "dense", "method", "collections", "number", "approach", "clustering", "hrs", "geometry", "stereo", "geo-location", "camera", "day", "system", "distance", "gist", "model", "dataset", "registered", "local", "clusters", "views", "geometric", "building", "code", "scheme", "appearance", "single", "berlin", "binary", "modeling", "computation", "graph", "features", "multiple", "set", "computer", "cloudless", "surface", "registration", "iconics", "advantage", "large", "heightmap", "appearance-based", "descriptor", "process", "matrix", "multi-view", "hamming", "based", "computed", "graphics", "cvpr", "spatial", "matching", "codes", "vocabulary", "relationships", "small", "consistent", "figure", "constraints", "internet", "pairs", "gpu", "pairwise", "view", "geometrically", "estimation", "community", "table", "frahm", "robust", "sets", "fusion", "scale", "step", "bundle", "takes", "memory", "real-time", "data", "matches", "magnitude", "millions", "tree", "san", "connected", "iccv", "vertical", "inlier", "lsbc"], "k": ["3d reconstruction", "Graphics Processors", "Image Clustering", "Parallel Implementation", "Photo Collection", "Structure From Motion"], "p": ["http://www.springerlink.com/index/pmjt7226801p770v.pdf", "http://www.springerlink.com/content/pmjt7226801p770v", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-4.html#FrahmGGJRWJDCL10", "http://dx.doi.org/10.1007/978-3-642-15561-1_27", "http://www.inf.ethz.ch/personal/pomarc/pubs/FrahmECCV10.pdf", "http://www.cs.unc.edu/~rraguram/papers/ECCV2010.pdf"], "r": [1942580, 696119, 51645, 2167392, 4247666, 39252170, 2175137, 4115842, 509526, 1321435, 4113727, 1788314, 2430612, 2138829, 4389580, 4116856, 4141389, 4248108, 4117954, 4114741, 39266032, 4253676, 2167282, 4704942, 4271235, 4253770, 5385706, 39261565, 4719975, 2425120, 4528820, 39261369, 39242389, 13992287], "t": "Building Rome on a Cloudless Day", "v": "ECCV", "y": 2010, "rn": 34, "h": ["resources/13995468/thumb-0.png", "resources/13995468/thumb-1.png", "resources/13995468/thumb-2.png", "resources/13995468/thumb-3.png", "resources/13995468/thumb-4.png", "resources/13995468/thumb-5.png", "resources/13995468/thumb-6.png", "resources/13995468/thumb-7.png", "resources/13995468/thumb-8.png", "resources/13995468/thumb-9.png", "resources/13995468/thumb-10.png", "resources/13995468/thumb-11.png", "resources/13995468/thumb-12.png", "resources/13995468/thumb-13.png"]}, {"a": ["Yekeun Jeong", "David Nist\u00e9r", "Drew Steedly", "Richard Szeliski", "In-So Kweon"], "b": "In this paper, we present results and experiments with several methods for bundle adjustment, producing the fastest bundle adjuster ever published. The fastest methods work with the well known reduced camera system and handle the block-sparse pattern arising in the reduced camera system in a natural way. Adapting to the naturally arising block-sparsity allows the use of BLAS3, efficient memory", "cn": 8, "i": 39261210, "k": ["Bundle Adjustment", "Minimum Degree", "Preconditioned Conjugate Gradient"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539795", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539795", "http://dx.doi.org/10.1109/CVPR.2010.5539795", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#JeongNSSK10", "http://research.microsoft.com/apps/pubs/default.aspx?id=131806", "http://research.microsoft.com/pubs/131806/Jeong-CVPR10.pdf"], "t": "Pushing the envelope of modern methods for bundle adjustment", "v": "CVPR", "y": 2010, "rn": 18}, {"a": ["Andrej Mikul\u00edk", "Michal Perdoch", "Ondrej Chum", "Jiri Matas"], "b": "\n A novel similarity measure for bag-of-words type large scale image retrieval is presented. The similarity function is learned\n in an unsupervised manner, requires no extra space over the standard bag-of-words method and is more discriminative than both\n L2-based soft assignment and Hamming embedding.\n \n \n We show experimentally that the novel similarity function achieves mean average precision that is superior to any", "cn": 7, "i": 13994911, "k": ["Image Retrieval", "Large Scale", "Similarity Function", "Similarity Measure", "Bag of Words", "Mean Average Precision"], "p": ["http://www.springerlink.com/content/p847x71m22681777", "http://www.springerlink.com/index/p847x71m22681777.pdf", "http://dx.doi.org/10.1007/978-3-642-15558-1_1", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-3.html#MikulikPCM10"], "t": "Learning a Fine Vocabulary", "v": "ECCV", "y": 2010, "rn": 19}, {"a": ["Sameer Agarwal", "Noah Snavely", "Steven Seitz", "Richard Szeliski"], "b": "\n We present the design and implementation of a new inexact Newton type algorithm for solving large-scale bundle adjustment\n problems with tens of thousands of images. We explore the use of Conjugate Gradients for calculating the Newton step and its\n performance as a function of some simple and computationally efficient preconditioners. We show that the common Schur complement\n trick is not", "cn": 7, "i": 13995278, "k": ["Bundle Adjustment", "Conjugate Gradient", "Design and Implementation", "Large Scale", "Photo Collection", "schur complement", "Truncated Newton Method"], "p": ["http://www.springerlink.com/content/2427931736554256", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#AgarwalSSS10", "http://dx.doi.org/10.1007/978-3-642-15552-9_3", "http://research.microsoft.com/apps/pubs/default.aspx?id=135847", "http://research.microsoft.com/pubs/135847/Agarwal-ECCV10.pdf"], "t": "Bundle Adjustment in the Large", "v": "ECCV", "y": 2010, "rn": 22}, {"a": ["Yunpeng Li", "Noah Snavely", "Daniel Huttenlocher"], "b": "We present a fast, simple location recognition and image localization method that leverages feature correspondence and geometry estimated from large Internet photo collections. Such recovered structure contains a significant amount of useful information about images and image features that is not available when considering images in isolation. For instance, we can predict which views will be the most common, which", "cn": 6, "i": 13995276, "k": ["Feature Matching", "Image Features", "Image Matching", "Image Registration", "Image Retrieval", "Photo Collection", "Structure From Motion"], "p": ["http://www.springerlink.com/content/u71701621l917222", "http://www.springerlink.com/index/u71701621l917222.pdf", "http://dx.doi.org/10.1007/978-3-642-15552-9_57", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#LiSH10", "http://www.cs.cornell.edu/~snavely/publications/papers/localization_eccv_2010.pdf"], "t": "Location Recognition Using Prioritized Feature Matching", "v": "ECCV", "y": 2010, "rn": 25}, {"a": ["Kyle Heath", "Natasha Gelfand", "Maks Ovsjanikov", "Mridul Aanjaneya", "Leonidas Guibas"], "b": "The widespread availability of digital cameras and ubiquitous Internet access have facilitated the creation of massive image collections. These collections can be highly interconnected through implicit links between image pairs viewing the same or similar objects. We propose building graphs called Image Webs to represent such connections. While earlier efforts studied local neighborhoods of such graphs, we are interested in", "cn": 6, "i": 39261323, "k": ["Digital Camera", "Internet Access", "Spectral Graph Theory", "Topological Analysis"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539991", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539991", "http://dx.doi.org/10.1109/CVPR.2010.5539991", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#HeathGOAG10"], "t": "Image webs: Computing and exploiting connectivity in image collections", "v": "CVPR", "y": 2010, "rn": 22}, {"a": ["Kai Ni", "Frank Dellaert"], "b": "We propose a novel batch algorithm for SLAM problems that distributes the workload in a hierarchical way. We show that the original SLAM graph can be recursively partitioned into multiple-level submaps using the nested dissection algorithm, which leads to the cluster tree, a powerful graph representation. By employing the nested dissection algorithm, our algorithm greatly minimizes the dependencies between two", "cn": 6, "i": 50988747, "k": ["Graph Representation", "Recursive Partitioning", "Bottom Up"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5650197", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05650197"], "t": "Multilevel submap based SLAM using nested dissection", "v": "IROS", "y": 2010, "rn": 29}, {"a": ["Jonathan Taylor", "Allan Jepson", "Kiriakos Kutulakos"], "b": "We introduce locally-rigid motion, a general framework for solving the M-point, N-view structure-from-motion problem for unknown bodies deforming under orthography. The key idea is to first solve many local 3-point, N-view rigid problems independently, providing a \u201csoup\u201d of specific, plausibly rigid, 3D triangles. The main advantage here is that the extraction of 3D triangles requires only very weak assumptions: (1)", "cn": 5, "i": 39261302, "k": ["Generic Algorithm", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540002", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540002", "http://dx.doi.org/10.1109/CVPR.2010.5540002", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#TaylorJK10"], "t": "Non-rigid structure from locally-rigid motion", "v": "CVPR", "y": 2010, "rn": 35}, {"a": ["Yunsu Bok", "Yekeun Jeong", "Dong-Geol Choi", "In-So Kweon"], "b": "Preserving a heritage as a digital archive is as important as preserving its physical structure. The digital preservation\n is essential for massive heritages which are often defenceless against various types of destruction and require frequent restorations.\n However, capturing heritages gets exceedingly harder as their scale grows. In this paper, we present a novel approach to reconstruct\n a massive-scale structure using", "cn": 3, "i": 39321391, "k": ["3d reconstruction", "Digital Archive", "Digital Preservation", "Error Reduction", "Large Scale", "Laser Scanner", "Motion Estimation", "Satellite Image", "Sensor Fusion", "Sensor System", "Field of View", "Level of Detail"], "p": ["http://www.springerlink.com/index/p3080g7424308537.pdf", "http://www.springerlink.com/content/p3080g7424308537", "http://dx.doi.org/10.1007/s11263-010-0397-8", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv94.html#BokJCK11"], "t": "Capturing Village-level Heritages with a Hand-held Camera-Laser Fusion Sensor", "v": "IJCV", "y": 2011, "rn": 18}, {"a": ["Andreas Geiger", "Julius Ziegler", "Christoph Stiller"], "b": "Accurate 3d perception from video sequences is a core subject in computer vision and robotics, since it forms the basis of subsequent scene analysis. In practice however, online requirements often severely limit the utilizable camera resolution and hence also reconstruction accuracy. Further- more, real-time systems often rely on heavy parallelism which can prevent applications in mobile devices or driver assistance", "cn": 3, "i": 51067869, "k": ["3d point cloud", "3d reconstruction", "Depth Map", "Driver Assistance System", "Feature Matching", "Mobile Device", "Scene Analysis", "Stereo Matching", "visual odometry", "Frames Per Second", "Real Time", "Real Time Systems"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05940405", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5940405"], "t": "StereoScan: Dense 3d reconstruction in real-time", "v": "IV", "y": 2011, "rn": 24}, {"a": ["David Gallup", "Marc Pollefeys", "Jan-Michael Frahm"], "b": "\n We present a novel method for 3D reconstruction of urban scenes extending a recently introduced heightmap model. Our model\n has several advantages for 3D modeling of urban scenes: it naturally enforces vertical surfaces, has no holes, leads to an\n efficient algorithm, and is compact in size. We remove the major limitation of the heightmap by enabling modeling of overhanging\n structures.", "cn": 3, "i": 13992287, "k": ["3d model", "3d reconstruction", "bayesian information criterion", "Cost Function", "Dynamic Program", "Efficient Algorithm", "Photo Collection", "Surface Model"], "p": ["http://www.springerlink.com/content/qg6nx2285h3622n0", "http://www.springerlink.com/index/qg6nx2285h3622n0.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/dagm/dagm2010.html#GallupPF10", "http://dx.doi.org/10.1007/978-3-642-15986-2_1"], "t": "3D Reconstruction Using an n-Layer Heightmap", "v": "", "y": 2010, "rn": 19}, {"a": ["Noah Snavely", "Ian Simon", "Michael Goesele", "Richard Szeliski", "Steven Seitz"], "b": "There are billions of photographs on the Internet, representing an extremely large, rich, and nearly comprehensive visual record of virtually every famous place on Earth. Unfortunately, these massive community photo collections are almost completely unstructured, making it very difficult to use them for applications such as the virtual exploration of our world. Over the past several years, advances in computer", "cn": 3, "i": 14375552, "k": ["Computer Vision", "Photo Collection", "Scene Reconstruction", "Spatial Distribution", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05483186", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5483186", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5483186", "http://research.microsoft.com/apps/pubs/default.aspx?id=101822", "http://research.microsoft.com/pubs/101822/Snavely-PIEEE10.pdf"], "t": "Scene Reconstruction and Visualization From Community Photo Collections", "v": "PIEEE", "y": 2010, "rn": 66}, {"a": ["Grant Schindler", "Frank Dellaert"], "b": "Modern structure from motion techniques are capable of building city-scale 3D reconstructions from large image collections, but have mostly ignored the problem of large-scale structural changes over time. We present a general framework for estimating temporal variables in structure from motion problems, including an unknown date for each camera and an unknown time interval for each structural element. Given a", "cn": 3, "i": 39261244, "k": ["3d reconstruction", "Large Scale Structure", "Structure From Motion", "Temporal Variability"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539803", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539803", "http://dx.doi.org/10.1109/CVPR.2010.5539803", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#SchindlerD10"], "t": "Probabilistic temporal inference on reconstructed 3D scenes", "v": "CVPR", "y": 2010, "rn": 10}, {"a": ["J\u00e9r\u00f4me Courchay", "Arnak Dalalyan", "Renaud Keriven", "Peter Sturm"], "b": "\n A technique for calibrating a network of perspective cameras based on their graph of trifocal tensors is presented. After\n estimating a set of reliable epipolar geometries, a parameterization of the graph of trifocal tensors is proposed in which\n each trifocal tensor is encoded by a 4-vector. The strength of this parameterization is that the homographies relating two\n adjacent trifocal tensors,", "cn": 2, "i": 13995212, "k": ["epipolar geometry"], "p": ["http://www.springerlink.com/content/53j804865q67276x", "http://www.springerlink.com/index/53j804865q67276x.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#CourchayDKS10", "http://dx.doi.org/10.1007/978-3-642-15552-9_7"], "t": "Exploiting Loops in the Graph of Trifocal Tensors for Calibrating a Network of Cameras", "v": "ECCV", "y": 2010, "rn": 32}, {"a": ["Martin Byr\u00f6d", "Kalle \u00c5str\u00f6m"], "b": "\n Bundle adjustment for multi-view reconstruction is traditionally done using the Levenberg-Marquardt algorithm with a direct\n linear solver, which is computationally very expensive. An alternative to this approach is to apply the conjugate gradients\n algorithm in the inner loop. This is appealing since the main computational step of the CG algorithm involves only a simple\n matrix-vector multiplication with the Jacobian. In", "cn": 2, "i": 13995291, "k": ["Bundle Adjustment", "Conjugate Gradient", "Least Square", "Qr Factorization", "levenberg marquardt"], "p": ["http://www.springerlink.com/index/b76232j7115531h3.pdf", "http://www.springerlink.com/content/b76232j7115531h3", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#ByrodA10", "http://dx.doi.org/10.1007/978-3-642-15552-9_9"], "t": "Conjugate Gradient Bundle Adjustment", "v": "ECCV", "y": 2010, "rn": 15}, {"a": ["M Shah"], "b": "", "cn": 2, "i": 13995392, "k": ["Google Map"], "p": ["http://www.springerlink.com/content/4056175758716352", "http://www.springerlink.com/index/4056175758716352.pdf", "http://dx.doi.org/10.1007/978-3-642-15561-1_19", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-4.html#ZamirS10"], "t": "Accurate image localization based on google maps street view", "v": "ECCV", "y": 2010, "rn": 14}, {"a": ["Anil Madhavapeddy", "Richard Mortier", "Jon Crowcroft", "Steven Hand"], "b": "In this paper, we present a vision of the future of heterogeneous cloud computing. Ours is a clean- slate approach, sweeping away decades of accreted system software. We believe the advent of the latest technology discontinuity\u2014the move to the virtual cloud\u2014makes this a necessary step to take, but one capable of delivering significant benefits in the security, reliability and efficiency", "cn": 2, "i": 14146559, "k": ["Cloud Computing", "Common Ground", "Software Platform"], "p": ["http://anil.recoil.org/papers/2010-bcs-visions.pdf"], "t": "Multiscale not Multicore: Efficient Heterogeneous Cloud Computing", "y": 2010, "rn": 30}, {"a": ["Y. Avrithis", "Y. Kalantidis", "G. Tolias", "E. Spyrou"], "b": "", "cn": 2, "i": 27812935, "k": ["Photo Collection", "Data Mining", "Image Clustering", "Image Retrieval", "Indexation", "Vector Quantizer", "Visual Features"], "p": ["http://portal.acm.org/citation.cfm?id=1873973", "http://portal.acm.org/ft_gateway.cfm?id=1873973&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1873951.1873973", "http://www.informatik.uni-trier.de/~ley/db/conf/mm/mm2010.html#AvrithisKTS10", "http://dl.acm.org/citation.cfm?id=1873973"], "t": "Retrieving Landmark and Non-Landmark Images From Community Photo Collections", "v": "MM", "y": 2010, "rn": 35}, {"a": ["Y. Kalantidis", "G. Tolias", "Y. Avrithis", "M. Phinikettos", "E. Spyrou", "P. Mylonas", "S. Kollias"], "b": "", "cn": 1, "i": 27812937, "k": ["Image Retrieval", "Indexation", "Large Scale", "Photo Collection"], "p": ["http://www.springerlink.com/content/543m12lp54h23360", "http://www.springerlink.com/index/543m12lp54h23360.pdf", "http://dx.doi.org/10.1007/s11042-010-0651-7", "http://www.informatik.uni-trier.de/~ley/db/journals/mta/mta51.html#KalantidisTAPSMK11"], "t": "Viral: Visual Image Retrieval and Localization", "v": "MTA", "y": 2011, "rn": 49}, {"a": ["Arnold Irschara", "Christof Hoppe", "Horst Bischof", "Stefan Kluckner"], "b": "In this paper we present an approach that leverages prior information from global positioning systems and inertial measurement units to speedup structure from motion computation. We propose a view selection strategy that advances vocabulary tree based coarse matching by also considering the geometric configuration between weakly oriented images. Furthermore, we introduce a fast and scalable reconstruction approach that relies on", "cn": 1, "i": 51098554, "k": ["Bundle Adjustment", "Global Position System", "Image Reconstruction", "Inertial Measurement Unit", "Prior Information", "Structure From Motion", "Three Dimensional", "Micro Aerial Vehicle"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05981775", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5981775"], "t": "Efficient structure from motion with weak position and orientation priors", "v": "CVPR", "y": 2011, "rn": 19}, {"a": ["Changchang Wu", "Sameer Agarwal", "Brian Curless", "Steven Seitz"], "b": "We present the design and implementation of new inexact Newton type Bundle Adjustment algorithms that exploit hardware parallelism for efficiently solving large scale 3D scene reconstruction problems. We explore the use of multicore CPU as well as multicore GPUs for this purpose. We show that overcoming the severe memory and bandwidth limitations of current generation GPUs not only leads to", "cn": 1, "i": 51108160, "k": ["3d scene reconstruction", "Bundle Adjustment", "Design and Implementation", "Efficient Algorithm", "Large Scale"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995552", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995552"], "t": "Multicore bundle adjustment", "v": "CVPR", "y": 2011, "rn": 10}, {"a": ["Stephan Gammeter", "Till Quack", "David Tingdahl", "Luc Gool"], "b": "\n Most of the recent work on image-based object recognition and 3D reconstruction has focused on improving the underlying algorithms.\n In this paper we present a method to automatically improve the quality of the reference database, which, as we will show,\n also affects recognition and reconstruction performances significantly. Starting out from a reference database of clustered\n images we expand small clusters.", "cn": 1, "i": 13995024, "k": ["3d reconstruction", "Image Clustering", "Image Mining", "Image Retrieval", "Object Recognition", "Scene Analysis"], "p": ["http://www.springerlink.com/content/w6k437386r005j66", "http://www.springerlink.com/index/w6k437386r005j66.pdf", "http://dx.doi.org/10.1007/978-3-642-15549-9_53", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-1.html#GammeterQTG10"], "t": "Size Does Matter: Improving Object Recognition and 3D Reconstruction with Cross-Media Analysis of Image Clusters", "v": "ECCV", "y": 2010, "rn": 24}, {"a": ["Michal Havlena", "Akihiko Torii", "Tom\u00e1s Pajdla"], "b": "\n We present an efficient structure from motion algorithm that can deal with large image collections in a fraction of time and\n effort of previous approaches while providing comparable quality of the scene and camera reconstruction. First, we employ\n fast image indexing using large image vocabularies to measure visual overlap of images without running actual image matching.\n Then, we select a", "cn": 1, "i": 13995350, "k": ["Connected Dominating Set", "Fast Imaging", "Image Matching", "Indexation", "Omnidirectional Image", "Omnidirectional Vision", "Polynomial Algorithm", "Structure From Motion"], "p": ["http://www.springerlink.com/index/d2qm187544253w53.pdf", "http://www.springerlink.com/content/d2qm187544253w53", "http://dx.doi.org/10.1007/978-3-642-15552-9_8", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#HavlenaTP10"], "t": "Efficient Structure from Motion by Graph Optimization", "v": "ECCV", "y": 2010, "rn": 25}, {"a": ["K. Bhat", "Marie-Odile Berger", "Gilles Simon", "Fr\u00e9d\u00e9ric Sur"], "b": "We present Transitive Closure based visual word for- mation technique for obtaining robust object represen- tations from smoothly varying multiple views. Each one of our visual words is represented by a set of feature vectors which is obtained by performing transitive clo- sure operation on SIFT features. We also present range- reducing tree structure to speed up the transitive closure", "cn": 1, "i": 14083969, "k": ["Feature Vector", "Multiple Views", "Object Detection", "Pose Estimation", "Structure From Motion", "Transitive Closure", "Tree Structure"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05597153", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597153", "http://dx.doi.org/10.1109/ICPR.2010.807", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2010.html#BhatBSS10", "http://www.loria.fr/~sur/articles/bhat10transitive.pdf"], "t": "Transitive Closure Based Visual Words for Point Matching in Video Sequence", "v": "ICPR", "y": 2010, "rn": 6}, {"a": ["Kathleen Tuite", "Noah Snavely", "Dun-Yu Hsiao", "Adam Smith", "Zoran Popovi\u0107"], "b": "We are interested in reconstructing real world locations as detailed 3D models, but to achieve this goal, we require a large quantity of photographic data. We designed a game to employ the efforts and digital cameras of everyday people to not only collect this data, but to do so in a fun and effective way. The result is PhotoCity, a", "cn": 1, "i": 39229313, "k": ["3d model", "3d reconstruction", "Computer Vision", "Data Acquisition", "Digital Camera", "Game Playing", "games with a purpose", "Virtual Worlds"], "p": ["http://portal.acm.org/citation.cfm?id=1822379", "http://portal.acm.org/ft_gateway.cfm?id=1822379&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "Reconstructing the world in 3D: bringing games with a purpose outdoors", "y": 2010, "rn": 7}, {"a": ["Michael Kroepfl", "Yonathan Wexler", "Eyal Ofek"], "b": "We present a method for efficient and reliable geo-positioning of images. It relies on image-based matching of the query images onto a trellis of existing images that provides accurate 5-DOF calibration (camera position and orientation without scale). As such it can handle any image input, including old historical images, matched against a whole city. On such a scale, care needs", "cn": 1, "i": 39230006, "k": ["Augmented Reality", "Feature Matching", "Image Matching", "Large Scale"], "p": ["http://portal.acm.org/citation.cfm?id=1869810", "http://portal.acm.org/ft_gateway.cfm?id=1869810&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1869790.1869810", "http://www.informatik.uni-trier.de/~ley/db/conf/gis/gis2010.html#KroepflWO10", "http://research.microsoft.com/apps/pubs/default.aspx?id=149302", "http://research.microsoft.com/pubs/149302/Kroepfl_MatchingUserPhotos.pdf"], "t": "Efficiently locating photographs in many panoramas", "v": "GIS", "y": 2010, "rn": 33}, {"a": ["Florent Lafarge", "Renaud Keriven", "Mathieu Br\u00e9dif", "Vu Hiep"], "b": "We propose a multi-view stereo reconstruction algorithm which recovers urban scenes as a combination of meshes and geometric primitives. It provides a compact model while preserving details: irregular elements such as statues and ornaments are described by meshes whereas regular structures such as columns and walls are described by primitives (planes, spheres, cylinders, cones and tori). A Jump-Diffusion process is", "cn": 1, "i": 39261608, "k": ["Compact Model", "Iterative Refinement", "Jump Diffusion", "jump-diffusion process", "multi-view stereo", "Reconstruction Algorithm", "Urban Structure"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540193", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540193", "http://dx.doi.org/10.1109/CVPR.2010.5540193", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#LafargeKBH10"], "t": "Hybrid multi-view reconstruction by Jump-Diffusion", "v": "CVPR", "y": 2010, "rn": 41}, {"a": ["Guofeng Zhang", "Zilong Dong", "Jiaya Jia", "Tien-Tsin Wong", "Hujun Bao"], "b": "Structure-from-motion (SfM) is an important computer vi- sion problem and largely relies on the quality of feature tracking. In im- age sequences, if disjointed tracks caused by objects moving in and out of the view, occasional occlusion, or image noise, are not handled well, the corresponding SfM could be signican tly aected. In this paper, we address the non-consecutive feature", "cn": 1, "i": 39262415, "k": ["Feature Point Tracking", "Feature Tracking", "Large Scale", "Structure From Motion"], "p": ["http://www.springerlink.com/content/x88k7p977701615p", "http://www.springerlink.com/index/x88k7p977701615p.pdf", "http://www.cse.cuhk.edu.hk/~leojia/papers/sfm_eccv2010.pdf", "http://dx.doi.org/10.1007/978-3-642-15555-0_31", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-5.html#ZhangDJWB10"], "t": "Efficient Nonconsecutive Feature Tracking for Structure-from-Motion", "v": "ECCV", "y": 2010, "rn": 30}, {"a": ["Jan-Michael Frahm", "Marc Pollefeys", "Svetlana Lazebnik", "Brian Clipp", "David Gallup", "Rahul Raguram", "Changchang Wu"], "b": "This paper tackles the active research problem of fast automatic modeling of large-scale environments from videos and unorganized still image collections. We describe a scalable 3D reconstruction framework that leverages recent research in robust estimation, image-based recognition, and stereo depth estimation. High computational speed is achieved through parallelization and execution on commodity graphics hardware. For video, we have implemented a", "cn": 1, "i": 39282597, "k": ["3d reconstruction", "Computer Model", "Depth Estimation", "Graphics Hardware", "Large Scale", "Photo Collection", "Robust Estimator", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5464819", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05464819", "http://dx.doi.org/10.1109/CISS.2010.5464819", "http://www.informatik.uni-trier.de/~ley/db/conf/ciss/ciss2010.html#FrahmPLCGRW10"], "t": "Fast robust reconstruction of large-scale environments", "v": "CISS", "y": 2010, "rn": 33}, {"a": ["Fabio Remondino", "Alessandro Rizzi"], "b": "The importance of cultural and natural heritage documentation is well recognized at international level, and there is an increasing\n pressure to document and preserve heritage also digitally. The continuous development of new sensors, data capture methodologies,\n and multi-resolution 3D representations and the improvement of existing ones can contribute significantly to the 3D documentation,\n conservation, and digital presentation of heritages and", "cn": 1, "i": 40169505, "k": ["3d representation", "Cultural Heritage", "Data Capture", "Laser Scanning", "Modeling Technique", "Multi Resolution"], "p": ["http://www.springerlink.com/content/l7pm52003v078472", "http://www.springerlink.com/index/l7pm52003v078472.pdf", "http://www.springerlink.com/index/10.1007/s12518-010-0025-x", "http://www.springerlink.com/index/pdf/10.1007/s12518-010-0025-x"], "t": "Reality-based 3D documentation of natural and cultural heritage sites\u2014techniques, problems, and examples", "v": "", "y": 2010, "rn": 46}, {"a": ["Yekeun Jeong", "David Nister", "Drew Steedly", "Richard Szeliski", "In-So Kweon"], "b": "In this paper, we present results and experiments with several methods for bundle adjustment, producing the fastest bundle adjuster ever published in terms of computation and convergence. From a computational perspective, the fastest methods naturally handle the block-sparse pattern that arises in a reduced camera system. Adapting to the naturally arising block-sparsity allows the use of BLAS3, efficient memory handling,", "cn": 0, "i": 57019482, "k": ["Bundle Adjustment", "Computer Vision", "Linear System", "Memory Management", "Minimum Degree", "Preconditioned Conjugate Gradient", "Sparse Matrices", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6109275", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06109275", "http://research.microsoft.com/apps/pubs/default.aspx?id=169956", "http://research.microsoft.com/pubs/169956/Jeong-PAMI12.pdf"], "t": "Pushing the Envelope of Modern Methods for Bundle Adjustment", "v": "PAMI", "y": 2012, "rn": 18}, {"a": ["Jean-Charles Bazin", "C\u00e9dric Demonceaux", "Pascal Vasseur", "Inso Kweon"], "b": "Rotation estimation is a fundamental step for various robotic applications such as automatic control of ground/aerial vehicles, motion estimation and 3D reconstruction. However it is now well established that traditional navigation equipments, such as global positioning systems (GPSs) or inertial measurement units (IMUs), suffer from several disadvantages. Hence, some vision-based works have been proposed recently. Whereas interesting results can be", "cn": 0, "i": 57172316, "k": ["3d reconstruction", "Automatic Control", "Feature Matching", "Frequency Domain", "Global Position System", "Inertial Measurement Unit", "Motion Estimation", "Omnidirectional Image", "Omnidirectional Vision", "Urban Environment", "Vanishing Point", "Field of View", "Real Time", "Top Down"], "p": ["http://dx.doi.org/10.1177/0278364911421954"], "t": "Rotation estimation and vanishing point extraction by omnidirectional vision in urban environment", "v": "IJRR", "y": 2012, "rn": 58}, {"a": ["Wei Guan", "Suya You", "Ulrich Neumann"], "b": "We present a recognition-based user tracking and augmented reality system that works in extreme large scale areas. The system will provide a user who captures an image of a building facade with precise location of the building and augmented information about the building. While GPS cannot provide information about camera poses, it is needed to aid reducing the searching ranges", "cn": 0, "i": 39236328, "k": ["Augmented Reality", "Clustering Method", "Image Database", "Image Matching", "Large Scale", "Prior Information", "Soft Handoff", "System Simulation", "Tracking System", "Real Time"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1943554&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1943554", "http://dl.acm.org/citation.cfm?id=1943554"], "t": "GPS-aided recognition-based user tracking system with augmented reality in extreme large-scale areas", "y": 2011, "rn": 21}, {"a": ["Ying Chen", "Fernando Torre"], "b": "Matching images with large geometric and iconic changes (e.g. faces under different poses and facial expressions) is an open research problem in computer vision. There are two fundamental approaches to solve the correspondence problem in images: Feature-based matching and model-based matching. Feature-based matching relies on the assumption that features are stable across view-points and iconic changes, and it uses some", "cn": 0, "i": 39263856, "k": ["Active Shape Model", "Computer Vision", "Conditional Model", "Correspondence Problem", "Facial Expression", "Facial Features", "Image Features", "Image Matching", "Image Reconstruction", "Image Similarity", "Model Generation", "model-based approach", "Solid Modeling", "Higher Order"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05771387", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5771387", "http://dx.doi.org/10.1109/FG.2011.5771387", "http://www.informatik.uni-trier.de/~ley/db/conf/fgr/fg2011.html#ChenT11"], "t": "Active conditional models", "v": "FGR", "y": 2011, "rn": 27}, {"a": ["Carl Olsson", "Olof Enqvist"], "b": "\n We present a non-incremental approach to structure from motion. Our solution is based on robustly computing global rotations\n from relative geometries and feeding these into the known-rotation framework to create an initial solution for bundle adjustment.\n To increase robustness we present a new method for constructing reliable point tracks from pairwise matches. We show that\n our method can be seen", "cn": 0, "i": 39277596, "k": ["Bundle Adjustment", "Degeneration", "epipolar geometry", "Structure From Motion"], "p": ["http://www.springerlink.com/index/232488031222u776.pdf", "http://www.springerlink.com/content/232488031222u776", "http://dx.doi.org/10.1007/978-3-642-21227-7_49", "http://www.informatik.uni-trier.de/~ley/db/conf/scia/scia2011.html#OlssonE11a"], "t": "Stable Structure from Motion for Unordered Image Collections", "v": "", "y": 2011, "rn": 29}, {"a": ["Yan-Tao Zheng", "Zheng-Jun Zha", "Tat-Seng Chua"], "b": "In recent years, the emergence of georeferenced media, like geotagged photos, on the Internet has opened up a new world of\n possibilities for geographic related research and applications. Despite of its short history, georeferenced media has been\n attracting attentions from several major research communities of Computer Vision, Multimedia, Digital Libraries and KDD. This\n paper provides a comprehensive survey on recent", "cn": 0, "i": 39326590, "k": ["Computer Vision", "Digital Library", "New World"], "p": ["http://www.springerlink.com/index/v4un20747w066180.pdf", "http://www.springerlink.com/content/v4un20747w066180", "http://dx.doi.org/10.1007/s11042-010-0630-z", "http://www.informatik.uni-trier.de/~ley/db/journals/mta/mta51.html#ZhengZC11"], "t": "Research and applications on georeferenced multimedia: a survey", "v": "MTA", "y": 2011, "rn": 84}, {"a": ["Liangliang Cao", "Guojun Qi", "Shen-Fu Tsai", "Min-Hsuan Tsai", "Andrey Pozo", "Thomas Huang", "Xuemei Zhang", "Suk Lim"], "b": "\n The popularity of personal digital cameras and online photo/video sharing community has lead to an explosion of multimedia\n information. Unlike traditional multimedia data, many new multimedia datasets are organized in a structural way, incorporating\n rich information such as semantic ontology, social interaction, community media, geographical maps, in addition to the multimedia\n contents by themselves. Studies of such structured multimedia data", "cn": 0, "i": 47925415, "k": ["Digital Camera", "Information Network", "Multimedia Data", "Network Structure", "Social Interaction", "Social Media", "Social Network"], "p": ["http://www.springerlink.com/index/v07440308727n270.pdf", "http://www.springerlink.com/content/v07440308727n270", "http://adsabs.harvard.edu/abs/2011snda.book..413C"], "t": "Multimedia Information Networks in Social Media", "y": 2011, "rn": 108}, {"a": ["Wei Guan", "Suya You", "Ulrich Neumann"], "b": "We present a recognition-driven navigation system for large-scale 3D virtual environments. The proposed system contains three parts, virtual environment reconstruction, feature database building and recognition-based navigation. The virtual environment is reconstructed automatically with LIDAR data and aerial images. The feature database is composed of image patches with features and registered location and orientation information. The database images are taken at", "cn": 0, "i": 51041592, "k": ["3d navigation", "3d virtual environment", "Aerial Image", "Large Scale", "Navigation System", "Virtual Environment", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5759439", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05759439"], "t": "Recognition-driven 3D navigation in large-scale virtual environments", "v": "VR", "y": 2011, "rn": 16}, {"a": ["Enliang Zheng", "Rahul Raguram", "Pierre Fite-Georgel", "Jan-Michael Frahm"], "b": "In this paper, we present an efficient technique for generating multi-perspective panoramic images of long scenes. The input to our system is a video sequence captured by a moving camera navigating through a long scene, and our goal is to efficiently generate a panoramic summary of the scene. This problem has received considerable attention in recent years, leading to the", "cn": 0, "i": 51080325, "k": ["Adaptive Optics", "Computational Complexity", "Cost Function", "Image Alignment", "Image Sequence", "Optical Imaging", "Panoramic Image", "Optical Flow"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955347", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955347"], "t": "Efficient Generation of Multi-perspective Panoramas", "v": "3DIMPVT", "y": 2011, "rn": 16}, {"a": ["Marie-Odile Berger", "Fr\u00e9d\u00e9ric Sur"], "b": "Visual vocabularies are standard tools in the object/image classification literature, and are emerging as a new tool for building point correspondences for pose estimation. This paper proposes several visual word based methods for point matching, with structure from motion and pose estimation applications in view. The three dimensional geometry of a scene is first extracted with bundle adjustment techniques based", "cn": 0, "i": 51080356, "k": ["3d reconstruction", "Bundle Adjustment", "Feature Extraction", "Formation Techniques", "Image Classification", "Pose Estimation", "Solid Modeling", "Structure From Motion", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955378", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955378"], "t": "Visual Words for 3D Reconstruction and Pose Computation", "v": "3DIMPVT", "y": 2011, "rn": 18}, {"a": ["Domingo Mery"], "b": "We propose a new methodology to detect parts of interest inside of complex objects using multiple X-ray views. Our method consists of two steps: \u2018structure estimation\u2019, to obtain a geometric model of the multiple views from the object itself, and \u2018parts detection\u2019, to detect the object parts of interest. The geometric model is estimated by a bundle adjustment algorithm on", "cn": 0, "i": 51098511, "k": ["Bundle Adjustment", "Complex Objects", "Feature Extraction", "Geometric Model", "Image Segmentation", "Image Sequence", "Multiple Views", "Structural Estimation", "Three Dimensional", "X Rays", "X-ray Imaging", "False Positive Rate", "True Positive"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5981715", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05981715"], "t": "Automated detection in complex objects using a tracking algorithm in multiple X-ray views", "v": "CVPR", "y": 2011, "rn": 30}, {"a": ["Andreas Wendel", "Arnold Irschara", "Horst Bischof"], "b": "We present a novel technique for the automatic alignment of Structure from Motion (SfM) models, acquired at ground level or by micro aerial vehicles, to an overhead Digital Surface Model (DSM) using GPS information. An additional refinement step based on the correlation of the DSM height map with the model height map corrects for the GPS localization uncertainties and results", "cn": 0, "i": 51098513, "k": ["3d reconstruction", "Computer Model", "Context Model", "Digital Surface Model", "Global Position System", "Image Reconstruction", "Seasonality", "Solid Modeling", "Structure From Motion", "Three Dimensional", "Micro Aerial Vehicle"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5981717", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05981717"], "t": "Automatic alignment of 3D reconstructions using a Digital Surface Model", "v": "CVPR", "y": 2011, "rn": 19}, {"a": ["Pablo Alcantarilla", "Kai Ni", "Luis Bergasa", "Frank Dellaert"], "b": "Fig. 1. Given a large city-scale 3D reconstruction, we predict the visible 3D points for a query camera view by fusing both geometric and appearance information from multiple neighbor cameras. Best viewed in color. Abstract\u2014 A crucial step in many vision based ap- plications, such as localization and structure from motion, is the data association between a large map of", "cn": 0, "i": 51099932, "k": ["3d model", "3d reconstruction", "Data Association", "Distance Metric", "Large Scale", "Memory Based Learning", "Structure From Motion", "Three Dimensional", "Urban Environment"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5979650", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05979650"], "t": "Visibility learning in large-scale urban environment", "v": "ICRA", "y": 2011, "rn": 18}, {"a": ["Bin Fan", "Fuchao Wu", "Zhanyi Hu"], "b": "A novel local image descriptor is proposed in this paper, which combines intensity orders and gradient distributions in multiple support regions. The novelty lies in three aspects: 1) The gradient is calculated in a rotation invariant way in a given support region; 2) The rotation invariant gradients are adaptively pooled spatially based on intensity orders in order to encode spatial", "cn": 0, "i": 51107998, "k": ["Rotation Invariance", "Spatial Information"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995385", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995385"], "t": "Aggregating gradient distributions into intensity orders: A novel local image descriptor", "v": "CVPR", "y": 2011, "rn": 21}, {"a": ["Rahul Garg", "Steven Seitz", "Deva Ramanan", "Noah Snavely"], "b": "Given a community-contributed set of photos of a crowded public event, this paper addresses the problem of finding all images of each person in the scene. This problem is very challenging due to large changes in camera viewpoints, severe occlusions, low resolution and photos from tens or hundreds of different photographers. Despite these challenges, the problem is made tractable by", "cn": 0, "i": 51108155, "k": ["Photo Collection", "Low Resolution"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995546", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995546"], "t": "Where's Waldo: Matching people in images of crowds", "v": "CVPR", "y": 2011, "rn": 15}, {"a": ["A. Rodriguez", "P. Lopez-de-Teruel", "A. Ruiz"], "b": "We propose a reduced algebraic cost based on pairwise epipolar constraints for the iterative refinement of a multiple view 3D reconstruction. The aim is to accelerate the intermediate steps required when incrementally building a reconstruction from scratch. Though the proposed error is algebraic, careful input data normalization makes it a good approximation to the true geometric epipolar distance. Its minimization", "cn": 0, "i": 51108176, "k": ["3d reconstruction", "Image Database", "Iterative Refinement", "Multiple Views", "Nonlinear Optimization", "Real-time Tracking"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995569", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995569"], "t": "Reduced epipolar cost for accelerated incremental SfM", "v": "CVPR", "y": 2011, "rn": 24}, {"a": ["David Crandall", "Andrew Owens", "Noah Snavely", "Dan Huttenlocher"], "b": "Recent work in structure from motion (SfM) has successfully built 3D models from large unstructured collections of images downloaded from the Internet. Most approaches use incremental algorithms that solve progressively larger bundle adjustment problems. These incremental techniques scale poorly as the number of images grows, and can drift or fall into bad local minima. We present an alternative formulation for", "cn": 0, "i": 51108231, "k": ["3d model", "Bundle Adjustment", "Continuous Optimization", "Incremental Algorithm", "Large Scale", "Large Scale Structure", "Local Minima", "Photo Collection", "Structure From Motion", "Vanishing Point", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995626", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995626"], "t": "Discrete-continuous optimization for large-scale structure from motion", "v": "CVPR", "y": 2011, "rn": 25}, {"a": ["Chris Beall", "Frank Dellaert", "Ian Mahon", "Stefan Williams"], "b": "In this paper we present a technique to generate highly accurate reconstructions of underwater structures by employing bundle adjustment on visual features, rather than relying on a filtering approach using navigational sensor data alone. This system improves upon previous work where an extended information filter was used to estimate the vehicle trajectory. This filtering technique, while very efficient, suffers from", "cn": 0, "i": 51110261, "k": ["3d reconstruction", "Bundle Adjustment", "Image Reconstruction", "Information Filtering", "Large Scale", "Nonlinear Least Squares", "Smoothing Method", "Three Dimensional", "Visual Features"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6003631", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06003631"], "t": "Bundle adjustment in large-scale 3D reconstructions based on underwater robotic surveys", "v": "EUROPE", "y": 2011, "rn": 20}, {"a": ["Yuanfan Xie", "Lixin Fan", "Yihong Wu"], "b": "Bundle adjustment has been considered as one of the most important components in many visual tasks such as 3D reconstruction, photogrammetry, visual SLAM, etc. Unfortunately, both time and space complexity of this adjustment prevent it from being directly applied to large scale datasets. This paper presents a submapping method, which partitions a large scale dataset into disjointed subsets and adjusts", "cn": 0, "i": 51118068, "k": ["3d reconstruction", "Binary Tree", "Bundle Adjustment", "Complexity Theory", "Graph Partitioning", "Image Reconstruction", "Large Scale", "Similarity Transformation", "Space Complexity", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6005984", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06005984"], "t": "Graph Partition Based Bundle Adjustment for Structured Dataset", "v": "ICIG", "y": 2011, "rn": 17}, {"a": ["Wei Guan", "Suya You", "Ulrich Neumann"], "b": "We present a retrieval-based tracking system that requires less computational time and cost. The system tracks a user\u2019s location through a small portion of an image captured by the camera, and then refines the camera pose by propagating matchings to the whole image. Augmented information such as building names and locations will be delivered to the user. The progressive way", "cn": 0, "i": 51159418, "k": ["Augmented Reality", "Feature Matching", "Large Scale", "Tracking System", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5711533", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05711533"], "t": "Computationally efficient retrieval-based tracking system and augmented reality for large-scale areas", "v": "WACV", "y": 2011, "rn": 14}, {"a": ["Vishwakarma Singh", "Sharath Venkatesha", "Ambuj Singh"], "b": "Images with GPS coordinates are a rich source of information about a geographic location. Innovative user services and applications are being built using geotagged images taken from community contributed repositories like Flickr. Only a small subset of the images in these repositories is geotagged, limiting their exploration and effective utilization. We propose to use optional meta-data along with image content", "cn": 0, "i": 13980859, "k": ["Graph Clustering", "Missing Data", "Probabilistic Approach", "Random Walk"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05575952", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5575952", "http://dx.doi.org/10.1109/GrC.2010.76", "http://www.informatik.uni-trier.de/~ley/db/conf/grc/grc2010.html#SinghVS10"], "t": "Geo-clustering of Images with Missing GeoTags", "v": "GRC", "y": 2010, "rn": 20}, {"a": ["Jairo S\u00e1nchez", "Hugo \u00c1lvarez", "Diego Borro"], "b": "\n Traditionally triangulating 3D points from image features is a complex task that involves non-linear optimization techniques\n that are computationally very expensive. This work proposes an algorithm based on Monte Carlo simulations that fits well on\n the graphics hardware and can perform the triangulation in real time. Results are compared against the well known Levenberg-Mardquart\n using real video sequences, showing that", "cn": 0, "i": 13988433, "k": ["Graphics Hardware", "Image Features", "Monte Carlo Simulation", "Non-linear Optimization", "Real Time"], "p": ["http://www.springerlink.com/index/2024q55443263gq4.pdf", "http://www.springerlink.com/content/2024q55443263gq4", "http://www.informatik.uni-trier.de/~ley/db/conf/iccvg/iccvg2010-2.html#SanchezAB10", "http://dx.doi.org/10.1007/978-3-642-15907-7_29"], "t": "GFT: GPU Fast Triangulation of 3D Points", "y": 2010, "rn": 12}, {"a": ["Tian Fang", "Long Quan"], "b": "\n This paper proposes a hierarchical framework that resamples 3D reconstructed points to reduce computation cost on time and\n memory for very large-scale Structure from Motion. The goal is to maintain accuracy and stability similar for different resample\n rates. We consider this problem in a level-of-detail perspective, from a very large scale global and sparse bundle adjustment\n to a very detailed", "cn": 0, "i": 13995361, "k": ["3d reconstruction", "Bundle Adjustment", "Large Scale", "Large Scale Structure", "Structure From Motion", "Level of Detail"], "p": ["http://www.springerlink.com/content/f908g03567021m47", "http://www.springerlink.com/index/f908g03567021m47.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#FangQ10", "http://dx.doi.org/10.1007/978-3-642-15552-9_1"], "t": "Resampling Structure from Motion", "v": "ECCV", "y": 2010, "rn": 22}, {"a": ["Ryo Nakamura", "Fumihiko Sakaue", "Jun Sato"], "b": "\n In this paper, we propose a method for emphasizing 3D structure of the scene visually by blending patterned lights projected\n from multiple projectors. The proposed method enables us to emphasize specific 3D structure of the scene without capturing\n image of the scene and without estimating 3D structure of the scene. As a result, the 3D structure can be emphasized visually", "cn": 0, "i": 39256517, "k": ["3d structure"], "p": ["http://www.springerlink.com/content/k1h1251577236122", "http://www.springerlink.com/index/k1h1251577236122.pdf", "http://dx.doi.org/10.1007/978-3-642-19309-5_9", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2010-2.html#NakamuraSS10"], "t": "Emphasizing 3D Structure Visually Using Coded Projection from Multiple Projectors", "v": "ACCV", "y": 2010, "rn": 9}, {"a": ["Jiong Xu", "Qing Wang", "Jie Yang"], "b": "\n This paper presents a technique to simultaneously model 3D urban scenes in the spatial-temporal space using a collection of\n photos that span many years. We propose to use a middle level representation, building, to characterize significant structure changes in the scene. We first use structure-from-motion techniques to build 3D point\n clouds, which is a mixture of scenes from different periods", "cn": 0, "i": 39256540, "k": ["3d model", "3d point cloud", "Point Cloud", "Probabilistic Model", "Space Use", "Structural Change", "Structure From Motion"], "p": ["http://www.springerlink.com/index/u7811076hn17k223.pdf", "http://www.springerlink.com/content/u7811076hn17k223", "http://dx.doi.org/10.1007/978-3-642-19309-5_29", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2010-2.html#XuWY10"], "t": "Modeling Urban Scenes in the Spatial-Temporal Space", "v": "ACCV", "y": 2010, "rn": 15}, {"a": ["Yubin Kuang", "Kalle \u00c5str\u00f6m", "Lars Kopp", "Magnus Oskarsson", "Martin Byr\u00f6d"], "b": "\n The state of the art for large database object retrieval in images is based on quantizing descriptors of interest points into\n visual words. High similarity between matching image representations (as bags of words) is based upon the assumption that\n matched points in the two images end up in similar words in hard assignment or in similar representations in soft assignment", "cn": 0, "i": 39256606, "k": ["Deformable Model", "Image Representation", "Interest Points", "Bag of Words", "Ground Truth", "K Means", "True Positive"], "p": ["http://www.springerlink.com/index/k003xh221513x2g3.pdf", "http://www.springerlink.com/content/k003xh221513x2g3", "http://dx.doi.org/10.1007/978-3-642-19282-1_21", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2010-4.html#KuangAKOB10"], "t": "Optimizing Visual Vocabularies Using Soft Assignment Entropies", "v": "ACCV", "y": 2010, "rn": 26}, {"a": ["Hongdong Li"], "b": "Most existing structure-from-motion methods follow a common two-step scheme, where relative camera motions are estimated in the first step and 3D structure is computed afterward in the second step. This paper presents a novel scheme which bypasses the motion-estimation step, and goes directly to structure computation step. By introducing graph rigidity theory to Sfm problems, we demonstrate that such a", "cn": 0, "i": 39261340, "k": ["3d structure", "Camera Motion", "Convex Relaxation", "Large Scale", "Motion Estimation", "Structure From Motion", "Semi Definite Program"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540005", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540005", "http://dx.doi.org/10.1109/CVPR.2010.5540005", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#Li10"], "t": "Multi-view structure computation without explicitly estimating motion", "v": "CVPR", "y": 2010, "rn": 31}, {"a": ["Shengqi Zhu", "Li Zhang", "Brandon Smith"], "b": "In this paper, we present a new framework for non-rigid structure from motion (NRSFM) that simultaneously addresses three significant challenges: severe occlusion, perspective camera projection, and large non-linear deformation. We introduce a concept called a model graph, which greatly reduces the computational cost of discovering groups of input images that depict consistent 3D shapes. A 3D model is constructed for", "cn": 0, "i": 39261394, "k": ["3d model", "Image Reconstruction", "Shape Representation", "Structure From Motion", "Synthetic Data"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540085", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540085", "http://dx.doi.org/10.1109/CVPR.2010.5540085", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#ZhuZS10"], "t": "Model evolution: An incremental approach to non-rigid structure from motion", "v": "CVPR", "y": 2010, "rn": 11}, {"a": ["Ricardo Fabbri", "Benjamin Kimia"], "b": "Interest point-based multiview 3D reconstruction and calibration methods have been very successful in select applications but are not applicable when an abundance of feature points are not available. They also lead to an unorganized point cloud reconstruction where the geometry of the scene is not explicit. The multiview stereo methods on the other hand yield dense surface geometry but require", "cn": 0, "i": 39261501, "k": ["3d reconstruction", "Interest Points", "Point Cloud", "Surface Geometry"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539787", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539787", "http://dx.doi.org/10.1109/CVPR.2010.5539787", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#FabbriK10"], "t": "3D curve sketch: Flexible curve-based stereo reconstruction and calibration", "v": "CVPR", "y": 2010, "rn": 25}, {"a": ["Ameesh Makadia"], "b": "\n We address the problem of large scale image retrieval in a wide-baseline setting, where for any query image all the matching\n database images will come from very different viewpoints. In such settings traditional bag-of-visual-words approaches are\n not equipped to handle the significant feature descriptor transformations that occur under large camera motions. In this paper\n we present a novel approach that", "cn": 0, "i": 39262420, "k": ["Camera Motion", "Feature Matching", "Feature Space", "Feature Tracking", "Image Retrieval", "Large Scale", "Bag of Visual Words"], "p": ["http://www.springerlink.com/content/u6837830k76447qp", "http://www.springerlink.com/index/u6837830k76447qp.pdf", "http://dx.doi.org/10.1007/978-3-642-15555-0_23", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-5.html#Makadia10"], "t": "Feature Tracking for Wide-Baseline Image Retrieval", "v": "ECCV", "y": 2010, "rn": 26}, {"a": ["Rodrigo Polastro", "Fabiano Corr\u00eaa", "Fabio Cozman", "Jun Jr"], "b": "\n Semantic mapping employs explicit labels to deal with sensor data in robotic mapping processes. In this paper we present a\n method for boosting performance of spatial mapping, through the use of a probabilistic ontology, expressed with a probabilistic\n description logic. Reasoning with this ontology allows segmentation and tagging of sensor data acquired by a robot during\n navigation; hence a robot", "cn": 0, "i": 39277519, "k": ["Description Logic", "Semantic Mapping", "Spatial Mapping"], "p": ["http://www.springerlink.com/index/4421118x66212875.pdf", "http://www.springerlink.com/content/4421118x66212875", "http://dx.doi.org/10.1007/978-3-642-16138-4_7", "http://www.informatik.uni-trier.de/~ley/db/conf/sbia/sbia2010.html#PolastroCCO10"], "t": "Semantic Mapping with a Probabilistic Description Logic", "v": "SBIA", "y": 2010, "rn": 21}, {"a": ["Anna Manferdini", "Fabio Remondino"], "b": "\n One of the most significant consequences of the introduction of digital 3D modeling in the Cultural Heritage field is the\n possibility to use 3D models as highly effective and intuitive means of communication as well as interface to share and visualize\n information collected in databases. Due to the usual complexity of architectural and archaeological artifacts or sites, their\n digital models", "cn": 0, "i": 39292915, "k": ["3d model", "Cultural Heritage", "Data Access", "Data Retrieval", "Laser Scanning", "Open Source", "web-based system"], "p": ["http://www.springerlink.com/content/1552546vm0319690", "http://www.springerlink.com/index/1552546vm0319690.pdf", "http://dx.doi.org/10.1007/978-3-642-16873-4_9", "http://www.informatik.uni-trier.de/~ley/db/conf/euromed/euromed2010.html#ManferdiniR10"], "t": "Reality-Based 3D Modeling, Segmentation and Web-Based Visualization", "y": 2010, "rn": 26}, {"a": ["Luigi Barazzetti"], "b": "\n It is normal for tourists to take photos during their holidays, which are then printed, loaded into digital frames or shared\n on the Internet. This paper describes a new methodology to obtain accurate 3D digital models and material replicas of real\n objects, starting from digital images acquired with consumer and professional cameras. The implemented software is completely\n automatic and provides", "cn": 0, "i": 39297783, "k": ["3d model", "Digital Image", "Level of Detail"], "p": ["http://www.springerlink.com/index/yx3567045702x60j.pdf", "http://www.springerlink.com/content/yx3567045702x60j", "http://adsabs.harvard.edu/abs/2011LNCS.6529...63B", "http://dx.doi.org/10.1007/978-3-642-18348-5_7", "http://www.informatik.uni-trier.de/~ley/db/conf/hcitoch/hcitoch2010.html#Barazzetti10"], "t": "A Trip to Rome: Physical Replicas of Historical Objects Created in a Fully Automated Way from Photos", "y": 2010, "rn": 16}, {"a": ["R. Gherardi", "R. Toldo", "M. Farenzena", "A. Fusiello"], "b": "In this paper we describe SAMANTHA, a Structure and Motion pipeline from images which is both more robust and computationally cheaper than current competing approaches. Pictures are organized into a hierarchical tree which has single images as leaves and partial reconstructions as internal nodes. The method proceeds bottom up until it reaches the root node, corresponding to the final result.", "cn": 0, "i": 48871443, "k": ["image-based modeling", "Laser Scanning", "Point Cloud", "Structure and Motion", "Bottom Up", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693107", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05693107"], "t": "Samantha: Towards Automatic Image-Based Model Acquisition", "v": "CVMP", "y": 2010, "rn": 33}, {"a": ["Xuejin Chen", "Y. Morvan", "Yu He", "J. Dorsey", "H. Rushmeier"], "b": "We introduce a tool for organizing images and drawings of archaeological sites. The tool is based on a 3D sketching system developed for conceptual architectural design. The sketching system for design allows a user to represent structures as strokes located on 2D canvases situated in 3D space. The design of a consistent 3D structure evolves as the user is allowed", "cn": 0, "i": 50919735, "k": ["3d environment", "3d structure", "Architectural Design", "Computer Vision", "System Development", "User Interaction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05543514", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5543514"], "t": "An integrated image and sketching environment for archaeological sites", "v": "CVPR", "y": 2010, "rn": 14}, {"a": ["J. Sa\u0301nchez", "H. A\u0301lvarez", "D. Borro"], "b": "This paper addresses the problem of camera tracking and 3D reconstruction from image sequences, i.e., the monocular SLAM problem. Traditionally, this problem is solved using non-linear minimization techniques that are very accurate but hardly used in real time. This work presents a highly parallelizable random sampling approach based on Monte Carlo simulations that fits very well on the graphics hardware.", "cn": 0, "i": 50986297, "k": ["3d reconstruction", "Bundle Adjustment", "Graphics Hardware", "Image Sequence", "Monte Carlo Simulation", "Non-linear Optimization", "Random Sampling", "Synthetic Data", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5643568", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05643568"], "t": "Towards real time 3D tracking and reconstruction on a GPU using Monte Carlo simulations", "v": "ISMAR", "y": 2010, "rn": 18}, {"a": ["Isaac Esteban", "Judith Dijk", "Frans Groen"], "b": "In this paper we present a fully automatic system for building 3D models of urban areas at the street level. We propose a novel approach for the accurate estimation of the scale consistent camera pose given two previous images. We employ a new method for global optimization and use a novel sampling technique for primitive fitting to obtain an efficient", "cn": 0, "i": 50994080, "k": ["3d model", "3d representation", "Global Optimization", "Sampling Technique", "Urban Area"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05676602", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5676602"], "t": "Automatic 3D modeling of the urban landscape", "v": "ICUMT", "y": 2010, "rn": 16}, {"a": ["Ting-Wang Chen", "Qing Wang"], "b": "This paper presents a fast and reliable approach for detecting 3D line segment from 3D point clouds. The main idea is to discover weak matching of line segments by re-projecting 3D point to 2D image plane and infer 3D line segment by spatial constraints. On the basis of 2D Line Segment Detector (LSD) and multi-view stereo, the proposed algorithm firstly", "cn": 0, "i": 51001401, "k": ["3d point cloud", "Clustering Method", "Detection Algorithm", "High Efficiency", "Large Scale", "Line Detection", "multi-view stereo", "Point Cloud"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5685113", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05685113"], "t": "3D line segment detection algorithm for large-scale scenes", "v": "ICALIP", "y": 2010, "rn": 8}, {"a": ["Noah Snavely", "Ian Simon", "Michael Goesele", "Richard Szeliski", "Steven Seitz"], "b": "There are billions of photographs on the Internet, representing an extremely large, rich, and nearly comprehensive visual record of virtually every famous place on Earth. Unfortu- nately, these massive community photo collections are almost completely unstructured, making it very difficult to use them for applicationssuchasthevirtualexplorationofourworld.Overthe past several years, advances in computer vision have made it possible to automatically reconstruct 3-D", "cn": 0, "i": 61402281, "k": ["Computer Vision", "Data Capture", "Photo Collection", "Scene Reconstruction", "Spatial Distribution", "Structure From Motion"], "p": [], "t": "Scene Reconstruction and Visualization From Community Photo Collections Recent progress is described in digitizing and visualizing the world from data captured by people taking photos and uploading them to the web", "y": 2010, "rn": 66}, {"a": ["James Philbin", "Josef Sivic", "Andrew Zisserman"], "b": "Given a large-scale collection of images our aim is to efficiently associate images which contain the same entity, for example\n a building or object, and to discover the significant entities. To achieve this, we introduce the Geometric Latent Dirichlet Allocation (gLDA) model for unsupervised discovery of particular objects in unordered image collections. This explicitly represents images\n as mixtures of particular", "cn": 0, "i": 15271299, "k": ["Generic Model", "Graph Connectivity", "Graph Representation", "large dataset", "Large Scale", "Latent Dirichlet Allocation", "Ground Truth"], "p": ["http://www.springerlink.com/content/fn64704131716746", "http://www.springerlink.com/index/fn64704131716746.pdf", "http://www.springerlink.com/index/10.1007/s11263-010-0363-5", "http://www.springerlink.com/index/pdf/10.1007/s11263-010-0363-5"], "t": "Geometric Latent Dirichlet Allocation on a Matching Graph for\u00a0Large-scale Image Datasets", "v": "IJCV", "y": 0, "rn": 48}, {"a": ["J\u00e9r\u00f4me Courchay", "Arnak Dalalyan", "Renaud Keriven", "Peter Sturm"], "b": "A technique for calibrating a network of perspective cameras based on their graph of trifocal tensors is presented. After\n estimating a set of reliable epipolar geometries, a parameterization of the graph of trifocal tensors is proposed in which\n each trifocal tensor is linearly encoded by a 4-vector. The strength of this parameterization is that the homographies relating\n two adjacent trifocal", "cn": 0, "i": 48455104, "k": ["Camera Calibration", "epipolar geometry", "Linear Approximation", "Structure From Motion", "Alternating Minimization", "Linear Program", "Sequential Linear Programming"], "p": ["http://www.springerlink.com/content/910052j1601u565h", "http://www.springerlink.com/index/910052j1601u565h.pdf"], "t": "On Camera Calibration with Linear Programming and Loop Constraint Linearization", "v": "IJCV", "y": 0, "rn": 38}, {"a": ["Thomas Pock", "Lukas Zebedin", "Horst Bischof"], "b": "\n Location awareness on the Internet and 3D models of our habitat (as produced by Microsoft (Bing) or Google (Google Earth))\n are a major driving force for creating 3D models from image data. A key factor for these models are highly accurate and fully\n automated stereo matching pipelines producing highly accurate 3D point clouds that are possible due to the fact", "cn": 0, "i": 48605263, "k": ["3d model", "3d point cloud", "Driving Force", "Google Earth", "Location Awareness", "Numerical Algorithm", "Range Image", "Stereo Matching", "Synthetic Data", "Variational Method", "Piece Wise Affine", "Second Order"], "p": ["http://www.springerlink.com/index/m458q3545677044g.pdf", "http://www.springerlink.com/content/m458q3545677044g"], "t": "TGV-Fusion", "y": 0, "rn": 12}, {"a": ["Marc Pollefeys", "Jan-Michael Frahm", "Friedrich Fraundorfer", "Christopher Zach", "Changchang Wu", "Brian Clipp", "David Gallup"], "b": "\n The topic of this paper is large-scale mapping and localization from images. We first describe recent progress in obtaining\n large-scale 3D visual maps from images only. Our approach consists of a multi-stage processing pipeline, which can process\n a recorded video stream in real-time on standard PC hardware by leveraging the computational power of the graphics processor.\n The output of this", "cn": 0, "i": 48696941, "k": ["3d model", "3d visualization", "Camera Calibration", "Graphics Processors", "Inertial Sensor", "Large Scale", "Local Computation", "Video Streaming", "Real Time"], "p": ["http://www.springerlink.com/index/t301675884714540.pdf", "http://www.springerlink.com/content/t301675884714540"], "t": "Towards Large-Scale Visual Mapping and Localization", "y": 0, "rn": 56}, {"a": ["David Lowe"], "b": "This paper presents a method for extracting distinctive invariant features from images, which can be used to perform reliable matching between different im- ages of an object or scene. The features are invariant to image scale and ro- tation, and are shown to provide robust matching across a a substantial range of affine distortion, addition of noise, change in 3D", "cn": 7806, "i": 1942580, "k": ["Image Features", "Image Matching", "Invariant Feature", "Least Squares Solution", "Object Recognition", "Scale Invariance", "Hough Transform", "Nearest Neighbor", "Near Real Time"], "p": ["http://robots.stanford.edu/cs223b04/SIFT02_RecentSummary_ijcv03.pdf", "http://www.springerlink.com/content/h4l02691327px768", "http://www.springerlink.com/index/h4l02691327px768.pdf", "http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv60.html#Lowe04", "http://www.photonscope.com/technicalreference/disc2/distinctive.pdf.pdf", "http://robots.stanford.edu/cs223b04/SIFT_ijcv03.pdf", "http://www.ai.mit.edu/courses/6.891/handouts/Lowe04ijcv.pdf", "http://pages.cs.wisc.edu/~lizhang/courses/cs766-2009f/syllabus/10-02-feature/lowe_ijcv04.pdf", "http://166.111.138.19/sigmm/sigmmWeb/Feature%20point/Distinctive%20image%20features%20from%20scale-invariant%20keypoints.pdf", "http://www.cise.ufl.edu/class/cis6930fa07atc/Papers/Lowe04.pdf", "http://www.cs.sfu.ca/CC/821/li/material/source/Lowe-SIFT.pdf", "http://leibniz.iimas.unam.mx/~yann/Vision/Lowe04.pdf", "http://pages.cs.wisc.edu/~lizhang/courses/cs766-2007f/syllabus/09-27-feature/lowe_ijcv04.pdf", "http://glorfindel.mavrinac.com/~aaron/school/pdf/lowe04_sift.pdf", "http://www.mmp.rwth-aachen.de/teaching/cvws08/additional/ijcv04.pdf", "http://www.eecs.umich.edu/~silvio/teaching/EECS598/papers/lowe.pdf", "http://cs.gmu.edu/~zduric/cs774/Papers/Lowe-Features-IJCV.pdf", "http://www.caip.rutgers.edu/~meer/TEACHTOO/PAPERS/lowe04.pdf", "http://www.cnbc.cmu.edu/cns/papers/lowe.pdf", "http://www-dsp.elet.polimi.it/VA-TLC/Elaborati/Stitching%20di%20immagini%20(panorama)/lowe_ijcv2004-Distinctive%20image%20features%20from%20scale%20invariant%20keypoints.pdf", "http://www.cs.sfu.ca/~mori/courses/cmpt882/fall07/papers/lowe_ijcv04.pdf", "http://courses.csail.mit.edu/6.891-trevor/handouts/Lowe04ijcv.pdf", "http://www-dsp.elet.polimi.it/VA-TLC/Articoli/lowe_ijcv2004-Distinctive%20image%20features%20from%20scale%20invariant%20keypoints.pdf", "http://www.cs.colby.edu/maxwell/courses/cs397-vision/F07/papers/lowe-SIFT-ijcv04.pdf", "http://www.cs.huji.ac.il/course/2005/impr/articles/ijcv04.pdf", "http://www.cs.sfu.ca/fas-info/cs/CC/414/li/material/refs/Lowe-SIFT.pdf", "http://www.cse.psu.edu/~rcollins/CSE597E/papers/loweijcv04.pdf", "http://www.eecs.berkeley.edu/Research/Projects/CS/vision/classes/cs294_people_places_things/2004sp/cs294/lowe-ijcv04.pdf", "http://www-users.itlabs.umn.edu/classes/Spring-2008/csci5561/assigns/ijcv04.pdf", "http://wcours.gel.ulaval.ca/2008/a/19263/default/7references/Lowe_sift_ijcv04.pdf", "http://www.ai.rug.nl/vakinformatie/cogrobot/content/SIFT.pdf", "http://www.csee.wvu.edu/%7Exinl/library/papers/infor/imaging/SIFT.pdf", "https://eprints.kfupm.edu.sa/35405/1/35405.pdf", "http://reference.kfupm.edu.sa/content/d/i/distinctive_image_features_from_scale_in_39825.pdf", "http://www.seas.upenn.edu/~cis580/lectures/lowe04ijcv.pdf", "http://www.ece.uvic.ca/~aalbu/computer%20vision%202010/sift-ijcv%202004.pdf", "http://www.cs.sfu.ca/~mori/courses/cmpt882/summer09/papers/lowe_ijcv04.pdf", "http://users.rsise.anu.edu.au/~roland/Courses/ENGN8530_CVIU/lowe_IJCV04_SIFT.pdf", "http://cvcl.mit.edu/SUNSeminar/Lowe_SIFT_IJCV04.pdf", "http://vis.uky.edu/~dnister/Teaching/CS684Fall2005/Lowe_ijcv04.pdf", "http://pages.cs.wisc.edu/~dyer/ai-qual/lowe-ijcv04.pdf", "http://www.csee.wvu.edu/%7Exinl/courses/ee569/lowe_SIFT.pdf", "http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Lowe04.pdf", "http://www1.idc.ac.il/Toky/ComputerVision-06/papers/Lowe2004.pdf", "http://www1.idc.ac.il/toky/CompPhoto-09/Handouts/SIFT.pdf", "http://www.cs.ualberta.ca/~nray1/CMPUT615/SVM/SIFT.pdf", "http://web.cs.swarthmore.edu/~turnbull/cs97/f08/paper/lowe04.pdf", "http://web.media.mit.edu/~maov/classes/vision08/handouts/Lowe04ijcv.pdf", "http://cs.gmu.edu/~kosecka/cs803/sift-ijcv04.pdf", "http://www.cs.berkeley.edu/~malik/cs294/lowe-ijcv04.pdf", "http://people.cs.ubc.ca/%7elowe/papers/ijcv04.pdf", "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=E139E65760E425ECC2D1FE2D3EED103F?doi=10.1.1.2.8899&rep=rep1&type=pdf", "http://www.cs.jhu.edu/~hager/teaching/cs461/LoweIJCV.pdf", "http://www6.in.tum.de/~panin/seminar07/lowe04distinctive.pdf", "http://www.uni-tuebingen.de/cog/teaching/ws2006_07/ham/vorl_theo/theo_sem/Lowe_CompVis04.pdf", "http://www.tecgraf.puc-rio.br/~mgattass/ra/ref/Features/lowe_SIFT_ijcv04.pdf", "http://www.eecs.umich.edu/~ebolson/courses/W09_598/readings/lowe2004ijcv.pdf", "http://www.cs.jhu.edu/~hager/Public/teaching/cs461/LoweIJCV.pdf", "http://www.cfar.umd.edu/%7Efer/cmsc828/classes/ijcv04-lowe.pdf", "http://www.cs.ubc.ca/~woodham/cpsc425/ijcv04.pdf", "http://mesh.brown.edu/engn1610/pdfs/lowe-ijcv2004.pdf", "http://www.cvmt.dk/%7Ehja/teaching/cv/LoweSIFT2004.pdf", "http://web.cs.swarthmore.edu/~turnbull/cs97/f09/paper/lowe04.pdf", "http://www.vis.uky.edu/~dnister/Teaching/CS684Fall2005/Lowe_ijcv04.pdf", "http://www.wisdom.weizmann.ac.il/~deniss/vision_spring04/papers/distinctiveImageFeatures_ijcv04.pdf", "http://fias.uni-frankfurt.de/~triesch/courses/260object/papers/Lowe_IJCV04.pdf", "http://www.stat.ucla.edu/~ywu/research/literature/SIFT_Lowe_ijcv.pdf", "http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/ijcv04.pdf", "http://courses.csail.mit.edu/6.869/handouts/Lowe04ijcv.pdf", "http://pages.cs.wisc.edu/~cs766-1/syllabus/10-02-feature/lowe_ijcv04.pdf", "http://www.cs.sfu.ca/CC/414/li/material/refs/Lowe-SIFT.pdf", "http://www.cs.ait.ac.th/~mdailey/cvreadings/Lowe-SIFT.pdf", "http://pages.cs.wisc.edu/~lizhang/courses/cs766-2008f/syllabus/10-02-feature/lowe_ijcv04.pdf", "http://www.tu-chemnitz.de/etit/proaut/paperdb/download/lowe04.pdf", "http://people.cs.ubc.ca/~woodham/cpsc425/ijcv04.pdf", "http://www.cse.unr.edu/~bebis/CS773C/ObjectRecognition/Papers/Lowe04.pdf", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000029664.99615.94"], "t": "Distinctive Image Features from Scale-Invariant Keypoints", "v": "IJCV", "y": 2004, "rn": 56}, {"a": ["GEORGE KARYPIS", "VIPIN KUMAR"], "b": "Recently, a number of researchers have investigated a class of graph partitioning algorithms that reduce the size of the graph by collapsing vertices and edges, partition the smaller graph, and then uncoarsen it to construct a partition for the original graph (Bui and Jones, Proc. of the 6th SIAM Conference on Parallel Processing for Scientific Computing, 1993, 445-452; Hen- drickson", "cn": 1062, "i": 1318048, "k": ["Finite Element", "Finite Element Method", "Graph Partitioning", "Minimum Degree", "Multilevel Algorithm", "Parallel Computer", "Parallel Processing", "Scientific Computing", "Sparse Matrices", "linear pro gramming", "Sparse Matrix", "Linear Program"], "p": ["http://masters.donntu.edu.ua/2006/fvti/shepel/library/mlevel_serial.pdf", "http://link.aip.org/link/SJOCE3/v20/i1/p359/s1&Agg=doi", "http://www.stanford.edu/class/cs238/handouts/mlevel_serial.pdf", "http://www.masters.donntu.edu.ua/2006/fvti/shepel/library/mlevel_serial.pdf", "http://glaros.dtc.umn.edu/gkhome/fetch/papers/mlevel_serial.pdf"], "t": "A fast and high quality multilevel scheme for partitioning irregulargraphs", "v": "", "y": 1999, "rn": 47}, {"a": ["Bill Triggs", "Philip Mclauchlan", "Richard Hartley", "Andrew Fitzgibbon"], "b": "", "cn": 763, "i": 607785, "k": ["Bundle Adjustment", "Computer Vision", "Cost Function", "Newton Method", "Nonlinear Least Squares", "Numerical Optimization", "Parameter Estimation", "Quality Control", "Scene Reconstruction", "Sparse Matrices", "Theory and Method"], "p": ["http://www.springerlink.com/content/plvcrq5bx753a2tn", "http://www.springerlink.com/index/plvcrq5bx753a2tn.pdf", "http://link.springer.de/link/service/series/0558/bibs/1883/18830298.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iccvw/iccvw1999.html#TriggsMHF99"], "t": "Bundle Adjustment - A Modern Synthesis", "v": "", "y": 1999, "rn": 84}, {"a": ["David Nist\u00e9r", "Henrik Stew\u00e9nius"], "b": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstrationthat recognizesCD-covers from a database of 40000 images of popular music CD's. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors", "cn": 570, "i": 2167392, "k": ["Indexation", "Ground Truth"], "p": ["http://www.vis.uky.edu/~dnister/Publications/2006/VocTree/nister_stewenius_cvpr2006.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1641018", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01641018", "http://www.cs.utexas.edu/~grauman/courses/spring2007/395T/papers/nister_cvpr2006.pdf", "http://www-inst.eecs.berkeley.edu/~cs294-6/fa06/papers/nister_stewenius_cvpr2006.pdf", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.264", "http://userweb.cs.utexas.edu/~grauman/courses/spring2007/395T/papers/nister_cvpr2006.pdf", "http://morse.cs.byu.edu/750/papers/nister_stewenius_cvpr2006.pdf", "http://inst.eecs.berkeley.edu/~cs294-6/fa06/papers/nister_stewenius_cvpr2006.pdf", "http://www.vis.uky.edu/%7estewe/publications/nister_stewenius_cvpr2006.pdf", "http://www.inf.fu-berlin.de/lehre/WS06/Musterererkennung/Paper/nister2006.pdf", "http://web.cs.swarthmore.edu/~turnbull/cs97/f08/paper/nister06.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-2.html#NisterS06", "http://www.eecs.berkeley.edu/~yang/courses/cs294-6/papers/nister_stewenius_cvpr2006.pdf", "http://www.cise.ufl.edu/class/cis6930fa07atc/Papers/Nister2006.pdf", "http://reference.kfupm.edu.sa/content/s/c/scalable_recognition_with_a_vocabulary_t_3570720.pdf"], "t": "Scalable Recognition with a Vocabulary Tree", "v": "CVPR", "y": 2006, "rn": 16}, {"a": ["Noah Snavely", "Steven Seitz", "Richard Szeliski"], "b": "is that these approaches will one day allow virtual tourism of the world's interesting and important sites. We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photo-graph as well as a", "cn": 376, "i": 2175137, "k": ["3d interface", "3d model", "3d navigation", "Auxiliary Information", "Image Based Rendering", "image-based modeling", "Information Interfaces and Presentation", "Multimedia Information System", "Photo Collection", "Photo Sharing", "Scene Understanding", "Structure From Motion", "arti cial intelligence", "Front End"], "p": ["http://doi.acm.org/10.1145/1141911.1141964", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog25.html#SnavelySS06"], "t": "Photo tourism: exploring photo collections in 3D", "v": "TOG", "y": 2006, "rn": 38}, {"a": ["D. Nister", "H. Stewenius"], "b": "Abstract A recognition scheme,that scales efficiently to a large number,of objects is presented. The efficiency and quality is exhibited in a live demonstrationthat recognizesCD-covers from a database of 40000 images of popular music CD\u2019s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background,clutter and occlusion. The local region descriptors are hierarchically", "cn": 328, "i": 4115842, "k": ["Indexation", "Ground Truth"], "p": [], "t": "Scalable recognition with a vo - cabulary tree", "v": "CVPR", "y": 2006, "rn": 13}, {"a": ["Grant Schindler", "Matthew Brown", "Richard Szeliski"], "b": "We look at the problem of location recognition in a large image dataset using a vocabulary tree. This entails finding the location of a query image in a large dataset containing 3 \u00d7 105 streetside images of a city. We investigate how the traditional invariant feature matching approach falls down as the size of the database grows. In particular we", "cn": 106, "i": 4112268, "k": ["Invariant Feature", "large dataset", "Search Algorithm"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#SchindlerBS07", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270175", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270175", "http://research.microsoft.com/pubs/75607/Schindler-CVPR07.pdf", "http://www.cc.gatech.edu/~phlosoft/files/schindler07cvpr2.pdf", "http://people.cs.ubc.ca/~mbrown/papers/cvpr2007c.pdf", "http://dx.doi.org/10.1109/CVPR.2007.383150"], "t": "City-Scale Location Recognition", "v": "CVPR", "y": 2007, "rn": 15}, {"a": ["Ondrej Chum", "James Philbin", "Josef Sivic", "Michael Isard", "Andrew Zisserman"], "b": "Given a query image of an object, our objective is to re- trieve all instances of that object in a large (1M+) image database. We adopt the bag-of-visual-words architecture which has proven successful in achieving high precision at low recall. Unfortunately, feature detection and quantiza- tion are noisy processes and this can result in variation in the particular visual words", "cn": 105, "i": 4116856, "k": ["Automatic Query Expansion", "False Positive", "Feature Detection", "Feature Modeling", "Image Database", "Query Expansion", "Text Retrieval", "Bag of Visual Words"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#ChumPSIZ07", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408891", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408891", "http://cmp.felk.cvut.cz/~chum/papers/chum07iccv.pdf", "https://research.microsoft.com/pubs/64601/iccv2007.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4408891", "http://research.microsoft.com/pubs/64601/iccv2007.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=64601"], "t": "Total Recall: Automatic Query Expansion with a Generative Feature Model for Object Retrieval", "v": "ICCV", "y": 2007, "rn": 20}, {"a": ["Marc Pollefeys", "David Nist\u00e9r", "Jan-michael Frahm", "Amir Akbarzadeh", "Philippos Mordohai", "Brian Clipp", "Christoph Engels", "David Gallup", "Seon Kim", "Paul Merrell", "C. Salmi", "Sudipta Sinha", "B. Talton", "Liang Wang", "Qingxiong Yang", "Henrik Stew\u00e9nius", "Ruigang Yang", "Greg Welch", "Herman Towles"], "c": [39266032, 4415836, 39265949, 6368072, 4704856, 39261347, 13255518, 18572091, 39261565, 13934003, 4970784, 4916690, 6368193, 5868185, 13334333, 5981808, 6804572, 12173560, 39321391, 13328913, 13992287, 39261244, 50767458, 13334229, 14005185, 14084978, 5387450, 6293384, 50270021, 5370035, 51098554, 51099850, 6046964, 13319666, 13995514, 39261277, 39261608, 39262415, 39282597, 50970201, 6084698, 27584281, 5541376, 6287251, 13074431, 48000085, 48325232, 57172348, 39230199, 39277583, 51043044, 51080349, 51098490, 51108122, 51108243, 51148418, 51155619, 51191072, 57167265, 13107377, 13337290, 13995361, 13995786, 14005188, 14085194, 18572126, 27584491, 39244561, 39256540, 39261340, 39291490, 39297783, 49573132, 50914006, 51009797, 5661744, 6044538, 6368000, 6726652, 13577605, 27491048, 39245275, 39246134, 50758951, 50782846, 50782858, 50782874, 50783023, 50783118, 39245083, 61402255, 50098346, 50098492, 50057526, 49908623, 49908791, 49908794, 4853928, 5767650, 5945121, 10531466, 13637541, 13699534, 48696941], "b": "The paper presents a system for automatic, geo-registered, real-time 3D recon- struction from video of urban scenes. The system collects video streams, as well as GPS and inertia measurements in order to place the reconstructed models in geo-registered coordinates. It is designed using current state of the art real-time modules for all processing steps. It employs commodity graphics hardware and", "cn": 104, "i": 4389476, "tw": ["depth", "camera", "plane", "stereo", "system", "estimate", "figure", "image", "map", "maps", "computer", "surface", "reconstruction", "reference", "model", "video", "gain", "data", "sweeping", "points", "images", "cost", "pixel", "approach", "algorithm", "planes", "fusion", "point", "urban", "large", "estimation", "estimates", "pose", "view", "motion", "processing", "real-time", "features", "surfaces", "fused", "vision", "number", "feature", "cameras", "models", "multiple", "reconstructed", "scene", "computed", "kalman", "support", "step", "pattern", "compute", "tracker", "tracking", "set", "range", "structure", "selected", "ground", "single", "sparse", "dense", "typically", "scale", "based", "current", "change", "performed", "prior", "klt", "error", "algorithms", "order", "computation", "space", "measurements", "frames", "graphics", "distance", "proposed", "time", "stability", "pixels", "matching", "minimum", "reconstructions", "work", "mesh", "best", "direction", "close", "accuracy", "achieve", "parts", "method", "standard", "implementation", "reconstruct"], "k": ["3d reconstruction", "Depth Map", "Dynamic Range", "Feature Tracking", "Graphics Hardware", "Large Scale", "Stereo Vision", "Structure From Motion", "Video Streaming", "Real Time"], "p": ["http://dx.doi.org/10.1007/s11263-007-0086-4", "http://www.springerlink.com/index/f1583x66t021313x.pdf", "http://www.springerlink.com/content/f1583x66t021313x", "http://cvg-pub.inf.ethz.ch/WebBIB/papers/2008/0_PollefeysIJCV08.pdf", "http://www.cs.unc.edu/~jmf/publications/IJCV_UrbanReconstruction.pdf", "http://www.springerlink.com/index/10.1007/s11263-007-0086-4", "http://www.springerlink.com/index/pdf/10.1007/s11263-007-0086-4", "http://www.cs.unc.edu/~bclipp/papers/IJCV_UrbanReconstruction.pdf", "http://www.cs.unc.edu/~welch/media/pdf/Pollefeys2007_IJCV_UrbanReconstruction.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv78.html#PollefeysNFAMCEGKMSSTWYSYWT08"], "r": [1305681, 333855, 3157575, 174769, 784340, 249233, 3990615, 2021603, 3157577, 115264, 2134883, 635631, 89287, 3157574, 96972, 361156, 4247666, 800123, 2167171, 1272762, 59982, 123647, 1399187, 382849, 2167312, 130464, 373096, 2173203, 1321435, 801105, 1788314, 509739, 4490176, 289909, 509727, 124633, 93686, 132724, 509243, 1714709, 930987, 173341, 1984870, 2076612, 33118, 2167293, 4271382, 1428354, 784324, 3495003, 2412651, 4247946, 2167282, 1242180, 3733145, 4528479, 1788604, 2377795, 359231, 1872535, 1719744, 501203, 524073, 1788487, 53152, 1875203, 95318, 2412733, 4113880, 4595909, 4528820, 18213, 422039, 15271193, 15271099, 1695197], "t": "Detailed Real-Time Urban 3D Reconstruction from Video", "v": "IJCV", "y": 2008, "rn": 76, "h": ["resources/4389476/thumb-0.png", "resources/4389476/thumb-1.png", "resources/4389476/thumb-2.png", "resources/4389476/thumb-3.png", "resources/4389476/thumb-4.png", "resources/4389476/thumb-5.png", "resources/4389476/thumb-6.png", "resources/4389476/thumb-7.png", "resources/4389476/thumb-8.png", "resources/4389476/thumb-9.png", "resources/4389476/thumb-10.png", "resources/4389476/thumb-11.png", "resources/4389476/thumb-12.png", "resources/4389476/thumb-13.png", "resources/4389476/thumb-14.png", "resources/4389476/thumb-15.png", "resources/4389476/thumb-16.png", "resources/4389476/thumb-17.png", "resources/4389476/thumb-18.png", "resources/4389476/thumb-19.png", "resources/4389476/thumb-20.png", "resources/4389476/thumb-21.png", "resources/4389476/thumb-22.png", "resources/4389476/thumb-23.png", "resources/4389476/thumb-24.png", "resources/4389476/thumb-25.png", "resources/4389476/thumb-26.png", "resources/4389476/thumb-27.png", "resources/4389476/thumb-28.png", "resources/4389476/thumb-29.png", "resources/4389476/thumb-30.png", "resources/4389476/thumb-31.png", "resources/4389476/thumb-32.png", "resources/4389476/thumb-33.png", "resources/4389476/thumb-34.png", "resources/4389476/thumb-35.png", "resources/4389476/thumb-36.png", "resources/4389476/thumb-37.png", "resources/4389476/thumb-38.png", "resources/4389476/thumb-39.png", "resources/4389476/thumb-40.png", "resources/4389476/thumb-41.png", "resources/4389476/thumb-42.png", "resources/4389476/thumb-43.png"]}, {"a": ["Philip Torr", "Andrew Zisserman"], "b": " A new method is presented for robustly estimatingmultiple view relations from image point correspondences.There are three new contributions, the firstis a general purpose method of parametrizing these relationsusing point correspondences. The second contributionis the formulation of a common MaximumLikelihood Estimate (MLE) for each of the multipleview relations. The parametrization facilitates a constrainedoptimization to obtain this MLE. The thirdcontribution is a", "cn": 98, "i": 307732, "k": ["Multiple Views"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00710798", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=710798"], "t": "Robust Computation and Parametrization of Multiple View Relations", "v": "ICCV", "y": 1998, "rn": 10}, {"a": ["Christian Fr\u00fch", "Avideh Zakhor"], "b": "In this paper, we describe an automated method for fast, ground-based acquisition of large-scale 3D city models. Our experimental set up consists of a truck equipped with one camera and two fast, inexpensive 2D laser scanners, being driven on city streets under normal traffic conditions. One scanner is mounted vertically to capture building facades, and the other one is mounted", "cn": 87, "i": 1714709, "k": ["3d city model", "3d model", "Aerial Photograph", "Data Acquisition", "Digital Surface Model", "Large Scale", "Laser Scanner", "Laser Scanning", "Mobile Robot", "Monte Carlo Localization", "Motion Estimation"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv60.html#FruhZ04", "http://www.springerlink.com/index/n6327364428j7726.pdf", "http://www.springerlink.com/content/n6327364428j7726", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000027787.82851.b6", "http://www-video.eecs.berkeley.edu/papers/frueh/ijcv2004.pdf", "http://www.cs.columbia.edu/~allen/PHOTOPAPERS/frueh.ijcv.pdf", "http://dx.doi.org/10.1023/B:VISI.0000027787.82851.b6", "http://www.cs.hunter.cuny.edu/~ioannis/3DP_S09/fruehIJCV04.pdf", "http://www.cs.unc.edu/Research/vision/urban3d/fruehIJCV04.pdf"], "t": "An Automated Method for Large-Scale, Ground-Based City Model Acquisition", "v": "IJCV", "y": 2004, "rn": 43}, {"a": ["Ian Simon", "Noah Snavely", "Steven Seitz"], "b": "We formulate the problem of scene summarization as se- lecting a set of images that efficiently represents the visual content of a given scene. The ideal summary presents the most interesting and important aspects of the scene with minimal redundancy. We propose a solution to this prob- lem using multi-user image collections from the Internet. Our solution examines the distribution", "cn": 85, "i": 4117954, "k": ["Visual Features", "Multi User"], "p": ["http://grail.cs.washington.edu/projects/canonview/canonview.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408863", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408863", "http://www.cs.washington.edu/homes/iansimon/canonview.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#SimonSS07", "http://grail.cs.washington.edu/pub/papers/simon2007ssf.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4408863", "http://www.cs.washington.edu/homes/iansimon/papers/canonview.pdf"], "t": "Scene Summarization for Online Image Collections", "v": "ICCV", "y": 2007, "rn": 21}, {"a": ["Xiaowei Li", "Changchang Wu", "Christopher Zach", "Svetlana Lazebnik", "Jan-michael Frahm"], "b": "This paper presents an approach for modeling landmark sites such as the Statue of Liberty based on large-scale contaminated\n image collections gathered from the Internet. Our system combines 2D appearance and 3D geometric constraints to efficiently\n extract scene summaries, build 3D models, and recognize instances of the landmark in new test images. We start by clustering\n images using low-dimensional global", "cn": 59, "i": 4253676, "k": ["3d model", "3d structure", "Geometric Constraints", "Large Scale", "Structure From Motion"], "p": ["http://www.springerlink.com/content/d206238531227757", "http://dx.doi.org/10.1007/978-3-540-88682-2_33", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2008-1.html#LiWZLF08"], "t": "Modeling and Recognition of Landmark Image Collections Using Iconic Scene Graphs", "v": "ECCV", "y": 2008, "rn": 0}, {"a": ["Manolis Lourakis", "Antonis Argyros"], "b": "Bundle adjustment constitutes a large, nonlinear least-squares problem that is often solved as the last step of feature-based structure and motion estimation computer vision algorithms to obtain optimal estimates. Due to the very large number of parameters involved, a general purpose least-squares algorithm incurs high computational and memory storage costs when applied to bundle adjustment. Fortunately, the lack of interaction", "cn": 58, "i": 4771561, "k": ["Bundle Adjustment", "Computer Vision", "High Efficiency", "Least Square", "Multiple View Geometry", "Nonlinear Least Squares", "Optimal Estimation", "Software Package", "Structure and Motion", "Unconstrained Optimization", "levenberg marquardt"], "p": ["http://portal.acm.org/citation.cfm?id=1486527", "http://portal.acm.org/ft_gateway.cfm?id=1486527&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1486525.1486527", "http://www.ics.forth.gr/~lourakis/sba/sba-toms.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/toms/toms36.html#LourakisA09"], "t": "SBA: A software package for generic sparse bundle adjustment", "v": "TOMS", "y": 2009, "rn": 55}, {"a": ["Matthew Antone", "Seth Teller"], "b": "We describe a linear-time algorithm that recovers absolute camera orientations and positions, along with uncertainty estimates, for networks of terrestrial image nodes spanning hundreds of meters in outdoor urban scenes. The algorithm produces pose estimates globally consistent to roughly 0:1 (2 milliradians) and 5 centimeters on average, or about four pixels of epipolar alignment. We assume that adjacent nodes observe", "cn": 39, "i": 30509, "k": ["Bundle Adjustment", "Expectation Maximization Algorithm", "Large Scale", "Linear Time Algorithm", "Pose Estimation", "Structure From Motion", "Uncertainty Estimation", "Vanishing Point", "Exterior Orientation", "Hough Transform"], "p": [], "t": "Scalable Extrinsic Calibration of OmniDirectional Image Networks", "v": "IJCV", "y": 2002, "rn": 69}, {"a": ["Noah Snavely", "Steven Seitz", "Richard Szeliski"], "b": "We address the problem of efficient structure from mo- tion for large, unordered, highly redundant, and irregular ly sampled photo collections, such as those found on Internet photo-sharing sites. Our approach computes a smallskele- tal subset of images, reconstructs the skeletal set, and adds the remaining images using pose estimation. Our technique drastically reduces the number of parameters that are", "cn": 36, "i": 4704942, "k": ["Bundle Adjustment", "Graph Algorithm", "Image Reconstruction", "Photo Collection", "Photo Sharing", "Pose Estimation", "Structure From Motion"], "p": ["http://www.cs.washington.edu/homes/snavely/publications/papers/SkeletalSets_cvpr08.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587678", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587678", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/338.pdf", "http://www.cs.cornell.edu/~snavely/publications/papers/SkeletalSets_cvpr08.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#SnavelySS08", "http://www.cs.cornell.edu/~snavely/projects/skeletalset/SkeletalSets_cvpr08.pdf", "http://dx.doi.org/10.1109/CVPR.2008.4587678", "http://research.microsoft.com/pubs/75619/Snavely-CVPR08.pdf", "http://grail.cs.washington.edu/pub/papers/snavely2008sgf.pdf", "http://www.cs.washington.edu/homes/snavely/projects/skeletalset/SkeletalSets_cvpr08.pdf"], "t": "Skeletal graphs for efficient structure from motion", "v": "CVPR", "y": 2008, "rn": 26}, {"a": ["Lukas Zebedin", "Joachim Bauer", "Konrad Karner", "Horst Bischof"], "b": "Accurate and realistic building models of urban environments are increasingly important for applications, like virtual tourism\n or city planning. Initiatives like Virtual Earth or Google Earth are aiming at offering virtual models of all major cities\n world wide. The prohibitively high costs of manual generation of such models explain the need for an automatic workflow.\n \n This paper proposes an algorithm", "cn": 25, "i": 4253852, "k": ["Aerial Image", "Aerial Imagery", "Building Model", "Building Reconstruction", "Global Optimization", "Google Earth", "Graph Cut", "Information Sources", "Urban Environment", "Ground Truth", "Level of Detail"], "p": ["http://www.springerlink.com/content/a83p7770g7m20x1r", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2008-4.html#ZebedinBKB08", "http://dx.doi.org/10.1007/978-3-540-88693-8_64"], "t": "Fusion of Feature and Area-Based Information for Urban Buildings Modeling from Aerial Imagery", "v": "ECCV", "y": 2008, "rn": 0}, {"a": ["Roberto Toldo", "Andrea Fusiello"], "b": "Planar patches are a very compact and stable intermedi- ate representation of 3D scenes, as they are a good starting point for a complete automatic reconstruction of surfaces. This paper presents a novel method for extracting planar patches from an unstructured cloud of points that is produced by a typical structure and motion pipeline. The method integrates several constraints inside", "cn": 2, "i": 39262452, "k": ["Method Integration", "Multiple Model", "Structure and Motion"], "p": ["http://www.springerlink.com/content/4020380731w6j062", "http://www.springerlink.com/index/4020380731w6j062.pdf", "http://dx.doi.org/10.1007/978-3-642-15555-0_43", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-5.html#ToldoF10", "http://profs.sci.univr.it/~fusiello/papers/eccv10j.pdf"], "t": "Photo-consistent Planar Patches from Unstructured Cloud of Points", "v": "ECCV", "y": 2010, "rn": 22}, {"a": ["Tam\u00e1s Fazakas", "R\u00f3bert Fekete"], "b": "In this paper, a full 3D reconstruction pipeline is presented to realize the navigation of an autonomous robot. The system utilizes the existing algorithms for multi-view stereo and develops them into an automated system where the input is a video (or random images) obtained by the robot and the output is the model of the reconstructed environment containing the path", "cn": 1, "i": 51000605, "k": ["3d reconstruction", "Autonomous Robot", "multi-view stereo"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5672236", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05672236"], "t": "3D reconstruction system for autonomous robot navigation", "v": "CINTI", "y": 2010, "rn": 4}, {"a": ["Adarsh Kowdle", "Yao-Jen Chang", "Andrew Gallagher", "Tsuhan Chen"], "b": "This paper presents an active-learning algorithm for piecewise planar 3D reconstruction of a scene. While previous interactive algorithms require the user to provide tedious interactions to identify all the planes in the scene, we build on successful ideas from the automatic algorithms and introduce the idea of active learning, thereby improving the reconstructions while considerably reducing the effort. Our algorithm", "cn": 0, "i": 51108243, "k": ["3d reconstruction", "Active Learning", "Energy Minimization", "User Study"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995638", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995638"], "t": "Active learning for piecewise planar 3D reconstruction", "v": "CVPR", "y": 2011, "rn": 32}, {"a": ["Alberto Argiles", "Javier Civera", "Luis Montesano"], "b": "", "cn": 0, "i": 51147849, "k": ["Feature Extraction", "Image Reconstruction", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6048114", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06048114"], "t": "Dense multi-planar scene estimation from a sparse set of images", "v": "IROS", "y": 2011, "rn": 21}, {"a": ["Sriram Kashyap", "Rhushabh Goradia", "Parag Chaudhuri", "Sharat Chandran"], "b": "Point-based representations of objects have been used as modeling alternatives to the almost ubiquitous quads or triangles. However, our ability to render these points has not matched their polygonal counterparts when we consider both rendering time and sophisticated lighting effects. In this paper, we present a framework for ray tracing massive point model environments at interactive frame rates on the", "cn": 0, "i": 39232624, "k": ["Data Structure", "Graphic Processing Unit", "Implicit Surface", "Ray Tracing"], "p": ["http://portal.acm.org/citation.cfm?id=1924590", "http://portal.acm.org/ft_gateway.cfm?id=1924590&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "Implicit surface octrees for ray tracing point models", "y": 2010, "rn": 21}, {"a": ["Rhushabh Goradia", "Sriram Kashyap", "Parag Chaudhuri", "Sharat Chandran"], "b": "When it comes to rendering models available as points, rather than meshes, splats are a common intermediate internal representation. In this paper we further the state of the art by ray tracing splats to produce expected effects such as reflections, refraction, and shadows. We render complex models at interactive frame rates allowing real time viewpoint, lighting, and material changes. Our", "cn": 0, "i": 51015817, "k": ["Graphic Processing Unit", "Ray Tracing", "Interaction Point", "Real Time"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05693033", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693033"], "t": "GPU-Based Ray Tracing of Splats", "v": "PG", "y": 2010, "rn": 27}, {"a": ["Mike James", "L. Applegarth", "Harry Pinkerton"], "b": "During long-lived basaltic eruptions, overflows from lava channels and breaching of channel lev\u00e9es are important processes\n in the development of extensive 'a'\u0101 lava flow-fields. Short-lived breaches result in inundation of areas adjacent to the\n main channel. However, if a breach remains open, lava supply to the original flow front is significantly reduced, and flow-field\n widening is favoured over lengthening. The", "cn": 0, "i": 48396525, "k": ["3d model", "Computer Vision", "Flow Field", "Image Sequence", "Structure From Motion"], "p": ["http://www.springerlink.com/index/14w7532717252447.pdf", "http://www.springerlink.com/content/14w7532717252447"], "t": "Lava channel roofing, overflows, breaches and switching: insights from the 2008\u20132009 eruption of Mt. Etna", "v": "BULL VOLCANOL", "y": 0, "rn": 35}, {"a": ["Jianbo Shi", "Jitendra Malik"], "b": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The", "cn": 3004, "i": 799939, "k": ["Computational Techniques", "Generalized Eigenvalue Problem", "Graph Partitioning", "Image Segmentation", "Local Features", "Normalized Cut", "Perceptual Grouping"], "p": ["http://www.computer.org/tpami/tp2000/i0888abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=868688", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00868688", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami22.html#ShiM00", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=868688"], "t": "Normalized Cuts and Image Segmentation", "v": "PAMI", "y": 2000, "rn": 32}, {"a": ["Jianbo Shi", "Jitendra Malik"], "b": " We propose a novel approach for solving the perceptualgrouping problem in vision. Rather than focusingon local features and their consistencies in theimage data, our approach aims at extracting the globalimpression of an image. We treat image segmentationas a graph partitioning problem and propose anovel global criterion, the normalized cut, for segmentingthe graph. The normalized cut criterion measuresboth the total dissimilarity", "cn": 2580, "i": 321498, "k": ["Graph Partitioning", "Image Segmentation", "Local Features", "Normalized Cut"], "p": ["http://www.cs.huji.ac.il/~csip/SM-ncut.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=609407", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00609407", "http://www.cse.msu.edu/%7Ecse902/S03/ncut.pdf", "http://cms.brookes.ac.uk/research/visiongroup/talks/rg_august_09_normalized_cuts/normalized_cuts.pdf", "http://www.cs.dartmouth.edu/~farid/teaching/cs88/pami00.pdf", "http://www.cs.ualberta.ca/~nray1/CMPUT605/track3_papers/shi-Malik2000.pdf", "http://www.cs.duke.edu/courses/cps296.1/spring06/handouts/SM-ncut.pdf", "http://www.cs.bgu.ac.il/~ben-shahar/Teaching/Computational-Vision/Readings/2000-Shi_and_Malik-Normalized_Cuts_and_Image_Segmentation.pdf", "http://reference.kfupm.edu.sa/content/n/o/normalized_cuts_and_image_segmentation__7789.pdf", "http://www.cs.berkeley.edu/~fowlkes/tutorial/sm_ncuts_tpami_00.pdf", "http://www.cs.berkeley.edu/~malik/papers/SM-ncut.pdf", "http://www.cs.duke.edu/courses/spring06/cps296.1/handouts/SM-ncut.pdf", "http://www.cs.duke.edu/courses/cps296.1/spring05/handouts/SM-ncut.pdf", "http://www.cs.ualberta.ca/~nray1/CMPUT615/Clustering/shi-Malik2000.pdf", "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=EB8F51BCB07B4B1D79565D78EF789217?doi=10.1.1.14.3601&rep=rep1&type=pdf", "http://www.cs.cmu.edu/~efros/courses/AP06/Papers/shi-pami-00.pdf", "http://leibniz.iimas.unam.mx/~yann/Vision/Shi00.pdf", "http://www.vavlab.ee.boun.edu.tr/courses/574/material/Segmentation/shi_NormalizedCuts.pdf", "http://idm.pku.edu.cn/jiaoxue-mmf/2009/normalized%20cuts%20and%20image%20segmentation.pdf", "http://www.cs.toronto.edu/~zemel/Courses/CS2535/Papers/shiMalik.pdf", "http://www.cis.upenn.edu/~jshi/papers/sm_ncuts_tpami_00.pdf", "http://www.vavlab.ee.boun.edu.tr/courses/574/material/GraphCuts%20And%20MRFs/shi_NormalizedCuts.pdf", "http://www.cs.duke.edu/courses/spring05/cps296.1/handouts/SM-ncut.pdf", "http://www.cs.tau.ac.il/~shekler/Workshop_2004s/Papers/Malik/shi-malik-ncut-IEEE.pdf", "http://www.umiacs.umd.edu/%7Epturaga/ENEE731/papers/Spectral/Shi_Malik_2000.pdf", "http://idm.pku.edu.cn/jiaoxue-mmf/2008/normalized%20cuts%20and%20image%20segmentation.pdf", "http://www.cs.dartmouth.edu/farid/teaching/cs88/pami00.pdf", "http://users.rsise.anu.edu.au/~roland/Courses/ENGN8530_CVIU/shi_malik_TPAMI2000_NormalisedCut.pdf", "http://hanyfarid.org/teaching/cs88/pami00.pdf", "http://www.csee.wvu.edu/%7Exinl/library/papers/comp/shi_malik2000.pdf"], "t": "Normalized Cuts and Image Segmentation", "v": "CVPR", "y": 1997, "rn": 30}, {"a": ["Brian Curless", "Marc Levoy"], "b": "A number of techniques have been developed for reconstructing surfaces by integrating groups of aligned range images. A desirable set of properties for such algorithms includes: incremental updating,representation of directional uncertainty, the ability to fill gaps in the reconstruction, and robustness in the presence of outliers. Prior algorithms possess subsets of these properties. In this paper, we present a volumetric", "cn": 937, "i": 115264, "k": ["cumulant", "Distance Function", "Isosurface Extraction", "Least Square", "Range Image", "Shape Recovery", "Surface Fitting", "Three Dimensional", "Run Length Encoding"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1996.html#CurlessL96", "http://portal.acm.org/ft_gateway.cfm?id=237269&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=237269", "http://portal.acm.org/citation.cfm?id=237170.237269", "http://kucg.korea.ac.kr/education/2003_2/VIP618/paper/curless.pdf", "http://www-hci.stanford.edu/papers/volrange/volrange.pdf", "http://www-graphics.stanford.edu/papers/volrange/volrange.pdf", "http://www.vision.caltech.edu/tutorial/papers/volrange.pdf", "http://mesh.brown.edu/en193s08%2D2003/refs/CurlesLevoy-sg96.pdf", "http://www.cs.jhu.edu/~misha/Fall05/Papers/curless96.pdf", "http://graphics.ethz.ch/Downloads/Seminar_Arbeiten/1997/ochinellato.pdf", "http://www.cg.inf.ethz.ch/Downloads/Seminar_Arbeiten/1997/ochinellato.pdf", "https://graphics.stanford.edu/papers/volrange/volrange.pdf", "http://www.cs.hunter.cuny.edu/%7Eioannis/volrange.pdf", "http://www.cs.hunter.cuny.edu/~ioannis/3DP_F03/PAPERS/MODELING/LEVOY/volrange.pdf", "https://formaurbis.stanford.edu/papers/volrange/volrange.pdf"], "t": "A volumetric method for building complex models from range images", "v": "SIGGRAPH", "y": 1996, "rn": 36}, {"a": ["Szymon Rusinkiewicz", "Marc Levoy"], "b": "Advances in 3D scanning technologies have enabled the practical cre- ation of meshes with hundreds of millions of polygons. Traditional algorithms for display, simplification, and progressive transmission of meshes are impractical for data sets of this size. We describe a system for representing and progressively displaying these meshes that com- bines a multiresolution hierarchy based on bounding spheres with a", "cn": 624, "i": 107294, "k": ["3d scanning", "Compression Algorithm", "Data Structure", "Image Quality", "Large Data Sets", "Large Scale", "Level of Detail Algorithms", "Progressive Transmission", "Rendering System", "Spatial Data Structure", "Level of Detail", "Computer Graphic", "Data Type", "Image Generation", "Methodology and Techniques", "Object Model", "Object Representation"], "p": ["http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Rusinkiewicz00.pdf", "http://portal.acm.org/citation.cfm?id=344940", "http://portal.acm.org/ft_gateway.cfm?id=344940&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.inf.uni-konstanz.de/cgip/ruggeri/PB3DGSemWS03-04/PBRPapers/RusiLevo00.pdf", "http://www.cs.princeton.edu/gfx/pubs/Rusinkiewicz_2000_QAM/qsplat_paper.pdf", "http://graphics.stanford.edu/papers/qsplat/qsplat_paper.pdf", "http://www.cs.princeton.edu/courses/archive/spr01/cs598b/papers/rusinkiewicz00.pdf", "http://www.cs.princeton.edu/courses/archive/spring01/cs598b/papers/rusinkiewicz00.pdf", "http://www.cs.princeton.edu/courses/archive/fall02/cs526/papers/rusinkiewicz00.pdf", "http://portal.acm.org/citation.cfm?id=344779.344940", "http://kucg.korea.ac.kr/seminar/2004/src/pa-04-17.pdf", "http://www.cs.stevens.edu/~quynh/courses/cs638-papers/point-based/qsplat.pdf", "http://www.cse.iitb.ac.in/~kashyap/seminar/final/qsplat_paper.pdf", "http://didactiekinf.uhasselt.be/gcg/qsplat_paper.pdf", "http://www.ics.uci.edu/~gopi/ICS280Win02/QSplat.pdf", "http://kucg.korea.ac.kr/education/2004/CSCE458/paper/qsplat.pdf", "https://www.cs.umd.edu/class/spring2005/cmsc828v/papers/p343-rusinkiewicz.pdf", "http://graphics.stanford.edu/~smr/qsplat/paper/qsplat_paper.pdf"], "t": "QSplat: a multiresolution point rendering system for large meshes", "v": "SIGGRAPH", "y": 2000, "rn": 50}, {"a": ["Steven Seitz", "Brian Curless", "James Diebel", "Daniel Scharstein", "Richard Szeliski"], "c": [4136935, 4389580, 4389476, 4248108, 4114741, 4415789, 2167293, 13313906, 2427393, 4271382, 4271345, 4704811, 4404089, 5551146, 39265949, 4704527, 4230594, 4271431, 4271445, 4248121, 4768227, 5653034, 4404236, 4111429, 4412035, 4247971, 4271272, 39261347, 4704598, 4977356, 4271397, 4464485, 6076398, 4271381, 4389432, 4704643, 4916642, 39261565, 39265981, 4704710, 4276221, 39261461, 6431766, 14160210, 4704930, 4142662, 6018983, 4704578, 13338319, 11702679, 5045958, 50656185, 10272014, 6076359, 4704793, 5651555, 5767284, 5257464, 4845187, 6140319, 6492130, 13320077, 5909338, 6026364, 12665645, 4959695, 13335870, 4879874, 5169723, 5326676, 4144161, 4247750, 4586028, 5619061, 39321365, 39236326, 39261440, 50904654, 5133421, 5750443, 14401084, 4301009, 5894793, 2470269, 4247807, 4289947, 2412776, 6442578, 14318105, 15231549, 51067869, 13765282, 14375552, 15271322, 39261412, 6032498, 13765916, 39244439, 39265936, 4404269, 4114211, 4346161, 5031635, 5599657, 12133075, 13982944, 39261295, 39261371, 39261556, 39261571, 39267410, 4710462, 5004336, 5429349, 6044645, 6050602, 6368204, 39266011, 4253841, 4704854, 27096219, 4845191, 5370035, 6221643, 15231555, 15271330, 27810891, 48822207, 51107960, 51108017, 56925025, 13332484, 13994810, 14002093, 39261608, 39282597, 50891556, 50943112, 6154996, 6770254, 10591238, 13150462, 13334213, 13621943, 50782794, 50861541, 4362927, 4434513, 4704669, 4705538, 4751392, 6367972, 39243842, 50723865, 2470297, 4271273, 5142384, 14373860, 27101098, 39321370, 39327348, 39329671, 48014765, 48790956, 48804184, 48874089, 48962411, 51034286, 51040909, 51042359, 51059509, 51067192, 51067903, 51080315, 51080334, 51080336, 51080365, 51081181, 51098490, 51108065, 51108155, 51108183, 51108243, 51108298, 51112116, 51117926, 51122689, 51132657, 51148305, 51148516, 51156216, 51178404, 51183663, 51187760, 51194645, 57463876, 5636750, 6046946, 7039102, 13107377, 13160170, 13337310, 13339076, 13759896, 13995361, 14083778, 14084717, 14356325, 15214001, 15214025, 15257922, 39232626, 39244508, 39244555, 39244566, 39256462, 39256616, 39256695, 39261218, 39261501, 39267859, 39291408, 39296062, 50893271, 50944138, 50986294, 50987973, 50989064, 50991186, 51003106, 51015671, 51015674, 51015813, 51022457, 51175158, 61402281, 5725872, 6030162, 6032507, 6032540, 6044548, 6044565, 6044654, 6044655, 6049624, 6076352, 6076383, 6176568, 6470443, 13298247, 13299883, 13765786, 39245335, 39258428, 50758931, 50758937, 50758944, 50782721, 50782824, 50782866, 50782868, 50782874, 50782968, 50783003, 50783046, 50783057, 50783076, 50797818, 50808790, 61401166, 4318040, 4323413, 4704521, 4716442, 4716717, 4718130, 4718669, 5337353, 39243763, 39243844, 50684450, 50701322, 4230452, 4247932, 4550549, 4592213, 4825115, 6026384, 10447707, 61402248, 4494100, 4808315, 4930886, 4982892, 4989268, 5197409, 5429013, 5752145, 6018085, 6556036, 6655884, 6737488, 10401368, 11438603, 11554041, 11656471, 13362371, 13637541, 48223353, 48329627, 48380463, 48394773, 48537691, 48712078, 48743464, 48799660, 48802092, 48818384], "b": "This paper presents a quantitative comparison of several multi-view stereo reconstruction algorithms. Until now, the lack of suitable calibrated multi-view image datasets with known ground truth (3D shape models) has prevented such direct comparisons. In this paper, we r st survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties. We then describe our", "cn": 318, "i": 2167171, "tw": ["surface", "stereo", "multi-view", "reconstruction", "scene", "algorithms", "points", "methods", "evaluation", "accuracy", "image", "space", "shape", "images", "set", "compute", "depth", "model", "datasets", "photo-consistency", "number", "measures", "ground", "completeness", "visibility", "camera", "visual", "truth", "measure", "techniques", "temple", "object", "function", "models", "nearest", "dino", "point", "mesh", "volumetric", "carving", "geometry", "cost", "data", "distance", "approach", "calibrated", "volume", "figure", "map", "sets", "voxel", "ring", "based", "quantitative", "distances", "reconstructions", "small", "full", "comparing", "taxonomy", "views", "cameras", "offsets", "hull", "hole", "geometric", "error", "minimize", "input", "dense", "represent", "large", "current", "method", "objects", "web", "voxels", "include", "bias", "table", "maps", "representation", "feature", "paper", "estimate", "silhouettes", "multiple", "class", "vertices", "reference", "surfaces", "pixels", "hernandez", "evaluating", "gantry", "well", "captured", "level-set", "sparse", "comparison"], "k": ["Evaluation Methodology", "multi-view stereo", "Reconstruction Algorithm", "Shape Modeling", "Ground Truth"], "p": ["http://research.microsoft.com/pubs/75610/Seitz-CVPR06.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01640800", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1640800", "https://research.microsoft.com/pubs/75610/Seitz-CVPR06.pdf", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.19", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-1.html#SeitzCDSS06", "http://morse.cs.byu.edu/750/papers/CVPR06-Seitz-MultiviewStereo.pdf", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Seitz-CVPR-06.pdf", "http://www.cs.hunter.cuny.edu/~ioannis/3DP_S09/seitz_mview_cvpr06.pdf", "http://vision.middlebury.edu/mview/seitz_mview_cvpr06.pdf"], "r": [784340, 115264, 79541, 800968, 1919161, 65765, 800299, 1232819, 72820, 523961, 1681336, 247412, 373096, 16462346, 1321435, 270327, 207949, 2145613, 27413, 2023565, 1872555, 1789051, 2201175, 141881, 101211, 173341, 16834, 299310, 2167293, 1788278, 509993, 1796558, 697459, 523954, 1788983, 1788985, 2503300, 1714699, 2017516, 506608, 1796355, 1796394, 369733, 2175082, 1796473, 1796455, 3823005, 509923, 509818, 523881, 722872, 2387649, 1790105, 2050675, 506934, 4394569, 1796400, 168121, 740167, 800376, 1788763, 2049930, 1796724, 1796416, 3212341, 4113604, 1071913], "t": "A Comparison and Evaluation of Multi-View Stereo Reconstruction Algorithms", "v": "CVPR", "y": 2006, "rn": 67, "h": ["resources/2167171/thumb-0.png", "resources/2167171/thumb-1.png", "resources/2167171/thumb-2.png", "resources/2167171/thumb-3.png", "resources/2167171/thumb-4.png", "resources/2167171/thumb-5.png", "resources/2167171/thumb-6.png", "resources/2167171/thumb-7.png"]}, {"a": ["Michael Kazhdan", "Matthew Bolitho", "Hugues Hoppe"], "b": "We show that surface reconstruction from oriented points can be cast as a spatial Poisson problem. This Poisson formulation considers all the points at once, without resorting to heuristic spatial partitioning or blending, and is therefore highly resilient to data noise. Unlike radial basis function schemes, our Poisson approach allows a hierarchy of locally supported basis functions, and therefore the", "cn": 166, "i": 3582575, "k": ["Radial Basis Function", "Space Complexity", "Sparse Linear System", "Spatial Partitioning", "Surface Reconstruction"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/sgp/sgp2006.html#KazhdanBH06", "http://portal.acm.org/citation.cfm?id=1281965", "http://research.microsoft.com/en-us/um/people/hoppe/poissonrecon.pdf", "http://doi.acm.org/10.1145/1281957.1281965"], "t": "Poisson surface reconstruction", "v": "SGP", "y": 2006, "rn": 33}, {"a": ["Carlos Esteban", "Francis Schmitt"], "b": "Abstract: In this paper we present a new approach to high quality 3Dobject reconstruction. Starting from a calibrated sequenceof color images, the algorithm is able to reconstruct boththe 3D geometry and the texture. The core of the method isbased on a deformable model, which defines the frameworkwhere texture and silhouette information can be fused. Thisis achieved by defining two external", "cn": 145, "i": 2145613, "k": ["3d reconstruction", "Color Image", "Deformable Model", "Object Model", "Gradient Vector Flow", "Visual Hull"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/cviu/cviu96.html#EstebanS04", "http://www.sciencedirect.com/science/article/pii/S1077314204000542", "http://linkinghub.elsevier.com/retrieve/pii/S1077314204000542", "http://dx.doi.org/10.1016/j.cviu.2004.03.016"], "t": "Silhouette and stereo fusion for 3D object modeling", "v": "CVIU", "y": 2004, "rn": 16}, {"a": ["Carlos Esteban", "Francis Schmitt"], "b": "In this paper, we present a new approach to high quality 3D object reconstruction. Start- ing from a calibrated sequence of color images, the algorithm is able to reconstruct both the 3D geometry and the texture. The core of the method is based on a deformable model, which denes the framework where texture and silhouette information can be fused. This", "cn": 116, "i": 1872555, "k": ["3d model", "3d reconstruction", "Color Image", "Deformable Model", "High Resolution", "O W Visualization", "Object Model", "Object Reconstruction", "Texture Mapping"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1240231", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01240231", "http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2003.html#EstebanS03", "http://csdl.computer.org/comp/proceedings/3dim/2003/1991/00/19910046abs.htm"], "t": "Silhouette and Stereo Fusion for 3D Object Modeling", "v": "3DIM", "y": 2003, "rn": 42}, {"a": ["George Vogiatzis", "Philip Torr", "Roberto Cipolla"], "c": [2167171, 2503356, 2427508, 4248108, 4362653, 2167293, 1796558, 13313906, 2427393, 2510621, 2427514, 4271345, 4111826, 4404089, 46262, 2167142, 39265949, 4271445, 2512389, 2362113, 4253660, 4248121, 4768227, 4111429, 4412035, 4470192, 4704573, 4271397, 3687918, 4255390, 4464485, 6076398, 4253669, 4271381, 2427410, 39261565, 2412695, 4113369, 10272014, 6076359, 4412817, 2167296, 6492130, 5891263, 2512396, 2444726, 13335870, 5169723, 4586028, 5894793, 2470269, 4271494, 2412776, 50783115, 5957618, 2167386, 4141148, 5860254, 13995243, 14401196, 2412779, 2440191, 2442612, 13994810, 39261534, 39261610, 6032484, 13264281, 50861541, 4255377, 2412716, 12866503, 13213199, 39262043, 39321385, 39327348, 39329671, 48014765, 51108183, 6046946, 13107377, 13339078, 15214001, 39232626, 50989064, 6176568, 39245335, 50782866, 50782874, 50782968, 50819987, 4230887, 4716717, 4718130, 27488385, 39243831, 50645532, 50660597, 4239142, 4239612, 4247932, 4457687, 4550549, 51172318, 5429013, 10406055, 10907254, 11196153, 11280841, 11909520, 12269417, 12906793], "b": "This paper presents a novel formulation for the multi- view scene reconstruction problem. While this formula- tion benefits from a volumetric scene representation, it is amenable to a computationally tractable global optimisa- tion using Graph-cuts. The algorithm proposed uses the visual hull of the scene to infer occlusions and as a con- straint on the topology of the scene. A", "cn": 112, "i": 1789051, "tw": ["surface", "scene", "sbase", "cost", "space", "volumetric", "graph", "base", "method", "point", "images", "stereo", "image", "work", "voxels", "methods", "functional", "carving", "visual", "figure", "volume", "level", "minimal", "face", "riemannian", "set", "discrete", "paper", "well", "model", "sin", "term", "hull", "reconstructed", "source", "smin", "problem", "optimisation", "minimum", "continuous", "graph-cuts", "surfaces", "cut", "synthetic", "representation", "presented", "voxel", "reconstruction", "sets", "area", "approximate", "visibility", "algorithm", "weight", "house", "energy", "belief", "silhouettes", "multiple", "boundary", "described", "corresponding", "result", "real", "occlusion", "matching", "slice", "represent", "global", "nodes", "ballooning", "correct", "experiment", "represented", "total", "optimal", "smoothness", "number", "smaller", "multi-view", "normal", "proceedings", "points", "approach", "prior", "propagation", "sequence", "viewpoints", "true", "inside", "photo-consistency", "depth", "technique", "solution", "small", "segmentation", "objects", "wij", "unit", "esurf"], "k": ["Cost Function", "Graph Cut", "Minimum Cut", "multi-view stereo", "Quantitative Evaluation", "Scene Reconstruction", "Weighted Graph", "Visual Hull"], "p": ["http://george-vogiatzis.org/publications/cvpr2005.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1467469", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01467469", "http://www.cse.buffalo.edu/courses/cse725/peter/Vogiatzis_2005.pdf", "http://cms.brookes.ac.uk/staff/PhilipTorr/Papers/CVPR05/George_cvpr2005.pdf", "http://mi.eng.cam.ac.uk/reports/svr-ftp/vogiatzis_cvpr2005.pdf", "http://eprints.pascal-network.org/archive/00002823/01/George_cvpr2005.pdf"], "r": [174769, 784340, 119729, 799549, 79541, 268093, 800914, 72820, 523961, 509735, 1681336, 373096, 1796367, 204601, 326313, 1796523, 2503324, 4394569, 4061214], "t": "Multi-View Stereo via Volumetric Graph-Cuts", "v": "CVPR", "y": 2005, "rn": 19, "h": ["resources/1789051/thumb-0.png", "resources/1789051/thumb-1.png", "resources/1789051/thumb-2.png", "resources/1789051/thumb-3.png", "resources/1789051/thumb-4.png", "resources/1789051/thumb-5.png", "resources/1789051/thumb-6.png", "resources/1789051/thumb-7.png"]}, {"a": ["Inderjit Dhillon", "Yuqiang Guan", "Brian Kulis"], "b": "", "cn": 98, "i": 4404151, "k": ["Cluster Algorithm", "Clustered Data", "Eigenvectors", "Gene Network", "Graph Clustering", "Graph Partitioning", "Image Segmentation", "Large Scale", "Multilevel Algorithm", "Normalized Cut", "Objective Function", "Social Network Analysis", "Spectral Clustering", "Weighted Graph", "K Means"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4302760", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04302760", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4302760", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.1115", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami29.html#DhillonGK07"], "t": "Weighted Graph Cuts without Eigenvectors A Multilevel Approach", "v": "TPAMI", "y": 2007, "rn": 33}, {"a": ["Michael Goesele", "Noah Snavely", "Brian Curless", "Hugues Hoppe", "Steven Seitz"], "b": "We present a multi-view stereo algorithm that addresses the extreme changes in lighting, scale, clutter, and other effects in large online community photo collections. Our idea is to intelligently choose images to match, both at a per-view and per-pixel level. We show that such adaptive view selection enables robust performance even with dra- matic appearance variability. The stereo matching tech-", "cn": 84, "i": 4114741, "k": ["Depth Map", "multi-view stereo", "Online Community", "Photo Collection", "Robust Performance", "Scene Reconstruction", "Stereo Matching", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408933", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408933", "http://dx.doi.org/10.1109/ICCV.2007.4408933", "https://research.microsoft.com/en-us/um/people/hoppe/mvscpc.pdf", "http://research.microsoft.com/en-us/um/people/hoppe/mvscpc.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#GoeseleSCHS07"], "t": "Multi-View Stereo for Community Photo Collections", "v": "ICCV", "y": 2007, "rn": 25}, {"a": ["Jean-philippe Pons", "Renaud Keriven", "Olivier Faugeras"], "b": "We present a new variational method for multi-view stereovision and non-rigid three-dimensional motion estimation from multiple video sequences. Our method minimizes the prediction error of the shape and motion estimates. Both problems then translate into a generic image registration task. The latter is entrusted to a global measure of image simi- larity, chosen depending on imaging conditions and scene properties.", "cn": 55, "i": 2503389, "k": ["Cross Correlation", "Hardware Implementation", "Image Registration", "large dataset", "Level Set", "Motion Estimation", "multi-view stereo", "Mutual Information", "Prediction Error", "Three Dimensional", "Variational Method", "Graphics Processor Unit"], "p": ["http://www.springerlink.com/index/jw816292548027l2.pdf", "http://www.springerlink.com/content/jw816292548027l2", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv72.html#PonsKF07", "http://www.springerlink.com/index/10.1007/s11263-006-8671-5", "http://dx.doi.org/10.1007/s11263-006-8671-5", "http://www.springerlink.com/index/pdf/10.1007/s11263-006-8671-5"], "t": "Multi-View Stereo Reconstruction and Scene Flow Estimation with a Global Image-Based Matching Score", "v": "IJCV", "y": 2007, "rn": 45}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "This paper proposes a novel algorithm for multiview stereopsis that outputs a dense set of small rectangular patches covering the surfaces visible in the images. Stereopsis is implemented as a match, expand, and filter procedure, starting from a sparse set of matched keypoints, and repeatedly expanding these before using visibility constraints to filter away false matches. The keys to the", "cn": 54, "i": 13313906, "k": ["Automatic Detection", "Computer Vision", "Quantitative Evaluation", "Scene Analysis", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5226635", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05226635", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5226635", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami32.html#FurukawaP10", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2009.161"], "t": "Accurate, Dense, and Robust Multiview Stereopsis", "v": "PAMI", "y": 2010, "rn": 33}, {"a": ["Arindam Banerjee", "Chase Krumpelman", "Joydeep Ghosh", "Sugato Basu", "Raymond Mooney"], "b": "While the vast majority of clustering algorithms are partitional, many real world datasets have inherently overlapping clusters. Several approaches to finding overlapping clusters have come from work on analysis of biological datasets. In this paper, we interpret an overlapping clustering model proposed by Segal et al. [23] as a generalization of Gaussian mixture models, and we extend it to an", "cn": 49, "i": 1775195, "k": ["Cluster Algorithm", "Cluster Model", "Exponential Family", "Exponential Model", "Gaussian Mixture Model", "Graphical Model", "High Dimensionality", "Synthetic Data"], "p": ["http://www.lans.ece.utexas.edu/~abanerjee/papers/05/f380-banerjee.pdf", "http://portal.acm.org/ft_gateway.cfm?id=1081932&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1081932", "http://doi.acm.org/10.1145/1081870.1081932", "http://www.lans.ece.utexas.edu/papers/banerjee05overlapping.pdf", "http://www.dtc.umn.edu/ddmc/resources/banerjee2.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/kdd/kdd2005.html#BanerjeeKGBM05", "https://www.dtc.umn.edu/ddmc/resources/banerjee2.pdf", "http://www.cs.utexas.edu/~ml/papers/moc-submitted-05.pdf", "http://portal.acm.org/citation.cfm?id=1081870.1081932", "http://www.cs.utexas.edu/users/ml/papers/moc-submitted-05.pdf"], "t": "Model-based overlapping clustering", "v": "KDD", "y": 2005, "rn": 38}, {"a": ["David Gallup", "Jan-michael Frahm", "Philippos Mordohai", "Qingxiong Yang", "Marc Pollefeys"], "b": "Recent research has focused on systems for obtaining automatic 3D reconstructions of urban environments from video acquired at street level. These systems record enormous amounts of video; therefore a key component is a stereo matcher which can process this data at speeds comparable to the recording frame rate. Furthermore, urban environments are unique in that they exhibit mostly planar surfaces.", "cn": 40, "i": 4247946, "k": ["3d reconstruction", "Graph Cut", "Graphic Processing Unit", "Urban Environment", "Real Time"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#GallupFMYP07", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270270", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270270", "http://www.cs.unc.edu/Research/urbanscape/public/Gallup_RealtimePlanesweepingStereo07.pdf", "http://vision.ai.uiuc.edu/~qyang6/publications/cvpr-07-david-gallup.pdf", "http://dx.doi.org/10.1109/CVPR.2007.383245", "http://vis.uky.edu/~liiton/publications/cvpr-07-Gallup.pdf", "http://www.cs.unc.edu/~marc/pubs/GallupCVPR07.pdf", "http://cvg-pub.inf.ethz.ch/WebBIB/papers/2007/GallupCVPR07.pdf", "http://www.cs.unc.edu/~jmf/publications/Gallup_Frahm_Mordohai_Pollefeys_CVPR2007.pdf", "http://www.inf.ethz.ch/personal/pomarc/pubs/GallupCVPR07.pdf", "http://www.cs.unc.edu/%7Egallup/papers/CVPR07.pdf"], "t": "Real-Time Plane-Sweeping Stereo with Multiple Sweeping Directions", "v": "CVPR", "y": 2007, "rn": 20}, {"a": ["Christopher Zach", "Thomas Pock", "Horst Bischof"], "b": "Robust integration of range images is an important task for building high-quality 3D models. Since range images, and in particular range maps from stereo vision, may have a substantial amount of outliers, any integration approach aiming at high-quality models needs an increased level of robustness. Additionally, a certain level of regularization is required to obtain smooth surfaces. Computational effi- ciency", "cn": 39, "i": 4271345, "k": ["3d model", "Global Convergence", "Global Optimization", "Integrated Approach", "Numerical Scheme", "Quality Model", "Range Image", "Stereo Vision"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408983", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408983", "http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Zach07.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#ZachPB07", "http://dx.doi.org/10.1109/ICCV.2007.4408983", "http://www.icg.tugraz.at/pub/pdf/iccv07_paper.pdf"], "t": "A Globally Optimal Algorithm for Robust TV-L1 Range Image Integration", "v": "ICCV", "y": 2007, "rn": 39}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "The advent of high-resolution digital cameras and sophisticated multi-view stereo algorithms offers the promise of unprecedented\n geometric fidelity in image-based modeling tasks, but it also puts unprecedented demands on camera calibration to fulfill\n these promises. This paper presents a novel approach to camera calibration where top-down information from rough camera parameter\n estimates and the output of a multi-view-stereo system on", "cn": 15, "i": 6076411, "k": ["Bundle Adjustment", "Camera Calibration", "Digital Camera", "High Resolution", "image-based modeling", "multi-view stereo", "Parameter Estimation", "Bottom Up", "Top Down", "Visual Hull"], "p": ["http://www.springerlink.com/content/5168rn553185n5w3", "http://dx.doi.org/10.1007/s11263-009-0232-2", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv84.html#FurukawaP09a", "http://www.springerlink.com/index/10.1007/s11263-009-0232-2", "http://www.springerlink.com/index/pdf/10.1007/s11263-009-0232-2"], "t": "Accurate Camera Calibration from Multi-View Stereo and Bundle Adjustment", "v": "IJCV", "y": 2009, "rn": 3}, {"a": ["David Gallup", "Jan-michael Frahm", "Philippos Mordohai", "Marc Pollefeys"], "b": "We present a novel multi-baseline, multi-resolution stereo method, which varies the baseline and resolution proportionally to depth to obtain a reconstruction in which the depth error is constant. This is in contrast to traditional stereo, in which the error grows quadratically with depth, which means that the accuracy in the near range far exceeds that of the far range. This", "cn": 15, "i": 4704947, "k": ["Multi Resolution"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587671", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587671", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#GallupFMP08", "http://dx.doi.org/10.1109/CVPR.2008.4587671"], "t": "Variable baseline/resolution stereo", "v": "CVPR", "y": 2008, "rn": 12}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "The advent of high-resolution digital cameras and so- phisticated multi-view stereo algorithms offers the promises of un- precedented geometric fidelity in image-based modeling tasks, but it also puts unprecedented demands on camera calibration to ful- fill these promises. This paper presents a novel approach to cam- era calibration where top-down information from rough camera parameter estimates and the output of", "cn": 14, "i": 4704643, "k": ["Bundle Adjustment", "Camera Calibration", "Digital Camera", "High Resolution", "image-based modeling", "multi-view stereo", "Parameter Estimation", "Bottom Up", "Top Down", "Visual Hull"], "p": ["http://www-cvr.ai.uiuc.edu/~yfurukaw/papers/cvpr08a.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587681", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587681", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#FurukawaP08a", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/341.pdf", "http://dx.doi.org/10.1109/CVPR.2008.4587681", "http://www.di.ens.fr/willow/pdfs/cvpr08a.pdf", "http://www.cs.washington.edu/homes/furukawa/papers/cvpr08a.pdf"], "t": "Accurate camera calibration from multi-view stereo and bundle adjustment", "v": "CVPR", "y": 2008, "rn": 23}, {"a": ["Matthew Bolitho", "Michael Kazhdan", "Randal Burns", "Hugues Hoppe"], "b": "Reconstruction of surfaces from huge collections of scanned points often requires out-of-core techniques, and most such techniques involve local computations that are not resilient to data errors. We show that a Poisson-based reconstruction scheme, which considers all points in a global analysis, can be performed efficiently in limited memory using a streaming framework. Specifically, we introduce a multilevel streaming representation,", "cn": 13, "i": 4114744, "k": ["Global Analysis", "large dataset", "Linear System", "Local Computation", "Surface Reconstruction"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/sgp/sgp2007.html#BolithoKBH07", "http://research.microsoft.com/en-us/um/people/hoppe/mlstream.pdf", "http://doi.acm.org/10.1145/1281991.1282001"], "t": "Multilevel streaming for out-of-core surface reconstruction", "v": "SGP", "y": 2007, "rn": 24}, {"a": ["Branislav Micus\u00edk", "Jana Kosecka"], "b": "", "cn": 11, "i": 6368088, "k": ["3d model"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206535", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#MicusikK09"], "t": "Piecewise planar city 3D modeling from street view panoramic sequences", "v": "CVPR", "y": 2009, "rn": 0}, {"a": ["David Chen", "Georges Baatz", "Kevin Koeser", "Sam Tsai", "Ramakrishna Vedantham", "Kimmo Roimela", "Jeff Bach", "Marc Pollefeys", "Bernd Girod", "Radek Grzeszczuk"], "b": "With recent advances in mobile computing, the demand for visual localization or landmark identification on mobile devices is gaining interest. We advance the state of the art in this area by fusing two popular representations of street- level image data\u2014facade-aligned and viewpoint-aligned\u2014 and show that they contain complementary information that can be exploited to significantly improve the recall rates on", "cn": 2, "i": 51108215, "k": ["Feature Detection", "Mobile Computer", "Mobile Device", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995610", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995610", "http://www.inf.ethz.ch/personal/pomarc/pubs/ChenCVPR11.pdf"], "t": "City-Scale Landmark Identification on Mobile Devices", "v": "CVPR", "y": 2011, "rn": 24}, {"a": ["Andreas Wendel", "Arnold Irschara", "Horst Bischof"], "b": "Highly accurate localization of a micro aerial vehicle (MAV) with respect to a scene is important for a wide range of applications, in particular surveillance and inspection. Most existing approaches to visual localization focus on indoor environments, while such tasks require outdoor navigation. Within this work, we introduce a novel algorithm for monocular visual localization for MAVs based on the", "cn": 1, "i": 51100540, "k": ["3d reconstruction", "Autonomous Navigation", "Feature Extraction", "Image Reconstruction", "Indoor Environment", "Simultaneous Localization and Mapping", "Three Dimensional", "Micro Aerial Vehicle"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5980317", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05980317"], "t": "Natural landmark-based monocular localization for MAVs", "v": "ICRA", "y": 2011, "rn": 26}, {"a": ["Engin Tola", "Christoph Strecha", "Pascal Fua"], "b": "We present a new approach for large-scale multi-view stereo matching, which is designed to operate on ultra high-resolution\n image sets and efficiently compute dense 3D point clouds. We show that, using a robust descriptor for matching purposes and\n high-resolution images, we can skip the computationally expensive steps that other algorithms require. As a result, our method\n has low memory requirements", "cn": 1, "i": 48000085, "k": ["3d point cloud", "3d reconstruction", "Computational Complexity", "High Resolution Imager", "Large Scale", "Memory Access", "multi-view stereo"], "p": ["http://www.springerlink.com/content/050r681641755263", "http://www.springerlink.com/index/050r681641755263.pdf"], "t": "Efficient large-scale multi-view stereo for ultra high-resolution image sets", "v": "MVA", "y": 0, "rn": 17}, {"a": ["Shahram Izadi", "David Kim", "Otmar Hilliges", "David Molyneaux", "Richard Newcombe", "Pushmeet Kohli", "Jamie Shotton", "Steve Hodges", "Dustin Freeman", "Andrew Davison", "Andrew Fitzgibbon"], "b": "KinectFusion enables a user holding and moving a standard Kinect camera to rapidly create detailed 3D reconstructions of an indoor scene. Only the depth data from Kinect is used to track the 3D pose of the sensor and reconstruct, geometrically precise, 3D models of the physical scene in real-time. The capabilities of KinectFusion, as well as the novel GPU-based pipeline", "cn": 0, "i": 56904787, "k": ["3d model", "3d reconstruction", "Augmented Reality", "Object Segmentation", "Surface Reconstruction", "User Interaction", "Real Time"], "p": ["http://dl.acm.org/citation.cfm?id=2047270", "http://research.microsoft.com/apps/pubs/default.aspx?id=155416", "http://research.microsoft.com/pubs/155416/kinectfusion-uist-comp.pdf"], "t": "KinectFusion: real-time 3D reconstruction and interaction using a moving depth camera", "y": 2011, "rn": 24}, {"a": ["Leonard Kaufman", "P. Rousseeuw"], "b": "", "cn": 2937, "i": 696119, "k": ["Cluster Analysis"], "p": ["http://adsabs.harvard.edu/abs/1990fgda.book.....K"], "t": "Finding Groups in Data: An Introduction to Cluster Analysis", "y": 1990, "rn": 0}, {"a": ["Aude Oliva", "Antonio Torralba"], "b": "In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimen- sional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that", "cn": 662, "i": 51645, "k": ["Computer Model", "Energy Spectrum", "Individual Object", "Model Generation", "Natural Images", "Principal Component", "Spatial Structure"], "p": ["http://www.cnbc.cmu.edu/cns/papers/Oliva-Torralba-IJCV-01.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv42.html#OlivaT01"], "t": "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope", "v": "IJCV", "y": 2001, "rn": 48}, {"a": ["David Nist\u00e9r"], "b": "", "cn": 390, "i": 4247666, "k": ["Camera Calibration", "Efficient Algorithm", "Motion Estimation", "Relative Orientation", "Scene Reconstruction", "Structure and Motion", "Structure From Motion", "Real Time", "Real Time Systems", "Camera Motion"], "p": ["http://csdl.computer.org/comp/proceedings/cvpr/2003/1900/02/190020195abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1288525", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01288525", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1211470", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01211470", "http://www.vis.uky.edu/~dnister/Publications/2004/5pointJournal/SINGLES2.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1288525", "http://www.vis.uky.edu/~dnister/Publications/2003/5point/nisterd_efficient.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2003-2.html#Nister03", "http://www-cvpr.iai.uni-bonn.de/kolev/papers/nister_five-point.pdf", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2004.17", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami26.html#Nister04"], "t": "An Efficient Solution to the Five-Point Relative Pose Problem", "v": "CVPR", "y": 2003, "rn": 47}, {"a": ["Andrew Harltey", "Andrew Zisserman"], "b": "", "cn": 382, "i": 39252170, "k": ["Computer Vision", "Multiple View Geometry"], "p": [], "t": "Multiple view geometry in computer vision (2. ed.)", "y": 2006, "rn": 0}, {"a": ["Frederik Schaffalitzky", "Andrew Zisserman"], "b": "There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views. In this paper we investigate the problem of establishing relative viewpoints given a large number", "cn": 197, "i": 509526, "k": ["Image Sequence", "Multiple Views"], "p": ["http://www.springerlink.com/content/w9j85ghr5q90d7f3", "http://www.cse.unr.edu/~bebis/CS773C/ObjectRecognition/Papers/Schaffalitzky02.pdf"], "t": "Multi-view Matching for Unordered Image Sets, or \"How Do I Organize My Holiday Snaps?", "v": "ECCV", "y": 2002, "rn": 24}, {"a": ["Sing Kang", "Richard Szeliski", "Jinxiang Chai"], "b": "While stereo matching was originally formulated as the recovery of 3D shape from a pair of images, it is now gen- erally recognized that using more than two images can dra- matically improve the quality of the reconstruction. Unfor- tunately, as more images are added, the prevalence of semi- occluded regions (pixels visible in some but not all images) also", "cn": 170, "i": 1321435, "k": ["Energy Minimization", "multi-view stereo", "Stereo Matching"], "p": ["http://www.cs.cmu.edu/~jchai/papers/cvpr01-stereo.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990462", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00990462", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2001.990462", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2001-1.html#KangSC01", "https://research.microsoft.com/pubs/69876/tr-2001-80.pdf", "http://research.microsoft.com/pubs/69876/tr-2001-80.pdf", "https://research.microsoft.com/en-us/um/people/sbkang/publications/cvpr01-stereo.pdf", "https://research.microsoft.com/en-us/um/people/sbkang/publications/MSR-TR-2001-80.pdf", "http://faculty.cs.tamu.edu/jchai/papers/cvpr01-stereo.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=69876"], "t": "Handling Occlusions in Dense Multi-view Stereo", "v": "CVPR", "y": 2001, "rn": 58}, {"a": ["Richard Szeliski"], "b": "", "cn": 158, "i": 4113727, "k": ["Image Alignment", "Large Scale"], "p": ["http://dx.doi.org/10.1561/0600000009", "http://www.nowpublishers.com/product.aspx?product=CGV&doi=0600000009", "http://www.informatik.uni-trier.de/~ley/db/journals/ftcgv/ftcgv2.html#Szeliski06", "http://www1.idc.ac.il/toky/CompPhoto-09/Handouts/Szeliski-Tutorial-TR06.pdf", "http://www.cs.huji.ac.il/course/2005/impr/articles/MSR-TR-2004-92.pdf", "http://www.image2003.com/paper/down/21812511420076141029477929736.pdf", "http://faculty.cse.tamu.edu/jchai/CPSC641/MSR-TR-2004-92-Jan26.pdf", "http://pages.cs.wisc.edu/~dyer/cs638/papers/szeliski-alignment-tutorial.pdf", "http://robots.stanford.edu/cs223b05/MSR-TR-2004-92-Jan26.pdf", "http://graphics.cs.cmu.edu/courses/15-463/2004_fall/www/Papers/MSR-TR-2004-92-Sep27.pdf", "http://morse.cs.byu.edu/750/papers/tr-2004-92.pdf", "http://research.microsoft.com/pubs/70092/tr-2004-92.pdf", "https://research.microsoft.com/pubs/70092/tr-2004-92.pdf", "http://semtle.kumoh.ac.kr/%7Ejindongp/alignment.pdf", "http://pages.cs.wisc.edu/~dyer/ai-qual/szeliski-tr06.pdf"], "t": "Image Alignment and Stitching: A Tutorial", "v": "FTCGV", "y": 2006, "rn": 266}, {"a": ["Ruigang Yang", "Marc Pollefeys"], "b": "In this paper a stereo algorithm suitable for implementa- tion on commodity graphics hardware is presented. This is important since it allows to free up the main proces- sor for other tasks including high-level interpretation of the stereo results. Our algorithm relies on the traditional sum-of-square-differences (SSD) dissimilarity measure b e- tween correlation windows. To achieve good results close to", "cn": 140, "i": 1788314, "k": ["Dissimilarity Measure", "Graphics Hardware", "Multi Resolution", "Real Time", "Sum of Squared Difference"], "p": ["http://www.cs.unc.edu/%7Emarc/pubs/YangCVPR03.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01211356", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1211356", "http://www.inf.ethz.ch/personal/pomarc/pubs/YangCVPR03.pdf", "http://csdl.computer.org/comp/proceedings/cvpr/2003/1900/01/190010211abs.htm", "http://www.vis.uky.edu/~ryang/publications/cvpr03-main.pdf", "http://galaga.netlab.uky.edu/~ryang/publications/cvpr03-main.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2003-1.html#YangP03", "http://wwwx.cs.unc.edu/Research/ootf/publications/Yang_CVPR03.pdf", "http://www.cs.unc.edu/Research/ootf/publications/Yang_CVPR03.pdf"], "t": "Multi-Resolution Real-Time Stereo on Commodity Graphics Hardware", "v": "CVPR", "y": 2003, "rn": 17}, {"a": ["Alexandr Andoni", "Piotr Indyk"], "b": "The goal of this article is twofold. In the first part, we survey a family of nearest neighbor algorithms that are based on the concept of locality- sensitive hashing. Many of these algorithm have already been successfully applied in a variety of practical scenarios. In the second part of this arti- cle, we describe a recently discovered hashing-based algorithm, for", "cn": 137, "i": 2430612, "k": ["Efficient Algorithm", "Euclidean Space", "High Dimension", "Locality Sensitive Hashing", "Approximate Nearest Neighbor", "Nearest Neighbor"], "p": ["http://www.mit.edu/~andoni/papers/cSquared.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4031381", "http://www.dcs.qmw.ac.uk/~ywang/download/p117-andoni.pdf", "http://web.mit.edu/andoni/www/papers/cSquared.pdf", "http://doi.ieeecomputersociety.org/10.1109/FOCS.2006.49", "http://www.informatik.uni-trier.de/~ley/db/conf/focs/focs2006.html#AndoniI06", "http://people.csail.mit.edu/indyk/p117-andoni.pdf", "http://cchen1.csie.ntust.edu.tw/students/2009/near-optimal%20hashing%20algorithms%20for%20near%20neighbor%20problem%20in%20high%20dimensions.pdf"], "t": "Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions", "v": "FOCS", "y": 2006, "rn": 43}, {"a": ["M. Lourakis", "A. Argyros"], "b": "Abstract: This paper presents the design andexplains the use of sba, a publicly available C/C++ software package for genericbundle adjustment based on the sparse Levenberg-Marquardt algorithm", "cn": 115, "i": 2138829, "k": ["Bundle Adjustment", "Design and Implementation", "Software Package", "levenberg marquardt"], "p": [], "t": "The design and implementation of a generic sparse bundle adjustment software package based on the Levenberg-Marquardt algorithm", "y": 2004, "rn": 13}, {"a": ["Noah Snavely", "Steven Seitz", "Richard Szeliski"], "c": [13934003, 13995468, 5678802, 13255522, 13255826, 6442578, 14375552, 39261412, 5829152, 6044558, 13995212, 13995291, 39226128, 39261556, 6368054, 6385092, 6579055, 42659283, 50270021, 4963388, 14373795, 39327733, 51040908, 51098554, 51108072, 51108234, 13995350, 15213464, 39235919, 39273961, 39282597, 40169505, 50985963, 51000605, 6062656, 6084698, 6139720, 13760298, 50098360, 6463412, 61402021, 15271315, 39230199, 39277596, 39326590, 39327348, 48871459, 51080347, 51080355, 51080365, 51098559, 51103527, 51107972, 51108155, 51108350, 51114381, 51117991, 51147849, 51148028, 51180108, 51187750, 13302522, 13326182, 13759896, 13761077, 13996292, 13997094, 14084027, 14084717, 14140376, 18572126, 39231779, 39256540, 39256559, 39256695, 39267849, 39286046, 39291408, 39297783, 50919800, 50988860, 51015970, 51022527, 61402281, 6030280, 6063628, 6453708, 39265973, 50782766, 50782988, 50783011, 50783063, 50867169, 50098346, 50098492, 49931784, 49908791, 5715456, 6892613, 14332654, 47673760, 48050520, 48329627, 48396525, 48455104, 48491054, 48844328, 49321167], "b": "There are billions of photographs on the Inter- net, comprising the largest and most diverse photo collec- tion ever assembled. How can computer vision researchers exploit this imagery? This paper explores this question from the standpoint of 3D scene modeling and visualization. We present structure-from-motion and image-based rendering algorithms that operate on hundreds of images downloaded as a result of", "cn": 108, "i": 4389580, "tw": ["image", "camera", "photo", "images", "photos", "set", "points", "computer", "scene", "user", "proceedings", "conference", "vision", "system", "data", "international", "reconstruction", "matching", "view", "feature", "object", "point", "cameras", "number", "techniques", "large", "vis", "comput", "int", "pair", "project", "work", "parameters", "sfm", "initial", "annotation", "photographs", "algorithm", "compute", "rendering", "motion", "time", "graph", "internet", "search", "imagery", "connectivity", "focal", "journal", "selected", "approach", "sparse", "views", "matches", "single", "video", "estimate", "digital", "map", "siggraph", "model", "clusters", "sets", "bundle", "virtual", "visible", "current", "ieee", "pane", "recovered", "described", "viewing", "structure", "great", "tools", "length", "based", "van", "algorithms", "three", "collections", "existing", "transfer", "features", "modeling", "inside", "navigation", "live", "zisserman", "locations", "threshold", "running", "plane", "reprojection", "ccurr", "input", "registered", "ransac", "reconstructed", "geometry"], "k": ["3d model", "3d navigation", "3d scene analysis", "Computer Vision", "Image Based Rendering", "Image Search", "Photo Collection", "Structure From Motion"], "p": ["http://phototour.cs.washington.edu/ModelingTheWorld_ijcv07.pdf", "http://www.springerlink.com/content/55m8034t78051qt8", "http://www.springerlink.com/index/55m8034t78051qt8.pdf", "http://www.springerlink.com/index/10.1007/s11263-007-0107-3", "http://www.springerlink.com/index/pdf/10.1007/s11263-007-0107-3", "http://dx.doi.org/10.1007/s11263-007-0107-3", "https://research.microsoft.com/pubs/74036/Snavely-IJCV08.pdf", "http://research.microsoft.com/pubs/74036/Snavely-IJCV08.pdf", "http://www.cs.cornell.edu/~snavely/publications/papers/snavely_ijcv07.pdf", "http://grail.cs.washington.edu/pub/papers/snavely2008mtw.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv80.html#SnavelySS08", "http://research.microsoft.com/apps/pubs/default.aspx?id=74036"], "r": [1942580, 771993, 1277722, 333855, 3157575, 784340, 107461, 261036, 3737239, 1714728, 3157577, 1286329, 309743, 392049, 498973, 1796435, 2386436, 607785, 289602, 2167392, 89287, 8858, 3157574, 787050, 96972, 799809, 450101, 1232819, 285131, 553615, 4247666, 4389503, 2175137, 3428182, 1714693, 1796633, 125794, 2167171, 120814, 784352, 1796766, 123647, 1399187, 450709, 509526, 652475, 1714694, 1986915, 2150695, 2427508, 884065, 4113727, 438956, 4415678, 216768, 2138829, 438921, 4361726, 14570985, 902742, 1714708, 2031616, 6104354, 1796523, 1979733, 50368399, 33118, 4415720, 2072090, 1872713, 650543, 1989291, 2510621, 4253634, 2412651, 1242180, 660625, 776850, 15271083, 2364112, 509689, 1594255, 1842384, 1850038, 17385, 4113880, 647633, 2368250, 4143357, 15271193], "t": "Modeling the World from Internet Photo Collections", "v": "IJCV", "y": 2008, "rn": 90, "h": ["resources/4389580/thumb-0.png", "resources/4389580/thumb-1.png", "resources/4389580/thumb-2.png", "resources/4389580/thumb-3.png", "resources/4389580/thumb-4.png", "resources/4389580/thumb-5.png", "resources/4389580/thumb-6.png", "resources/4389580/thumb-7.png", "resources/4389580/thumb-8.png", "resources/4389580/thumb-9.png", "resources/4389580/thumb-10.png", "resources/4389580/thumb-11.png", "resources/4389580/thumb-12.png", "resources/4389580/thumb-13.png", "resources/4389580/thumb-14.png", "resources/4389580/thumb-15.png", "resources/4389580/thumb-16.png", "resources/4389580/thumb-17.png", "resources/4389580/thumb-18.png", "resources/4389580/thumb-19.png", "resources/4389580/thumb-20.png", "resources/4389580/thumb-21.png"]}, {"a": ["Alexandr Andoni", "Piotr Indyk"], "b": "Abstract We present an algorithm,for the c-approximate nearest neighbor problem in ad-dimensional Euclidean space, achieving query time ofO(dn. Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders,for the Leech Lattice.", "cn": 104, "i": 4141389, "k": ["Euclidean Space", "High Dimension", "Approximate Nearest Neighbor"], "p": ["http://portal.acm.org/citation.cfm?doid=1327452.1327494", "http://portal.acm.org/citation.cfm?id=1327494", "http://portal.acm.org/ft_gateway.cfm?id=1327494&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.informatik.uni-trier.de/~ley/db/journals/cacm/cacm51.html#AndoniI08", "http://doi.acm.org/10.1145/1327452.1327494"], "t": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions", "v": "CACM", "y": 2008, "rn": 45}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "This paper proposes a novel algorithm for calibrated multi-view stereopsis that outputs a (quasi) dense set of rectan- gular patches covering the surfaces visible in the input images. This algorithm does not require any initialization in the form of a bounding volume, and it detects and discards automatically out- liers and obstacles. It does not perform any smoothing across nearby", "cn": 92, "i": 4248108, "k": ["image-based modeling"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270271", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270271", "http://dx.doi.org/10.1109/CVPR.2007.383246", "http://www.ece.wisc.edu/~facerec/cameranet/accurate_dense_robust_multiview_stereopsis__furukawa_0278.pdf"], "t": "Accurate, Dense, and Robust Multi-View Stereopsis", "v": "CVPR", "y": 2007, "rn": 16}, {"a": ["Nico Cornelis", "Kurt Cornelis", "Luc Gool"], "b": "Nowadays, GPS-based car navigation systems mainly use speech and aerial views of simplified road maps to guide drivers to their destination. However, drivers often experience difficulties in linking the simple 2D aerial map with the visual impression that they get from the real environment, which is inherently ground-level based. Therefore, supplying realistically textured 3D city models at ground-level proves very", "cn": 40, "i": 2167282, "k": ["3d city model", "High Speed", "Navigation System"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01640913", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1640913", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.118", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-2.html#CornelisCG06"], "t": "Fast Compact City Modeling for Navigation Pre-Visualization", "v": "CVPR", "y": 2006, "rn": 16}, {"a": ["Kai Ni", "Drew Steedly", "Frank Dellaert"], "b": "Large-scale 3D reconstruction has recently received much attention from the computer vision community. Bun- dle adjustment is a key component of 3D reconstruction problems. However, traditional bundle adjustment algo- rithms require a considerable amount of memory and com- putational resources. In this paper, we present an ex- tremely efficient, inherently out-of-core bundle adjustment algorithm. We decouple the original problem into", "cn": 27, "i": 4271235, "k": ["3d reconstruction", "Bundle Adjustment", "Computer Vision", "Coordinate System", "Cost Function", "Large Scale"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04409085", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4409085", "http://dx.doi.org/10.1109/ICCV.2007.4409085", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#NiSD07"], "t": "Out-of-Core Bundle Adjustment for Large-Scale 3D Reconstruction", "v": "ICCV", "y": 2007, "rn": 16}, {"a": ["Rahul Raguram", "Jan-michael Frahm", "Marc Pollefeys"], "b": "The Random Sample Consensus (RANSAC) algorithm is a popular tool for robust estimation problems in computer vision, primarily\n due to its ability to tolerate a tremendous fraction of outliers. There have been a number of recent efforts that aim to increase\n the efficiency of the standard RANSAC algorithm. Relatively fewer efforts, however, have been directed towards formulating\n RANSAC in a", "cn": 25, "i": 4253770, "k": ["Comparative Analysis", "Computer Vision", "Random Sampling", "Real-time Implementation", "Robust Estimator", "Fixed Time", "Real Time"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2008-2.html#RaguramFP08", "http://www.springerlink.com/content/84t23624123q1377", "http://dx.doi.org/10.1007/978-3-540-88688-4_37"], "t": "A Comparative Analysis of RANSAC Techniques Leading to Adaptive Real-Time Random Sample Consensus", "v": "ECCV", "y": 2008, "rn": 11}, {"a": ["Maxim Raginsky", "Svetlana Lazebnik"], "b": "This paper addresses the problem of designing binary codes for high-dimensional data such that vectors that are similar in the original space map to similar bi- nary strings. We introduce a simple distribution-free encoding scheme based on random projections, such that the expected Hamming distance between the bi- nary codes of two vectors is related to the value of a", "cn": 15, "i": 5385706, "k": ["Gaussian Kernel", "Hamming Distance", "High Dimensional Data", "Random Projection", "Space Mapping", "Theoretical Analysis", "Shift Invariant"], "p": ["http://people.ee.duke.edu/~maxim/pubs/raginsky_lazebnik_NIPS09.pdf", "http://books.nips.cc/papers/files/nips22/NIPS2009_0146.pdf"], "t": "Locality-Sensitive Binary Codes from Shift-Invariant Kernels", "v": "NIPS", "y": 0, "rn": 16}, {"a": ["James Philbin", "Andrew Zisserman"], "b": "Automatic organization of large, unordered image collections is an extremely challenging problem with many potential applications. Often, what is required is that images taken in the same place, of the same thing, or of the same person be conceptually grouped together. This work focuses on grouping images containing the same object, despite significant changes in scale, viewpoint and partial occlusions,", "cn": 10, "i": 4719975, "k": ["Clustering Method", "Computer Vision", "Data Mining", "Image Retrieval"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4756143", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04756143", "http://dx.doi.org/10.1109/ICVGIP.2008.103", "http://www.informatik.uni-trier.de/~ley/db/conf/icvgip/icvgip2008.html#PhilbinZ08"], "t": "Object Mining Using a Matching Graph on Very Large Image Collections", "v": "ICVGIP", "y": 2008, "rn": 27}, {"a": ["Christian Beder", "Richard Steffen"], "b": "Algorithms for metric 3d reconstruction of scenes from cali- brated image sequences always require an initialization phase for fixing the scale of the reconstruction. Usually this is done by selecting two frames from the sequence and fixing the length of their base-line. In this paper a quality measure, that is based on the uncertainty of the recon- structed scene points,", "cn": 10, "i": 2425120, "k": ["3d reconstruction", "Image Sequence", "Quality Measures", "Simultaneous Localization and Mapping"], "p": ["http://www.springerlink.com/index/vk3gv636707367g4.pdf", "http://www.springerlink.com/content/vk3gv636707367g4", "http://www.ipb.uni-bonn.de/uploads/tx_ikgpublication/beder06.determining.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/dagm/dagm2006.html#BederS06", "http://dx.doi.org/10.1007/11861898_66"], "t": "Determining an Initial Image Pair for Fixing the Scale of a 3D Reconstruction from an Image Sequence", "v": "", "y": 2006, "rn": 32}, {"a": ["S. Kim", "D. Gallup", "J.-M. Frahm", "A. Akbarzadeh", "Q. Yang", "R. Yang", "D. Nister", "M. Pollefeys"], "b": "This paper introduces a multi-view stereo matcher that gen- erates depth in real-time from a monocular video stream of a static scene. A key feature of our processing pipeline is that it estimates global camera gain changes in the feature tracking stage and eciently compensates for these in the stereo stage without impacting the real-time performance. This is very important", "cn": 8, "i": 4528820, "k": ["Dynamic Range", "Feature Tracking", "Graphic Processing Unit", "multi-view stereo", "Video Streaming", "Real Time"], "p": [], "t": "Gain Adaptive Real-Time Stereo Streaming", "v": "ICVS", "y": 2007, "rn": 22}, {"a": ["Christoph Strecha", "Timo Pylv\u00e4n\u00e4inen", "Pascal Fua"], "b": "Recent approaches to reconstructing city-sized areas from large image collections usually process them all at once and only produce disconnected descriptions of image subsets, which typically correspond to major landmarks. In contrast, we propose a framework that lets us take advantage of the available meta-data to build a single, consistent description from these potentially disconnected descriptions. Furthermore, this description can", "cn": 6, "i": 39261369, "k": ["Image Reconstruction", "Large Scale"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540184", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540184", "http://dx.doi.org/10.1109/CVPR.2010.5540184", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#StrechaPF10"], "t": "Dynamic and scalable large scale image reconstruction", "v": "CVPR", "y": 2010, "rn": 12}, {"a": ["Noah Snavely", "Steven Seitz", "Richard Szeliski"], "b": "We present a system for interactively browsing and exploring large unstructured collections of photographs of a scene using a novel 3D interface. Our system consists of an image-based modeling front end that automatically computes the viewpoint of each photograph as well as a sparse 3D model of the scene and image to model correspondences. Our photo explorer uses image-based rendering", "cn": 5, "i": 39242389, "k": ["3d interface", "3d model", "3d navigation", "Auxiliary Information", "Image Based Rendering", "image-based modeling", "Photo Collection", "Photo Sharing", "Structure From Motion", "Front End"], "p": ["http://portal.acm.org/citation.cfm?id=1141964"], "t": "Photo tourism: exploring photo collections in 3D", "v": "SIGGRAPH", "y": 2006, "rn": 0}, {"a": ["Sudipta Sinha", "Drew Steedly", "Richard Szeliski", "Maneesh Agrawala", "Marc Pollefeys"], "b": "We present an interactive system for generating photorealistic, tex- tured, piecewise-planar 3D models of architectural structures and urban scenes from unordered sets of photographs. To reconstruct 3D geometry in our system, the user draws outlines overlaid on 2D photographs. The 3D structure is then automatically computed by combining the 2D interaction with the multi-view geometric in- formation recovered by performing", "cn": 35, "i": 4415836, "k": ["3d model", "3d structure", "Automatic Generation", "Building Model", "Geometric Structure", "Graph Cut", "Interactive System", "Photo Collection", "Structure From Motion", "Texture Mapping", "Vanishing Point"], "p": ["http://portal.acm.org/citation.cfm?doid=1409060.1409112", "http://portal.acm.org/citation.cfm?id=1409112", "http://portal.acm.org/ft_gateway.cfm?id=1409112&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog27.html#SinhaSSAP08", "http://cs.unc.edu/%7Essinha/pubs/SinhaSIGASIA08.2mb.pdf", "http://doi.acm.org/10.1145/1457515.1409112", "http://vis.berkeley.edu/papers/photoModel/SinhaSIGASIA08.2mb.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=75479", "http://research.microsoft.com/pubs/75479/Sinha-SGA08.pdf"], "t": "Interactive 3D architectural modeling from unordered photo collections", "v": "TOG", "y": 2008, "rn": 32}, {"a": ["Yasutaka Furukawa", "Brian Curless", "Steven Seitz", "Richard Szeliski"], "c": [13934003, 13334333, 13765282, 14375552, 15271322, 39261244, 39262452, 39261277, 39261608, 57172348, 39277589, 51080349, 51080361, 51090557, 51099842, 51100356, 51103527, 51108243, 51143436, 51147849, 51147996, 13334301, 13510170, 14356325, 39244561, 39244563, 48871443, 50891575, 61402281, 48822813], "b": "This paper proposes a fully automated 3D reconstruction and visualization system for architectural scenes (interiors and exteriors). The reconstruction of indoor environments from photographs is particularly challenging due to texture-poor planar surfaces such as uniformly-painted walls. Our system first uses structure-from-motion, multi-view stereo, and a stereo algorithm specifically designed for Manhattan-world scenes (scenes consisting predominantly of piece-wise planar surfaces with", "cn": 30, "i": 39265949, "tw": ["depth", "voxel", "system", "grid", "reconstruction", "surface", "maps", "mvs", "map", "number", "voxels", "stereo", "reconstructed", "images", "input", "set", "algorithm", "manhattan-world", "figure", "term", "model", "axis-aligned", "house", "surfaces", "architectural", "interior", "volume", "resolution", "mesh", "scenes", "points", "image", "models", "small", "reconstructing", "dominant", "boundary", "faces", "simple", "exterior", "visualization", "camera", "minimum", "approaches", "note", "multi-view", "ground", "approach", "image-based", "entire", "pixel", "oriented", "gallery", "reconstruct", "volumetric", "sub-voxel", "scale", "integration", "time", "slice", "table", "amount", "aligned", "high", "effects", "geometry", "plane", "geometric", "modeling", "evidence", "planar", "pruning", "planes", "building", "space", "global", "denotes", "bounding", "solution", "full", "visibility", "control", "algorithms", "produces", "scene", "walls", "smoothness", "rendering", "fully", "energy", "optical", "viewer", "plan", "minimum-volume", "based", "texture", "three", "binary", "dense", "step"], "k": ["3d model", "3d reconstruction", "Computer Vision", "Depth Map", "Indoor Environment", "multi-view stereo", "Structure From Motion", "Visual System"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459145", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459145", "http://research.microsoft.com/apps/pubs/default.aspx?id=101030", "http://research.microsoft.com/pubs/101030/Furukawa-ICCV09.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459145", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#FurukawaCSS09"], "r": [883686, 261036, 309743, 2175137, 125794, 2167171, 2175112, 3582575, 3699802, 1789051, 4389476, 4389472, 175382, 4271345, 4415774, 4415836, 14418800, 4253852, 4248121], "t": "Reconstructing building interiors from images", "v": "ICCV", "y": 2009, "rn": 19, "h": ["resources/39265949/thumb-0.png", "resources/39265949/thumb-1.png", "resources/39265949/thumb-2.png", "resources/39265949/thumb-3.png", "resources/39265949/thumb-4.png", "resources/39265949/thumb-5.png", "resources/39265949/thumb-6.png", "resources/39265949/thumb-7.png"]}, {"a": ["Arnold Irschara", "Christopher Zach", "Jan-michael Frahm", "Horst Bischof"], "b": "Efficient view registration with respect to a given 3D re- construction has many applications like inside-out tracking in indoor and outdoor environments, and geo-locating im- ages from large photo collections. We present a fast loca- tion recognition technique based on structure from motion point clouds. Vocabulary tree-based indexing of features directly returns relevant fragments of 3D models instead of documents", "cn": 24, "i": 6368072, "k": ["3d model", "Graphic Processing Unit", "Image Database", "Perforation", "Photo Collection", "Point Cloud", "Structure From Motion", "Urban Modeling", "Real Time"], "p": ["http://cs.unc.edu/~cmzach/pdf/cvpr2009b-preprint.pdf", "http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206587", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#IrscharaZFB09"], "t": "From structure-from-motion point clouds to fast location recognition", "v": "CVPR", "y": 2009, "rn": 29}, {"a": ["Changchang Wu", "Brian Clipp", "Xiaowei Li", "Jan-michael Frahm", "Marc Pollefeys"], "b": "The robust alignment of images and scenes seen from widely different viewpoints is an important challenge for camera and scene reconstruction. This paper introduces a novel class of viewpoint independent local features for robust registration and novel algorithms to use the rich in- formation of the new features for 3D scene alignment and large scale scene reconstruction. The key point", "cn": 24, "i": 4704856, "k": ["3d model", "Camera Motion", "Invariant Feature", "Large Scale", "Local Features", "Matching Method", "Scene Reconstruction", "Similarity Transformation", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587501", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587501", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#WuCLFP08", "http://dx.doi.org/10.1109/CVPR.2008.4587501", "http://www.cs.unc.edu/~bclipp/papers/WuCVPR08.pdf"], "t": "3D model matching with Viewpoint-Invariant Patches (VIP)", "v": "CVPR", "y": 2008, "rn": 22}, {"a": ["Richard Newcombe", "Andrew Davison"], "b": "We present a method which enables rapid and dense reconstruction of scenes browsed by a single live camera. We take point-based real-time structure from motion (SFM) as our starting point, generating accurate 3D camera pose estimates and a sparse point cloud. Our main novel contribution is to use an approximate but smooth base mesh generated from the SFM to predict", "cn": 19, "i": 39261347, "k": ["Augmented Reality", "Depth Map", "Indoor Environment", "Mesh Generation", "Point Cloud", "Pose Estimation", "Reference Frame", "Structure From Motion", "View Synthesis", "Optical Flow", "Real Time"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539794", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539794", "http://dx.doi.org/10.1109/CVPR.2010.5539794", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#NewcombeD10"], "t": "Live dense reconstruction with a single moving camera", "v": "CVPR", "y": 2010, "rn": 18}, {"a": ["Matthew Johnson-Roberson", "Oscar Pizarro", "Stefan Williams", "Ian Mahon"], "b": "", "cn": 18, "i": 13255518, "k": ["Large Scale", "Three-dimensional Reconstruction"], "p": ["http://dx.doi.org/10.1002/rob.20324", "http://doi.wiley.com/10.1002/rob.20324", "http://www.informatik.uni-trier.de/~ley/db/journals/jfr/jfr27.html#Johnson-RobersonPWM10"], "t": "Generation and visualization of large-scale three-dimensional reconstructions from underwater robotic surveys", "v": "JFR", "y": 2010, "rn": 50}, {"a": ["Shi Pu", "George Vosselman"], "b": "This paper presents an automatic method for reconstruction of building fa\u00e7ade models from terrestrial laser scanning data. Important fa\u00e7ade elements such as walls and roofs are distinguished as features. Knowledge about the features\u2019 sizes, positions, orientations, and topology is then introduced to recognize these features in a segmented laser point cloud. An outline polygon of each feature is generated by", "cn": 14, "i": 18572091, "k": ["Building Model", "Building Reconstruction", "Convex Hull", "Feature Extraction", "Knowledge Base", "Least Square", "Point Cloud", "Terrestrial Laser Scanning"], "p": ["http://www.sciencedirect.com/science/article/pii/S0924271609000501", "http://linkinghub.elsevier.com/retrieve/pii/S0924271609000501", "http://adsabs.harvard.edu/abs/2009IJPRS..64..575P"], "t": "Knowledge based reconstruction of building models from terrestrial laser scanning data", "v": "ISPRS J PHOTOGRAMM", "y": 2009, "rn": 9}, {"a": ["David Gallup", "Jan-Michael Frahm", "Marc Pollefeys"], "b": "Piecewise planar models for stereo have recently be- come popular for modeling indoor and urban outdoor scenes. The strong planarity assumption overcomes the challenges presented by poorly textured surfaces, and re- sults in low complexity 3D models for rendering, storage, and transmission. However, such a model performs poorly in the presence of non-planar objects, for example, bushes, trees, and other", "cn": 12, "i": 13934003, "k": ["3d model", "3d reconstruction", "Low Complexity", "Model Performance", "multi-view stereo", "Scene Reconstruction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539804", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539804", "http://www.inf.ethz.ch/personal/pomarc/pubs/GallupCVPR10.pdf", "http://dx.doi.org/10.1109/CVPR.2010.5539804", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#GallupFP10"], "t": "Piecewise Planar and NonPlanar Stereo for Urban Scene Reconstruction", "v": "CVPR", "y": 2010, "rn": 21}, {"a": ["Christopher Zach", "David Gallup", "Jan-Michael Frahm"], "b": "High-performance feature tracking from video input is a valuable tool in many computer vision techniques and mixed reality applications. This work presents a refined and substantially accelerated approach to KLT feature tracking performed on the GPU. Additionally, a global gain ratio between successive frames is estimated to compensate for changes in the camera exposure. The proposed approach achieves more than", "cn": 12, "i": 4970784, "k": ["Computer Vision", "Feature Tracking", "Graphics Processors", "High Performance", "Mixed Reality", "Frames Per Second", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4563089", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04563089", "http://cs.unc.edu/~cmzach/pdf/cvgpu2008-preprint.pdf", "http://www.cs.unc.edu/%7Egallup/papers/CVGPU08.pdf"], "t": "Fast gain-adaptive KLT tracking on the GPU", "v": "CVPR", "y": 2008, "rn": 19}, {"a": ["Davide Scaramuzza", "Friedrich Fraundorfer", "Marc Pollefeys", "Roland Siegwart"], "b": "In structure-from-motion with a single camera it is well known that the scene can be only recovered up to a scale. In order to compute the absolute scale, one needs to know the baseline of the camera motion or the dimension of at least one element in the scene. In this paper, we show that there exists a class of", "cn": 11, "i": 4916690, "k": ["Camera Motion", "Mobile Robot", "nonholonomic constraint", "Structure From Motion", "visual odometry"], "p": ["http://cvg-pub.inf.ethz.ch/WebBIB/papers/2009/fraundorfer2009absolutescale.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459294", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459294", "http://asl.epfl.ch/~scaramuz/research/Davide_Scaramuzza_files/publications/pdf/ICCV09_scaramuzza.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459294", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#ScaramuzzaFPS09"], "t": "Absolute scale in structure from motion from a single vehicle mounted camera by exploiting nonholonomic constraints", "v": "ICCV", "y": 2009, "rn": 13}, {"a": ["Vivek Pradeep", "G\u00e9rard Medioni", "James Weiland"], "b": "", "cn": 7, "i": 6368193, "k": ["Multi Resolution"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#PradeepMW09", "http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206769"], "t": "Visual loop closing using multi-resolution SIFT grids in metric-topological SLAM", "v": "CVPR", "y": 2009, "rn": 22}, {"a": ["Erik Murphy-Chutorian", "Mohan Trivedi"], "b": "We describe a new approach to vision-based 3D object tracking, using appearance-based particle filters to follow 3D model reconstructions. This method is targeted towards modern graphics processors, which are optimized for 3D reconstruction and are capable of highly parallel computation. We discuss an OpenGL implementation of this approach, which uses two rendering passes to update the particle filter weights. In", "cn": 5, "i": 5868185, "k": ["3d model", "3d reconstruction", "Graphics Processors", "Normalized Cross Correlation", "Object Tracking", "Parallel Computer", "Particle Filter", "State Estimation"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4563102", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04563102", "http://cvrr.ucsd.edu/publications/2008/murphychutorian_trivedi_cvgpu08.pdf"], "t": "Particle filtering with rendered models: A two pass approach to multi-object 3D tracking with the GPU", "v": "CVPR", "y": 2008, "rn": 10}, {"a": ["Liangliang Nan", "Andrei Sharf", "Hao Zhang", "Daniel Cohen-Or", "Baoquan Chen"], "b": "We introduce an interactive tool which enables a user to quickly assemble an architectural model directly over a 3D point cloud acquired from large-scale scanning of an urban scene. The user loosely defines and manipulates simple building blocks, which we call SmartBoxes, over the point samples. These boxes quickly snap to their proper locations to conform to common architectural struc-", "cn": 4, "i": 13334333, "k": ["3d point cloud", "Building Block", "Data Fitting", "Discrete Optimization", "Large Scale", "Point Cloud", "On The Fly"], "p": ["http://portal.acm.org/citation.cfm?doid=1778765.1778830", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog29.html#NanSZCC10", "http://portal.acm.org/citation.cfm?doid=1833351.1778830", "http://doi.acm.org/10.1145/1833351.1778830", "http://www.cs.sfu.ca/~haoz/pubs/nan_sig10.pdf"], "t": "SmartBoxes for interactive urban reconstruction", "v": "TOG", "y": 2010, "rn": 26}, {"a": ["Manmohan Chandraker", "Jongwoo Limy", "David Kriegman"], "b": "We present a fast and robust system for estimating struc- ture and motion using a stereo pair, with straight lines as features. Our first set of contributions are efficient algo- rithms to perform this estimation using a few (two or three) lines, which are well-suited for use in a hypothesize-and-test framework. Our second contribution is the design of an efficient", "cn": 4, "i": 5981808, "k": ["Cost Function", "Indoor Environment", "overdetermined system", "Performance Estimation", "Rigid Body Motion", "Structure and Motion", "Structure From Motion"], "p": ["http://vision.ucsd.edu/kriegman-grp/papers/iccv09a.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459390", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459390", "http://vision.ucsd.edu/~manu/pdf/iccv09_linesfm.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459390", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#ChandrakerLK09"], "t": "Moving in stereo: Efficient structure and motion using lines", "v": "ICCV", "y": 2009, "rn": 18}, {"a": ["Michela Farenzena", "Andrea Fusiello", "Riccardo Gherardi"], "b": "This papers introduces a novel hierarchical scheme for computing Structure and Motion. The images are organized into a tree with agglomerative clustering, using a measure of overlap as the distance. The reconstruction then follows this tree from the leaves to the root. As a result, the problems is broken into smaller instances, which are then separately solved and combined. Compared", "cn": 4, "i": 6804572, "k": ["Hierarchical Clustering", "Structure and Motion"], "p": ["http://profs.sci.univr.it/~fusiello/papers/3dim09.pdf"], "t": "Structure-and-motion Pipeline on a Hierarchical Cluster Tree", "y": 2009, "rn": 32}, {"a": ["Jianxiong Xiao", "Fang Ping", "TanPeng Zhao", "Eyal Ofek"], "b": "We propose in this paper a semi-automatic image-based approach to facade modeling that uses images captured along streets and re- lies on structure from motion to recover camera positions and point clouds automatically as the initial stage for modeling. We start by considering a building facade as a flat rectangular plane or a developable surface with an associated texture image", "cn": 4, "i": 12173560, "k": ["3d point cloud", "Building Model", "Developable Surface", "Directed Acyclic Graph", "Image Compositing", "image-based modeling", "Point Cloud", "Structure From Motion", "User Feedback", "Bottom Up", "Top Down"], "p": ["http://web.mit.edu/jxiao/Public/publication/2008/TOG_facade/paper_low-res.pdf"], "t": "Image-based Facade Modeling", "v": "TOG", "y": 0, "rn": 30}, {"a": ["Lazaros Nalpantidis", "Antonios Gasteratos"], "b": "Many robotic and machine-vision applications rely on the accurate results of stereo correspondence algorithms. However, difficult environmental conditions, such as differentiations in illumination depending on the viewpoint, heavily affect the stereo algorithms\u2019 performance. This work proposes a new illumination-invariant dissimilarity measure in order to substitute the established intensity-based ones. The proposed measure can be adopted by almost any of the", "cn": 3, "i": 13328913, "k": ["Color Space", "Dissimilarity Measure", "Environmental Conditions", "Illumination Invariance", "Machine Vision", "Stereo Vision"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/ivc/ivc28.html#NalpantidisG10", "http://www.sciencedirect.com/science/article/pii/S0262885609002674", "http://dx.doi.org/10.1016/j.imavis.2009.11.011", "http://linkinghub.elsevier.com/retrieve/pii/S0262885609002674"], "t": "Stereo vision for robotic applications in the presence of non-ideal lighting conditions", "v": "IVC", "y": 2010, "rn": 25}, {"a": ["Andreas Geiger"], "b": "Marking-based lane recognition requires an unobstructed view onto the road. In practice however, heavy traffic often constrains the visual field, especially in urban scenarios such as urban crossroads. In this paper we present a novel approach to road mosaicing for dynamic environments. Our method is based on a multistage registration procedure and uses blending techniques. We show that under modest", "cn": 3, "i": 50767458, "k": ["Dynamic Environment", "Heavy Traffic", "Image Sequence", "Urban Environment", "Field of View", "Visual Field"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05164267", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5164267"], "t": "Monocular road mosaicing for urban environments", "v": "IV", "y": 2009, "rn": 14}, {"a": ["Soonmin Bae", "Aseem Agarwala", "Fr\u00e9do Durand"], "b": "Rephotographers aim to recapture an existing photograph from the same viewpoint. A historical photograph paired with a well-aligned modern rephotograph can serve as a remarkable visualization of the passage of time. However, the task of rephotography is tedious and often imprecise, because reproducing the viewpoint of the original photograph is challenging. The rephotographer must disambiguate between the six degrees of", "cn": 2, "i": 13334229, "k": ["Computer Vision", "Degree of Freedom", "Pose Estimation", "User Study", "Visualization Technique", "Real Time"], "p": ["http://doi.acm.org/10.1145/1805964.1805968", "http://portal.acm.org/citation.cfm?id=1805968", "http://portal.acm.org/ft_gateway.cfm?id=1805968&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?doid=1805964.1805968", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog29.html#BaeAD10", "http://agarwala.org/Other/soonmin.pdf", "http://dl.acm.org/citation.cfm?id=1805968"], "t": "Computational rephotography", "v": "TOG", "y": 2010, "rn": 37}, {"a": ["Vivek Pradeep", "Gerard Medioni", "James Weiland"], "b": "We present a head-mounted, stereo-vision based navigational assistance device for the visually impaired. The head-mounted design enables our subjects to stand and scan the scene for integrating wide-field information, compared to shoulder or waist-mounted designs in literature which require body rotations. In order to extract and maintain orientation information for creating a sense of egocentricity in blind users, we incorporate", "cn": 2, "i": 14005185, "k": ["assistive device", "Blind Users", "Pose Estimation", "Robot Vision", "Stereo Vision", "Tactile Interface", "Visual Impairment", "visual odometry"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5543579", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05543579"], "t": "Robot Vision for the Visually Impaired", "v": "CVPR", "y": 2010, "rn": 25}, {"a": ["Hideyuki Kume", "Takafumi Taketomi", "Tomokazu Sato", "Naokazu Yokoya"], "b": "This paper proposes a method for estimating extrinsic camera parameters using video images and position data acquired by GPS. In conventional methods, the accuracy of the estimated camera position largely depends on the accuracy of GPS positioning data because they assume that GPS position error is very small or normally distributed. However, the actual error of GPS positioning easily grows", "cn": 2, "i": 14084978, "k": ["Energy Function", "Normal Distribution", "Parameter Estimation", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597673", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05597673", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2010.html#KumeTSY10", "http://dx.doi.org/10.1109/ICPR.2010.954"], "t": "Extrinsic Camera Parameter Estimation Using Video Images and GPS Considering GPS Positioning Accuracy", "v": "ICPR", "y": 2010, "rn": 9}, {"a": ["Lu Wang", "Ulrich Neumann"], "b": "Airborne LiDAR technology draws increasing interest in large-scale 3D urban modeling in recent years. 3D Li- DAR data typically has no texture information. To gener- ate photo-realistic 3D models, oblique aerial images are needed for texture mapping, in which the key step is to ob- tain accurate registration between aerial images and un- textured 3D LiDAR data. We present a", "cn": 2, "i": 5387450, "k": ["3d model", "Aerial Image", "Airborne Lidar", "Feature Detection", "Large Scale", "Recovery Rate", "Texture Mapping", "Urban Modeling"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206600", "http://graphics.usc.edu/cgit/pdf/papers/lu_CVPR09.pdf", "http://graphics.usc.edu/~luwang/pdf/lu_CVPR09.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#WangN09"], "t": "A robust approach for automatic registration of aerial images with untextured aerial LiDAR data", "v": "CVPR", "y": 2009, "rn": 19}, {"a": ["Xiaofeng Ren", "Matthai Philipose"], "b": "Recognizing objects being manipulated in hands can provide essential information about a person's activities and have far-reaching impacts on the application of vision in everyday life. The egocentric viewpoint from a wearable camera has unique advantages in recognizing handled objects, such as having a close view and seeing objects in their natural positions. We collect a comprehensive dataset and analyze", "cn": 2, "i": 6293384, "k": ["Everyday Life", "Human Subjects", "Motion Blur", "Object Recognition", "Quantitative Evaluation", "Upper Bound", "Video Streaming"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5204360", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05204360", "http://www.seattle.intel-research.net/egovision09/papers/01.pdf"], "t": "Egocentric recognition of handled objects: Benchmark and analysis", "v": "CVPR", "y": 2009, "rn": 32}, {"a": ["Sean Hum", "Michal Okoniewski", "R. Davies"], "b": "This paper presents a resonant electrode structure that can be employed in optical modulator designs to improve the optical response of the modulator over a narrow frequency band, and improve the performance of optical radio systems. A simple model of the structure is developed, and experimental results presented.", "cn": 2, "i": 50270021, "k": ["Optical Modulator", "Radio On Fiber"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1017800", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01017800"], "t": "Modulator structures for radio-on-fiber applications", "v": "MIKON", "y": 2002, "rn": 30}, {"a": ["Ioannis Stamos"], "b": "The photorealistic modeling of large-scale scenes, such as urban structures, requires a fusion of range sensing techno logy and traditional digital photography. This paper summarizes the contributi ons of our group in that area. We present a system that integra tes automated 3D-to-3D and 2D-to-3D registration techniques, with multiview geometry for the photorealistic modeling of urban scenes. The 3D range", "cn": 2, "i": 5370035, "k": ["3d model", "3d point cloud", "3d registration", "Digital Photography", "Human Interaction", "Large Scale", "Range Image", "Structure From Motion", "Texture Mapping", "Urban Environment", "Urban Structure", "Rotation Scaling and Translation"], "p": ["http://www.commission5.isprs.org/3darch09/pdf/stamos.pdf", "http://www.isprs.org/commission5/3darch09/pdf/stamos.pdf"], "t": "AUTOMATED 3D MODELING OF URBAN ENVIRONMENTS", "y": 0, "rn": 14}, {"a": ["Yekeun Jeong", "Yunsu Bok", "Jun-Sik Kim", "In-So Kweon"], "b": "In this paper, we present an accurate and robust 6D SLAM method that uses multiple 2D sensors, i.e. perspective cameras and planar laser scanners. We have investigated strengths and weaknesses of those two sensors for 6D SLAM by conducting specifically designed experiments, and found that the sensors can complement each other. In order to take full advantages of each approach,", "cn": 1, "i": 51099850, "k": ["Bundle Adjustment", "Large Scale", "Laser Scanner", "Motion Estimation", "Simultaneous Localization and Mapping", "Structure From Motion", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05979568", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5979568"], "t": "Complementation of cameras and lasers for accurate 6D SLAM: From correspondences to bundle adjustment", "v": "ICRA", "y": 2011, "rn": 25}, {"a": ["Qian Zhang", "Taeg Whangbo"], "b": "\n As usual, laser scanning and structured light projection represent the optical measurement technologies mostly employed for\n 3D digitizing of the human body surface. The disadvantage is higher costs of producing hardware components with more precision.\n This paper presents a solution to the problem of in vivo human skin micro-surface reconstruction based on stereo matching.\n Skin images are taken by camera", "cn": 1, "i": 6046964, "k": ["Feature Detection", "Human Body", "Human Skin", "Laser Scanning", "Prior Knowledge", "Stereo Matching", "Stereo Vision", "Structured Light", "Surface Reconstruction", "Triangular Mesh"], "p": ["http://www.springerlink.com/content/el70380wl8184322", "http://www.springerlink.com/index/el70380wl8184322.pdf", "http://dx.doi.org/10.1007/978-3-642-11301-7_6", "http://www.informatik.uni-trier.de/~ley/db/conf/mmm/mmm2010.html#ZhangW10"], "t": "Two Stages Stereo Dense Matching Algorithm for 3D Skin Micro-surface Reconstruction", "v": "MMM", "y": 2010, "rn": 18}, {"a": ["Lazaros Nalpantidis", "Antonios Gasteratos"], "b": "In this paper a novel stereo correspondence algorithm is presented. It incorporates many biologically and psychologically inspired features to an adaptive weighted sum of absolute differences (SAD) framework in order to determine the correct depth of a scene. In addition to ideas already exploited, such as the color information utilization, gestalt laws of proximity and similarity, new ones have been", "cn": 1, "i": 13319666, "k": ["Stereo Vision", "Weighted Sums"], "p": ["http://linkinghub.elsevier.com/retrieve/pii/S0921889010000394", "http://www.sciencedirect.com/science/article/pii/S0921889010000394", "http://dx.doi.org/10.1016/j.robot.2010.02.002", "http://www.informatik.uni-trier.de/~ley/db/journals/ras/ras58.html#NalpantidisG10"], "t": "Biologically and psychophysically inspired adaptive support weights algorithm for stereo correspondence", "v": "RaS", "y": 2010, "rn": 23}, {"a": ["Friedrich Fraundorfer", "Petri Tanskanen", "Marc Pollefeys"], "b": "It this paper we present a novel minimal case solution to the calibrated relative pose problem using 3 point correspondences for the case of two known orientation angles. This case is relevant when a camera is coupled with an inertial measurement unit (IMU) and it recently gained importance with the omnipresence of Smartphones (iPhone, Nokia N900) that are equipped with", "cn": 1, "i": 13995514, "k": ["Degeneration", "Inertial Measurement Unit", "Pose Estimation", "Synthetic Data"], "p": ["http://www.springerlink.com/index/n7g0061u2156l115.pdf", "http://www.springerlink.com/content/n7g0061u2156l115", "http://dx.doi.org/10.1007/978-3-642-15561-1_20", "http://www.inf.ethz.ch/personal/pomarc/pubs/FraundorferECCV10.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-4.html#FraundorferTP10"], "t": "A minimal case solution to the calibrated relative pose problem for the case of two known orientation angles ?", "v": "ECCV", "y": 2010, "rn": 16}, {"a": ["Carlos Vanegas", "Daniel Aliaga", "Bedrich Benes"], "b": "We present a passive computer vision method that exploits existing mapping and navigation databases in order to automatically create 3D building models. Our method defines a grammar for representing changes in building geometry that approximately follow the Manhattan-world assumption which states there is a predominance of three mutually orthogonal directions in the scene. By using multiple calibrated aerial images, we", "cn": 1, "i": 39261277, "k": ["3d building model", "Aerial Image", "Building Reconstruction", "Computer Vision", "Geometric Model"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540190", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540190", "http://dx.doi.org/10.1109/CVPR.2010.5540190", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#VanegasAB10"], "t": "Building reconstruction using manhattan-world grammars", "v": "CVPR", "y": 2010, "rn": 24}, {"a": ["Mirko Nentwig", "M. Stamminger"], "b": "Since the 1980's computer aided engineering (CAE) and simulation (CAS) methods are widely used in the car development process. First the focus was set on crash simulation and car body design. Since a few years due to the rapidly increasing complexity of new electronic systems these techniques are applied in the development and test processes of advanced driving assistance systems", "cn": 1, "i": 50970201, "k": ["Computer Aided Engineering", "Computer Vision", "Cost Reduction", "Cycle Time", "Development Process", "Haar Wavelet", "Image Processing", "Vehicle Detection"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05625005", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5625005"], "t": "A method for the reproduction of vehicle test drives for the simulation based evaluation of image processing algorithms", "v": "ITSC", "y": 2010, "rn": 8}, {"a": ["Yann Morvan", "Carol O'sullivan"], "b": "Panoramic images are very effective at conveying a visual sense of presence at very low cost and great ease of authoring. They are, however, limited in the navigation options they offer, unlike 3D representations. It is therefore desirable to provide pleasing transitions from one panorama to another, or from a panorama to a 3D model. We focus on motions where", "cn": 1, "i": 6084698, "k": ["3d model", "3d representation", "Camera Motion", "Panoramic Image", "User Study", "Area of Interest"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1609972&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1609972", "http://doi.acm.org/10.1145/1609967.1609972", "http://www.informatik.uni-trier.de/~ley/db/journals/tap/tap6.html#MorvanO09a"], "t": "Handling occluders in transitions from panoramic images: A perceptual study", "v": "TAP", "y": 2009, "rn": 19}, {"a": ["Hai-Xia XU", "Yao-Nan WANG", "Xiao-Fang YUAN", "Jiang ZHU", "Wei ZHOU"], "b": "", "cn": 1, "i": 27584281, "k": [], "p": ["http://pub.chinasciencejournal.com/article/getArticleRedirect.action?doiCode=10.3724/SP.J.1004.2009.01140"], "t": "Solution to the P5P Problem with Un-calibrated Camera Based on Vector Difference", "v": "", "y": 2009, "rn": 13}, {"a": ["Radek Grzeszczuk", "Jana Kosecka", "Ramakrishna Vedantham", "Harlan Hile"], "b": "We present a method for automatically constructing compact, photo-realistic architectural 3D models. This method uses simple 3D building outlines obtained from ex- isting GIS databases to bootstrap reconstruction and works with both structured and unstructured image datasets. We propose an optimal view-selection algorithm for selecting a small set of views for texture mapping that best describe the structure, while minimizing", "cn": 1, "i": 5541376, "k": ["3d model", "Large Scale", "Texture Mapping", "Urban Modeling", "Visual Representation", "Real Time"], "p": ["http://research.nokia.com/files/grzeszczuk_3dreco_3dim09.pdf"], "t": "Creating Compact Architectural Models by Geo-registering Image Collections", "y": 0, "rn": 28}, {"a": ["Yixiang Tian", "Qing Zhu", "Markus Gerke", "George Vosselman"], "b": "D city models constructed from ground based data are becoming an interesting and challenging problem as they present the realistic facades, which contain more details than the models constructed from aerial data. Such kind of informa tion is interesting for quite a lot of applications. This paper presents a new meth od for connecting building fa\u00e7ade surface patches t hat", "cn": 1, "i": 6287251, "k": ["Image Sequence", "Knowledge Base", "Structural Model"], "p": ["http://www.isprs.org/commission5/3darch09/pdf/tian_etal.pdf", "http://www.commission5.isprs.org/3darch09/pdf/tian_etal.pdf"], "t": "KNOWLEDGE-BASED TOPOLOGICAL RECONSTRUCTION FOR BUILDING FA\u00c7ADE SURFACE PATCHES", "y": 0, "rn": 9}, {"a": ["Gregor Fabritius", "Jan Kranigg", "Lars Krecklau", "Christopher Manthei", "Alexander Hornung", "Martin Habbecke", "Leif Kobbelt"], "b": "Virtual city models become more and more important in applications like vir- tual city guides, geographic information systems or large scale visualizations, and also play an important role during the design of wireless networks and the simulation of noise distribu- tion or environmental phenomena. However, generating city models of sucient quality with respect to dierent target applications is still an", "cn": 1, "i": 13074431, "k": ["3d city model", "Geographic Information System", "Large Scale", "Model Generation", "Real-time Visualization", "Wireless Network"], "p": ["http://www.graphics.rwth-aachen.de/uploads/media/vrar_01.pdf"], "t": "City Virtualization", "y": 0, "rn": 19}, {"a": ["Yixiang Tian", "Markus Gerke", "George Vosselman", "Qing Zhu"], "b": "Automatic 3D building reconstruction is becoming increasingly important for a number of applications. This paper aims to present\n a new approach for an automatic pipeline to reconstruct surface patches from a video image sequence, which can deal with images\n acquired with an uncalibrated hand held camera. In order to skip the details to get the surface patches that present the", "cn": 1, "i": 48325232, "k": ["Building Reconstruction", "Image Sequence"], "p": ["http://www.springerlink.com/content/v31116u88630m491", "http://www.springerlink.com/index/v31116u88630m491.pdf"], "t": "Automatic Surface Patch Generation from a Video Image Sequence", "y": 0, "rn": 8}, {"a": ["Peter Henry", "Michael Krainin", "Evan Herbst", "Xiaofeng Ren", "Dieter Fox"], "b": "RGB-D cameras (such as the Microsoft Kinect) are novel sensing systems that capture RGB images along with per-pixel depth information. In this paper we investigate how such cameras can be used for building dense 3D maps of indoor environments. Such maps have applications in robot navigation, manipulation, semantic mapping, and telepresence. We present RGB-D Mapping, a full 3D mapping system", "cn": 0, "i": 57172348, "k": ["3d model", "Indoor Environment", "Optimal Algorithm", "Robot Navigation", "Semantic Mapping", "Visual Features"], "p": ["http://dx.doi.org/10.1177/0278364911434148"], "t": "RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments", "v": "IJRR", "y": 2012, "rn": 45}, {"a": ["Andrew Miller", "Vishal Jain", "Joseph Mundy"], "b": "A dense 3-d terrain model obtained using reconstruction methods from aerial images is represented in a probabilistic volumetric framework. The choice of probabilistic representation is to represent inherent ambiguity in reconstruction of surface from images. Such probabilistic representation handles the ambiguity very well but leads to expensive dense volumetric storage. The area coverage required for building 3-d models varies from", "cn": 0, "i": 39230199, "k": ["Aerial Image", "Memory Access", "Real Time Rendering", "Real-time Visualization", "Terrain Modeling"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1964190&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1964190", "http://dl.acm.org/citation.cfm?id=1964190"], "t": "Real-time rendering and dynamic updating of 3-d volumetric data", "y": 2011, "rn": 7}, {"a": ["Thomas Warsop", "Sameer Singh"], "b": "\n In this work, we perform three-dimensional scene recovery from image data capturing railway transportation corridors. Typical\n three-dimensional scene recovery methods initialise recovered feature positions by searching for correspondences between image\n frames. We intend to take advantage of a relationship between image data and recovered scene data to reduce the search space\n traversed when performing such correspondence matching. We build multi-dimensional", "cn": 0, "i": 39277583, "k": ["Data Capture", "Search Space", "Three Dimensional", "Unsupervised Learning", "Visual Features", "Multi Dimensional"], "p": ["http://www.springerlink.com/index/ag775j052w23qh27.pdf", "http://www.springerlink.com/content/ag775j052w23qh27", "http://dx.doi.org/10.1007/978-3-642-21227-7_37", "http://www.informatik.uni-trier.de/~ley/db/conf/scia/scia2011.html#WarsopS11"], "t": "Unsupervised Learning for Improving Efficiency of Dense Three-Dimensional Scene Recovery in Corridor Mapping", "v": "", "y": 2011, "rn": 27}, {"a": ["Dorota Iwaszczuk", "Ludwig Hoegner", "U. Stilla"], "b": "Thermal inspections of buildings contribute to detection of damaged\r\n\tand weak spots in the building hull. 3D spatial reference for this\r\n\tpurpose can be achieved combining infrared images with 3D building\r\n\tmodels via texture mapping. Using terrestrial image sequences from\r\n\ta camera mounted in a mobile platform frontal faces can be captured,\r\n\twhile airborne image sequences can be taken for", "cn": 0, "i": 51043044, "k": ["3d building model", "Image Sequence", "Infrared Imaging", "Point Cloud", "Relative Orientation", "Texture Mapping"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05764710", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5764710"], "t": "Matching of 3D building models with IR images for texture extraction", "v": "JURSE", "y": 2011, "rn": 12}, {"a": ["Antonio Adan", "Daniel Huber"], "b": "Laser scanners are often used to create 3D models of buildings for civil engineering applications. The current manual process is time-consuming and error-prone. This paper presents a method for using laser scanner data to model predominantly planar surfaces, such as walls, floors, and ceilings, despite the presence of significant amounts of clut- ter and occlusion, which occur frequently in natural", "cn": 0, "i": 51080349, "k": ["3d model", "3d reconstruction", "Data Model", "Image Reconstruction", "Indoor Environment", "Laser Scanner", "Point Cloud", "Supervised Learning", "Surface Reconstruction", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955371", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955371"], "t": "3D Reconstruction of Interior Wall Surfaces under Occlusion and Clutter", "v": "3DIMPVT", "y": 2011, "rn": 19}, {"a": ["Duan Yong", "Chen Lei", "Wang Yucheng", "Yang Min", "Qin Xiameng", "He Shaoyang", "Jia Yunde"], "b": "In this paper we present a real-time 3D recovery system using multiple FPGA-based RGBD imagers. The RGBD imager developed in our lab produces color images combined with corresponding dense disparity maps encoding 3D information. Multiple RGBD imagers are externally triggered to sense the 3D world synchronously. The acquired 3D information of a dynamic scene from multiple viewpoints is then streamed", "cn": 0, "i": 51098490, "k": ["3d reconstruction", "Color Image", "Coordinate System", "Depth Map", "Dynamic Scenes", "Large Scale", "Moving Object", "Pc Cluster", "Three Dimensional", "Real Time", "Real Time Systems", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05981680", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5981680"], "t": "A real-time system for 3D recovery of dynamic scene with multiple RGBD imagers", "v": "CVPR", "y": 2011, "rn": 20}, {"a": ["Ali Elqursh", "Ahmed Elgammal"], "b": "We present an algorithm for calibrated camera relative pose estimation from lines. Given three lines with two of the lines parallel and orthogonal to the third we can compute the relative rotation between two images. We can also compute the relative translation from two intersection points. We also present a framework in which such lines can be detected. We evaluate", "cn": 0, "i": 51108122, "k": ["Indoor Environment", "Pose Estimation"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995512", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995512"], "t": "Line-based relative pose estimation", "v": "CVPR", "y": 2011, "rn": 24}, {"a": ["Yunsu Bok", "Dong-Geol Choi", "Yekeun Jeong"], "b": "In this paper, we present a sensor fusion system of cameras and 2D laser sensors for 3D reconstruction. The proposed system is designed to capture data on a fast-moving ground vehicle. The system consists of six cameras and one 2D laser sensor. In order to capture data at high speed, we synchronized all sensors by detecting the laser ray at", "cn": 0, "i": 51148418, "k": ["3d reconstruction", "3d structure", "High Speed", "Image Reconstruction", "Laser Scanning", "Motion Estimation", "Moving Object", "Range Data", "Satellite Image", "Sensor Fusion", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6048740", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06048740"], "t": "Capturing city-level scenes with a synchronized camera-laser fusion sensor", "v": "IROS", "y": 2011, "rn": 13}, {"a": ["Ersin Ozuag", "M. Gullu", "Oguzhan Urhan", "Sarp Erturk"], "b": "This paper presents a metric measurement approach from sequences of images captured from a moving spherical camera without the need of additional equipment, such as laser scanners or motion detection units. The user assists the algorithms with simple inputs to facilitate the measurement process. The operator initially selects a keyframe that contains the object of interest that is to be", "cn": 0, "i": 51155619, "k": ["Laser Scanner", "Motion Detection", "Phase Correlation", "Random Sampling", "Scale Invariant Feature Transform"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6064622", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06064622"], "t": "Metric measurement from street view sequences with simple operator assistance and phase correlation based frame selection", "v": "MLSP", "y": 2011, "rn": 18}, {"a": ["Daniel Neilson", "Yee-Hong Yang"], "b": "Match cost functions are common elements of every stereopsis algorithm that are used to provide a dissimilarity measure between pixels in different images. Global stereopsis algorithms incorporate assumptions about the smoothness of the resulting distance map that can interact with match cost functions in unpredictable ways. In this paper, we present a large-scale study on the relative performance of a", "cn": 0, "i": 51191072, "k": ["Cost Function", "Dissimilarity Measure", "Heuristic Algorithm", "Image Color Analysis", "Large Scale", "Smoothing Method", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5740924", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05740924"], "t": "A Component-Wise Analysis of Constructible Match Cost Functions for Global Stereopsis", "v": "PAMI", "y": 2011, "rn": 30}, {"a": ["Justin Hollands", "Matthew Lamb"], "b": "Objective: The effect of viewpoint on the navigation of complex terrain and on spatial awareness was examined with the use of a simulated remotely operated vehicle.Background: The ability to build terrain models in real time may soon allow remote vehicular control from any viewpoint. A virtual tether couples the viewpoint to the vehicle\u2019s position and orientation, but shows more of", "cn": 0, "i": 57167265, "k": ["Complex Terrain", "Remotely Operated Vehicle", "Spatial Cognition", "Terrain Modeling", "Unmanned Ground Vehicle", "Virtual Environment", "Real Time"], "p": ["http://dx.doi.org/10.1177/0018720811399757"], "t": "Viewpoint Tethering for Remotely Operated Vehicles: Effects on Complex Terrain Navigation and Spatial Awareness", "v": "HUM FACTORS", "y": 2011, "rn": 12}, {"a": ["Nader Salman", "Mariette Yvinec"], "b": "This article describes an original method to reconstruct a 3D scene from a sequence of images. Our approach uses both the dense 3D point cloud extracted by multi-view stereovision and the calibrated images. It combines depth-maps construction in the image planes with surface reconstruction through restricted Delaunay triangulation. The method may handle very large scale outdoor scenes. Its accuracy has", "cn": 0, "i": 13107377, "k": ["3d point cloud", "delaunay triangulation", "Depth Map", "Indexing Terms", "Large Scale", "multi-view stereo", "Multiple Views", "Surface Reconstruction"], "p": ["http://www.ijvr.org/issues/issue1-2010/4.pdf"], "t": "Surface Reconstruction from Multi-View Stereo of Large-Scale Outdoor Scenes", "y": 2010, "rn": 28}, {"a": ["T. Colleu", "St\u00e9phane Pateux", "Luce Morin", "Claude Labit"], "b": "This paper presents a polygon soup representation for multiview data. Starting from a sequence of multiview video plus depth (MVD) data, the proposed quad-based representation takes into account, in a unified manner, different issues such as compactness, compression, and intermediate view synthesis. The representation is extracted from MVD data in two steps. First, a set of 3D quads is extracted", "cn": 0, "i": 13337290, "k": ["3d video", "Compact Representation", "Depth Map", "View Synthesis"], "p": ["http://linkinghub.elsevier.com/retrieve/pii/S1047320310000040", "http://www.sciencedirect.com/science/article/pii/S1047320310000040", "http://dx.doi.org/10.1016/j.jvcir.2010.01.003", "http://www.informatik.uni-trier.de/~ley/db/journals/jvcir/jvcir21.html#ColleuPML10"], "t": "A polygon soup representation for multiview coding", "v": "JVCIR", "y": 2010, "rn": 6}, {"a": ["Chenxi Zhang", "Liang Wang", "Ruigang Yang"], "b": "\n In this paper we present a framework for semantic scene parsing and object recognition based on dense depth maps. Five view-independent\n 3D features that vary with object class are extracted from dense depth maps at a superpixel level for training a classifier\n using randomized decision forest technique. Our formulation integrates multiple features in a Markov Random Field (MRF) framework\n to", "cn": 0, "i": 13995786, "k": ["Depth Map", "Object Recognition", "Video Database", "Markov Random Field"], "p": ["http://www.springerlink.com/index/u5810807m10u760v.pdf", "http://www.springerlink.com/content/u5810807m10u760v", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-4.html#ZhangWY10", "http://dx.doi.org/10.1007/978-3-642-15561-1_51"], "t": "Semantic Segmentation of Urban Scenes Using Dense Depth Maps", "v": "ECCV", "y": 2010, "rn": 20}, {"a": ["Vivek Pradeep", "Jongwoo Lim"], "b": "We describe a novel and robust minimal solver for performing online visual odometry with a stereo rig. The proposed method can compute the underlying camera motion given any arbitrary, mixed combination of point and line correspondences across two stereo views. This facilitates a hybrid visual odometry pipeline that is enhanced by well-localized and reliably-tracked line features while retaining the well-known", "cn": 0, "i": 14005188, "k": ["Camera Motion", "Polynomial System", "visual odometry"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539792", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539792", "http://dx.doi.org/10.1109/CVPR.2010.5539792", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#PradeepL10"], "t": "Egomotion Using Assorted Features", "v": "CVPR", "y": 2010, "rn": 26}, {"a": ["Pekka Koskenkorva", "Juho Kannala", "Sami Brandt"], "b": "This paper proposes a method for computing a quasi-dense set of matching points between three views of a scene. The method takes a sparse set of seed matches between pairs of views as input and then propagates the seeds to neighboring regions. The proposed method is based on the best-first match propagation strategy, which is here extended from two-view matching", "cn": 0, "i": 14085194, "k": ["Depth Map", "Image Matching", "multi-view stereo", "Multiple Views"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05596051", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5596051", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2010.html#KoskenkorvaKB10", "http://dx.doi.org/10.1109/ICPR.2010.203"], "t": "Quasi-dense Wide Baseline Matching for Three Views", "v": "ICPR", "y": 2010, "rn": 14}, {"a": ["Yixiang Tian", "Markus Gerke", "George Vosselman", "Qing Zhu"], "b": "The paper presents an automatic method for the reconstruction of building models from video image sequences. These videos may be recorded using a hand-held camera or a camera mounted on a moving car. Such terrestrial video sequences are economic and flexible. Presenting buildings as geometric models\u2013rather than for instance a representation from a simple meshing of 3D points\u2013enables one to", "cn": 0, "i": 18572126, "k": ["Building Model", "Building Reconstruction", "Geometric Model", "Hybrid Model", "Image Sequence", "Knowledge Base", "Satisfiability", "Structural Model", "Topological Relation"], "p": ["http://www.sciencedirect.com/science/article/pii/S0924271610000419", "http://linkinghub.elsevier.com/retrieve/pii/S0924271610000419", "http://adsabs.harvard.edu/abs/2010IJPRS..65..395T"], "t": "Knowledge-based building reconstruction from terrestrial video sequences", "v": "ISPRS J PHOTOGRAMM", "y": 2010, "rn": 18}, {"a": ["Feng ZHANG", "Li-Min SHI", "Feng-Mei SUN", "Zhan-Yi HU"], "b": "", "cn": 0, "i": 27584491, "k": ["3d reconstruction"], "p": ["http://pub.chinasciencejournal.com/article/getArticleRedirect.action?doiCode=10.3724/SP.J.1004.2010.00625"], "t": "An Image Based 3D Reconstruction System for Large Indoor Scenes", "v": "", "y": 2010, "rn": 9}, {"a": ["Liangliang Nan", "Andrei Sharf", "Hao Zhang", "Daniel Cohen-Or", "Baoquan Chen"], "b": "We introduce an interactive tool which enables a user to quickly assemble an architectural model directly over a 3D point cloud acquired from large-scale scanning of an urban scene. The user loosely defines and manipulates simple building blocks, which we call SmartBoxes, over the point samples. These boxes quickly snap to their proper locations to conform to common architectural structures.", "cn": 0, "i": 39244561, "k": ["3d point cloud", "Building Block", "Data Fitting", "Discrete Optimization", "Large Scale", "Point Cloud", "On The Fly"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1778830&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1778830"], "t": "SmartBoxes for interactive urban reconstruction", "y": 2010, "rn": 26}, {"a": ["Codruta Ancuti", "Cosmin Ancuti", "Philippe Bekaert"], "b": "Matching images taken from widely different viewpoints is still an open problem being extremely challenging. In this paper is presented a new method that manipulates effectively the color in order to improve the matching performances of the well-known SIFT operator for the wide-baseline case. Without exploiting additional information, the algorithm employs a new model that preserves efficiently the initial variations", "cn": 0, "i": 39291490, "k": [], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05495289", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5495289", "http://dx.doi.org/10.1109/ICASSP.2010.5495289", "http://www.informatik.uni-trier.de/~ley/db/conf/icassp/icassp2010.html#AncutiAB10a"], "t": "CC-SIFT: Exploiting chromatic contrast forwide-baseline matching", "v": "ICASSP", "y": 2010, "rn": 13}, {"a": ["I. Umelo", "G. Chen", "E. Teugels", "J. Gr\u00e8ve"], "b": "", "cn": 0, "i": 49573132, "k": ["Drug Resistance", "Non Small Cell Lung Cancer"], "p": ["http://www.sciencedirect.com/science/article/pii/S135963491071911X"], "t": "206 The cis/trans effect of the T790M drug resistant mutation in non-small cell lung cancer", "v": "EJC SUPPL", "y": 2010, "rn": 8}, {"a": ["Qi Pan", "Gerhard Reitmayr", "Edward Rosten", "Tom Drummond"], "b": "Off-line model reconstruction relies on an image collection phase and a slow reconstruction phase, requiring a long time to verify a model obtained from an image sequence is acceptable. Our reconstruction system, ProFORMA, generates 3D models on-line as the input sequence is being collected. As the user rotates the object in front of a stationary camera, generated partial models aid", "cn": 0, "i": 50914006, "k": ["3d model", "3d modelling", "Image Sequence", "Object Model", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5533344", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05533344"], "t": "Rapid 3D modelling from live video", "y": 2010, "rn": 24}, {"a": ["Hongyan Quan"], "b": "Dynamic texture augmentation techniques are widely used. It has been a hot spot in the area of computer vision. Reconstruction is a very important technique in dynamic texture augmentation. In this paper we propose an efficient reconstruction method of dynamic texture video. First we present an efficient structure and motion recovery method for dynamic texture video. On the basis of", "cn": 0, "i": 51009797, "k": ["Computer Vision", "Dynamic Texture", "Hot Spot", "Level Set", "Region Segmentation", "Structure and Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05691428", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5691428"], "t": "A reconstruction method of dynamic texture video", "v": "ICISE", "y": 2010, "rn": 11}, {"a": ["Ludwig Hoegner", "Uwe Stilla"], "b": "Focus of the paper lies on automated texturing of 3d building models\r\n\twith images recorded with infrared (IR) cameras. Therefore, a data\r\n\tfusion of given 3d models and recorded IR image sequences is performed.\r\n\tA relative orientation of the images of the sequence is generated\r\n\tusing Nister's five-point algorithm and image triplets. This results\r\n\tin a point cloud of correspondence", "cn": 0, "i": 5661744, "k": ["3d building model", "3d model", "Electromagnetic Radiation", "Feature Extraction", "Image Sequence", "Infrared", "Ir Spectra", "Least Square", "Minimum Distance", "Mobile Mapping", "Object Recognition", "Point Cloud", "Relative Orientation", "Data Fusion"], "p": ["http://www.pf.bv.tum.de/pub/2009/hoegner_stilla_jurse09_pap.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05137681", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5137681"], "t": "Thermal leakage detection on building facades using infrared texturesgenerated by mobile mapping", "v": "JURSE", "y": 2009, "rn": 14}, {"a": ["Timo Pylv\u00e4n\u00e4inen", "Lixin Fan", "Vincent Lepetit"], "b": "This paper revisits the pose estimation from point correspondences problem to properly exploit data provided by a GPS. In\n practice, the location given by the GPS is only a noisy estimate, and some point correspondences may be erroneous. Our method\n therefore starts from the GPS location estimate to progressively refine the full pose estimate by hypothesizing correct correspondences.\n We show", "cn": 0, "i": 6044538, "k": ["Correspondence Problem", "Location Estimation", "Pose Estimation"], "p": ["http://www.springerlink.com/content/50k8462853068825", "http://www.springerlink.com/index/50k8462853068825.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-1.html#PylvanainenFL09", "http://dx.doi.org/10.1007/978-3-642-10331-5_76"], "t": "Revisiting the PnP Problem with a GPS", "v": "ISVC", "y": 2009, "rn": 21}, {"a": ["Tomasz Byczkowski", "Jochen Lang"], "b": "In this paper, we introduce a 3D scanning system consisting of a stereo camera combined with an inertial navigation system. We employ this system to explore the suitability of the standard 3D scanning pipeline when working with stereo range data of objects and architecture in an outdoor setting. Our range scanning system is very mobile without any mechanical actuators. We", "cn": 0, "i": 6368000, "k": ["3d model", "3d scanning", "Inertial Navigation", "Inertial Navigation System", "Range Data", "Stereo Vision", "Visual Features", "Iterative Closest Point Algorithm"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5230514", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05230514", "http://www.informatik.uni-trier.de/~ley/db/conf/crv/crv2009.html#ByczkowskiL09", "http://doi.ieeecomputersociety.org/10.1109/CRV.2009.40"], "t": "A Stereo-Based System with Inertial Navigation for Outdoor 3D Scanning", "v": "CRV", "y": 2009, "rn": 24}, {"a": ["Martin Kada", "Michael Peter", "Dieter Fritsch", "Oliver Siemoneit", "Christoph Hubig"], "b": "Privacy and security issues within geospatial information systems are of growing public and scientific interest. Especially with the launch of Google Street View and Google Earth, geospatial data has come to the attention of the public, thereby not only raising support for these technologies, but also massive concerns. It is the duty of science to pick up today\"s uprising debates", "cn": 0, "i": 6726652, "k": ["3d city model", "geospatial data", "Google Earth", "Point of View", "Privacy Enhancing Technologies", "geospatial information system"], "p": ["http://www.ifp.uni-stuttgart.de/publications/2009/peter-springl_privacy_enabling_abstraction_09.pdf"], "t": "Privacy-Enabling Abstraction and Obfuscation Techniques for 3D City Models (Position Paper)", "y": 2009, "rn": 18}, {"a": ["Bo Shu", "Ting Li", "Xianjie Qiu", "Zhaoqi Wang"], "b": "In this paper, we present an automatic and efficient image based modeling system which can create objects' 3D models directly from images captured from different viewpoints. The system firstly uses structure from motion to generate camera parameters and sparse 3D patches. Then, a conservative plane based sweep stereo method on GPU is used to compute quasi-dense depth maps which usually", "cn": 0, "i": 13577605, "k": ["3d model", "Conservation Strategies", "Depth Map", "image-based modeling", "Shape Modeling", "Structure From Motion"], "p": ["http://doi.acm.org/10.1145/1629739.1629749", "http://portal.acm.org/citation.cfm?id=1629749", "http://portal.acm.org/ft_gateway.cfm?id=1629749&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.informatik.uni-trier.de/~ley/db/conf/cgi/cgi2009.html#ShuLQW09"], "t": "An automatic image based modeling system by patch growing", "v": "CGI", "y": 2009, "rn": 14}, {"a": ["Hiroyuki Inatsuka", "Makoto Uchino", "Satoshi Ueno", "Masahiro Okuda"], "b": "", "cn": 0, "i": 27491048, "k": ["Texture Classification"], "p": ["http://www.hindawi.com/journals/ivp/2009/432853.html", "http://www.hindawi.com/journals/ivp/2009/432853.pdf", "http://dx.doi.org/10.1155/2009/432853", "http://www.informatik.uni-trier.de/~ley/db/journals/ejivp/ejivp2009.html#InatsukaUUO09"], "t": "Texture Classification for 3D Urban Map", "v": "EURASIP J Image Video Process", "y": 2009, "rn": 7}, {"a": ["Nianjuan Jiang", "Ping Tan", "Loong-Fah Cheong"], "b": "We present a method to recover a 3D texture-mapped architecture model from a single image. Both single image based modeling and architecture modeling are challenging problems. We handle these difficulties by employing constraints derived from shape symmetries, which are prevalent in architecture. We first present a novel algorithm to calibrate the camera from a single image by exploiting symmetry. Then", "cn": 0, "i": 39245275, "k": ["3d model", "3d reconstruction", "3d texture mapping", "User Interaction"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1618459&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1618459"], "t": "Symmetric architecture modeling with a single image", "y": 2009, "rn": 32}, {"a": ["Martin Kada", "Michael Peter", "Dieter Fritsch", "Oliver Siemoneit", "Christoph Hubig"], "b": "Privacy and security issues within geospatial information systems are of growing public and scientific interest. Especially with the launch of Google Street View and Google Earth, geospatial data has come to the attention of the public, thereby not only raising support for these technologies, but also massive concerns. It is the duty of science to pick up today's uprising debates", "cn": 0, "i": 39246134, "k": ["3d city model", "geospatial data", "Google Earth", "Point of View", "Privacy Enhancing Technologies", "geospatial information system"], "p": ["http://portal.acm.org/citation.cfm?id=1667515", "http://portal.acm.org/ft_gateway.cfm?id=1667515&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "Privacy-enabling abstraction and obfuscation techniques for 3D city models", "y": 2009, "rn": 18}, {"a": ["T. Colleu", "L. Morin", "C. Labit", "S. Pateux", "R. Balter"], "b": "The context of this study is 3D video. Starting from a sequence of multi-view video plus depth (MVD) data, the proposed quad-based representation takes into account, in a unified manner, different issues such as compactness, compression, and intermediate view synthesis. The representation is obtained into two steps. Firstly, a set of 3D quads is extracted by using a quadtree decomposition", "cn": 0, "i": 50758951, "k": ["3d video", "Compact Representation", "Data Representation", "Depth Map", "View Synthesis"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05069648", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5069648"], "t": "Compact quad-based representation for 3D video", "v": "DTV-CON", "y": 2009, "rn": 11}, {"a": ["Arnold Irschara", "Christopher Zach", "Jan-Michael Frahm", "Horst Bischof"], "b": "Efficient view registration with respect to a given 3D reconstruction has many applications like inside-out tracking in indoor and outdoor environments, and geo-locating images from large photo collections. We present a fast location recognition technique based on structure from motion point clouds. Vocabulary tree-based indexing of features directly returns relevant fragments of 3D models instead of documents from the images", "cn": 0, "i": 50782846, "k": ["3d model", "3d reconstruction", "Graphic Processing Unit", "Image Database", "Photo Collection", "Point Cloud", "Structure From Motion", "Urban Modeling", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206587", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206587"], "t": "From structure-from-motion point clouds to fast location recognition", "v": "CVPR", "y": 2009, "rn": 25}, {"a": ["Lu Wang", "Ulrich Neumann"], "b": "Airborne LiDAR technology draws increasing interest in large-scale 3D urban modeling in recent years. 3D LiDAR data typically has no texture information. To generate photo-realistic 3D models, oblique aerial images are needed for texture mapping, in which the key step is to obtain accurate registration between aerial images and untextured 3D LiDAR data. We present a robust automatic registration approach.", "cn": 0, "i": 50782858, "k": ["3d model", "Aerial Image", "Airborne Lidar", "Feature Detection", "Large Scale", "Recovery Rate", "Texture Mapping", "Urban Environment", "Urban Modeling"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206600", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206600"], "t": "A robust approach for automatic registration of aerial images with untextured aerial LiDAR data", "v": "CVPR", "y": 2009, "rn": 19}, {"a": ["Vu Hiep", "Renaud Keriven", "Patrick Labatut", "Jean-Philippe Pons"], "b": "Boosted by the Middlebury challenge, the precision of dense multi-view stereovision methods has increased drastically in the past few years. Yet, most methods, although they perform well on this benchmark, are still inapplicable to large-scale data sets taken under uncontrolled conditions. In this paper, we propose a multi-view stereo pipeline able to deal at the same time with very large", "cn": 0, "i": 50782874, "k": ["Global Optimization", "High Resolution", "Large Scale", "multi-view stereo", "Point Cloud"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206617", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206617"], "t": "Towards high-resolution large-scale multi-view stereo", "v": "CVPR", "y": 2009, "rn": 48}, {"a": ["Vivek Pradeep", "Gerard Medioni", "James Weiland"], "b": "We present an image based simultaneous localization and mapping (SLAM) framework with online, appearance only loop closing. We adopt a layered approach with metric maps over small areas at the local level and a global, graph based abstract topological framework to build consistent maps over large distances. Rao-Blackwellised particle filtering and sparse bundle adjustment are efficiently coupled with a stereo", "cn": 0, "i": 50783023, "k": ["3d reconstruction", "Bundle Adjustment", "Conditional Independence", "Degree of Freedom", "Generic Model", "Simultaneous Localization and Mapping", "Stereo Vision", "Visual Impairment", "Multi Resolution", "rao blackwellised particle filter"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206769", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206769"], "t": "Visual loop closing using multi-resolution SIFT grids in metric-topological SLAM", "v": "CVPR", "y": 2009, "rn": 22}, {"a": ["Yasutaka Furukawa", "Brian Curless", "Steven Seitz", "Richard Szeliski"], "b": "Multi-view stereo (MVS) algorithms now produce reconstructions that rival laser range scanner accuracy. However, stereo algorithms require textured surfaces, and therefore work poorly for many architectural scenes (e.g., building interiors with textureless, painted walls). This paper presents a novel MVS approach to overcome these limitations for Manhattan World scenes, i.e., scenes that consists of piece-wise planar surfaces with dominant directions.", "cn": 0, "i": 50783118, "k": ["Depth Map", "Laser Range Scanner", "multi-view stereo", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206867", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206867"], "t": "Manhattan-world stereo", "v": "CVPR", "y": 2009, "rn": 18}, {"a": ["Jianxiong Xiao", "Tian Fang", "Ping Tan", "Peng Zhao", "Eyal Ofek", "Long Quan"], "b": "We propose in this paper a semi-automatic image-based approach to fa\u00e7ade modeling that uses images captured along streets and relies on structure from motion to recover camera positions and point clouds automatically as the initial stage for modeling. We start by considering a building fa\u00e7ade as a flat rectangular plane or a developable surface with an associated texture image composited", "cn": 0, "i": 39245083, "k": ["3d point cloud", "Building Model", "Developable Surface", "Directed Acyclic Graph", "Image Compositing", "image-based modeling", "Point Cloud", "Structure From Motion", "User Feedback", "Bottom Up", "Top Down"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1409114&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1409114"], "t": "Image-based fa\u00e7ade modeling", "y": 2008, "rn": 30}, {"a": ["Sudipta Sinha", "Drew Steedly", "Richard Szeliski", "Maneesh Agrawala", "Marc Pollefeys", "ETH Zurich"], "b": "We present an interactive system for generating photorealistic, textured, piecewise-planar 3D models of architectural structures and urban scenes from unordered sets of photographs. To reconstruct 3D geometry in our system, the user draws outlines overlaid on 2D photographs. The 3D structure is then automatically computed by combining the 2D interaction with the multi-view geometric information recovered by performing structure from", "cn": 0, "i": 61402255, "k": ["3d model", "3d structure", "Automatic Generation", "Building Model", "Geometric Structure", "Graph Cut", "Interactive System", "Structure From Motion", "Texture Mapping", "Vanishing Point"], "p": [], "t": "Interactive3DArchitecturalModelingfromUnorderedPhotoCollections", "y": 2008, "rn": 29}, {"a": ["Soumya Jana", "Anamitra Makur"], "b": "The coding gain in subband coding, a popular technique for achieving signal compression, depends on how the input signal spectrum is decomposed into subbands. The optimality of such decomposition is conventionally addressed by designing appropriate filter banks. The issue of optimal decomposition of the input spectrum is addressed by choosing the set of band that, for a given number of", "cn": 0, "i": 50098346, "k": ["Binary Tree", "Coding Gain", "Spectrum", "Subband Coding", "System Performance", "Upper Bound", "Filter Bank"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00652252", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=652252"], "t": "Determining optimum subband edges for signal compression", "v": "ICICS", "y": 1997, "rn": 22}, {"a": ["T. Teo", "E. Tan", "A. Premkumar"], "b": "We describe our experience of implementing a CELP algorithm on a TMS320C44 digital signal processing board. The particular implementation we consider is the Federal Standard 1016 (FS1016) 4.8 Kbps CELP vocoder. Our main focus is on exploiting the high-performance architecture and the features of the DSP processor for possible real-time applications", "cn": 0, "i": 50098492, "k": ["Digital Signal Processing", "High Performance", "Real Time Application", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=648206", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00648206"], "t": "Exploiting high-performance DSP hardware for real-time CELP implementation", "v": "TENCON", "y": 1997, "rn": 14}, {"a": ["Masamitsu Honda", "Toshio Murakami", "Yasuo Tonoya"], "b": "This paper investigates some possibilities of ionized air's quench (suppression) effects on the transient electromagnetic field which emanates from a metal-metal electrostatic discharge (ESD) event. In the specific ionized air environment, significant suppression of both transient field strength and its spectrum distributions are confirmed.", "cn": 0, "i": 50057526, "k": ["Electromagnetic Field", "Electrostatic Discharge", "Spectrum"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=865160", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00865160"], "t": "Study of ESD quench effects by air ionization", "v": "EOS/ESD", "y": 1996, "rn": 25}, {"a": ["Robert Maher"], "b": "Amplitude beating between closely spaced frequency components is a well-known effect in musical acoustics, psychoacoustics, and other fields [l-31. Depending on the musical context and the personal preference of the listener, the presence of amplitude lbeating can either be an undesirable artifact of the limited frequency resolution of the human hearing apparatus, or a pleasant quality that adds timbral variety", "cn": 0, "i": 49908623, "k": ["Audio Signal Processing", "Digital Signal Processing", "Space Frequency"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=634148", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00634148"], "t": "Control Of Interharmonic In Polyphonic Music", "v": "WASPAA", "y": 1991, "rn": 18}, {"a": ["Girgis Girgis"], "b": "A time-domain approach for the calculation of the active, reactive and distortion power components in power systems confronted with the presence of substantial voltage and current distortion as well as measurement noise is presented. This approach uses autocorrelation and third-order cumulants for estimating the power components. The third-order cumulant is defined in terms of its joint moment of order up", "cn": 0, "i": 49908791, "k": ["cumulant", "Measurement Noise", "Power System", "Reactive Power", "Signal Extraction", "Time Domain"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00161665", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=161665"], "t": "Reactive power calculations using quadratic phase coupling estimation", "v": "I2MTC", "y": 1991, "rn": 31}, {"a": ["Darren Sapashe", "J. Ashley"], "b": "The authors correct the error of current jargon, including electromagnetic emissions at extra low frequency (ELF), and correctly define the terms needed to describe fringing electric potential gradient and magnetic flux density near any magnetically deflected, raster scan, CRT display. Application of Maxwell's equations shows that the commonly used pickup coil responds to the derivative of magnetic flux density; furthermore,", "cn": 0, "i": 49908794, "k": ["Electric Field", "Field Measurement", "Magnetic Field", "Occupational Health", "Power Supply", "Low Frequency", "Video Display Terminal"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=161669", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00161669"], "t": "Potential errors in VDT fringing field measurements", "v": "I2MTC", "y": 1991, "rn": 47}, {"a": ["Viktor Kolbe", "Folke Isaksson", "Thomas Beckman"], "b": "", "cn": 0, "i": 4853928, "k": [], "p": ["http://www.control.isy.liu.se/research/reports/2009/2889.pdf"], "t": "Indoor photorealistic 3D mapping using stereo images from SLR cameras", "y": 0, "rn": 11}, {"a": ["Hao Tang", "Zhigang Zhu"], "b": "We propose a content-based 3D mosaic (CB3M) representation for long video sequences of 3D and dynamic urban scenes captured by a camera on a mobile platform. In the first phase, a set of parallel-perspective (pushbroom) mosaics with varying viewing directions is generated to capture both the 3D and dynamic aspects of the scene under the camera coverage. In the second", "cn": 0, "i": 5767650, "k": ["3d reconstruction", "3d structure", "epipolar geometry", "Image Registration", "image-based modeling", "Large Scale", "Moving Object", "Stereo Matching", "Structure and Motion", "Target Detection", "Transportation Planning", "Video Coding", "Video Surveillance", "Visual Representation"], "p": ["http://tr.cs.gc.cuny.edu/tr/files/TR-2008013.pdf"], "t": "Content-Based 3D Mosaics for Large-Scale Dynamic Urban Scenes", "y": 0, "rn": 48}, {"a": ["Xenophon Zabulis", "Nikos Grammalidis", "Georgios Floros"], "b": "This paper deals with the automatic stereo reconstruc- tion of wide-area scenes. Its particular goal is a compu- tationally efficient method that can be performed on a per- sonal computer, despite the large amount of data involved in the reconstruction of wide-area scenes. Robustness is con- sidered in terms of the accuracy of the final reconstruction, as well as, in", "cn": 0, "i": 5945121, "k": ["multi-view stereo"], "p": ["http://www.cc.gatech.edu/conferences/3DPVT08/Program/Papers/paper183.pdf", "http://www.ics.forth.gr/~zabulis/paper183.pdf"], "t": "An efficient and memory-conserving implementation of multi -view stereo for wide-area reconstruction", "y": 0, "rn": 29}, {"a": ["Oliver Siemoneit", "Christoph Hubig", "Martin Kada", "Michael Peter", "Dieter Fritsch"], "b": "The Google Street View technology has proven to be highly controversial. Especially in a lot of European countries - where privacy and data protection laws are far stricter than e.g. in the United States - the launch of Street View has caused many residents and citizens to issues complaints to government officials about the project thereby claiming that it is", "cn": 0, "i": 10531466, "k": ["Data Privacy", "Data Protection", "Point of View", "Privacy Enhancing Technologies", "United States", "geospatial information system"], "p": ["http://www.ifp.uni-stuttgart.de/publications/2009/peter-APCAP_Google_Street_View_09.pdf"], "t": "Google Street View and Privacy Some thoughts from a philosophical and engineering point of view", "y": 0, "rn": 17}, {"a": ["Pekka Paalanen", "Joni-Kristian Kamarainen"], "b": "Our ultimate goal is a system capable of on-line 3D re- construction from a monocular video and running on com- modity hardware. One intrinsic module in such a sys- tem is a fast stereo algorithm, which produces depth maps from given views with known camera calibration and pose. Plane-sweep stereo algorithms are well-suited for real-time GPU implementation and can easily", "cn": 0, "i": 13637541, "k": ["3d reconstruction", "Camera Calibration", "Depth Map", "Evaluation Framework", "Image Matching", "Source Code", "Real Time"], "p": ["http://personal.lut.fi/users/joni.kamarainen/downloads/publications/3dpvt2010.pdf"], "t": "NARROW BASELINE GLSL MULTIVIEW STEREO", "y": 0, "rn": 27}, {"a": ["Kimmo Roimela", "Ramakrishna Vedantham", "Joonas Itaranta", "Ruisheng Wang", "Radek Grzeszczuk"], "b": "We propose an automatic method for fast and accurate alignment and multi-view segmentation of city-scale street view data. We use simple 3D building outlines to bootstrap and automate all three steps of the algorithm: alignment of the LIDAR data, image segmentation using graph cuts and its multi-view refinement. The method can process city- scale datasets in approximately a day on", "cn": 0, "i": 13699534, "k": ["Graph Cut", "Image Segmentation"], "p": ["http://research.nokia.com/files/pylvanainen_automatic_3dpvt10.pdf"], "t": "Automatic Alignment and Multi-View Segmentation of Street View Data using", "y": 0, "rn": 23}, {"a": ["R. Hartley", "A. Zisserman"], "b": "", "cn": 5371, "i": 1305681, "k": ["Computer Vision", "Multiple View Geometry"], "p": [], "t": "Multiple view geometry in computer vision", "y": 2000, "rn": 0}, {"a": ["Bruce Lucas", "Takeo Kanade"], "b": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between", "cn": 3231, "i": 333855, "k": ["Computer Vision", "Image Registration", "Stereo Vision", "newton raphson"], "p": ["http://www.cs.virginia.edu/~gfx/Courses/2007/ComputerVision/papers/lucas_kanade.pdf", "http://cseweb.ucsd.edu/classes/sp02/cse252/lucaskanade81.pdf", "http://www.csd.uwo.ca/faculty/beau/CS9645/OUTLINE/Lucas-Kanade-81.pdf", "http://graphics.stanford.edu/courses/cs448a-00-fall/lucaskanade81.pdf", "http://dli.iiit.ac.in/ijcai/IJCAI-81-VOL-2/PDF/017.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=66323"], "t": "An Iterative Image Registration Technique with an Application to Stereo Vision", "v": "IJCAI", "y": 1981, "rn": 6}, {"a": ["Jianbo Shi", "C. Toamsi"], "b": "No feature-based vision system can work until good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still an open problem. We propose a feature selection criterion that is optimal by construction because", "cn": 2137, "i": 3157575, "k": ["Feature Selection", "Search Method", "Vision System", "newton raphson"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00323794", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=323794"], "t": "Good features to track", "v": "CVPR", "y": 1994, "rn": 11}, {"a": ["Yuri Boykov", "Olga Veksler", "Ramin Zabih"], "b": "In this paper we address the problem of minimizing a large class of energy functions that occur in early vision. The major restriction is that the energy func- tion's smoothness term must only involve pairs of pix- els. We propose two algorithms that use graph cuts to compute a local minimum even when very large moves are allowed. The rst", "cn": 1587, "i": 174769, "k": ["Energy Function", "Energy Minimization", "Graph Cut", "Image Restoration", "Indexing Terms", "Large Classes", "Maximum Flow", "Minimum Cut", "piecewise smooth", "potts model", "Markov Random Field", "Approximate Algorithm", "Computer Vision", "Simulated Annealing", "Ground Truth"], "p": ["http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Boykov99.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=791245", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=969114", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00969114", "http://www.csd.uwo.ca/faculty/yuri/Papers/pami01.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami23.html#BoykovVZ01", "http://computer.org/tpami/tp2001/i1222abs.htm", "http://www.soe.ucsc.edu/classes/cmpe290v/Spring05/graphcut.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=969114", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv1999-1.html#BoykovVZ99", "http://www.cs.cornell.edu/rdz/Papers/BVZ-iccv99.pdf", "http://www.csd.uwo.ca/~yuri/Papers/pami01.pdf", "http://www.cs.cornell.edu/courses/cs664/2000sp/Handouts/pami.pdf", "http://www.cs.cornell.edu/~rdz/papers/bvz-iccv99.pdf", "http://www.wisdom.weizmann.ac.il/~mica/CVspring06/papers/vid_visualization/Boykov%20graph%20cuts.pdf", "http://www.csd.uwo.ca/~yuri/Papers/iccv99.pdf", "http://www.csd.uwo.ca/faculty/yuri/Papers/iccv99.pdf", "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=171003BDE7117B23CADE924C46189E58?doi=10.1.1.112.6806&rep=rep1&type=pdf", "http://www.cs.cornell.edu/courses/cs664/2001fa/Handouts/pami.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=64226"], "t": "Fast Approximate Energy Minimization via Graph Cuts", "v": "ICCV", "y": 1999, "rn": 58}, {"a": ["Daniel Scharstein", "Richard Szeliski"], "b": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively lit- tle work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods. Our taxonomy is designed to assess the dif- ferent components and design", "cn": 1585, "i": 784340, "k": ["Computer Vision", "Software Evaluation", "Software Platform", "Stereo Matching", "Ground Truth"], "p": ["http://www.cfar.umd.edu/~fer/cmsc426/images/taxonomy-IJCV.pdf", "http://www.springerlink.com/content/admu16yrtmq0j5wp", "http://www.springerlink.com/index/admu16yrtmq0j5wp.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv47.html#ScharsteinS02", "http://www.ittc.ku.edu/~potetz/EECS_841_Fall08/Readings/Lecture_23_ScharsteinSzeliski_StereoTaxonomy_ijcv02.pdf", "http://research.microsoft.com/pubs/64200/Scharstein-IJCV02.pdf", "http://www.cs.cornell.edu/courses/cs664/2001fa/handouts/scharsteinwsmbv.pdf", "http://research.microsoft.com/pubs/75605/Scharstein-WSMBV01.pdf", "http://research.microsoft.com/pubs/69895/tr-2001-81.pdf", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/A:1014573219977", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/szeliski-IJCV02.pdf", "https://research.microsoft.com/pubs/64200/scharstein-ijcv02.pdf", "http://www.caip.rutgers.edu/~meer/TEACHTOO/PAPERS/scharstein.pdf", "http://vision.middlebury.edu/stereo/tr-2001-81.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=64200"], "t": "A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms", "v": "IJCV", "y": 2002, "rn": 147}, {"a": ["Michael Garland", "Paul Heckbert"], "b": "Many applications in computer graphics require complex, highly detailed models. However, the level of detail actually necessary may vary considerably. To control processing time, it is often desir- able to use approximations in place of excessively detailed models. We have developed a surface simplification algorithm which can rapidly produce high quality approximations of polygonal models. The algorithm uses iterative contractions", "cn": 1416, "i": 249233, "k": ["Computer Graphic", "multiresolution modeling", "Object Model", "Object Representation", "Quadric Error Metric", "Surface Model", "Surface Simplification", "Level of Detail"], "p": ["http://www.faculty.idc.ac.il/arik/LODSeminar/02Progressive%20Meshes/quadrics.pdf", "http://portal.acm.org/citation.cfm?id=258849", "http://portal.acm.org/ft_gateway.cfm?id=258849&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://graphics.stanford.edu/courses/cs348a-01-winter/Papers/garland-heckbert.pdf", "http://www-graphics.stanford.edu/courses/cs348a-03-winter/Papers/garland-heckbert.pdf", "http://graphics.cs.ucdavis.edu/~joy/ecs277/papers/quadrics.pdf", "http://mesh.caltech.edu/ee148/refs/GarlandHeckbert-sg97.pdf", "http://www-graphics.stanford.edu/courses/cs348a-05-winter/Papers/garland-heckbert.pdf", "http://kucg.korea.ac.kr/seminar/2004/src/SR-04-03.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2002/BigData/papers/Maintaining%20Interactivity/Surface%20Simplification%20Using%20Quadric%20Error%20Metrics.pdf", "http://graphics.stanford.edu/courses/cs348a-08-winter/Papers/garland-heckbert.pdf", "http://ccis.edu.sa/~mhussain/Papers%20for%20Presentation/Mesh%20Simplification/Garland%20-%20Surface%20Simplification%20Using%20Quadric%20Error%20Metrics.pdf", "http://www1.cs.columbia.edu/~cs4162/garland97.pdf", "http://ljk.imag.fr/membres/Nicolas.Szafran/ENSEIGNEMENT/ENSIMAG/GarlandHeckbertSurfaceSimplifQEMquadrics.pdf", "http://www-cgi.cs.cmu.edu/afs/cs/user/garland/www/Papers/quadrics.pdf", "http://graphics.stanford.edu/courses/cs348a-05-winter/Papers/garland-heckbert.pdf", "https://graphics.stanford.edu/courses/cs348a-02-winter/Papers/garland-heckbert.pdf", "http://www.cs.dartmouth.edu/~fabio/teaching/cs82-winter08/papers/garland97.pdf", "http://kucg.korea.ac.kr/education/2003_2/VIP618/paper/qem.pdf", "http://graphics.stanford.edu/courses/cs348a-02-winter/Papers/garland-heckbert.pdf", "https://graphics.stanford.edu/courses/cs348a-06-fall/Papers/garland-heckbert.pdf", "https://graphics.stanford.edu/courses/cs348a-04-winter/Papers/garland-heckbert.pdf", "http://www.cc.gatech.edu/classes/AY2007/cs3451_spring/quadrics.pdf", "http://www.ri.cmu.edu/pub_files/pub2/garland_michael_1997_1/garland_michael_1997_1.pdf", "http://evasion.imag.fr/Membres/Franck.Hetroy/Teaching/Geo3D/Articles/garland1997.pdf", "http://www.math.zju.edu.cn/cagd/seminar/2007_autumnwinter/2007_autumn_master_zhangfengwei_ref.pdf", "http://www-graphics.stanford.edu/courses/cs348a-01-winter/Papers/garland-heckbert.pdf", "http://www1.cs.columbia.edu/~cs4162/html05s/garland97.pdf", "http://www.cs.uu.nl/docs/vakken/ddm/slides/papers/garland.pdf", "https://graphics.stanford.edu/courses/cs348a-01-winter/Papers/garland-heckbert.pdf", "http://www-hci.stanford.edu/courses/cs348a-03-winter/Papers/garland-heckbert.pdf", "http://mgarland.org/files/papers/quadrics.pdf", "http://www-evasion.imag.fr/Membres/Franck.Hetroy/Teaching/Geo3D/Articles/garland1997.pdf", "http://www-graphics.stanford.edu/courses/cs348a-02-winter/Papers/garland-heckbert.pdf", "http://www-graphics.stanford.edu/courses/cs348a-08-winter/Papers/garland-heckbert.pdf", "http://www.cs.princeton.edu/courses/archive/fall02/cs526/papers/garland97.pdf", "http://graphics.stanford.edu/courses/cs348a-06-fall/Papers/garland-heckbert.pdf", "http://www-hci.stanford.edu/courses/cs348a-01-winter/Papers/garland-heckbert.pdf", "http://www-2.cs.cmu.edu/afs/cs/user/garland/www/Papers/quadrics.pdf", "http://www.lis.inpg.fr/pages_perso/attali/DEA-IVR/PAPERS/quadrics.pdf", "http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Garland97.pdf", "http://www.enseignement.polytechnique.fr/profs/informatique/Xavier.Decoret/private/papers/quadrics.pdf", "http://mesh.brown.edu/en193s08%2D2003/refs/GarlandHeckbert-sg97.pdf", "http://kucg.korea.ac.kr/education/2004/CSCE458/paper/qem.pdf", "http://kucg.korea.ac.kr/seminar/2002/src/sr-02-05.pdf", "http://www2.in.tu-clausthal.de/~hormann/teaching/GPSS07/GarlandHeckbert.pdf", "http://www.eecs.berkeley.edu/~jrs/meshpapers/GarlandHeckbert2.pdf", "http://www.cs.caltech.edu/~cs175/cs175-01/resources/GarlandHeckbert2.pdf", "http://www.cs.caltech.edu/courses/cs175/cs175-01/resources/GarlandHeckbert2.pdf", "http://www.cse.ohio-state.edu/~hwshen/Su01_888/garland.pdf", "http://www.cs.umd.edu/class/spring2005/cmsc828v/papers/p209-garland.pdf", "http://www.cs.berkeley.edu/~jrs/meshpapers/GarlandHeckbert2.pdf", "http://www.cs.princeton.edu/courses/archive/fall03/cs526/papers/garland97.pdf", "http://www.cs.cmu.edu/afs/cs.cmu.edu/user/garland/www/Papers/quadrics.pdf"], "t": "Surface simplification using quadric error metrics", "v": "SIGGRAPH", "y": 1997, "rn": 11}, {"a": ["Faugeras Olivier"], "b": "", "cn": 1272, "i": 3990615, "k": ["Computer Vision", "Three Dimensional"], "p": [], "t": "Three Dimensional Computer Vision-A Geometrical Viewpoint", "y": 1993, "rn": 0}, {"a": ["O. Faugeras"], "b": "", "cn": 1218, "i": 2021603, "k": ["Computer Vision", "Three Dimensional"], "p": [], "t": "Three-Dimensional Computer Vision: A Geometric Viewpoint", "v": "AI", "y": 1996, "rn": 0}, {"a": ["J. Shi", "C. Tomasi"], "b": "", "cn": 1091, "i": 3157577, "k": [], "p": [], "t": "Good Features to Track", "v": "CVPR", "y": 1999, "rn": 0}, {"a": ["O. Faugeras"], "b": "", "cn": 825, "i": 2134883, "k": ["Computer Vision"], "p": [], "t": "Three-dimensionnal computer vision: a geometric viewpoint", "y": 1993, "rn": 0}, {"a": ["Greg Turk", "Marc Levoy"], "b": "Range imaging offers an inexpensive and accurate means for digitizing the shape of three-dimensional objects. Because most objects self occlude, no single range image suffices to describe the entire object. We present a method for combining a collection of range images into a single polygonal mesh that completely describes an object to the extent that it is visible from the", "cn": 646, "i": 635631, "k": ["Polygonal Meshes", "Range Data", "Range Image", "Structured Light", "Surface Fitting", "Surface Geometry", "Surface Reconstruction", "Three Dimensional", "User Interaction", "Iterative Closest Point Algorithm", "Weighted Averaging"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1994.html#TurkL94", "http://portal.acm.org/ft_gateway.cfm?id=192241&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=192241", "http://doi.acm.org/10.1145/192161.192241", "http://portal.acm.org/citation.cfm?id=192161.192241"], "t": "Zippered polygon meshes from range images", "v": "SIGGRAPH", "y": 1994, "rn": 16}, {"a": ["Marc Pollefeys", "Reinhard Koch", "Luc Gool"], "b": "In this paper the theoretical and practical feasibility of self\u203acalibration in the presence of varying intrinsic camera parameters is under investigation. The paper's main contribution is to propose a self\u203acalibration method which efciently deals with all kinds of constraints on the intrinsic camera parameters. Within this framework a practical method is proposed which can retrieve metric reconstruction from image sequences", "cn": 562, "i": 89287, "k": ["Image Sequence"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=710705", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00710705", "http://www.cs.unc.edu/~jmf/StructureFromMotion/pollefeys98selfcalibration.pdf", "http://www.cs.unc.edu/~marc/pubs/PollefeysIJCV99.pdf", "http://www.inf.ethz.ch/personal/pomarc/pubs/PollefeysIJCV99.pdf"], "t": "Self-Calibration and Metric Reconstruction in Spite of Varying and Unknown Internal Camera Parameters", "v": "ICCV", "y": 1998, "rn": 25}, {"a": ["J. Shi", "T. Carlo"], "b": "", "cn": 558, "i": 3157574, "k": [], "p": [], "t": "Good features to track", "v": "CVPR", "y": 1997, "rn": 0}, {"a": ["Daniel Scharstein", "Richard Szeliski", "R. Zabih"], "b": "Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo", "cn": 525, "i": 96972, "k": ["Computer Vision", "Software Platform", "Stereo Matching", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=988771", "http://research.microsoft.com/apps/pubs/default.aspx?id=69895", "http://research.microsoft.com/pubs/69895/tr-2001-81.pdf"], "t": "A taxonomy and evaluation of dense two-frame stereo correspondence algorithms", "v": "SMBV", "y": 2001, "rn": 145}, {"a": ["Olivier Faugeras", "Quang-tuan Luong", "Stephen Maybank"], "b": "The problem of finding the internal orientation of a camera (camera calibration) is extremely important for practical applications. In this paper a complete method for calibrating a camera is presented. In contrast with existing methods it does not require a calibration object with a known 3D shape. The new method requires only point matches from image sequences. It is shown,", "cn": 510, "i": 361156, "k": ["Camera Calibration", "Camera Motion", "Continuation Method", "Image Sequence", "Noisy Data", "Point of Interest"], "p": ["http://www.springerlink.com/index/7231177731663065.pdf", "http://www.springerlink.com/content/7231177731663065", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv1992.html#FaugerasLM92"], "t": "Camera Self-Calibration: Theory and Experiments", "v": "ECCV", "y": 1992, "rn": 10}, {"a": ["Ali Azarbayejani", "Alex Pentland"], "b": " We present a formulation for recursive recoveryof motion, pointwise structure, and focal length from featurecorrespondences tracked through an image sequence.In addition to adding focal length to the state vector, severalrepresentational improvements are made over earlierstructure from motion formulations, yielding a stable andaccurate estimation framework which applies uniformly toboth true perspective and orthographic projection. Resultson synthetic and real imagery illustrate the...", "cn": 379, "i": 800123, "k": ["Image Sequence", "Recursive Estimation"], "p": ["http://www.computer.org/tpami/tp1995/i0562abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=387503", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00387503", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami17.html#AzarbayejaniP95", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=387503"], "t": "Recursive Estimation of Motion, Structure, and Focal Length", "v": "PAMI", "y": 1995, "rn": 34}, {"a": ["R. Brown", "P. Hwang"], "b": "", "cn": 316, "i": 1272762, "k": ["kalman filter"], "p": [], "t": "Introduction to random signals and applied kalman filtering (3rd ed", "y": 1997, "rn": 0}, {"a": ["Szymon Rusinkiewicz", "Olaf Hall-Holt", "Marc Levoy"], "b": "The digitization of the 3D shape of real objects is a rapidly expanding field, with applications in entertainment, design, and archaeology. We propose a new 3D model acquisition system that permits the user to rotate an object by hand and see a continuously-updated model as the object is scanned. This tight feedback loop allows the user to find and fill", "cn": 276, "i": 59982, "k": ["3d model", "3d scanning", "Feedback Loop", "Iterative Closest Point", "Structured Light", "Real Time"], "p": ["http://www.cs.princeton.edu/~smr/papers/rt_model/rt_model.pdf", "http://portal.acm.org/citation.cfm?id=566600", "http://portal.acm.org/ft_gateway.cfm?id=566600&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.soe.ucsc.edu/classes/cmps290b/Fall05/readings/rt_model.pdf", "http://www.cs.princeton.edu/gfx/pubs/Rusinkiewicz_2002_R3M/rt_model.pdf", "http://www.hunter.cuny.edu/cs/Faculty/Stamos/3DP_F03/PAPERS/SZYMON/rusinkiewicz.pdf"], "t": "Real-time 3D model acquisition", "v": "TOG", "y": 2002, "rn": 37}, {"a": ["Andrew Fitzgibbon", "Andrew Zisserman"], "b": " . We describe progress in completely automatically recovering3D scene structure together with 3D camera positions from a sequence ofimages acquired by an unknown camera undergoing unknown movement.The main departure from previous structure from motion strategies isthat processing is not sequential. Instead a hierarchical approach is employedbuilding from image triplets and associated trifocal tensors. Thisis advantageous both in obtaining correspondences and", "cn": 254, "i": 123647, "k": ["Image Sequence", "Structure From Motion"], "p": ["http://www.springerlink.com/content/d334346k230720x5", "http://www.springerlink.com/index/d334346k230720x5.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv1998-1.html#FitzgibbonZ98", "http://link.springer.de/link/service/series/0558/bibs/1406/14060311.htm"], "t": "Automatic Camera Recovery for Closed or Open Image Sequences", "v": "ECCV", "y": 1998, "rn": 29}, {"a": ["Marc Pollefeys", "Reinhard Koch", "Luc Gool"], "b": "In this paper the theoretical and practical feasibility of self-calibration in the presence of varying intrinsic camera parameters is under investigation. The paper's main contribution is to propose a self-calibration method which efficiently deals with all kinds of constraints on the intrinsic camera parameters. Within this framework a practical method is proposed which can retrieve metric reconstruction from image sequences", "cn": 224, "i": 1399187, "k": ["3d reconstruction", "Image Sequence"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv32.html#PollefeysKG99", "http://www.springerlink.com/index/m614017373626881.pdf", "http://www.springerlink.com/content/m614017373626881", "http://dx.doi.org/10.1023/A:1008109111715"], "t": "Self-Calibration and Metric Reconstruction Inspite of Varying and Unknown Intrinsic Camera Parameters", "v": "IJCV", "y": 1999, "rn": 19}, {"a": ["Robert Collins"], "b": "The problem of determining feature correspon- dences across multiple views is considered. The term \"true multi-image\" matching is introduced to describe techniques that make full and efficient use of the geo- metric relationships between multiple images and the scene. A true multi-image technique must generalize to any number of images, be oflinear algorithmic com- plexity in the number of images,", "cn": 212, "i": 382849, "k": ["Aerial Image", "Image Matching", "Multiple Views"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00517097", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=517097", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Collins-space-sweep-96.pdf"], "t": "A Space-Sweep Approach to True Multi-Image Matching", "v": "CVPR", "y": 1996, "rn": 18}, {"a": ["Derek Hoiem", "Alexei Efros", "Martial Hebert"], "b": "Image understanding requires not only individually esti- mating elements of the visual world but also capturing the interplay among them. In this paper, we provide a frame- work for placing local object detection in the context of the overall 3D scene by modeling the interdependence of ob- jects, surface orientations, and camera viewpoint. Most object detection methods consider all scales", "cn": 209, "i": 2167312, "k": ["Image Understanding", "Integrated Approach", "Object Detection"], "p": ["http://www.csd.uwo.ca/faculty/olga/Courses/Fall2007/840/StudentPapers/hoiem_cvpr06.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01641015", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1641015", "http://www.csd.uwo.ca/%7Eolga/Courses/Fall2007/840/StudentPapers/hoiem_cvpr06.pdf", "http://www.cs.sfu.ca/~mori/courses/cmpt882/fall07/papers/hoiem_objects_perspective_cvpr06.pdf", "http://www.cs.sfu.ca/~mori/courses/cmpt882/summer09/papers/hoiem_objects_perspective_cvpr06.pdf", "http://www.ri.cmu.edu/pub_files/pub4/hoiem_derek_2006_1/hoiem_derek_2006_1.pdf", "http://www.csd.uwo.ca/courses/CS840a/StudentPapers/hoiem_cvpr06.pdf", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.232", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-2.html#HoiemEH06", "http://www.cs.utexas.edu/~grauman/courses/spring2007/395T/papers/hoiem_cvpr06.pdf", "http://www.cs.uiuc.edu/homes/dhoiem/publications/hoiem_cvpr06.pdf"], "t": "Putting Objects in Perspective", "v": "CVPR", "y": 2006, "rn": 34}, {"a": ["Paul Beardsley", "Andrew Zisserman", "David Murray"], "b": " . A structure from motion algorithm is described which recovers structure and camera position,modulo a projective ambiguity. Camera calibration is not required, and camera parameters such as focallength can be altered freely during motion. The structure is updated sequentially over an image sequence,in contrast to schemes which employ a batch process. A specialisation of the algorithm to recover structureand camera", "cn": 207, "i": 130464, "k": ["Affine Transformation", "Batch Process", "Camera Calibration", "Corner Detection", "Image Sequence", "Indoor Environment", "Path Planning", "Projective Structure", "Space Mapping", "Structure From Motion"], "p": ["http://www.springerlink.com/content/l8836070213193j7", "http://www.springerlink.com/index/l8836070213193j7.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv23.html#BeardsleyZM97"], "t": "Sequential Updating of Projective and Affine Structure from Motion", "v": "IJCV", "y": 1997, "rn": 43}, {"a": ["P. Narayanan", "Peter Rander", "Takeo Kanade"], "b": " We present Virtualized Reality, a technique to create virtualworlds out of dynamic events using densely distributed stereoviews. The intensity image and depth map for each camera viewat each time instant are combined to form a Visible SurfaceModel. Immersive interaction with the virtualized event is possibleusing a dense collection of such models. Additionally, aComplete Surface Model of each instant can be", "cn": 205, "i": 373096, "k": ["Depth Map", "Surface Model", "Virtual Reality", "Virtual Worlds"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00710694", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=710694", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv1998.html#NarayananRK98"], "t": "Constructing Virtual Worlds Using Dense Stereo", "v": "ICCV", "y": 1998, "rn": 15}, {"a": ["David Nist\u00e9r"], "b": "A system capable of performing robust live ego-motion estimation for perspective cameras is presented. The system is powered by random sample consensus with preemptive scoring of the motion hypotheses. A general statement of the problem of efficient preemptive scoring is given. Then a theoretical investigation of preemptive scoring under a simple inlier\u2013outlier model is performed. A practical preemption scheme is", "cn": 181, "i": 2173203, "k": ["3d reconstruction", "Motion Estimation", "Random Sampling", "Robust Estimator", "Structure and Motion", "Structure From Motion", "Real Time"], "p": ["http://www.vis.uky.edu/~dnister/Publications/2003/Preemptive/1180_nister_d.pdf", "http://www.springerlink.com/content/fgh2726600352583", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238341", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238341", "http://vis.uky.edu/~dnister/Publications/2005/preemptive/nister_preemptive.pdf", "http://www.tu-chemnitz.de/etit/proaut/paperdb/download/nister03a.pdf", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0199_nister.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/01/195010199abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-1.html#Nister03", "http://www.springerlink.com/index/pdf/10.1007/s00138-005-0006-y", "http://dx.doi.org/10.1007/s00138-005-0006-y", "http://vis.uky.edu/~dnister/Publications/2003/Preemptive/1180_nister_d.pdf", "http://www.springerlink.com/index/10.1007/s00138-005-0006-y"], "t": "Preemptive RANSAC for live structure and motion estimation", "v": "MVA", "y": 2005, "rn": 23}, {"a": ["Marc Soucy", "Denis Laurendeau"], "b": "This paper presents a new and general solution to the problem of range view integration. The integration problem consists in computing a connected surface model from a set of registered range images acquired from different viewpoints. The proposed method does not impose constraints on the topology of the observed surfaces, the position of the viewpoints, or the number of views", "cn": 162, "i": 801105, "k": ["constrained delaunay triangulation", "General Solution", "Integrable Model", "Range Image", "Surface Model"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=385982", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=385982", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00385982", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami17.html#SoucyL95"], "t": "A General Surface Approach to the Integration of a Set of Range Views", "v": "PAMI", "y": 1995, "rn": 23}, {"a": ["Reinhard Koch", "Marc Pollefeys", "Luc Gool"], "b": "This contribution describes an automatic 3D surface modeling system that extracts dense metric 3D surfaces from an uncalibrated\n video sequence. A static 3D scene is observed from multiple viewpoints by freely moving a video camera around the object.\n No restrictions on camera movement and internal camera parameters like zoom are imposed, as the camera pose and intrinsic\n parameters are calibrated", "cn": 134, "i": 509739, "k": ["Automatic Generation", "Depth Estimation", "Economic Model", "Geometric Correction", "Image Sequence", "Image Texture", "Measurement Uncertainty", "Specular Reflection", "Super Resolution", "Surface Model", "Surface Reconstruction", "Texture Mapping"], "p": ["http://www.springerlink.com/content/l7175q6t63457202", "http://www.springerlink.com/index/l7175q6t63457202.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv1998-1.html#KochPG98", "http://link.springer.de/link/service/series/0558/bibs/1406/14060055.htm"], "t": "Multi Viewpoint Stereo from Uncalibrated Video Sequences", "v": "ECCV", "y": 1998, "rn": 20}, {"a": ["David Nist\u00e9r", "Oleg Naroditsky", "James Bergen"], "b": "We present a system that estimates the motion of a stereo head or a single moving camera based on video input. The system operates in real-time with low delay and the motion estimates are used for navigational purposes. The front end of the system is a feature tracker. Point features are matched between pairs of frames and linked into image", "cn": 126, "i": 4490176, "k": ["Camera Motion", "Feature Tracking", "Motion Estimation", "Pose Estimation", "Prior Knowledge", "Robust Estimator", "visual odometry", "Front End", "Real Time"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/jfr/jfr23.html#NisterNB06", "http://doi.wiley.com/10.1002/rob.20103", "http://www.vis.uky.edu/~dnister/Publications/2006/JFR/JFR1.pdf", "http://dx.doi.org/10.1002/rob.20103", "http://vis.uky.edu/~dnister/Publications/2006/JFR/JFR1.pdf"], "t": "Visual odometry for ground vehicle applications", "v": "JFR", "y": 2006, "rn": 32}, {"a": ["Stan Birchfield", "Carlo Tomasi"], "b": "Slanted surfaces pose a problem for correspondence algo- rithms utilizing search because of the greatly increased number of possibilities, when compared with fronto- parallel surfaces. In this paper we propose an algorithm to compute correspondence between stereo images or be- tween frames of a motion sequence by minimizing an energy functional that accounts for slanted surfaces. The energy is minimized", "cn": 126, "i": 289909, "k": ["Energy Function", "Local Minima"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=791261", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00791261", "http://computer.org/proceedings/iccv/0164/vol%201/01640489abs.htm", "http://www.ces.clemson.edu/~stb/publications/multiwaycut_iccv1999.pdf", "http://cat.middlebury.edu/stereo/papers/multiwaycut_iccv1999.pdf"], "t": "Multiway Cut for Stereo and Motion with Slanted Surfaces", "v": "ICCV", "y": 1999, "rn": 20}, {"a": ["Adrian Hilton", "Andrew Stoddart", "John Illingworth", "Terry Windeatt"], "b": "", "cn": 120, "i": 509727, "k": ["Range Image"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv1996-1.html#HiltonSIW96"], "t": "Reliable Surface Reconstructiuon from Multiple Range Images", "v": "ECCV", "y": 1996, "rn": 17}, {"a": ["Mark Wheeler", "Yoichi Sato", "Katsushi Ikeuchi"], "b": " In this paper, we present a robust method for creating a triangulated surface mesh from multiple range images. Our method merges a set of range images into a volumetric implicit-surface representation which is converted to a surface mesh using a variant of the marching-cubes algorithm. Unlike previous techniques based on implicit-surface representations, our method estimates the signed distance to the", "cn": 113, "i": 124633, "k": ["Implicit Surface", "Marching Cube", "Range Image", "Robust Method", "Geometric Model", "Range Data"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv1998.html#WheelerSI98", "http://www.springerlink.com/content/q64865n6261r0g24", "http://www.springerlink.com/index/q64865n6261r0g24.pdf"], "t": "Consensus Surfaces for Modeling 3D Objects from Multiple Range Images", "v": "ICCV", "y": 1998, "rn": 10}, {"a": ["Andr\u00e9 Fischer", "Thomas Kolbe", "Felicitas Lang", "Armin Cremers", "Wolfgang F\u00f6rstner", "Lutz Pl\u00fcmer", "Volker Steinhage"], "b": " We propose a model-based approach to automated 3D extraction of buildings fromaerial images. We focus on a reconstruction strategy that is not restricted to a small classof buildings. Therefore, we employ a generic modeling approach which relies on the welldened combination of building part models. Building parts are classied by their roof type.", "cn": 99, "i": 93686, "k": ["Aerial Image", "Constraint Logic Programs", "Generic Model", "Model Building", "model-based approach"], "p": ["http://www.sciencedirect.com/science/article/pii/S1077314298907214", "http://linkinghub.elsevier.com/retrieve/pii/S1077314298907214"], "t": "Extracting Buildings from Aerial Images Using Hierarchical Aggregation in 2D and 3D", "v": "CVIU", "y": 1998, "rn": 44}, {"a": ["Hailin Jin", "Paolo Favaro", "Stefano Soatto"], "b": "We develop an efcient algorithm to track point features supported by image patches undergoing afne deformations and changes in illumination. The algorithm is based on a combined model of geometry and photometry that is used to track features as well as to detect outliers in a hypothesis testing framework. The algorithm runs in real time on a personal computer, and", "cn": 94, "i": 132724, "k": ["Deformable Template", "Feature Tracking", "Hypothesis Test", "Personal Computer", "Structure From Motion", "Real Time"], "p": ["http://www.vision.ucla.edu/~hljin/papers/iccv01.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=937588", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00937588", "http://vision.ucla.edu/~hljin/papers/iccv01.pdf", "http://vision.ucla.edu/papers/jinFS01.pdf"], "t": "Real-Time Feature Tracking and Outlier Rejection with Changes in Illumination", "v": "ICCV", "y": 2001, "rn": 23}, {"a": ["Tom\u00e1s Werner", "Andrew Zisserman"], "b": "We investigate a strategy for reconstructing of buildings from multi- ple (uncalibrated) images. In a similar manner to the Facade approach we first generate a coarse piecewise planar model of the principal scene planes and their delineations, and then use these facets to guide the search for indentations and protrusions such as windows and doors. However, unlike the Facade approach", "cn": 88, "i": 509243, "k": ["Generic Model", "Model Fitting", "Texture Mapping"], "p": ["http://www.springerlink.com/content/6hdpyccjq8cmfv4d", "http://link.springer.de/link/service/series/0558/bibs/2351/23510541.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2002-2.html#WernerZ02"], "t": "New Techniques for Automated Architectural Reconstruction from Photographs", "v": "ECCV", "y": 2002, "rn": 22}, {"a": ["Ioannis Stamos", "Peter Allen"], "b": "This paper presents a systematic approach to the problem of photorealistic 3-D model acquisition from the combination of range and image sensing. The input is a sequence of unregistered range scans of the scene and a sequence of unregistered 2-D photographs of the same scene. The output is a true texture-mapped geometric model of the scene. We believe that the", "cn": 87, "i": 930987, "k": ["Geometric Correction", "Geometric Model", "Image Acquisition", "Image Registration", "Large Scale", "Solid Modeling", "Texture Mapping"], "p": ["http://dx.doi.org/10.1006/cviu.2002.0963", "http://www.sciencedirect.com/science/article/pii/S107731420290963X", "http://linkinghub.elsevier.com/retrieve/pii/S107731420290963X", "http://www.informatik.uni-trier.de/~ley/db/journals/cviu/cviu88.html#StamosA02", "http://www.cs.hunter.cuny.edu/%7eioannis/cviu.ioannis.pdf", "http://www.cs.columbia.edu/~allen/PAPERS/cviu.ioannis.pdf", "http://www.hunter.cuny.edu/cs/Faculty/Stamos/3DP_F03/PAPERS/STAMOS/cviu.ioannis2.pdf"], "t": "Geometry and Texture Recovery of Scenes of Large Scale", "v": "CVIU", "y": 2002, "rn": 51}, {"a": ["Daniel Morris", "Takeo Kanade"], "b": " Given a set of 3D points that we know lie on thesurface of an object, we can define many possible surfacesthat pass through all of these points. Even whenwe consider only surface triangulations, there are stillan exponential number of valid triangulations that allfit the data. Each triangulation will produce a differentfaceted surface connecting the points.Our goal is to overcome this", "cn": 76, "i": 173341, "k": [], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=855837", "http://computer.org/proceedings/cvpr/0662/Volume%201/06621332abs.htm"], "t": "Image-Consistent Surface Triangulation", "v": "CVPR", "y": 2000, "rn": 9}, {"a": ["Pascal Fua"], "b": "We present a framework for 3-dimensional surface reconstruction that can be used to model fully 3-D scenes from an arbitrary number of stereo views taken from vastly different viewpoints. This is a key step toward producing 3-D world-descriptions of complex scenes using stereo and is a very challenging problem: real-world scenes tend to contain many 3-D objects, they do not", "cn": 72, "i": 1984870, "k": ["Object Representation", "Surface Reconstruction", "3 dimensional"], "p": ["http://www.springerlink.com/content/t58x2u7h02525x10", "http://www.springerlink.com/index/t58x2u7h02525x10.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv24.html#Fua97", "http://dx.doi.org/10.1023/A:1007918123901"], "t": "From Multiple Stereo Views to Multiple 3-D Surfaces", "v": "IJCV", "y": 1997, "rn": 32}, {"a": ["Armin Gruen", "Xinhua Wang"], "b": "In this paper, we introduce a semi-automated topology generator for 3-D objects, CC-Modeler (CyberCity Modeler). Given the data as point clouds measured on Analytical Plotters or Digital Stations, we present a new method for fitting planar structures to the measured sets of point clouds. While this topology generator has been originally designed to model buildings, it can also be used", "cn": 69, "i": 2076612, "k": ["Building Reconstruction", "Least Square", "Model Building", "Point Cloud"], "p": ["http://www.sciencedirect.com/science/article/pii/S0924271698000112", "http://linkinghub.elsevier.com/retrieve/pii/S0924271698000112", "http://www.ifp.uni-stuttgart.de/publications/commIV/gruen1neu.pdf", "http://adsabs.harvard.edu/abs/1998IJPRS..53..286G"], "t": "CC-Modeler: a topology generator for 3-D city models 1 Revised version of a paper presented at the ISPRS Commission IV Symposium, September 7\u201310, 1998, Stuttgart, Germany. 1", "v": "ISPRS J PHOTOGRAMM", "y": 1998, "rn": 5}, {"a": ["Seth Teller", "Matthew Antone", "Zachary Bodnar", "Michael Bosse", "Satyan Coorg", "Manish Jethwa", "Neel Master"], "b": "We describe a dataset of several thousand calibrated, geo-referenced, high dynamic range color images, ac- quired under uncontrolled, variable illumination in an outdoor region spanning hundreds of meters. All im- age, feature, calibration, and geo-referencing data are available at http://city.lcs.mit.edu/data. Calibrated imagery is of fundamental interest in a wide variety of applications. We have made this data available in the", "cn": 65, "i": 33118, "k": ["3d reconstruction", "Color Image", "Computer Graphic", "Computer Vision", "High Dynamic Range", "High Dynamic Range Imaging", "Image Based Rendering", "Systems and Applications", "Urban Area"], "p": ["http://people.csail.mit.edu/seth/pubs/TABBCJM_IJCV2003.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv53.html#TellerABBCJM03", "http://people.csail.mit.edu/teller/pubs/TellerEtAlDatasetCVPR2001.pdf", "http://people.csail.mit.edu/seth/pubs/TellerEtAlDatasetCVPR2001.pdf", "http://people.csail.mit.edu/teller/pubs/TABBCJM_IJCV2003.pdf"], "t": "Calibrated, Registered Images of an Extended Urban Area", "v": "IJCV", "y": 2003, "rn": 27}, {"a": ["Michael Goesele", "Brian Curless", "Steven Seitz"], "b": "We present an extremely simple yet robust multi-view stereo algorithm and analyze its properties. The algorithm r st computes individual depth maps using a window-based vot- ing approach that returns only good matches. The depth maps are then merged into a single mesh using a straight- forward volumetric approach. We show results for several datasets, showing accuracy comparable to the", "cn": 64, "i": 2167293, "k": ["Depth Map", "multi-view stereo"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01641048", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1641048", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.199", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-2.html#GoeseleCS06"], "t": "Multi-View Stereo Revisited", "v": "CVPR", "y": 2006, "rn": 16}, {"a": ["Paul Merrell", "Amir Akbarzadeh", "Liang Wang", "Philippos Mordohai", "Jan-michael Frahm", "Ruigang Yang", "David Nist\u00e9r", "Marc Pollefeys"], "b": "We present a viewpoint-based approach for the quick fu- sion of multiple stereo depth maps. Our method selects depth estimates for each pixel that minimize violations of visibility constraints and thus remove errors and inconsis- tencies from the depth maps to produce a consistent surface. We advocate a two-stage process in which the first stage generates potentially noisy, overlapping depth", "cn": 50, "i": 4271382, "k": ["Depth Estimation", "Depth Map", "Hardware Accelerator", "multi-view stereo", "Quantitative Analysis", "Frames Per Second", "Ground Truth", "High Throughput", "Real Time"], "p": ["http://cvg-pub.inf.ethz.ch/WebBIB/papers/2007/MerrellICCV07.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408984", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408984", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#MerrellAWMFYNP07", "http://www.inf.ethz.ch/personal/pomarc/pubs/MerrellICCV07", "http://dx.doi.org/10.1109/ICCV.2007.4408984", "http://cs.unc.edu/~jmf/publications/Merrell_DepthMapFusion07.pdf"], "t": "Real-Time Visibility-Based Fusion of Depth Maps", "v": "ICCV", "y": 2007, "rn": 23}, {"a": ["Zhigang Zhu", "Allen Hanson", "Edward Riseman"], "b": "In this paper, we present a new method for automatically and efficiently generating stereoscopic mosaics by seamless registration of images collected by a video camera mounted on an airborne platform. Using a parallel-perspective representation, a pair of geometrically registered stereo mosaics can be precisely constructed under quite general motion. A novel parallel ray interpolation for stereo mosaicing (PRISM) approach is", "cn": 49, "i": 1428354, "k": ["Depth Estimation", "linear functionals", "Motion Parallax"], "p": ["http://csdl.computer.org/comp/trans/tp/2004/02/i0226abs.htm", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01262190", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1262190", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami26.html#ZhuHR04", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1262190", "http://www-cs.engr.ccny.cuny.edu/%7Ezhu/tpami117016.pdf", "http://visionlab.engr.ccny.cuny.edu/ccvcl/assets/publications/38/paper/tpami117016.pdf", "http://visionlab.engr.ccny.cuny.edu/ccvcl/assets/publications/75/paper/tpami117016.pdf"], "t": "Generalized Parallel-Perspective Stereo Mosaics from Airborne Video", "v": "PAMI", "y": 2004, "rn": 32}, {"a": ["Tomokazu Sato", "Masayuki Kanbara", "Naokazu Yokoya", "Haruo Takemura"], "b": "Three-dimensional (3-D) models of outdoor scenes are widely used for object recognition, navigation, mixed re- ality, and so on. Because such models are often made man- ually with high costs, automatic and dense 3-D reconstruc- tion is widely investigated. In related work, a dense 3-D model is generated by using a stereo method. However, these methods cannot use several hundreds", "cn": 49, "i": 784324, "k": ["Depth Estimation", "Object Recognition", "Three Dimensional"], "p": ["http://yokoya.aist-nara.ac.jp/paper/datas/272/cvpr_workshop.pdf", "http://yokoya.naist.jp/paper/datas/272/cvpr_workshop.pdf", "http://yokoya.naist.jp/paper/datas/584/IJCV_SATO.pdf", "http://yokoya.aist-nara.ac.jp/~tomoka-s/research/SMV2001.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv47.html#SatoKYT02", "http://yokoya.aist-nara.ac.jp/paper/datas/584/IJCV_SATO.pdf"], "t": "Dense 3-D Reconstruction of an Outdoor Scene by Hundreds-Baseline Stereo Using a Hand-Held Video Camera", "v": "IJCV", "y": 2002, "rn": 16}, {"a": ["A. Hilton", "A. Stoddart", "J. Illingworth", "T. Windeatt"], "b": "This paper addresses the problem of reconstructing an integrated 3D model from multiple 2.5D range images. A novel integration algorithm is presented based on a continuous implicit surface representation. This is the first reconstruction algorithm to use operations in 3D space only. The algorithm is guaranteed to reconstruct the correct topology of surface features larger than the range image sampling", "cn": 49, "i": 3495003, "k": ["3d model", "Complex Objects", "Computational Complexity", "Implicit Surface", "Performance Characterization", "Range Image", "Reconstruction Algorithm", "Surface Reconstruction"], "p": ["http://www.springerlink.com/content/y80502lx17wr16q1"], "t": "Reliable surface reconstruction from multiple range images", "v": "ECCV", "y": 0, "rn": 0}, {"a": ["Amir Akbarzadeh", "Jan-michael Frahm", "Philippos Mordohai", "Brian Clipp", "Chris Engels", "David Gallup", "Paul Merrell", "M. Phelps", "Sudipta Sinha", "B. Talton", "Liang Wang", "Qingxiong Yang", "Henrik Stew\u00e9nius", "Ruigang Yang", "Greg Welch", "Herman Towles", "David Nist\u00e9r", "Marc Pollefeys"], "b": "The paper introduces a data collection system and a processing pipeline for automatic geo-registered 3D recon- struction of urban scenes from video. The system collects multiple video streams, as well as GPS and INS measure- ments in order to place the reconstructed models in geo- registered coordinates. Besides high quality in terms of both geometry and appearance, we aim at", "cn": 46, "i": 2412651, "k": ["3d reconstruction", "Data Collection", "Perforation", "Video Streaming", "Real Time"], "p": ["http://www.inf.ethz.ch/personal/pomarc/pubs/Akbarzadeh3DPVT06.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04155703", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4155703", "http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2006.html#AkbarzadehFMCEGMPSTWYSYWTNP06", "http://vis.uky.edu/%7Eengels/files/3DPVT_UrbanReconstruction06.pdf", "http://www.cs.unc.edu/~pmerrell/Akbarzadeh3DPVT06.pdf", "http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.141", "http://www1.cs.columbia.edu/~allen/PHOTOPAPERS/pollefeysvideocity.pdf", "http://cs.unc.edu/Research/urbanscape/public/Akbarzadeh_UrbanReconstruction06.pdf", "http://www.seas.upenn.edu/~mordohai/public/Akbarzadeh_UrbanReconstruction06.pdf", "http://vis.uky.edu/~liiton/publications/3dpvt-06-Akbarzadeh.pdf", "http://www.vis.uky.edu/~dnister/Publications/2006/Urban/Akbarzadeh_UrbanReconstruction06.pdf", "http://www.cs.unc.edu/~bclipp/papers/Akbarzadeh3DPVT06.pdf", "http://www.cs.unc.edu/%7Ewelch/media/pdf/Akbarzadeh3DPVT06.pdf", "http://www.cs.unc.edu/%7Emarc/pubs/Akbarzadeh3DPVT06.pdf", "http://www.cs.unc.edu/Research/urbanscape/public/Akbarzadeh_UrbanReconstruction06.pdf", "http://vis.uky.edu/~dnister/Publications/2006/Urban/Akbarzadeh_UrbanReconstruction06.pdf", "http://homes.esat.kuleuven.be/~cengels/files/akbarzadeh_3dpvt_2006.pdf", "http://vis.uky.edu/~wangl/Research/Publication/2006/UrbanReconstruction_3dpvt06.pdf", "http://vis.uky.edu/~gravity/publications/2006/UrbanReconstruction_3dpvt06.pdf"], "t": "Towards Urban 3D Reconstruction from Video", "v": "3DPVT", "y": 2006, "rn": 34}, {"a": ["Augusto Roman", "Gaurav Garg", "Marc Levoy"], "b": "Multi-perspective images are a useful way to visualize extended, roughly planar scenes such as landscapes or city blocks. However, constructing effective multi-perspective images is something of an art. In this paper, we describe an interactive system for creating multi-perspective images composed of serially blended cross-slits images. Beginning with a sideways-looking video of the scene as might be captured from a", "cn": 38, "i": 1242180, "k": ["Interaction Design", "Interactive System"], "p": ["http://csdl.computer.org/dl/proceedings/vis/2004/8788/00/87880537.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372240", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01372240", "http://portal.acm.org/citation.cfm?id=1034490", "http://portal.acm.org/ft_gateway.cfm?id=1034490&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.informatik.uni-trier.de/~ley/db/conf/visualization/visualization2004.html#RomanGL04", "http://portal.acm.org/citation.cfm?id=1032664.1034490"], "t": "Interactive Design of Multi-Perspective Images for Visualizing Urban Landscapes", "v": "", "y": 2004, "rn": 17}, {"a": ["P. Beardsley", "A. Zisserman", "D. Murray"], "b": "", "cn": 38, "i": 3733145, "k": ["Structure From Motion"], "p": [], "t": "Sequential update of projective and a ne structure from motion", "v": "IJCV", "y": 1997, "rn": 0}, {"a": ["Sudipta Sinha", "Jan-Michael Frahm", "Marc Pollefeys", "Yakup Genc"], "b": "Abstract,This paper describes novel implementations,of the KLT feature tracking and SIFT feature extraction algorithms that run on the graphics processing unit (GPU) and is suitable for video analysis in real-time vision systems. While significant acceleration over standard CPU implementations,is obtained by exploiting parallelism provided by modern programmable graphics hardware, the CPU is freed up to run other computations in parallel.", "cn": 37, "i": 4528479, "k": ["Feature Extraction", "Feature Tracking", "Graphic Processing Unit", "Programmable Graphics Hardware", "Real-time Vision", "Robot Navigation", "Vehicle Tracking", "Video Analysis", "Video Surveillance", "Vision System", "Visual Inspection", "Visual Tracking", "Real Time"], "p": ["http://www.springerlink.com/index/8t05rv61u5p24360.pdf", "http://www.springerlink.com/content/8t05rv61u5p24360", "http://www.springerlink.com/index/10.1007/s00138-007-0105-z", "http://www.springerlink.com/index/pdf/10.1007/s00138-007-0105-z", "http://dx.doi.org/10.1007/s00138-007-0105-z", "http://www.informatik.uni-trier.de/~ley/db/journals/mva/mva22.html#SinhaFPG11"], "t": "Feature tracking and matching in video using programmable graphics hardware", "v": "MVA", "y": 2011, "rn": 18}, {"a": ["Abhijit Ogale", "Yiannis Aloimonos"], "b": "We examine the stereo correspondence problem in the presence of slanted scene surfaces. In particular, we high- light a previously overlooked geometric fact: a horizontally slanted surface (i.e. having depth variation in the direction of the separation of the two cameras) will appear horizon- tally stretched in one image as compared to the other image. Thus, while corresponding two images,", "cn": 37, "i": 1788604, "k": ["Correspondence Problem", "High Light"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01315082", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1315082", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2004-1.html#OgaleA04", "http://csdl.computer.org/comp/proceedings/cvpr/2004/2158/01/215810568abs.htm", "http://www.cs.umd.edu/~ogale/papers/ocvpr04.pdf", "http://www.cs.umd.edu/users/ogale/papers/ocvpr04.pdf", "https://www.cs.umd.edu/~ogale/papers/ocvpr04.pdf"], "t": "Stereo Correspondence with Slanted Surfaces: Critical Implications of Horizontal Slant", "v": "CVPR", "y": 2004, "rn": 24}, {"a": ["Renato Pajarola"], "b": "Real-time rendering and multiresolution modeling of tri- angulated surfaces has attracted growing interest over the last decade. For interactive visualization of very large scale grid digital elevation models efficiency is a particularly important aspect. The graphics rendering load must be con- trolled by reducing the number of rendered primitives using level-of-detail (LOD) techniques, adaptive extraction of LOD triangle meshes in", "cn": 37, "i": 2377795, "k": ["Digital Elevation Model", "Interactive Rendering", "Interactive Visualization", "Large Scale", "multiresolution modeling", "Real Time Rendering", "Terrain Visualization", "Triangle Mesh", "Level of Detail"], "p": ["http://kucg.korea.ac.kr/education/2004/CSCE458/paper/quadtree.pdf", "http://www.cs.uzh.ch/vmml/admin/upload/UCI-ICS-02-01.pdf", "http://vmml.ifi.uzh.ch/files/pdf/publications/UCI-ICS-02-01.pdf", "http://www.ifi.uzh.ch/arvo/vmml/admin/upload/UCI-ICS-02-01.pdf"], "t": "Overview of Quadtree-based Terrain Triangulation and Visualization", "y": 2002, "rn": 38}, {"a": ["S. Soattot", "P. Peronat", "R Frezzat", "G. Piccis"], "b": "An algorithm that performs recursive estimation of ego-motion and ambient structure from a stream of monocular perspective images of a number of feature points is presented. The algorithm is based on an extended Kalman filter (EKF) that integrates over time the instantaneous motion and structure measurements computed by a two-perspective-views step. The key features of the authors' filter are: global", "cn": 33, "i": 359231, "k": ["extended kalman filter", "Recursive Estimation", "Structural Estimation", "Structure and Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=341095", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00341095"], "t": "Recursive motion and structure estimation with complete error characterization", "v": "CVPR", "y": 1993, "rn": 28}, {"a": ["Sabry El-hakim", "J.-Angelo Beraldin", "Michel Picard", "Antonio Vettore"], "b": "Over the past few years, remarkable increase has occurred in the demand for 3D models for cultural heritage applications. The techniques employed have evolved from surveying and CAD tools and/or traditional photogrammetry into laser scanning and more automated image-based techniques. However, selecting the most effective technique for a given project is not obvious. We will discuss each technique and point", "cn": 32, "i": 1872535, "k": ["3d model", "Cultural Heritage", "Image Based Rendering", "image-based modeling", "Laser Scanning", "Level of Detail"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1240263", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01240263", "http://csdl.computer.org/comp/proceedings/3dim/2003/1991/00/19910302abs.htm", "http://www.3dphotomodeling.org/El-Hakim-3DIM_03.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2003.html#El-HakimBPV03"], "t": "Effective 3D Modeling Of Heritage Sites", "v": "3DIM", "y": 2003, "rn": 12}, {"a": ["Richard Szeliski", "Daniel Scharstein"], "b": "A central issue in stereo algorithm design is the choice of matching cost. Many algorithms simply use squared or absolute intensity differences based on integer disparity steps. In this paper we address potential problems with such approaches. We begin with a careful analysis of the properties of the continuous disparity space image (DSI) and propose several new matching cost variants", "cn": 29, "i": 1719744, "k": ["Algorithm Design", "Empirical Evaluation", "Disparity Space Image", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1262341", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1262341", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami26.html#SzeliskiS03", "http://benjerry.middlebury.edu/~schar/papers/symcosts-draft.pdf", "http://www.cs.middlebury.edu/~schar/papers/symcosts-draft.pdf", "http://csdl.computer.org/comp/trans/tp/2004/03/i0419abs.htm"], "t": "Sampling the Disparity Space Image", "v": "PAMI", "y": 2003, "rn": 20}, {"a": ["Reinhard Koch", "Marc Pollefeys", "Luc Gool"], "b": "Abstract   In this  contribution we  focus  on calibration  and  D  surface modeling  from  uncalibrated  images   A  large  number  of  images  from  a scene is collected with a hand held camera by simply waving the camera around  the  objects  to  be  modeled   The  images  need  not  be  taken  in sequential  order   thus  either  video  streams  or  sets  of  still  images  may", "cn": 24, "i": 501203, "k": ["Depth Estimation", "Depth Map", "Geometric Model", "Image Matching", "Image Sequence", "Probability Density", "Structure From Motion", "Surface Model", "Surface Representation", "Video Streaming"], "p": [], "t": "Robust Calibration and 3D Geometric Modeling From Large Collections of Uncalibrated Images", "v": "", "y": 1999, "rn": 0}, {"a": ["Peter Burt", "Lambert Wixson", "Garbis Salgian"], "b": "A key to developing computationally efficient stereo vision is the incorporation of intelligent control. Stereo is most effective when it is able to \u201cfocus\u201d its analysis on regions and details of a scene that are important to the task at hand, while avoiding less important regions and unnecessary detail. The paper describes two methods for electronically \u201cfocusing\u201d stereo measurement through", "cn": 23, "i": 524073, "k": ["Intelligent Control", "Stereo Vision"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00466801", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=466801"], "t": "Electronically Directed \"Focal\" Stereo", "v": "ICCV", "y": 1995, "rn": 6}, {"a": ["Grant Schindler", "Frank Dellaert"], "b": "Edges in man-made environments, grouped according to vanishing point directions, provide single-view constraints that have been exploited before as a precursor to both scene understanding and camera calibration. A Bayesian ap- proach to edge grouping was proposed in the \u00ecManhattan World\u00ee paper by Coughlan and Yuille, where they assume the existence of three mutually orthogonal vanishing direc- tions in the", "cn": 22, "i": 1788487, "k": ["Camera Calibration", "Degree of Freedom", "Em Algorithm", "Expectation Maximization", "High Dimensionality", "Mobile Robot", "Recursive Estimation", "Relative Orientation", "Scene Understanding", "Stochastic Algorithm", "Vanishing Point"], "p": ["http://csdl.computer.org/comp/proceedings/cvpr/2004/2158/01/215810203abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1315033", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01315033", "http://www.cc.gatech.edu/~dellaert/ftp/Schindler04cvpr.pdf", "http://www.cc.gatech.edu/~dellaert/pub/Schindler04cvpr.pdf", "http://www.cc.gatech.edu/~phlosoft/files/schindler04cvpr.pdf"], "t": "Atlanta World: An Expectation Maximization Framework for Simultaneous Low-Level Edge Grouping and Camera Calibration in Complex Man-Made Environments", "v": "CVPR", "y": 2004, "rn": 14}, {"a": ["Michael Bosse", "Richard Rikoski", "John Leonard", "Seth Teller"], "b": "This paper describes a system for structure-from-motion us- ing vanishing points and three-dimensional lines extracted from omni-directional video sequences. Two novel aspects of this work are its deferred initialization of features using noisy observations from multiple, uncertain vantage points, and its use of dynamic programming for efficient 3D line tracking. We show preliminary results from the system for both indoor", "cn": 20, "i": 53152, "k": ["Dynamic Program", "Structure From Motion", "Three Dimensional", "Vanishing Point", "Visual Navigation"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2002-3.html#BosseRLT02", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01039020", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1039020"], "t": "Vanishing points and 3D lines from omnidirectional video", "v": "ICIP", "y": 2002, "rn": 26}, {"a": ["Xenophon Zabulis", "Kostas Daniilidis"], "b": "In this paper, we present a new algorithm for recon- structing an environment from images recorded by multi- ple calibrated cameras. Multiple camera systems challenge traditional stereo algorithms in many issues including view registration, selection of commonly visible image parts for matching, and the fact that surfaces are imaged differently from different viewpoints and poses. On the other hand, multiple", "cn": 19, "i": 1875203, "k": [], "p": ["http://www.ics.forth.gr/~zabulis/C13.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01335388", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1335388", "http://csdl.computer.org/comp/proceedings/3dpvt/2004/2223/00/22230733abs.htm", "http://www.cis.upenn.edu/~kostas/mypub.dir/zabulis04-3dpvt.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2004.html#ZabulisD04"], "t": "Multi-Camera Reconstruction based on Surface Normal Estimation and Best Viewpoint Selection", "v": "3DPVT", "y": 2004, "rn": 15}, {"a": ["A Zisserman", "D Murray", "P Beardsley"], "b": " . A structure from motion algorithm is described whichrecovers structure and camera position,modulo a projectiveambiguity. Camera calibration is not required, and camera parameters such as focallength can be altered freely during motion. The structure is updated sequentially over an image sequence,in contrast to schemes which employabatch process. A specialisation of the algorithm to recover structureand camera position modulo an affine", "cn": 19, "i": 95318, "k": ["Affine Transformation", "Camera Calibration", "Image Sequence", "Structure From Motion"], "p": [], "t": "Sequential Updating of Projective and Affine Structure from Motion", "v": "IJCV", "y": 2001, "rn": 0}, {"a": ["Grant Schindler", "Panchapagesan Krishnamurthy", "Frank Dellaert"], "b": "We present a novel method for recovering the 3D-line struc- ture of a scene from multiple widely separated views. Tra- ditional optimization-based approaches to line-based struc- ture from motion minimize the error between measured line segments and the projections of corresponding 3D lines. In such a case, 3D lines can be optimized using a minimum of 4 parameters. We show", "cn": 17, "i": 2412733, "k": ["3d reconstruction", "Automatic Detection", "Degree of Freedom", "Estimation Method", "Structure From Motion", "Urban Environment", "Vanishing Point"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2006.html#SchindlerKD06", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4155810", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04155810", "http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.90", "http://www.cc.gatech.edu/~phlosoft/files/schindler06_3dpvt.pdf"], "t": "Line-Based Structure from Motion for Urban Environments", "v": "3DPVT", "y": 2006, "rn": 13}, {"a": ["Grant Schindler", "Frank Dellaert", "Sing Kang"], "b": "In this paper, we describe a technique to temporally sort a collection of photos that span many years. By reasoning about persistence of visible structures, we show how this sorting task can be formulated as a constraint satisfaction problem (CSP). Casting this problem as a CSP allows us to efficiently find a suitable ordering of the images despite the large", "cn": 12, "i": 4113880, "k": ["3d structure", "Constraint Satisfaction Problem"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#SchindlerDK07", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270113", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270113", "http://www.cc.gatech.edu/~phlosoft/files/schindler07cvpr.pdf", "http://www.eecs.umich.edu/~silvio/teaching/EECS598/papers/schindler07cvpr.pdf", "http://dx.doi.org/10.1109/CVPR.2007.383088"], "t": "Inferring Temporal Order of Images From 3D Structure", "v": "CVPR", "y": 2007, "rn": 12}, {"a": ["Henrik Stew", "Magnus Oskarsson"], "b": "We present a method to obtain the solutions to the general- ized 6-point relative pose problem. The problem is to find the relative positions of two generalized cameras so that six corresponding image rays meet in space. Here, a general- ized camera is a camera that captures some arbitrary set of rays and does not adhere to the central perspective", "cn": 11, "i": 4595909, "k": ["Coordinate System", "General Relativity", "Numerical Experiment", "Relative Position"], "p": ["http://www.vis.uky.edu/~stewe/publications/stewenius_05_omnivis_sm26gen.pdf", "http://www.fieldrobotics.org/~cgeyer/OMNIVIS05/final/Stewenius.pdf", "http://www.vis.uky.edu/~dnister/Publications/2005/Generalized2ViewPose/sm26gen_omnivis.pdf", "http://vis.uky.edu/~dnister/Publications/2005/Generalized2ViewPose/sm26gen_omnivis.pdf"], "t": "Solutions to Minimal Generalized Relative Pose Problems", "y": 0, "rn": 12}, {"a": ["Louis-philippe Morency", "Ali Rahimi", "Trevor Darrell"], "b": "We propose a fast 3D model acquisition system that aligns intensity and depth images, and reconstructs a tex- tured 3D mesh. 3D views are registered with shape align- ment based on intensity gradient constraints and a global registration algorithm. We reconstruct the 3D model using a new Cubic Ray Projection merging algorithm which takes advantage of a novel data structure:", "cn": 6, "i": 18213, "k": ["3d model", "Data Structure", "Face Modeling", "Real Time"], "p": ["http://groups.csail.mit.edu/vision/vip/papers/3dpvt2002.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1024057", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01024057", "http://csdl.computer.org/comp/proceedings/3dpvt/2002/1521/00/15210172abs.htm"], "t": "Fast 3D Model Acquisition from Stereo Images", "v": "3DPVT", "y": 2002, "rn": 16}, {"a": ["Renato Pajarola", "Yu Meng", "Miguel Sainz"], "b": "", "cn": 5, "i": 422039, "k": [], "p": [], "t": "Fast Depth-Image Meshing and Warping", "y": 0, "rn": 24}, {"a": ["Seth Teller", "Matthew Antone", "Zachary Bodnar", "Michael Bosse", "Satyan Coorg", "Manish Jethwa", "Neel Master"], "b": "We describe a dataset of several thousand calibrated, time-stamped, geo-referenced, high dynamic range color images, acquired under uncontrolled, variable illumination conditions in an outdoor region spanning several hundred meters. The image data is grouped into several regions which have little mutual inter-visibility. For each group, the calibration data is globally consistent on average to roughly five centimeters and 0 1\u00b0,", "cn": 3, "i": 15271193, "k": ["Close Range Photogrammetry", "Color Image", "High Dynamic Range", "Image Features", "Structure From Motion", "Urban Area"], "p": ["http://www.springerlink.com/index/v5828283375k0655.pdf", "http://www.springerlink.com/content/v5828283375k0655", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/A:1023035826052"], "t": "Calibrated, Registered Images of an Extended Urban Area", "v": "IJCV", "y": 2003, "rn": 22}, {"a": ["Tomokazu Sato", "Masayuki Kanbara", "Naokazu Yokoya", "Haruo Takemura"], "b": "Three-dimensional (3-D) models of outdoor scenes are widely used for object recognition, navigation, mixed reality, and so on. Because such models are often made manually with high costs, automatic 3-D reconstruction has been widely investigated. In related work, a dense 3-D model is generated by using a stereo method. However, such approaches cannot use several hundreds images together for dense", "cn": 3, "i": 15271099, "k": ["Depth Estimation", "Depth Map", "Image Sequence", "Mixed Reality", "Object Recognition", "Three Dimensional"], "p": ["http://www.springerlink.com/content/bc1pjq7qwf9h6t57", "http://www.springerlink.com/index/bc1pjq7qwf9h6t57.pdf", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/A:1014537706773"], "t": "Dense 3-D Reconstruction of an Outdoor Scene by Hundreds-Baseline Stereo Using a Hand-Held Video Camera", "v": "IJCV", "y": 2002, "rn": 13}, {"a": ["Michael Bosse", "Richard Rikoski", "John Leonard", "Seth Teller"], "b": "There is increasing interest in the development of structure from motion (SFM) algorithms capable of running in real-time [6, 8]. Real-time SFM will en-able applications such as (1) real-time navigation of mobile robots in unknown environments, (2) real-time capture of three-dimensional (3-D) computer models using hand-held cameras, and (3) real-time head tracking in extended environments. The set of choices in", "cn": 2, "i": 1695197, "k": ["Computer Model", "Head Tracking", "Mobile Robot", "Sequential Monte Carlo Method", "State Estimation", "Structure From Motion", "Three Dimensional", "Vanishing Point", "kalman filter", "Real Time"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/vc/vc19.html#BosseRLT03", "http://dx.doi.org/10.1007/s00371-003-0205-"], "t": "Vanishing points and three-dimensional lines from omni-directional video", "v": "VC", "y": 2003, "rn": 25}, {"a": ["Benjamin Pitzer", "S\u00f6ren Kammel", "Charles DuHadway", "Jan Becker"], "b": "This paper describes a system for automatic mapping and generation of textured 3D models of indoor environments without user interaction. Our data acquisition system is based on a Segway RMP platform which allows us to automatically acquire large amounts of textured 3D scans in a short amount of time. The first data processing step is registration and mapping. We propose", "cn": 3, "i": 13765282, "k": ["3d model", "3d scanning", "Automatic Generation", "Data Acquisition System", "Data Processing", "Indoor Environment", "Large Scale", "Non-rigid Registration", "Prior Distribution", "Sensor Model", "Surface Reconstruction", "Surface Representation", "User Interaction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509568", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05509568", "http://www.informatik.uni-trier.de/~ley/db/conf/icra/icra2010.html#PitzerKDB10"], "t": "Automatic reconstruction of textured 3D models", "v": "ICRA", "y": 2010, "rn": 28}, {"a": ["Branislav Micus\u00edk", "Jana Koseck\u00e1"], "b": "Urban environments possess many regularities which can be efficiently exploited for 3D dense reconstruction from multiple\n widely separated views. We present an approach utilizing properties of piecewise planarity and restricted number of plane\n orientations to suppress reconstruction and matching ambiguities causing failures of standard dense stereo methods. We formulate\n the problem of the 3D reconstruction in MRF framework built on", "cn": 3, "i": 15271322, "k": ["3d reconstruction", "multi-view stereo", "Urban Environment"], "p": ["http://www.springerlink.com/index/xgg1785874pt3330.pdf", "http://www.springerlink.com/content/xgg1785874pt3330", "http://www.springerlink.com/index/10.1007/s11263-010-0327-9", "http://www.springerlink.com/index/pdf/10.1007/s11263-010-0327-9", "http://dx.doi.org/10.1007/s11263-010-0327-9", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv89.html#MicusikK10"], "t": "Multi-view Superpixel Stereo in Urban Environments", "v": "IJCV", "y": 2010, "rn": 41}, {"a": ["Carl Olsson", "Anders Eriksson"], "b": "\n In this theoretical paper we consider the problem of accurately triangulating a scene plane. Rather than first triangulating\n a set of points and then fitting a plane to these points, we try to minimize the back-projection errors as functions of the\n plane parameters directly. As this is both geometrically and statistically meaningful our method performs better than the\n standard two", "cn": 0, "i": 39277589, "k": ["Optimal Method"], "p": ["http://www.springerlink.com/content/w0621367146043g1", "http://www.springerlink.com/index/w0621367146043g1.pdf", "http://dx.doi.org/10.1007/978-3-642-21227-7_2", "http://www.informatik.uni-trier.de/~ley/db/conf/scia/scia2011.html#OlssonE11"], "t": "Triangulating a Plane", "v": "", "y": 2011, "rn": 21}, {"a": ["Bernhard Zeisl", "Christopher Zach", "Marc Pollefeys"], "b": "Image-based computation of a 3D map for an indoor environment is a very challenging task, but also a useful step for vision-based navigation and path planning for autonomous systems, and for efficient visualization of interior spaces. Since computational stereo is a highly ill-posed problem for the typically weakly textured, specular, and even sometimes transparent indoor environments, one has to incorporate", "cn": 0, "i": 51080361, "k": ["3d reconstruction", "Autonomic System", "Computer Model", "Depth Estimation", "Dynamic Program", "Ill-posed Problem", "Image Reconstruction", "Indoor Environment", "Open Space", "Path Planning", "Three Dimensional", "Vertical Structure"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955383", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955383", "http://www.inf.ethz.ch/personal/pomarc/pubs/Zeisl3DIMPVT11.pdf"], "t": "Stereo Reconstruction of Building Interiors with a Vertical Structure Prior", "v": "3DIMPVT", "y": 2011, "rn": 18}, {"a": ["S. Shukor", "K. Young", "E. Rushforth"], "b": "This document highlights on a knowledge-based method to reconstruct planar surfaces of a real indoor environment with occlusion and clutter, which produce a reliable 3D modeling rapidly. The input is 3D point cloud data obtained from a laser scanner, which is known for its accuracy and speed in producing 3D data. The laser is attached on a mobile platform with", "cn": 0, "i": 51090557, "k": ["3d model", "3d point cloud", "Building Information Model", "Computational Geometry", "Facility Management", "Indoor Environment", "Knowledge Base", "Laser Scanner", "Mobile Robot", "Semantic Mapping", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5971296", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05971296"], "t": "3D modeling of indoor surfaces with occlusion and clutter", "v": "ICM", "y": 2011, "rn": 13}, {"a": ["Kentaro Kofuji", "Yoshihiro Watanabe", "Takashi Komuro", "Masatoshi Ishikawa"], "b": "We propose a new method of indoor-scene stereo vision that uses probabilistic prior knowledge of indoor scenes in order to exploit the global structure of artificial objects. In our method, we assume three properties of the global structure \u2014 planarity, connectivity, and parallelism/orthogonality \u2014 and we formulate them in the framework of maximum a posteriori (MAP) estimation. To enable robust", "cn": 0, "i": 51099842, "k": ["3d reconstruction", "Image Reconstruction", "Image Segmentation", "Map Estimation", "Prior Knowledge", "Probability Distribution", "Robust Estimator", "Shape Estimation", "Stereo Vision", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05979560", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5979560"], "t": "Stereo 3D reconstruction using prior knowledge of indoor scenes", "v": "ICRA", "y": 2011, "rn": 21}, {"a": ["Asako Kanezaki", "Takahiro Suzuki", "Tatsuya Harada", "Yasuo Kuniyoshi"], "b": "Realizing automatic object search by robots in an indoor environment is one of the most important and challenging topics in mobile robot research. If the target object does not exist in a nearby area, the obvious strategy is to go to the area in which it was last observed. We have developed a robot system that collects 3D-scene data in", "cn": 0, "i": 51100356, "k": ["Color Image", "Data Extraction", "Feature Extraction", "Image Color Analysis", "Indoor Environment", "Learning Process", "Mobile Robot", "Object Detection", "Range Image", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05980129", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5980129"], "t": "Fast object detection for robots in a cluttered indoor environment using integral 3D feature table", "v": "ICRA", "y": 2011, "rn": 25}, {"a": ["Wang Tao", "Yan Lei"], "b": "", "cn": 0, "i": 51103527, "k": ["Bundle Adjustment", "Data Model", "Feature Extraction", "Flight Control", "image mosaicing", "Mathematical Model"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05987568", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5987568"], "t": "UAV aerotriangulation with flight-control data support", "v": "MACE", "y": 2011, "rn": 5}, {"a": ["Maarten Aerts", "Erwin Six"], "b": "", "cn": 0, "i": 51143436, "k": ["Camera Calibration", "Image Segmentation", "Mathematical Model"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6042906", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06042906"], "t": "Staging RANSAC: An indoor camera calibration method", "y": 2011, "rn": 13}, {"a": ["Christopher Zach", "Jongwoo Lim", "Ananth Ranganathan", "Marc Pollefeys"], "b": "We present a method to reconstruct indoor envi- ronments from stereo image pairs, suitable for the navigation of robots. To enable a robot to navigate solely using visual cues it receives from a stereo camera, the depth information needs to be extracted from the image pairs and combined into a common representation. The initially determined raw depthmaps are fused into", "cn": 0, "i": 51147996, "k": ["Computational Complexity", "Cost Function", "Depth Map", "Energy Function", "Energy Optimization", "Image Reconstruction", "Indoor Environment", "Information Need", "Least Squares Approximation", "Robot Navigation", "Total Variation Regularization", "Visual Cues"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6048261", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06048261", "http://www.inf.ethz.ch/personal/pomarc/pubs/HaeneIROS11.pdf"], "t": "Stereo Depth Map Fusion for Robot Navigation", "v": "IROS", "y": 2011, "rn": 13}, {"a": ["Michael Goesele", "Jens Ackermann", "Simon Fuhrmann", "Carsten Haubold", "Ronny Klowsky"], "b": "View interpolation and image-based rendering algorithms often produce visual artifacts in regions where the 3D scene geometry is erroneous, uncertain, or incomplete. We introduce ambient point clouds constructed from colored pixels with uncertain depth, which help reduce these artifacts while providing non-photorealistic background coloring and emphasizing reconstructed 3D geometry. Ambient point clouds are created by randomly sampling colored points along", "cn": 0, "i": 13334301, "k": ["3d point cloud", "Image Based Rendering", "Point Cloud", "Rendering System", "View Interpolation"], "p": ["http://doi.acm.org/10.1145/1833351.1778832", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog29.html#GoeseleAFHKD10", "http://portal.acm.org/citation.cfm?doid=1833351.1778832", "http://portal.acm.org/citation.cfm?doid=1778765.1778832", "http://research.microsoft.com/apps/pubs/default.aspx?id=131808", "http://research.microsoft.com/pubs/131808/Goesele-SG10.pdf"], "t": "Ambient point clouds for view interpolation", "v": "TOG", "y": 2010, "rn": 30}, {"a": ["Tomokazu Sato", "Hiroyuki Koshizawa", "Naokazu Yokoya"], "b": "This paper proposes a method to render free viewpoint images from omnidirectional videos using a deformable 3-D mesh model. In the proposed method, a 3-D mesh is placed in front of a virtual viewpoint and deformed by using the pre-estimated omnidirectional depth maps that are selected on the basis of position and posture of the virtual viewpoint. Although our approach", "cn": 0, "i": 13510170, "k": ["Depth Map", "Geometric Correction", "Indexing Terms", "Omnidirectional Vision", "View Synthesis", "Virtual Environment", "Virtual Worlds"], "p": ["http://yokoya.naist.jp/paper/datas/1140/ijvr_sato.pdf"], "t": "Omnidirectional Free-viewpoint Rendering Using a Deformable 3-D Mesh Model", "y": 2010, "rn": 18}, {"a": ["Florent Lafarge", "Renaud Keriven", "Mathieu Bredif"], "b": "We propose an original hybrid modeling process of urban scenes that represents 3-D models as a combination of mesh-based surfaces and geometric 3-D-primitives. Meshes describe details such as ornaments and statues, whereas 3-D-primitives code for regular shapes such as walls and columns. Starting from an 3-D-surface obtained by multiview stereo techniques, these primitives are inserted into the surface after being", "cn": 0, "i": 14356325, "k": ["Compact Model", "Depth Map", "Graph Cut", "Hybrid Model"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5430920", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5430920", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05430920", "http://dx.doi.org/10.1109/TIP.2010.2045695", "http://www.informatik.uni-trier.de/~ley/db/journals/tip/tip19.html#LafargeKB10", "http://adsabs.harvard.edu/abs/2010ITIP...19.1683L"], "t": "Insertion of 3-D-Primitives in Mesh-Based Representations: Towards Compact Models Preserving the Details", "v": "", "y": 2010, "rn": 49}, {"a": ["Michael Goesele", "Jens Ackermann", "Simon Fuhrmann", "Carsten Haubold", "Ronny Klowsky", "Drew Steedly", "Richard Szeliski"], "b": "View interpolation and image-based rendering algorithms often produce visual artifacts in regions where the 3D scene geometry is erroneous, uncertain, or incomplete. We introduce ambient point clouds constructed from colored pixels with uncertain depth, which help reduce these artifacts while providing non-photorealistic background coloring and emphasizing reconstructed 3D geometry. Ambient point clouds are created by randomly sampling colored points along", "cn": 0, "i": 39244563, "k": ["3d point cloud", "Image Based Rendering", "Point Cloud", "Real Time Rendering", "View Interpolation"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1778832&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1778832"], "t": "Ambient point clouds for view interpolation", "y": 2010, "rn": 31}, {"a": ["Shanat Kolhatkar", "R. Laganie\u0300re"], "b": "In this paper we present a method for achieving real-time view interpolation in a virtual navigation application that uses a collection of pre-captured panoramic views as a representation of the environment. In this context, viewpoint interpolation is essential to achieve smooth and realistic viewpoint transition while the user is moving from one panorama to another. In this proposed approach, view", "cn": 0, "i": 50891575, "k": ["Flow Field", "View Interpolation", "Optical Flow", "On The Fly", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5479488", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05479488"], "t": "Real-Time Virtual Viewpoint Generation on the GPU for Scene Navigation", "v": "CRV", "y": 2010, "rn": 11}, {"a": ["Takuji Narumi", "Oribe Hayashi", "Kazuhiro Kasada", "Mitsuhiko Yamazaki", "Tomohiro Tanikawa", "Michitaka Hirose"], "b": "\n In this paper, we propose a MR museum exhibition system, the \u201cDigital Diorama\u201d system, to convey background information intuitively.\n The The system aims to offer more features than the function of existing dioramas in museum exhibitions by using mixed reality\n technology. The system superimposes computer generated diorama scene reconstructed from related image/video materials onto\n real exhibits. First, we implement and", "cn": 0, "i": 48822813, "k": ["Location Estimation", "Mixed Reality", "Scene Reconstruction"], "p": ["http://www.springerlink.com/content/k23765421574t1ml", "http://www.springerlink.com/index/k23765421574t1ml.pdf"], "t": "Digital Diorama: AR Exhibition System to Convey Background Information for Museums", "y": 0, "rn": 19}, {"a": ["William Lorensen", "Harvey Cline"], "b": "We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to gen- erate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of", "cn": 4258, "i": 883686, "k": ["Computed Tomography", "Computer Graphic", "Divide and Conquer", "High Resolution", "Information Presentation", "Linear Interpolation", "Magnetic Resonance", "Marching Cube", "Medical Image", "Single Photon Emission Computed Tomography", "Solid Modeling", "Surface Model", "Surface Reconstruction"], "p": ["http://doi.acm.org/10.1145/37401.37422", "http://portal.acm.org/citation.cfm?id=37401.37422", "http://ljk.imag.fr/membres/Stefanie.Hahmann/ENSIMAG/TP_VISC/LorensenClineMarchingCubes1987.pdf", "http://www.cs.sfu.ca/~haoz/teaching/cmpt464/references/87_Lorensen_MarchingCubes.pdf", "http://www.cc.gatech.edu/~bader/COURSES/GATECH/CS8803-Fall2006/papers/LC87.pdf", "http://www.cc.gatech.edu/~bader/COURSES/GATECH/CSE6140-Fall2009/papers/LC87.pdf", "http://www.cs.technion.ac.il/~u_shani/cs236807-S2/papers/p163-lorensen.pdf", "http://kucg.korea.ac.kr/seminar/2002/src/SR-02-07.pdf", "http://www.cs.stevens.edu/~quynh/courses/cs638-papers/marching_cubes.pdf", "http://www.cs.stevens.edu/~quynh/courses/cs537-notes/marching_cubes.pdf", "http://www.cc.gatech.edu/~bader/COURSES/GATECH/CSE6140-Fall2007/papers/LC87.pdf", "http://www-ee.uta.edu/Online/Devarajan/ee6358/marching%20cubes%20algorithm.pdf", "http://portal.acm.org/citation.cfm?doid=37402.37422", "http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1987.html#LorensenC87", "http://portal.acm.org/citation.cfm?id=37402.37422", "http://www.cs.duke.edu/courses/spring03/cps296.8/papers/MarchingCubes.pdf", "http://marchingcubes.org/images/f/f9/MarchingCubes.pdf", "http://www.hpc2n.umu.se/events/ngssc/04/visualization/reading/p163-lorensen.pdf", "http://graphics.cs.ucdavis.edu/~joy/ecs277/papers/MarchingCubes.pdf", "http://www.cs.virginia.edu/johntran/GLunch/marchingcubes.pdf", "http://faculty.cs.tamu.edu/schaefer/teaching/689_Fall2006/p163-lorensen.pdf", "http://tremere.web.elte.hu/cg/files/Marching%20cubes%20-%20A%20high%20resolution%203D%20surface%20construction%20algorithm.pdf", "http://undergraduate.csse.uwa.edu.au/units/CITS4241/Project/references/Lorensen-Cline.pdf", "http://www.miba.auc.dk/~se/Teaching/ImageAnalysis/Literature/Lorensen1987.pdf", "http://kucg.korea.ac.kr/seminar/2004/src/sr-04-01.pdf", "http://kucg.korea.ac.kr/education/2003_2/VIP618/paper/mc.pdf", "http://www.cc.gatech.edu/fac/bader/COURSES/GATECH/CSE6140-Fall2008/papers/LC87.pdf", "http://www.cs.duke.edu/courses/cps124/fall01/resources/p163-lorensen.pdf", "http://graphics.ethz.ch/teaching/scivis_common/Literature/lorensen87.pdf", "http://www.csee.wvu.edu/~tmcgraw/cs593spring2006/p163-lorensen.pdf", "http://cse.spsu.edu/jpreston/cs6353/2008%20Fall/readings/marching_cubes.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2002/BigData/papers/Volume%20Rendering/Marching%20Cubes%20-%20A%20High%20Resolution%20Surface%20Reconstruction%20Algorithm.pdf", "http://www.cs.duke.edu/courses/cps124/fall02/resources/p163-lorensen.pdf", "http://www.cg.inf.ethz.ch/teaching/scivis_common/Literature/lorensen87.pdf", "http://www.cs.purdue.edu/homes/aliaga/cs197-10/papers/marching_cubes.pdf", "http://mesh.brown.edu/3dpgp-2008/pdfs/lorensen-sg87.pdf", "http://www.cs.stevens.edu/~quynh/courses/cs437-fa06/marching_cubes.pdf", "http://www.cse.nd.edu/courses/cse598w/www/p163-lorensen.pdf", "http://www.cc.gatech.edu/~bader/COURSES/GATECH/CSE6140-Fall2008/papers/LC87.pdf", "http://www.cc.gatech.edu/fac/bader/COURSES/GATECH/CSE6140-Fall2009/papers/LC87.pdf", "http://kucg.korea.ac.kr/seminar/2003/src/sr-03-04.pdf"], "t": "Marching cubes: A high resolution 3D surface construction algorithm", "v": "", "y": 1987, "rn": 32}, {"a": ["Steven Gortler", "Radek Grzeszczuk", "Richard Szelinski", "Michael Cohen"], "b": "This paper discusses a new method for capturing the complete appearance of both synthetic and real world objects and scenes, representing this information, and then using this representation to render images of the object from new camera positions. Unlike the shape capture process traditionally used in computer vision and the rendering process traditionally used in computer graphics, our approach does", "cn": 1159, "i": 261036, "k": ["Computer Graphic", "plenoptic function"], "p": ["http://portal.acm.org/citation.cfm?id=237200", "http://doi.acm.org/10.1145/237170.237200", "http://portal.acm.org/citation.cfm?id=237170.237200", "http://research.microsoft.com/apps/pubs/default.aspx?id=68168", "http://research.microsoft.com/pubs/68168/Gortler-SG96.pdf"], "t": "The Lumigraph", "v": "SIGGRAPH", "y": 1996, "rn": 32}, {"a": ["Paul Debevec", "Camillo Taylor", "Jitendra Malik"], "b": "We present an approach for creating realistic synthetic views of existing architectural scenes from a sparse set of still photographs. Our approach, which combines both geometry-based and image-based modeling and rendering techniques, has two components. The first component is an easy-to-use photogrammetric modeling system which facilitates the recovery of a basic geometric model of the photographed scene. The modeling system", "cn": 1039, "i": 309743, "k": ["Geometric Model", "Image Based Rendering", "image-based modeling", "image-based modeling and rendering", "Model System", "Texture Mapping"], "p": ["http://www.cs.hunter.cuny.edu/~ioannis/3DP_F03/PAPERS/MATERIAL_LIGHT_MODEL/DEBEVEC/debevec-siggraph96.pdf", "http://portal.acm.org/ft_gateway.cfm?id=237191&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=237191", "http://www.debevec.org/Research/debevec-siggraph96.pdf", "http://www.cs.unc.edu/~ibr/other_pubs/debevec_sig96.pdf", "http://www.cis.upenn.edu/~cjtaylor/PUBLICATIONS/pdfs/DebevecSIGGRAPH96.pdf", "http://www.cs.cmu.edu/~seitz/course/SIGG99/papers/debe96.pdf", "http://artis.imag.fr/~Gilles.Debunne/Enseignement/DEA/PDF/IBR/HybridModel.pdf", "http://doi.acm.org/10.1145/237170.237191", "http://kucg.korea.ac.kr/seminar/2002/src/PA-02-07.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2006/DataDriven/bib/ibm/debevec96.pdf", "http://artis.imag.fr/Membres/Gilles.Debunne/Enseignement/DEA/PDF/IBR/HybridModel.pdf", "http://artis.imag.fr/Members/Gilles.Debunne/Enseignement/DEA/PDF/IBR/HybridModel.pdf", "http://www.cs.ucsb.edu/%7Eholl/CS595B/handouts/SIGGRAPH1996/Debevec-1996-ModelingPhotographs.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1996.html#DebevecTM96", "http://www.seas.upenn.edu/~cjtaylor/PUBLICATIONS/pdfs/DebevecSIGGRAPH96.pdf"], "t": "Modeling and rendering architecture from photographs: a hybrid geometry- and image-based approach", "v": "SIGGRAPH", "y": 1996, "rn": 49}, {"a": ["Chris Buehler", "Michael Bosse", "Leonard McMillan", "Steven Gortler", "Michael Cohen"], "b": "We describe an image based rendering approach that generalizes many current image based rendering algorithms, including light field rendering and view-dependent texture mapping. In particular, it allows for lumigraph-style rendering from a set of input cameras in arbitrary configurations (i.e., not restricted to a plane or to any specific manifold). In the case of regular and planar input camera positions,", "cn": 322, "i": 125794, "k": ["Image Based Rendering", "Light Field Rendering", "Texture Mapping"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph2001.html#BuehlerBMGC01", "http://portal.acm.org/citation.cfm?id=383309", "http://dl.acm.org/citation.cfm?id=383309"], "t": "Unstructured lumigraph rendering", "v": "SIGGRAPH", "y": 2001, "rn": 21}, {"a": ["Pascal M\u00fcller", "Peter Wonka", "Simon Haegler", "Andreas Ulmer", "Luc Gool"], "b": "CGA shape, a novel shape grammar for the procedural modeling of CG architecture, produces building shells with high visual quality and geometric detail. It produces extensive architectural models for computer games and movies, at low cost. Context sensitive shape rules allow the user to specify interactions between the entities of the hierarchical shape descriptions. Selected examples demonstrate solutions to previously", "cn": 182, "i": 2175112, "k": ["Computer Aided Design", "Computer Game", "Procedural Modeling", "Shape Description", "Urban Modeling", "Visual Quality", "Level of Detail"], "p": ["http://portal.acm.org/citation.cfm?doid=1141911.1141931", "http://www.vision.ee.ethz.ch/~pmueller/documents/mueller.procedural_modeling_of_buildings.SG2006.web-version.pdf", "http://www.public.asu.edu/~pwonka/Publications/mueller.procedural%20modeling%20of%20buildings.SG2006.final-web.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog25.html#MullerWHUG06", "http://people.ee.ethz.ch/~pmueller/documents/mueller.procedural_modeling_of_buildings.SG2006.web-version.pdf", "http://kucg.korea.ac.kr/seminar/2006/src/PA-06-26.pdf", "http://doi.acm.org/10.1145/1141911.1141931"], "t": "Procedural modeling of buildings", "v": "TOG", "y": 2006, "rn": 28}, {"a": ["P. Hammer", "P. Hansen", "B. Simeone"], "b": "The paper is concerned with the \u2018primal\u2019 problem of maximizing a given quadratic pseudo-boolean function. Four equivalent\n problems are discussed\u2014the primal, the \u2018complementation\u2019, the \u2018discrete Rhys LP\u2019 and the \u2018weighted stability problem of a\n SAM graph\u2019. Each of them has a relaxation\u2014the \u2018roof dual\u2019, the \u2018quadratic complementation,\u2019 the \u2018continuous Rhys LP\u2019 and the\n \u2018fractional weighted stability problem of a SAM", "cn": 125, "i": 3699802, "k": ["Discrete Optimization", "Maximum Flow", "Optimal Solution", "Polynomial Time", "Pseudo Boolean"], "p": ["http://www.springerlink.com/content/f647l28231653427", "http://www.springerlink.com/index/f647l28231653427.pdf", "http://www.springerlink.com/index/10.1007/BF02612354", "http://www.springerlink.com/index/pdf/10.1007/BF02612354"], "t": "Roof duality, complementation and persistency in quadratic 0\u20131 optimization", "v": "", "y": 1984, "rn": 16}, {"a": ["Nico Cornelis", "Bastian Leibe", "Kurt Cornelis", "Luc Gool"], "b": "Supplying realistically textured 3D city models at ground level promises to be useful for pre-visualizing upcoming traffic\n situations in car navigation systems. Because this pre-visualization can be rendered from the expected future viewpoints of\n the driver, the required maneuver will be more easily understandable. 3D city models can be reconstructed from the imagery\n recorded by surveying vehicles. The vastness of", "cn": 52, "i": 4389472, "k": ["3d city model", "3d reconstruction", "Automatic Detection", "High Speed", "Model Integration", "Navigation System", "Object Detection", "Object Recognition", "Structure From Motion", "Temporal Integration", "Video Streaming"], "p": ["http://www.springerlink.com/index/m46246q0153333q5.pdf", "http://www.springerlink.com/content/m46246q0153333q5", "http://www.springerlink.com/index/10.1007/s11263-007-0081-9", "http://www.springerlink.com/index/pdf/10.1007/s11263-007-0081-9", "http://dx.doi.org/10.1007/s11263-007-0081-9", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv78.html#CornelisLCG08"], "t": "3D Urban Scene Modeling Integrating Recognition and Reconstruction", "v": "IJCV", "y": 2008, "rn": 42}, {"a": ["James Coughlan", "Alan Yuille"], "b": "When designing computer vision systems for the blind and visually impaired it is important to determine the orientation of the user relative to the scene. We observe that most indoor and outdoor (city) scenes are designed on a Manhattan three-dimensional grid. This Manhattan grid structure puts strong constraints on the intensity gradients in the image. We demonstrate an algorithm for", "cn": 52, "i": 175382, "k": ["bayesian inference", "Computer Vision", "Edge Detection", "Three Dimensional", "Visual Impairment"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=790349", "http://computer.org/proceedings/iccv/0164/vol%202/01640941abs.htm"], "t": "Manhattan World: Compass Direction from a Single Image by Bayesian Inference", "v": "ICCV", "y": 1999, "rn": 8}, {"a": ["Noah Snavely", "Rahul Garg", "Steven Seitz", "Richard Szeliski"], "b": "", "cn": 36, "i": 4415774, "k": [], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog27.html#SnavelyGSS08", "http://portal.acm.org/citation.cfm?doid=1360612.1360614", "http://doi.acm.org/10.1145/1360612.1360614"], "t": "Finding paths through the world's photos", "v": "TOG", "y": 2008, "rn": 0}, {"a": ["Jianxiong Xiao", "Tian Fang", "Ping Tan", "Peng Zhao", "Eyal Ofek", "Long Quan"], "b": "We propose in this paper a semi-automatic image-based approach that uses images captured along the streets, and relies on structure from motion to automatically recover the camera positions and point clouds as the initial stage for the modeling. We start a building facade as a flat rectangular plane or a developable surface, and the texture image of the flat facade", "cn": 26, "i": 14418800, "k": ["Developable Surface", "Directed Acyclic Graph", "Point Cloud", "Structure From Motion", "Bottom Up", "Top Down"], "p": ["http://portal.acm.org/citation.cfm?doid=1409060.1409114", "http://research.microsoft.com/apps/pubs/default.aspx?id=149312"], "t": "Image Based Facade Modeling", "v": "TOG", "y": 2008, "rn": 0}, {"a": ["Carlos Hern\u00e1ndez", "George Vogiatzis", "Roberto Cipolla"], "b": "Abstract We present a new formulation to multi-view stereo that treats the problem,as probabilistic 3D segmentation. Pre- vious work has used the stereo photo-consistency criterion as a detector of the boundary,between,the 3D scene and the surrounding,empty space. Here we show how the same criterion can also provide a foreground/background model that can predict if a 3D location is inside or", "cn": 24, "i": 4248121, "k": ["3d segmentation", "Graph Cut", "multi-view stereo", "Foreground Background", "Multi Resolution"], "p": ["http://dx.doi.org/10.1109/CVPR.2007.383193", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270218", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270218", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#HernandezVC07"], "t": "Probabilistic visibility for multi-view stereo", "v": "CVPR", "y": 2007, "rn": 20}, {"a": ["Simon Baker", "Daniel Scharstein", "J. Lewis", "Stefan Roth", "Michael Black", "Richard Szeliski"], "b": "", "cn": 195, "i": 4136935, "k": ["Evaluation Method", "Evaluation Methodology", "Natural Scenes", "Quantitative Evaluation", "Ground Truth", "Next Generation", "Optical Flow"], "p": ["http://www.gris.informatik.tu-darmstadt.de/~sroth/pubs/iccv07baker.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408903", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408903", "http://www.cs.brown.edu/people/black/Papers/flowEval07.pdf", "http://www.idiom.com/~zilla/Work/Gamespace/home/Work/V/FLOWEVAL.pdf", "http://www.cs.brown.edu/~black/Papers/flowEval07.pdf", "http://list.cs.brown.edu/people/black/Papers/flowEval07.pdf", "http://list.cs.brown.edu/~black/Papers/flowEval07.pdf", "http://sca2002.cs.brown.edu/people/black/Papers/flowEval07.pdf", "http://vision3d.iro.umontreal.ca/wp-content/uploads/2009/05/floweval-iccv07.pdf", "http://vision.middlebury.edu/flow/flowEval-iccv07.pdf", "http://mir13.iro.umontreal.ca/wordpress/wp-content/uploads/2009/05/floweval-iccv07.pdf", "http://sca2002.cs.brown.edu/~black/Papers/flowEval07.pdf", "http://research.microsoft.com/pubs/69460/ofdatabase_iccv_07.pdf", "http://www.idiom.com/~zilla/Work/V/FLOWEVAL.pdf", "http://research.microsoft.com/pubs/117766/ofevaltr2.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4408903", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#BakerSLRBS07", "http://research.microsoft.com/apps/pubs/default.aspx?id=69460"], "t": "A Database and Evaluation Methodology for Optical Flow", "v": "ICCV", "y": 2007, "rn": 87}, {"a": ["Daniel Vlasic", "Ilya Baran", "Wojciech Matusik", "Jovan Popovic"], "b": "Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work, we demonstrate a prac- tical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video images that record a human performance from multiple viewpoints and an articulated template of the performer, our system captures the", "cn": 68, "i": 4415789, "k": ["Computer Graphic", "Deformable Model", "Human Performance", "Motion Capture", "Software Systems", "Three-dimensional Graphics and Realism", "Video Recording", "Visual Quality"], "p": ["http://www.cs.washington.edu/homes/jovan/papers/vlasic-2008-ama.pdf", "http://portal.acm.org/citation.cfm?doid=1360612.1360696", "http://people.csail.mit.edu/jovan/assets/papers/vlasic-2008-ama.pdf", "http://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Vlasic08.pdf", "http://people.csail.mit.edu/wojciech/MeshAnim/vlasic-2008-ama.pdf", "http://groups.csail.mit.edu/graphics/pubs/vlasic-2008-ama.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog27.html#VlasicBMP08", "http://www.mit.edu/~ibaran/papers/silhouettes.pdf", "http://web.mit.edu/~ibaran/www/papers/silhouettes.pdf", "http://doi.acm.org/10.1145/1360612.1360696"], "t": "Articulated mesh animation from multi-view silhouettes", "v": "TOG", "y": 2008, "rn": 41}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "This article presents a novel method for acquiring high-quality solid models of complex 3D shapes from multi- ple calibrated photographs. After the purely geometric con- straints associated with the silhouettes found in each image have been used to construct a coarse surface approximation in the form of a visual hull, photoconsistency constraints are enforced in three consecutive steps: (1) the", "cn": 51, "i": 2427393, "k": ["Global Optimization", "Graph Cut", "image-based modeling", "multi-view stereo", "Solid Modeling", "Surface Approximation", "dy namic programming", "Visual Hull"], "p": ["http://www.springerlink.com/content/m41t1355v7262153", "http://www.springerlink.com/index/m41t1355v7262153.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2006-1.html#FurukawaP06", "http://dx.doi.org/10.1007/11744023_44", "http://www.cs.ait.ac.th/~mdailey/cvreadings/Furukawa-VisualHulls.pdf"], "t": "Carved Visual Hulls for Image-Based Modeling", "v": "ECCV", "y": 2006, "rn": 35}, {"a": ["Christoph Strecha", "Wolfgang Hansen", "Luc Gool", "Pascal Fua", "Ulrich Thoennessen"], "b": "In this paper we want to start the discussion on whether image based 3-D modelling techniques can possibly be used to replace LIDAR systems for outdoor 3D data acquisi- tion. Two main issues have to be addressed in this context: (i) camera calibration (internal and external) and (ii) dense multi-view stereo. To investigate both, we have acquired test data from", "cn": 38, "i": 4704811, "k": ["3d model", "Camera Calibration", "High Resolution Imagery", "multi-view stereo", "Pose Estimation", "Ground Truth"], "p": ["http://dx.doi.org/10.1109/CVPR.2008.4587706", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587706", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587706", "http://cvlab.epfl.ch/~strecha/publications/strecha_cvpr_2008.pdf", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/366.pdf", "http://cvlab.epfl.ch/publications/publications/2008/C.StrechaHGFT08.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#StrechaHGFT08", "http://infoscience.epfl.ch/record/126393/files/strecha_cvpr_2008.pdf"], "t": "On benchmarking camera calibration and multi-view stereo for high resolution imagery", "v": "CVPR", "y": 2008, "rn": 18}, {"a": ["George Vogiatzis", "Carlos Esteban", "Philip Torr", "Roberto Cipolla"], "b": "Abstract This paper presents a volumetric formulation for the multi-view,stereo problem,which,is amenable,to a computationally,tractable global optimisation using Graph-cuts. Our approach,is to seek the optimal partitioning of 3D space into two regions labelled as \u2018object\u2019 and \u2018empty\u2019 under a cost functional consisting of the following two terms: (1) A term that forces the boundary between the two regions to pass through", "cn": 37, "i": 4404089, "k": ["Cost Function", "Cross Correlation", "Global Optimisation", "Global Optimization", "Graph Algorithm", "Graph Cut", "Indexing Terms", "Minimum Cut", "multi-view stereo", "Scene Analysis", "Weighted Graph"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4359958", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04359958", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.70712", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4359958", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami29.html#VogiatzisETC07"], "t": "Multiview Stereo via Volumetric Graph-Cuts and Occlusion Robust Photo-Consistency", "v": "PAMI", "y": 2007, "rn": 31}, {"a": ["Andrei Zaharescu", "Edmond Boyer", "Kiran Varanasi", "Radu Horaud"], "b": "In this paper we revisit local feature detec- tors/descriptors developed for 2D images and extend them to the more general framework of scalar fields defined on 2D manifolds. We provide methods and tools to detect and describe features on surfaces equiped with scalar func- tions, such as photometric information. This is motivated by the growing need for matching and tracking", "cn": 30, "i": 5551146, "k": ["3d reconstruction", "Feature Detection", "Local Features", "Scalar Field"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206748", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#ZaharescuBVH09", "http://hal.inria.fr/docs/00/44/04/07/PDF/ZaharescuCVPR09.pdf", "https://perception.inrialpes.fr/Publications/2009/ZBVH09/ZaharescuCVPR09.pdf", "http://perception.inrialpes.fr/Publications/2009/ZBVH09/ZaharescuCVPR09.pdf"], "t": "Surface feature detection and description with applications to mesh matching", "v": "CVPR", "y": 2009, "rn": 26}, {"a": ["Derek Bradley", "Tamy Boubekeur", "Wolfgang Heidrich"], "b": "This paper presents a new algorithm for multi-view reconstruction that demonstrates both accuracy and effi- ciency. Our method is based on robust binocular stereo matching, followed by adaptive point-based filtering of the merged point clouds, and efficient, high-quality mesh gen- eration. All aspects of our method are designed to be highly scalable with the number of views. Our technique produces", "cn": 29, "i": 4704527, "k": ["Deformable Objects", "Point Cloud", "Stereo Matching"], "p": ["http://people.cs.ubc.ca/~heidrich/Papers/CVPR.08.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587792", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587792", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#BradleyBH08", "http://perso.telecom-paristech.fr/~boubek/papers/AMR/amr.pdf", "http://people.cs.ubc.ca/~heidrich/Projects/CVPR.08.pdf", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/452.pdf", "http://dx.doi.org/10.1109/CVPR.2008.4587792"], "t": "Accurate multi-view reconstruction using robust binocular stereo and surface meshing", "v": "CVPR", "y": 2008, "rn": 43}, {"a": ["Andrei Zaharescu", "Edmond Boyer", "Radu Horaud"], "b": "Most of the algorithms dealing with image based 3-D reconstruc- tion involve the evolution of a surface based on a minimization criterion. The mesh parametrization, while allowing for an accurate surface representation, suf- fers from the inherent problems of not being able to reliably deal with self- intersections and topology changes. As a consequence, an important number of methods choose", "cn": 28, "i": 4230594, "k": ["Adaptive Mesh", "Surface Reconstruction", "Surface Representation", "Level Set Method"], "p": ["http://www.springerlink.com/index/m042467831n63m21.pdf", "http://www.springerlink.com/content/m042467831n63m21", "http://dx.doi.org/10.1007/978-3-540-76390-1_17", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2007-2.html#ZaharescuBH07"], "t": "TransforMesh : A Topology-Adaptive Mesh-Based Approach to Surface Evolution", "v": "ACCV", "y": 2007, "rn": 17}, {"a": ["Carlos Hern\u00e1ndez", "George Vogiatzis", "Gabriel Brostow", "Bj\u00f6rn Stenger", "Roberto Cipolla"], "b": "We present an algorithm and the associated capture methodology to acquire and track the detailed 3D shape, bends, and wrinkles of deforming surfaces. Moving 3D data has been difficult to obtain by methods that rely on known surface features, structured light, or silhouettes. Multi spec- tral photometric stereo is an attractive alternative becau se it can recover a dense normal", "cn": 28, "i": 4271431, "k": ["Boundary Condition", "Photometric Stereo", "Structured Light", "Optical Flow", "Red Green and Blue"], "p": ["http://mi.eng.cam.ac.uk/research/projects/VideoNormals/NonRigidPhotometricStereoWithColoredLights_iccv2007.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408939", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408939", "http://dx.doi.org/10.1109/ICCV.2007.4408939", "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2007-ICCV-colour-photometric-video.pdf", "http://george-vogiatzis.org/publications/hernandez_iccv07.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#HernandezVBSC07"], "t": "Non-rigid Photometric Stereo with Colored Lights", "v": "ICCV", "y": 2007, "rn": 19}, {"a": ["Patrick Labatut", "Jean-philippe Pons", "Renaud Keriven"], "b": "We present a novel method to reconstruct the 3D shape of a scene from several calibrated images. Our motivation is that most existing multi-view stereovision approaches re- quire some knowledge of the scene extent and often even of its approximate geometry (e.g. visual hull). This makes these approaches mainly suited to compact objects admit- ting a tight enclosing box, imaged", "cn": 27, "i": 4271445, "k": ["3d point cloud", "Compact Object", "delaunay triangulation", "Global Optimization", "Graph Cut", "Interest Points", "Large Scale", "Minimum Cut", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408892", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408892", "http://dx.doi.org/10.1109/ICCV.2007.4408892", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#LabatutPK07", "http://imagine.enpc.fr/publications/papers/07iccv_a.pdf", "http://certis.enpc.fr/publications/papers/07iccv_a.pdf", "http://www.di.ens.fr/willow/pdfs/07iccv_a.pdf", "http://www.normalesup.org/~labatut/papers/iccv2007-efficient-multiview.pdf"], "t": "Efficient Multi-View Reconstruction of Large-Scale Scenes using Interest Points, Delaunay Triangulation and Graph Cuts", "v": "ICCV", "y": 2007, "rn": 44}, {"a": ["Guofeng Zhang", "Jiaya Jia", "Tien-tsin Wong", "Hujun Bao"], "b": "This paper presents a novel method for recovering consistent depth maps from a video sequence. We propose a bundle optimization framework to address the major difficulties in stereo reconstruction, such as dealing with image noise, occlusions, and outliers. Different from the typical multi-view stereo methods, our approach not only imposes the photo-consistency constraint, but also explicitly associates the geometric coherence", "cn": 23, "i": 4768227, "k": ["Depth Map", "multi-view stereo", "Temporal Coherence", "Space Time"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04798169", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4798169", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4798169", "http://dx.doi.org/10.1109/TPAMI.2009.52", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami31.html#ZhangJWB09"], "t": "Consistent Depth Maps Recovery from a Video Sequence", "v": "PAMI", "y": 2009, "rn": 56}, {"a": ["Sudipta Sinha", "Drew Steedly", "Richard Szeliski"], "b": "We present a novel multi-view stereo method designed for image-based rendering that generates piecewise planar depth maps from an unordered collection of photographs. First a discrete set of 3D plane candidates are computed based on a sparse point cloud of the scene (recovered by structure from motion) and sparse 3D line segments recon- structed from multiple views. Next, evidence is", "cn": 23, "i": 5653034, "k": ["Depth Map", "Energy Minimization", "Graph Cut", "Image Based Rendering", "multi-view stereo", "Multiple Views", "Optimization Problem", "Point Cloud", "Structure From Motion", "Markov Random Field"], "p": ["https://research.microsoft.com/en-us/um/redmond/groups/ivm/PlanarStereo/sinhaICCV09.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459417", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459417", "http://research.microsoft.com/pubs/101031/Sinha-ICCV09.pdf", "http://research.microsoft.com/en-us/um/redmond/groups/ivm/PlanarStereo/sinhaICCV09.pdf", "https://research.microsoft.com/pubs/101031/Sinha-ICCV09.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459417", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#SinhaSS09", "http://research.microsoft.com/apps/pubs/default.aspx?id=101031"], "t": "Piecewise planar stereo for image-based rendering", "v": "ICCV", "y": 2009, "rn": 31}, {"a": ["Carlos Esteban", "George Vogiatzis", "Roberto Cipolla"], "b": "Abstract This paper addresses the problem of obtaining complete, detailed reconstructions of textureless shiny objects. We present an algorithm which uses silhouettes of the object, as well as images obtained under changing,illumination conditions. In contrast with previous photometric,stereo techniques, ours is not limited to a single viewpoint but pro duces accurate reconstructions in full 3D. A number of images of", "cn": 22, "i": 4404236, "k": ["Camera Motion", "multi-view stereo", "Photometric Stereo", "Quantitative Evaluation", "Surface Reconstruction", "Synthetic Data", "Visual Hull"], "p": ["http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.70820", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04384496", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4384496", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4384496", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami30.html#EstebanVC08"], "t": "Multiview Photometric Stereo", "v": "PAMI", "y": 2008, "rn": 15}, {"a": ["Martin Habbecke", "Leif Kobbelt"], "b": "We present a new approach to reconstruct the shape of a 3D object or scene from a set of calibrated images. The central idea of our method is to combine the topologi- cal flexibility of a point-based geometry representation with the robust reconstruction properties of scene-aligned pla- nar primitives. This can be achieved by approximating the shape with a set", "cn": 21, "i": 4111429, "k": ["Energy Function", "Image Matching", "multi-view stereo", "Sampling Strategy", "Shape Priors"], "p": ["http://www.graphics.rwth-aachen.de/uploads/media/habbecke_07_CVPR_01.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270220", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270220", "http://www-i8.informatik.rwth-aachen.de/uploads/media/habbecke_07_CVPR_01.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#HabbeckeK07", "http://www-i8.informatik.rwth-aachen.de/uploads/media/habbecke_07_CVPR.pdf", "http://dx.doi.org/10.1109/CVPR.2007.383195"], "t": "A Surface-Growing Approach to Multi-View Stereo Reconstruction", "v": "CVPR", "y": 2007, "rn": 24}, {"a": ["Elena Stoykova", "A. Alatan", "Philip Benzie", "Nikolaos Grammalidis", "Sotiris Malassiotis", "Joern Ostermann", "Sergej Piekh", "Ventseslav Sainov", "Christian Theobalt", "Thangavel Thevar", "Xenophon Zabulis"], "b": "Advances in image sensors and evolution of digital computation is a strong stimulus for development and imple- mentation of sophisticated methods for capturing, processing and analysis of 3D data from dynamic scenes. Research on perspective time-varying 3D scene capture technologies is important for the upcoming 3DTV displays. Methods such as shape-from- texture, shape-from-shading, shape-from-focus and shape-from- motion extraction can restore", "cn": 21, "i": 4412035, "k": ["3d imaging", "3d reconstruction", "Cost Function", "Digital Holography", "Dynamic Scenes", "High Resolution", "Image Sensor", "Indexing Terms", "Infrared", "Motion Analysis", "Motion Tracking", "multi-view stereo", "Multiple Views", "Scene Analysis", "Shape From Motion", "Shape From Shading", "Three Dimensional", "Video Analysis", "Real Time", "Shape From Focus", "Time of Flight", "Time Varying"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04373330", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4373330", "http://doi.ieeecomputersociety.org/10.1109/TCSVT.2007.909975", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4373330", "http://www.informatik.uni-trier.de/~ley/db/journals/tcsv/tcsv17.html#StoykovaABGMOPSTTZ07"], "t": "3-D Time-Varying Scene Capture Technologies - A Survey", "v": "TCSV", "y": 2007, "rn": 287}, {"a": ["Mark Young", "Erik Beeson", "James Davis", "Szymon Rusinkiewicz", "Ravi Ramamoorthi"], "b": "We introduce a theoretical framework and practical al- gorithms for replacing time-coded structured light patterns with viewpoint codes, in the form of additional camera loca- tions. Current structured light methods typically use log(N) light patterns, encoded over time, to unambiguously recon- struct N unique depths. We demonstrate that each addi- tional camera location may replace one frame in a tempo-", "cn": 20, "i": 4247971, "k": ["High Frequency", "Structured Light", "Theoretical Framework"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270317", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270317", "http://www.cs.princeton.edu/gfx/pubs/Young_2007_VSL/viewpointcoding.pdf", "http://www.cs.berkeley.edu/~ravir/cvpr07.pdf", "http://www.cs.columbia.edu/cg/pdfs/126-cvpr07.pdf", "http://www1.cs.columbia.edu/%7Eravir/cvpr07.pdf", "http://dx.doi.org/10.1109/CVPR.2007.383292", "http://graphics.cs.berkeley.edu/papers/Young-VCS-2007-06/Young-VCS-2007-06.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#YoungBDRR07"], "t": "Viewpoint-Coded Structured Light", "v": "CVPR", "y": 2007, "rn": 36}, {"a": ["P Yan", "M Shah"], "b": "", "cn": 20, "i": 4271272, "k": [], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408897", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408897", "http://longwood.cs.ucf.edu/~vision/papers/SaadMICCV07.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4408897", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#KhanYS07", "http://server.cs.ucf.edu/~vision/papers/SaadMICCV07.pdf"], "t": "A homographic framework for the fusion of multi-view silhouettes", "v": "ICCV", "y": 2007, "rn": 19}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "This paper proposes a novel approach to non- rigid, markerless motion capture from synchronized video streams acquired by calibrated cameras. The instantaneous geometry of the observed scene is represented by a poly- hedral mesh with fixed topology. The initial mesh is con- structedin thefirst frameusingthe publiclyavailablePMVS software for multi-view stereo (7). Its deformation is cap- tured by tracking its vertices", "cn": 19, "i": 4704598, "k": ["Motion Capture", "multi-view stereo", "Time Use", "Video Streaming"], "p": ["http://dx.doi.org/10.1109/CVPR.2008.4587495", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587495", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587495", "http://www-cvr.ai.uiuc.edu/~yfurukaw/papers/cvpr08b.pdf", "http://www.di.ens.fr/willow/pdfs/cvpr08b.pdf", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/155.pdf", "http://www.cs.washington.edu/homes/furukawa/papers/cvpr08b.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#FurukawaP08"], "t": "Dense 3D motion capture from synchronized video streams", "v": "CVPR", "y": 2008, "rn": 23}, {"a": ["Alexander Ladikos", "Selim Benhimane", "Nassir Navab"], "b": "In this paper we present two efficient GPU-based visual hull computation algorithms. We compare them in terms of performance using image sets of varying size and different voxel resolutions. In addition, we present a real-time 3D reconstruction system which uses the proposed GPU-based reconstruction method to achieve real-time performance (30 fps) using 16 cameras and 4 PCs.", "cn": 19, "i": 4977356, "k": ["3d reconstruction", "Real Time", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4563098", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04563098", "http://wwwnavab.in.tum.de/pub/ladikos2008cvgpu/ladikos2008cvgpu.pdf", "http://campar.in.tum.de/pub/ladikos2008cvgpu/ladikos2008cvgpu.pdf", "http://ar.in.tum.de/pub/ladikos2008cvgpu/ladikos2008cvgpu.pdf"], "t": "Efficient visual hull computation for real-time 3D reconstruction using CUDA", "v": "CVPR", "y": 2008, "rn": 31}, {"a": ["Sudipta Sinha", "Philippos Mordohai", "Marc Pollefeys"], "b": "We formulate multi-view 3D shape reconstruction as the computation of a minimum cut on the dual graph of a semi- regular, multi-resolution, tetrahedral mesh. Our method does not assume that the surface lies within a finite band around the visual hull or any other base surface. Instead, it uses photo-consistency to guide the adaptive subdivision of a coarse mesh of", "cn": 18, "i": 4271397, "k": ["3d shape reconstruction", "Cost Function", "Graph Cut", "Minimal Surface", "Minimum Cut", "multi-view stereo", "Surface Deformation", "Surface Reconstruction", "Tetrahedral Mesh", "Multi Resolution", "Visual Hull"], "p": ["http://www.seas.upenn.edu/~mordohai/public/Sinha_GraphCutsAdaptiveMesh07.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408997", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408997", "http://www.cs.stevens.edu/~mordohai/public/Sinha_GraphCutsAdaptiveMesh07.pdf", "http://cvg-pub.inf.ethz.ch/WebBIB/papers/2007/SinhaICCV07.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#SinhaMP07", "http://cs.unc.edu/%7Essinha/pubs/SinhaICCV07.pdf", "http://www.inf.ethz.ch/personal/pomarc/pubs/SinhaICCV07.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4408997"], "t": "Multi-View Stereo via Graph Cuts on the Dual of an Adaptive Tetrahedral Mesh", "v": "ICCV", "y": 2007, "rn": 19}, {"a": ["Neill Campbell", "George Vogiatzis", "Carlos Hern\u00e1ndez", "Roberto Cipolla"], "b": "We propose an algorithm for automatically obtaining a segmentation of a rigid object in a sequence of images that are calibrated for camera pose and intrinsic parameters. Until recently, the best segmentation results have been obtained by interactive methods that require manual labelling of image regions. Our method requires no user input but instead relies on the camera fixating on", "cn": 16, "i": 4464485, "k": ["Automatic Segmentation", "Global Optimization", "Graph Cut", "Interactive Method", "Multiple Views", "Object Segmentation"], "p": ["http://dx.doi.org/10.1016/j.imavis.2008.09.005", "http://www.sciencedirect.com/science/article/pii/S026288560800200X", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/2007/papers/paper-296.pdf", "http://linkinghub.elsevier.com/retrieve/pii/S026288560800200X", "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2007-BMVC-Campbell-volumetric.pdf", "http://mi.eng.cam.ac.uk/~ndfc2/papers/bmvc07_automatic_segmentation.pdf", "http://www.bmva.org/bmvc/2007/papers/paper-296.pdf", "http://george-vogiatzis.org/publications/bmvc07_automatic_segmentation.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ivc/ivc28.html#CampbellVHC10"], "t": "Automatic 3D object segmentation in multiple views using volumetric graph-cuts", "v": "IVC", "y": 2010, "rn": 22}, {"a": ["Kalin Kolev", "Maria Klodt", "Thomas Brox", "Daniel Cremers"], "b": "In this article, we introduce a new global optimization method to the field of multiview 3D reconstruction. While global minimization\n has been proposed in a discrete formulation in form of the maxflow-mincut framework, we suggest the use of a continuous convex\n relaxation scheme. Specifically, we propose to cast the problem of 3D shape reconstruction as one of minimizing a spatially", "cn": 15, "i": 6076398, "k": ["3d reconstruction", "3d shape reconstruction", "Convex Function", "Convex Optimization", "Convex Relaxation", "Global Optimization", "Graph Cut", "Quantitative Evaluation", "Spatial Resolution", "Surface Area"], "p": ["http://www.springerlink.com/index/j18r13h24656358n.pdf", "http://www.springerlink.com/content/j18r13h24656358n", "http://dx.doi.org/10.1007/s11263-009-0233-1", "http://www.springerlink.com/index/pdf/10.1007/s11263-009-0233-1", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv84.html#KolevKBC09"], "t": "Continuous Global Optimization in Multiview 3D Reconstruction", "v": "IJCV", "y": 2009, "rn": 40}, {"a": ["Pau Gargallo", "Emmanuel Prados", "Peter Sturm"], "b": "This paper addresses the problem of image-based sur- face reconstruction. The main contribution is the computa- tion of the exact derivative of the reprojection error func- tional. This allows its rigorous minimization via gradient descent surface evolution. The main difficulty has been to correctly take into account the visibility changes that occur when the surface moves. A geometric and analytical", "cn": 15, "i": 4271381, "k": ["3d reconstruction", "Surface Reconstruction", "Gradient Descent"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#GargalloPS07", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4409003", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04409003", "http://dx.doi.org/10.1109/ICCV.2007.4409003", "http://perception.inrialpes.fr/Publications/2008/GPS08/RFIA08-visibilite.pdf", "http://perception.inrialpes.fr/people/gargallo/papers/gargallo07minimizing.pdf", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Inproceedings@1176ddd04d5_125169d/GargalloPradosSturm-iccv2007.pdf", "http://hal.archives-ouvertes.fr/docs/00/26/62/87/PDF/GargalloPradosSturm-iccv2007.pdf", "http://perception.inrialpes.fr/Publications/2007/GPS07/GargalloPradosSturm-iccv2007.pdf", "http://hal.archives-ouvertes.fr/docs/00/29/92/54/PDF/RFIA08-visibilite.pdf"], "t": "Minimizing the Reprojection Error in Surface Reconstruction from Images", "v": "ICCV", "y": 2007, "rn": 30}, {"a": ["Hailin Jin", "Daniel Cremers", "Dejun Wang", "Emmanuel Prados", "Anthony Yezzi", "Stefano Soatto"], "b": "We propose a variational algorithm to jointly estimate the shape, albedo, and light configuration of a Lambertian scene from a collection of images taken from dierent vantage points. Our work can be thought of as extending classical multi-view stereo to cases where point correspondence cannot be established, or extending classical shape from shading to the case of multiple views with", "cn": 14, "i": 4389432, "k": ["3d reconstruction", "Cost Function", "Local Minima", "multi-view stereo", "Multiple Views", "Shape From Shading", "Level Set Method"], "p": ["http://hal.inria.fr/docs/00/26/04/33/PDF/Jin-Wang-Cremers-Prados-Yezzi-soatto-jicv-2007.pdf", "http://www.springerlink.com/content/wr447l403481255t", "http://www.springerlink.com/index/wr447l403481255t.pdf", "http://www.springerlink.com/index/10.1007/s11263-007-0055-y", "http://wwwcremers.in.tum.de/pub/pub/jin_et_al_ijcv08.pdf", "http://www.springerlink.com/index/pdf/10.1007/s11263-007-0055-y", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv76.html#JinCWPYS08", "http://hal.archives-ouvertes.fr/docs/00/26/04/33/PDF/Jin-Wang-Cremers-Prados-Yezzi-soatto-jicv-2007.pdf", "http://dx.doi.org/10.1007/s11263-007-0055-y", "http://vision.ucla.edu/papers/jinWCPYS07.pdf", "http://www.vision.cs.ucla.edu/papers/jinWCPYS07.pdf", "http://perception.inrialpes.fr/Publications/2008/JCWPYS08/Jin-Wang-Cremers-Prados-Yezzi-soatto-jicv-2007.pdf"], "t": "3-D Reconstruction of Shaded Objects from Multiple Images Under Unknown Illumination", "v": "IJCV", "y": 2008, "rn": 45}, {"a": ["Qingxiong Yang", "Chris Engels", "Amir Akbarzadeh"], "b": "Several real-time/near real-time stereo algorithms can currently provide ac- curate 3D reconstructions for well-textured scenes. However, most of these fail in sufficiently large regions that are weakly textured. Conversely, other scene reconstruction algorithms assume strong planarity in the environment. Such approaches can handle lack of texture, but tend to force nonplanar ob- jects onto planes. We propose a compromise approach", "cn": 14, "i": 4916642, "k": ["3d reconstruction", "Color Segmentation", "Depth Estimation", "Loopy Belief Propagation", "Scene Reconstruction", "Near Real Time", "Real Time"], "p": ["http://www.comp.leeds.ac.uk/bmvc2008/proceedings/papers/144.pdf", "http://www.bmva.org/bmvc/2008/papers/144.pdf", "http://homes.esat.kuleuven.be/~cengels/files/yang_bmvc_2008.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2008.html#YangEA08"], "t": "Near Real-time Stereo for Weakly-Textured Scenes", "v": "BMVC", "y": 2008, "rn": 19}, {"a": ["Jean-Yves Guillemaut", "Joe Kilner", "Adrian Hilton"], "b": "Current state-of-the-art image-based scene reconstruction techniques are capable of generating high-fidelity 3D models when used under controlled capture conditions. However, they are often inadequate when used in more challenging outdoor environments with moving cameras. In this case, algorithms must be able to cope with relatively large calibration and segmentation errors as well as input images separated by a wide-baseline and", "cn": 12, "i": 39265981, "k": ["3d model", "Complex Dynamics", "Energy Function", "Graph Cut", "Multiple Views", "Scene Reconstruction", "Free Viewpoint Video", "On The Fly"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459299", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459299", "http://dx.doi.org/10.1109/ICCV.2009.5459299", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#GuillemautKH09"], "t": "Robust graph-cut scene segmentation and reconstruction for free-viewpoint video of complex dynamic scenes", "v": "ICCV", "y": 2009, "rn": 22}, {"a": ["Guofeng Zhang", "Jiaya Jia", "Tien-tsin Wong", "Hujun Bao"], "b": "This paper presents a novel method for reconstruct- ing high-quality video depth maps. A bundle optimization model is proposed to address the key issues, including im- age noise and occlusions, in stereo reconstruction. Our method not only uses the color constancy constraint, but also explicitly incorporates the geometric coherence con- straint associating multiple frames in a video, thus can nat-", "cn": 12, "i": 4704710, "k": ["Color Constancy", "Depth Map", "Optimization Model", "Temporal Coherence"], "p": ["http://dx.doi.org/10.1109/CVPR.2008.4587496", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587496", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587496", "http://www.cse.cuhk.edu.hk/~leojia/all_final_papers/videodepth_cvpr08.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#ZhangJWB08", "http://mplab.ucsd.edu/wp-content/uploads/cvpr2008/conference/data/papers/156.pdf"], "t": "Recovering consistent video depth maps via bundle optimization", "v": "CVPR", "y": 2008, "rn": 25}, {"a": ["Cevahir Cigla", "Xenophon Zabulis", "A. Alatan"], "b": "A novel multi-view region-based dense depth map estimation problem is presented, based on a modified plane- sweeping strategy. In this approach, the whole scene is assumed to be region-wise planar. These planar regions are defined by back-projections of the over-segmented homogenous color regions on the images and the plane parameters are determined by angle-sweeping at different depth levels. The position", "cn": 12, "i": 4276221, "k": ["Cost Function", "Depth Map", "Indexing Terms", "multi-view stereo", "Search Algorithm"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4379803", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04379803", "http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2007-5.html#CiglaZA07", "http://www.ics.forth.gr/~zabulis/C1.pdf", "http://dx.doi.org/10.1109/ICIP.2007.4379803", "http://www.eee.metu.edu.tr/~cevahir/icip07.pdf"], "t": "Region-Based Dense Depth Extraction from Multi-View Video", "v": "ICIP", "y": 2007, "rn": 12}, {"a": ["Yan Cui", "Sebastian Schuon", "Derek Chan", "Sebastian Thrun", "Christian Theobalt"], "b": "We describe a method for 3D object scanning by aligning depth scans that were taken from around an object with a time-of-flight camera. These ToF cameras can measure depth scans at video rate. Due to comparably simple technology they bear potential for low cost production in big volumes. Our easy-to-use, cost-effective scanning solution based on such a sensor could make", "cn": 11, "i": 39261461, "k": ["3d scanning", "Cost Effectiveness", "Data Quality", "New Combination", "Random Noise", "Time of Flight"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540082", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540082", "http://dx.doi.org/10.1109/CVPR.2010.5540082", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#CuiSCTT10"], "t": "3D shape scanning with a time-of-flight camera", "v": "CVPR", "y": 2010, "rn": 20}, {"a": ["Sebastian Lieberknecht", "Selim Benhimane", "Peter Meier", "Nassir Navab"], "b": "Unlike dense stereo, optical flow or multi-view stereo, template-based tracking lacks benchmark datasets allowing a fair comparison between state-of-the-art algorithms. Until now, in order to evaluate objectively and quantitatively the performance and the robustness of template-based tracking algorithms, mainly synthetically generated image sequences were used. The evaluation is therefore often intrinsically biased. In this paper, we describe the process we", "cn": 11, "i": 6431766, "k": ["Camera Motion", "Critical Parameter", "Evaluation Methodology", "Image Sequence", "multi-view stereo", "Object Detection", "Ground Truth", "Optical Flow"], "p": ["http://doi.ieeecomputersociety.org/10.1109/ISMAR.2009.5336487", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5336487", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05336487", "http://www.informatik.uni-trier.de/~ley/db/conf/ismar/ismar2009.html#LieberknechtBMN09"], "t": "A dataset and evaluation methodology for template-based tracking algorithms", "v": "ISMAR", "y": 2009, "rn": 16}, {"a": ["Kazunori Umeda", "Yuuki Hashimoto", "Tatsuya Nakanishi", "Kota Irie", "Kenji Terabayashi"], "b": "This study aims at developing a practical stereo camera that is suitable for applications such as surveillance, in which detection of anomalies or measurement of moving people are required. In such surveillance cases, targets to measure usually move. In this paper, \"Subtraction stereo\" is proposed that focuses on motion information to increase the robustness of the stereo matching. It realizes", "cn": 11, "i": 14160210, "k": ["Error Analysis", "Motion Analysis", "Range Image", "Stereo Matching", "Stereo Vision", "Three Dimensional"], "p": ["http://www.mech.chuo-u.ac.jp/umedalab/introduction/g4/pdf/Subtraction%20Stereo%20-A%20Stereo%20Camera%20System%20That%20Focuses%20On%20Moving%20Regions-.pdf", "http://adsabs.harvard.edu/abs/2009SPIE.7239E...7U"], "t": "Subtraction stereo: a stereo camera system that focuses on moving regions", "v": "", "y": 2009, "rn": 9}, {"a": ["Tony Tung", "Shohei Nobuhara", "Takashi Matsuyama"], "b": "This paper presents a new method to increase the quality of 3D video, a new media developed to represent 3D objects in motion. This representation is obtained from multi-view reconstruction techniques that require images recorded simultaneously by several video cameras. All cameras are calibrated and placed around a dedicated studio to fully surround the models. The limited quality and quantity", "cn": 11, "i": 4704930, "k": ["3d model", "3d shape reconstruction", "3d video", "Graph Cut", "New Media", "Optimal Solution", "Shape Modeling", "Super Resolution", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587703", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587703", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#TungNM08", "http://dx.doi.org/10.1109/CVPR.2008.4587703"], "t": "Simultaneous super-resolution and 3D video using graph-cuts", "v": "CVPR", "y": 2008, "rn": 30}, {"a": ["Victor Lempitsky", "Denis Ivanov"], "b": "", "cn": 11, "i": 4142662, "k": ["Computer Vision", "Coordinate System", "Energy Optimization", "Image Editing", "Object Model", "Structure and Motion", "Texture Mapping", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270103", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270103", "http://dx.doi.org/10.1109/CVPR.2007.383078", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#LempitskyI07"], "t": "Seamless Mosaicing of Image-Based Texture Maps", "v": "CVPR", "y": 2007, "rn": 30}, {"a": ["Christopher Zach", "Marc Niethammer", "Jan-michael Frahm"], "b": "Convex and continuous energy formulations for low level vision problems enable efficient search procedures for the corresponding globally optimal solutions. In this work we extend the well-established continuous, isotropic capacity- based maximal flow framework to the anisotropic setting. By using powerful results from convex analysis, a very sim- ple and efficient minimization procedure is derived. Fur- ther, we show that", "cn": 10, "i": 6018983, "k": ["Convex Analysis", "Global Optimization", "Markov Random Field"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206565", "http://cs.unc.edu/~cmzach/pdf/cvpr2009a-preprint.pdf"], "t": "Continuous maximal flows and Wulff shapes: Application to MRFs", "v": "CVPR", "y": 2009, "rn": 29}, {"a": ["Daniel Aliaga", "Yi Xu"], "b": "Structured-light methods actively generate geometric correspondence data between projectors and cameras in order to facilitate robust 3D reconstruction. In this paper, we present photogeometric structured light whereby a standard structured light method is extended to include photometric methods. Photometric processing serves the double purpose of increasing the amount of recovered surface detail and of enabling the structured-light setup to be", "cn": 10, "i": 4704578, "k": ["3d model", "3d reconstruction", "Photometric Methods", "Structured Light"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#AliagaX08", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587709", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587709", "http://dx.doi.org/10.1109/CVPR.2008.4587709"], "t": "Photogeometric structured light: A self-calibrating and multi-viewpoint framework for accurate 3D modeling", "v": "CVPR", "y": 2008, "rn": 18}, {"a": ["Bogumil Bartczak", "Kevin Koeser", "Felix Woelk", "Reinhard Koch"], "b": "This work presents a system for the generation of a free-form surface model from video sequences. Although any single centered\n camera can be applied in the proposed system the approach is demonstrated using fish-eye lenses because of their good properties\n for tracking. The system is designed to function automatically and to be flexible with respect to size and shape of", "cn": 10, "i": 13338319, "k": ["Analysis By Synthesis", "Decision Models", "Depth Estimation", "Depth Map", "Error Propagation", "Independent Set", "Measurement Uncertainty", "Omnidirectional Vision", "Real-time Tracking", "Reference Model", "Robust Statistics", "Structure From Motion", "Surface Model", "Triangle Mesh", "Visual Landmarks", "Field of View"], "p": ["http://springerlink.metapress.com/content/e12087n368645531/", "http://www.springerlink.com/content/e12087n368645531", "http://www.springerlink.com/index/e12087n368645531.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/jrtip/jrtip2.html#BartczakKWK07", "http://www.springerlink.com/index/10.1007/s11554-007-0042-0", "http://www.springerlink.com/index/pdf/10.1007/s11554-007-0042-0"], "t": "Extraction of 3D freeform surfaces as visual landmarks for real-time tracking", "v": "", "y": 2007, "rn": 58}, {"a": ["Carlos Hern", "George Vogiatzis", "Roberto Cipolla"], "b": "", "cn": 10, "i": 11702679, "k": ["Photometric Stereo"], "p": ["http://www.george-vogiatzis.org/publications/hernandez_pami07c.pdf"], "t": "Multi-view photometric stereo", "v": "PAMI", "y": 0, "rn": 15}, {"a": ["Ama\u00ebl Delaunoy", "Emmanuel Prados", "Pau Gargallo", "Jean-Philippe Pons", "Peter Sturm"], "b": "This article proposes a variational multi-view stereo vision method based on meshes for recovering 3D scenes (shape and radiance) from images. Our method is based on generative models and minimizes the reprojection error (difference between the observed images and the images synthesized from the reconstruction). Our contributions are twofold. 1) For the first time, we rigor- ously compute the gradient", "cn": 9, "i": 5045958, "k": ["Generic Model", "multi-view stereo", "Triangular Mesh"], "p": ["http://certis.enpc.fr/publications/papers/BMVC08.pdf", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/papers/75.pdf", "http://www.bmva.org/bmvc/2008/papers/75.pdf", "http://hal.archives-ouvertes.fr/docs/00/30/89/44/PDF/delaunoy-prados-etal-BMVC08.pdf", "http://imagine.enpc.fr/publications/papers/BMVC08.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2008.html#DelaunoyPGPS08"], "t": "Minimizing the Multi-view Stereo Reprojection Error for Triangular Surface Meshes", "v": "BMVC", "y": 2008, "rn": 26}, {"a": ["J. Starch", "J. Kilner", "A. Hilton"], "b": "This paper addresses the problem of objectively measuring quality in free-viewpoint video production. The accuracy of scene reconstruction is typically limited and an evaluation of free-viewpoint video should explicitly consider the quality of image production. A simple objective measure of accuracy is presented in terms of structural registration error in view synthesis. This technique can be applied as a full-reference", "cn": 9, "i": 50656185, "k": ["Image Based Rendering", "Quality Assessment", "Scene Reconstruction", "View Synthesis", "Full Reference", "Free Viewpoint Video", "Ground Truth", "No Reference"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04547849", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4547849"], "t": "Objective Quality Assessment in Free-Viewpoint Video Production", "v": "DTV-CON", "y": 2008, "rn": 10}, {"a": ["George Vogiatzis", "Carlos Esteban", "Philip Torr", "Roberto Cipolla"], "b": "", "cn": 9, "i": 10272014, "k": ["Graph Cut", "multi-view stereo"], "p": ["http://carlos-hernandez.org//papers/hernandez_pami07b.pdf", "http://www.george-vogiatzis.org//publications/pami2007.pdf", "http://www.george-vogiatzis.org/publications/pami2007.pdf", "http://carlos-hernandez.org/papers/hernandez_pami07b.pdf", "http://mi.eng.cam.ac.uk/~cipolla/publications/article/2008-PAMI-volumetric-graphcuts.pdf", "http://cms.brookes.ac.uk/staff/PhilipTorr/Papers/2007/George%20Pami/accepted_volgraphcut_pami.pdf", "http://george-vogiatzis.org/publications/pami2007.pdf"], "t": "Multi-view Stereo via Volumetric Graph-cuts and Occlusion Robust Photo-Consistency", "v": "PAMI", "y": 0, "rn": 29}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "This article presents a novel method for acquiring high-quality solid models of complex 3D shapes from multiple calibrated\n photographs. After the purely geometric constraints associated with the silhouettes found in each image have been used to\n construct a coarse surface approximation in the form of a visual hull, photoconsistency constraints are enforced in three\n consecutive steps: (1)\u00a0the rims where the", "cn": 8, "i": 6076359, "k": ["Dynamic Program", "Geometric Constraints", "Global Optimization", "Graph Cut", "image-based modeling", "multi-view stereo", "Solid Modeling", "Surface Approximation", "Visual Hull"], "p": ["http://www.springerlink.com/index/8183932647482508.pdf", "http://www.springerlink.com/content/8183932647482508", "http://www.springerlink.com/index/pdf/10.1007/s11263-008-0134-8", "http://dx.doi.org/10.1007/s11263-008-0134-8", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv81.html#FurukawaP09", "http://www.springerlink.com/index/10.1007/s11263-008-0134-8"], "t": "Carved Visual Hulls for Image-Based Modeling", "v": "IJCV", "y": 2009, "rn": 32}, {"a": ["Li Guan", "Marc Pollefeys", "Jean-sebastien Franco"], "b": "This paper deals with the 3D shape estimation from sil- houette cues of multiple moving objects in general indoor or outdoor 3D scenes with potential static obstacles, us- ing multiple calibrated video streams. Most shape-from- silhouette techniques use a two-classification of space oc- cupancy and silhouettes, based on image regions that match or disagree with a static background appearance model.", "cn": 8, "i": 4704793, "k": ["bayesian reasoning", "Model Elimination", "Moving Object", "multi-view stereo", "Scene Analysis", "Scene Reconstruction", "Shape Estimation", "Shape From Silhouette", "Video Streaming"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587786", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587786", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#GuanFP08", "http://dx.doi.org/10.1109/CVPR.2008.4587786", "http://hal.inria.fr/inria-00349114/PDF/cvpr08.pdf"], "t": "Multi-Object Shape Estimation and Tracking from Silhouette Cues", "v": "CVPR", "y": 2008, "rn": 22}, {"a": ["Tomoaki Higo", "Yasuyuki Matsushita", "Neel Joshi", "Katsushi Ikeuchi"], "b": "This paper presents a simple yet practical 3-D model- ing method for recovering surface shape and reflectance from a set of images. We attach a point light source to a hand-held camera to add a photometric constraint to the multi-view stereo problem. Using the photometric con- straint, we simultaneously solve for shape, surface normal, and reflectance. Unlike prior approaches, we", "cn": 7, "i": 5651555, "k": ["multi-view stereo", "Photometric Stereo"], "p": ["http://research.microsoft.com/en-us/people/yasumat/handheld_iccv09.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459331", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459331", "https://research.microsoft.com/en-us/people/yasumat/handheld_iccv09.pdf", "http://www.cvl.iis.u-tokyo.ac.jp/%7Ehigo/papers/iccv2009handheld.pdf", "http://yuwing.kaist.ac.kr/courses/CS770/reading/iccv2009handheld.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=132791", "http://dx.doi.org/10.1109/ICCV.2009.5459331", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#HigoMJI09"], "t": "A Hand-held Photometric Stereo Camera for 3-D Modeling", "v": "ICCV", "y": 2009, "rn": 25}, {"a": ["Brandon Smith", "Li Zhang", "Hailin Jin"], "b": "We propose a novel formulation of stereo matching that considers each pixel as a feature vector. Under this view, matching two or more images can be cast as matching point clouds in feature space. We build a nonparametric depth smoothness model in this space that correlates the image fea- tures and depth values. This model induces a sparse graph that", "cn": 7, "i": 5767284, "k": ["Dynamic Scenes", "Feature Space", "Feature Vector", "Graph Cut", "Image Segmentation", "Nonparametric Smoothing", "Point Cloud", "Stereo Matching"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#SmithZJ09", "http://pages.cs.wisc.edu/~bmsmith/projects/2009/cvpr/SmithCVPR09.pdf", "http://www.vision.ucla.edu/~hljin/papers/cvpr09-stereo.pdf", "http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206793", "http://pages.cs.wisc.edu/~lizhang/projects/mvstereo/cvpr2009/SmithCVPR09.pdf"], "t": "Stereo matching with nonparametric smoothness priors in feature space", "v": "CVPR", "y": 2009, "rn": 38}, {"a": ["Sameer Agarwal", "Noah Snavely", "Steven Seitz"], "b": "Many problems in multi-view geometry, when posed as minimization of the maximum reprojection error across observations, can be solved optimally in polynomial time. We show that these problems are instances of a convex-concave generalized fractional program. We survey the major solution methods for solving problems of this form and present them in a unified framework centered around a single parametric", "cn": 7, "i": 5257464, "k": ["Fast Algorithm", "Fractional Programming", "Open Source", "Parametric Optimization", "Polynomial Time"], "p": ["http://grail.cs.washington.edu/pub/papers/sagarwal2008faf.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587713", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587713", "http://mplab.ucsd.edu/wp-content/uploads/cvpr2008/conference/data/papers/373.pdf", "http://www.cs.washington.edu/homes/sagarwal/gfp.pdf"], "t": "Fast algorithms for L\u221e problems in multiview geometry", "v": "CVPR", "y": 2008, "rn": 23}, {"a": ["Jean-yves Guillemaut", "Adrian Hilton", "Jonathan Starck", "Joe Kilner", "Oliver Grau"], "b": "Conventional approaches to 3D scene reconstruction often treat matting and reconstruction as two separate problems, with matting a prerequisite to reconstruction. The prob- lem with such an approach is that it requires taking irre- versible decisions at the first stage, which may translate into reconstruction errors at the second stage. In this pa- per, we propose an approach which attempts", "cn": 7, "i": 4845187, "k": ["3d reconstruction", "3d scene reconstruction", "bayesian framework", "Global Solution", "Graph Cut", "Large Scale", "Shape From Silhouette", "View Synthesis"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4296752", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04296752", "http://dx.doi.org/10.1109/3DIM.2007.3", "http://xm2vtsdb.ee.surrey.ac.uk/CVSSP/Publications/papers/guillemaut-3dim-2007.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2007.html#GuillemautHSKG07", "http://www.ee.surrey.ac.uk/CVSSP/VMRG/Publications/guillemaut073dim.pdf"], "t": "A Bayesian Framework for Simultaneous Matting and 3D Reconstruction", "v": "3DIM", "y": 2007, "rn": 18}, {"a": ["Young Kim", "Christian Theobalt", "James Diebel", "Jana Kosecka", "Branislav Miscusik", "Sebastian Thrun"], "b": "Multi-view stereo methods frequently fail to properly re- construct 3D scene geometry if visible texture is sparse or the scene exhibits difficult self-occlusions. Time-of-Flight (ToF) depth sensors can provide 3D information regardless of texture but with only limited resolution and accuracy. To find an optimal reconstruction, we propose an integrated multi-view sensor fusion approach that combines informa- tion from multiple", "cn": 7, "i": 6140319, "k": ["3d model", "3d reconstruction", "Energy Function", "multi-view stereo", "Sensor Fusion", "Time of Flight"], "p": ["http://www.stanford.edu/~jinhae/iccv09/iccv09.pdf", "http://www.mpi-inf.mpg.de/~theobalt/3dim09.pdf"], "t": "Multi-view Image and ToF Sensor Fusion for Dense 3D Reconstruction", "y": 0, "rn": 18}, {"a": ["Kalin Kolev", "Maria Klodt", "Thomas Brox", "Daniel Cremers"], "b": "In this paper, we make two contributions. Firstly, we replace the generic balloon constraints widely used in 3D reconstruction by a more sophisticated data-dependent re- gional term. The key idea is to propagate classical photo- consistency along visual rays into regional values describ- ing voxel probabilities for being inside or outside the ob- served object. Secondly, we cast the optimization", "cn": 7, "i": 6492130, "k": ["3d reconstruction", "Convex Function", "Data Dependence", "Graph Cut"], "p": ["http://www-cvpr.iai.uni-bonn.de/pub/pub/KKBC-07.pdf"], "t": "Propagated Photoconsistency and Convexity in Variational Multiview 3D Reconstruction", "y": 0, "rn": 21}, {"a": ["Kuk-Jin Yoon", "Emmanuel Prados", "Peter Sturm"], "b": "We propose a generative model based method for recovering both the shape and the reflectance of the surface(s) of a scene\n from multiple images, assuming that illumination conditions and cameras calibration are known in advance. Based on a variational\n framework and via gradient descents, the algorithm minimizes simultaneously and consistently a global cost functional with\n respect to both shape and", "cn": 6, "i": 13320077, "k": ["3d reconstruction", "Camera Calibration", "Cost Function", "Generic Model", "Photometric Stereo", "Shape From Shading", "Gradient Descent"], "p": ["http://springerlink.metapress.com/content/m82880786g283vhr/", "http://www.springerlink.com/index/m82880786g283vhr.pdf", "http://www.springerlink.com/content/m82880786g283vhr", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv86.html#YoonPS10", "http://www.springerlink.com/index/10.1007/s11263-009-0222-4", "http://www.springerlink.com/index/pdf/10.1007/s11263-009-0222-4"], "t": "Joint Estimation of Shape and Reflectance using Multiple Images with Known Illumination Conditions", "v": "IJCV", "y": 2010, "rn": 53}, {"a": ["Miao Liao", "Qing Zhang", "Huamin Wang", "Ruigang Yang", "Minglun Gong"], "b": "We propose a novel approach to reconstruct complete 3D deformable models over time by a single depth camera, provided that most parts of the models are observed by the camera at least once. The core of this algorithm is based on the assumption that the deformation is continuous and predictable in a short temporal interval. While the cam- era can", "cn": 6, "i": 5909338, "k": ["Deformable Model", "Deformable Objects", "Mesh Deformation", "Surface Deformation", "Surface Reconstruction"], "p": ["http://vis.uky.edu/~gravity/publications/2009/IEEECertified_4DModel.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459161", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459161", "http://vis.uky.edu/%7Eliaomiao/publication_files/IEEECertified_4DModel.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459161", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#LiaoZWYG09"], "t": "Modeling deformable objects from a single depth camera", "v": "ICCV", "y": 2009, "rn": 33}, {"a": ["Joe Kilner", "Jonathan Starck", "Adrian Hilton", "Oliver Grau"], "b": "Generating free-viewpoint video in outdoor sports environ- ments is currently an unsolved problem due to difficulties in obtaining accurate background segmentation and cam- era calibration. This paper introduces a technique for the reconstruction of a scene in the presence of these errors. We tackle the issues of reconstruction completeness, and accuracy of surface shape and appearance. We introduce the concept", "cn": 6, "i": 6026364, "k": ["Data Fitting", "Deformable Model", "Quantitative Evaluation", "Free Viewpoint Video", "Leave One Out", "Visual Hull"], "p": ["http://dx.doi.org/10.1109/3DIM.2007.22", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4296753", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04296753", "http://xm2vtsdb.ee.surrey.ac.uk/CVSSP/Publications/papers/Kilner-3DIM-2007.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2007.html#KilnerSHG07"], "t": "Dual-Mode Deformable Models for Free-Viewpoint Video of Sports Events", "v": "3DIM", "y": 2007, "rn": 19}, {"a": ["Dan Koppel", "Chao-I. Chen", "Yuan-Fang Wang", "Hua Lee", "Jia Gu", "Allen Poirson", "Rolf Wolters"], "b": "A 3D colon model is an essential component of a computer-aided diagnosis (CAD) system in colonoscopy to assist surgeons in visualization, and surgical planning and training. This research is thus aimed at developing the ability to construct a 3D colon model from endoscopic videos (or images). This paper summarizes our ongoing research in automated model building in colonoscopy. We have", "cn": 6, "i": 12665645, "k": ["3d model", "Camera Motion", "Computer Aided Diagnosis", "Computer Vision", "image-based modeling", "image-guided therapy", "Model Building", "Model System", "Surgical Planning"], "p": ["http://excelsior.cs.ucsb.edu/papers/spie07.pdf", "http://adsabs.harvard.edu/abs/2007SPIE.6509E..56K"], "t": "Toward automated model building from video in computer-assisted diagnoses in colonoscopy", "y": 2007, "rn": 39}, {"a": ["Matthias Heinrichs", "Volker Rodehorst", "Olaf Hellwich"], "b": "This paper describes an efficient method for dense matching of two or three images. After some investigations in different similarity measures we propose a modification of Semi-Global Matching, which uses a simple energy function that implies piecewise smoothness but no ordering and gives promising results in practice. Our improvements include a symmetric and hierarchical matching strategy and allow an efficient", "cn": 6, "i": 4959695, "k": ["Energy Function", "Image Matching", "piecewise smooth", "Similarity Measure", "Stereo Matching", "Surface Reconstruction"], "p": ["http://www.fpk.tu-berlin.de/~vr/papers/acrobat/PIA07.pdf", "http://www.cv.tu-berlin.de/fileadmin/fg140/EFFICIENT_SEMI-GLOBAL.pdf", "http://srv-43-200.bv.tu-berlin.de/publications/pdf/PIA07.pdf", "http://www.rodehorst.info/web/html/img/pool/PIA07.pdf"], "t": "EFFICIENT SEMI-GLOBAL MATCHING FOR TRINOCULAR STEREO", "y": 0, "rn": 17}, {"a": ["Yebin Liu", "Qionghai Dai", "Wenli Xu"], "b": "This paper presents a robust multiview stereo (MVS) algorithm for free-viewpoint video. Our MVS scheme is totally point-cloud-based and consists of three stages: point cloud extraction, merging, and meshing. To guarantee reconstruction accuracy, point clouds are first extracted according to a stereo matching metric which is robust to noise, occlusion, and lack of texture. Visual hull information, frontier points, and", "cn": 5, "i": 13335870, "k": ["Point Cloud", "Stereo Matching", "Free Viewpoint Video", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5184831", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5184831", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05184831", "http://www.informatik.uni-trier.de/~ley/db/journals/tvcg/tvcg16.html#LiuDX10", "http://doi.ieeecomputersociety.org/10.1109/TVCG.2009.88"], "t": "A Point-Cloud-Based Multiview Stereo Algorithm for Free-Viewpoint Video", "v": "TVCG", "y": 2010, "rn": 40}, {"a": ["Joe Kilner", "Jonathan Starck", "Jean-Yves Guillemaut", "Adrian Hilton"], "b": "This paper addresses the problem of objectively measur- ing quality in free-viewpoint video production. The accuracy of scene reconstruction is typically limited and an evaluation of free-viewpoint video should explicitly consider the quality of image production. A simple objective measure of accuracy is presented in terms of structural registration error in view synthesis. This technique can be applied as a", "cn": 5, "i": 4879874, "k": ["Image Based Rendering", "Indexing Terms", "Quality Assessment", "Scene Reconstruction", "View Synthesis", "Full Reference", "Free Viewpoint Video", "Ground Truth", "No Reference"], "p": ["http://xm2vtsdb.ee.surrey.ac.uk/CVSSP/Publications/papers/Starck-3DTV-2008.pdf", "http://www.sciencedirect.com/science/article/pii/S0923596508001112", "http://xm2vtsdb.ee.surrey.ac.uk/CVSSP/Publications/papers/Kilner-SPIC-2009.pdf", "http://dx.doi.org/10.1016/j.image.2008.10.004", "http://www.informatik.uni-trier.de/~ley/db/journals/spic/spic24.html#KilnerSGH09", "http://linkinghub.elsevier.com/retrieve/pii/S0923596508001112"], "t": "Objective quality assessment in free-viewpoint video production", "v": "SIGNAL PROCESS-IMAGE COMMUN", "y": 2009, "rn": 61}, {"a": ["Kalin Kolev", "Daniel Cremers"], "b": "We introduce a convex relaxation framework to optimally minimize continuous surface ratios. The key idea is to min- imize the continuous surface ratio by solving a sequence of convex optimization problems. We show that such min- imal ratios are superior to traditionally used minimal sur- face formulations in that they do not suffer from a shrinking bias and no longer", "cn": 5, "i": 5169723, "k": ["3d reconstruction", "Convex Optimization", "Convex Relaxation", "Multiple Views", "Three Dimensional"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#KolevC09", "http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206608", "http://wwwcremers.in.tum.de/pub/pub/Kolev-Cremers-09.pdf", "http://www-cvpr.iai.uni-bonn.de/pub/pub/Kolev-Cremers-09.pdf"], "t": "Continuous ratio optimization via convex relaxation with applications to multiview 3D reconstruction", "v": "CVPR", "y": 2009, "rn": 23}, {"a": ["Chris Hermans", "Yannick Francken", "Tom Cuypers", "Philippe Bekaert"], "b": "In this paper we present a novel method for 3D structure acquisition, based on structured light. Unlike classical structured light methods, in which a static projector illuminates a scene with time-varying illumination patterns, our technique makes use of a moving projector emitting a static striped illumination pattern. This projector is translated at a constant velocity, in the direction of the", "cn": 5, "i": 5326676, "k": ["3d structure", "Image Sequence", "Specular Reflection", "Structured Light", "Subsurface Scattering", "Dominant Frequency", "Time Varying"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206610", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#HermansFCB09", "http://research.edm.uhasselt.be/~tcuypers/publications/cvpr09/cvpr09-Depth%20From%20Sliding%20Projections.pdf", "http://research.edm.uhasselt.be/~chermans/pdf/Hermans%20et%20al.%20-%20Depth%20from%20Sliding%20Projections.pdf"], "t": "Depth from sliding projections", "v": "CVPR", "y": 2009, "rn": 24}, {"a": ["Alex Rav-acha", "Pushmeet Kohli", "Carsten Rother", "Andrew Fitzgibbon"], "b": "We introduce a new representation for video which facilitates a number of common editing tasks. The representation has some of the power of a full reconstruction of 3D surface models from video, but is designed to be easy to recover from a priori unseen and un- calibrated footage. By modelling the image-formation process as a 2D-to-2D transformation from an object's", "cn": 5, "i": 4144161, "k": ["Deformable Objects", "Image Formation", "Motion Estimation", "Surface Model", "Texture Mapping", "Video Editing"], "p": ["https://research.microsoft.com/en-us/um/people/pkohli/papers/rkrf_siggraph08_lres.pdf", "http://research.microsoft.com/en-us/um/people/pkohli/papers/rkrf_siggraph08_lres.pdf", "http://kucg.korea.ac.kr/seminar/2009/src/PA-09-01-15.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog27.html#Rav-AchaKRF08", "http://doi.acm.org/10.1145/1360612.1360616", "http://research.microsoft.com/apps/pubs/default.aspx?id=65407"], "t": "Unwrap mosaics: a new representation for video editing", "v": "TOG", "y": 2008, "rn": 40}, {"a": ["Anke Bellmann", "Olaf Hellwich", "Volker Rodehorst", "Ulas Yilmaz"], "b": "Numerous techniques were invented in computer vision and photogrammetry to obtain spatial information from digital images. We intend to describe and improve the performance of these vision techniques by providing test objectives, data, metrics and test protocols. In this paper we propose a comprehensive benchmarking dataset for evaluating a variety of automatic surface reconstruction algorithms (shape-from-X) and a methodology for", "cn": 5, "i": 4247750, "k": ["Digital Image", "Numerical Technique", "Performance Evaluation", "Spatial Information", "Surface Reconstruction"], "p": ["http://www.cv.tu-berlin.de/fileadmin/fg140/A_Benchmarking_Dataset.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270347", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270347", "http://dx.doi.org/10.1109/CVPR.2007.383349", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#BellmannHRY07"], "t": "A Benchmarking Dataset for Performance Evaluation of Automatic Surface Reconstruction Algorithms", "v": "CVPR", "y": 2007, "rn": 22}, {"a": ["Gregor Miller", "Jonathan Starck", "Adrian Hilton"], "b": "This paper introduces a novel method of surface refinement for free-viewpoint video of dynamic scenes. Unlike previous approaches, the method presented here uses both visual hull and silhouette contours to constrain refinement of view- dependent depth maps from wide baseline views. A technique for extracting silhouette contours as rims in 3D from the view-dependent visual hull (VDVH) is presented. A", "cn": 5, "i": 4586028, "k": ["Depth Map", "Dynamic Scenes", "Global Optimisation", "Graph Cut", "Real Time Rendering", "Free Viewpoint Video", "Visual Hull"], "p": ["http://www.ee.surrey.ac.uk/CVSSP/VMRG/Publications/miller06cvmp.pdf"], "t": "Projective Surface Refinement for Free-Viewpoint Video", "y": 2006, "rn": 22}, {"a": ["Fabio REMONDINO", "Fabio MENNA"], "b": "Recent new developments in the electronics have leaded to the manufacturing of new high-resolution digital sensors (up to 39 mega pixel) for terrestrial cameras. These technological innovations, together with new processing algorithms of image matching, allow to obtain image-based surface models in an almost automatic way with an accuracy and a detail level that can be surely compared with the", "cn": 5, "i": 5619061, "k": ["3d model", "Active Sensor", "Close Range", "Digital Camera", "Digital Image", "High Resolution", "Image Matching", "Image Resolution", "Object Model", "Surface Measurement", "Surface Model", "Surface Reconstruction", "Technological Innovation"], "p": ["http://www.isprs.org/congresses/beijing2008/proceedings/5_pdf/36.pdf"], "t": "IMAGE-BASED SURFACE MEASUREMENT FOR CLOSE-RANGE HERITAGE DOCUMENTATION", "y": 0, "rn": 30}, {"a": ["Simon Baker", "Daniel Scharstein", "J. Lewis", "Stefan Roth", "Michael Black", "Richard Szeliski"], "b": "The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. The challenges for optical flow algorithms today go beyond the datasets and\n evaluation methods proposed in that paper. Instead, they center on problems associated with complex natural scenes, including\n nonrigid motion, real sensor noise, and motion discontinuities. We propose a new set", "cn": 4, "i": 39321365, "k": ["Evaluation Method", "Evaluation Methodology", "Evaluation Metric", "Natural Scenes", "Quantitative Evaluation", "Ground Truth", "Next Generation", "Optical Flow"], "p": ["http://www.springerlink.com/index/p516733117226378.pdf", "http://www.springerlink.com/content/p516733117226378", "http://dx.doi.org/10.1007/s11263-010-0390-2", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv92.html#BakerSLRBS11", "http://research.microsoft.com/apps/pubs/default.aspx?id=138246", "http://research.microsoft.com/pubs/138246/Baker-IJCV11.pdf"], "t": "A Database and Evaluation Methodology for Optical Flow", "v": "IJCV", "y": 2011, "rn": 94}, {"a": ["Ram Vasudevan", "Edgar Lobaton", "Gregorij Kurillo", "Ruzena Bajcsy", "Tony Bernardin", "Bernd Hamann", "Klara Nahrstedt"], "b": "Though the quality of imaging devices, the accuracy of algorithms that construct 3D data, and the hardware available to render such data have all improved, the algorithms available to calibrate, reconstruct, and then visualize such data are difficult to use, extremely noise sensitive, and unreasonably slow. In this paper, we describe a multi-camera system that creates a highly accurate (on", "cn": 4, "i": 39236326, "k": ["3d reconstruction", "3d video", "Compression Ratio", "Data Collection", "Human Computer Interaction", "Point Cloud", "Virtual Reality", "Real Time", "Unified Model"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1730871&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1730871"], "t": "A methodology for remote virtual interaction in teleimmersive environments", "y": 2010, "rn": 24}, {"a": ["Xiaoyan Hu", "Philippos Mordohai"], "b": "We present an extensive evaluation of 13 confidence metrics for stereo matching that compares the most widely used metrics as well as four novel techniques proposed here. We begin by categorizing the methods according to which aspects of stereo computation they take into account and, then, assess their strengths and weaknesses. The evaluation is conducted on indoor and outdoor datasets", "cn": 4, "i": 39261440, "k": ["Depth Estimation", "Depth Map", "multi-view stereo", "Stereo Matching", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539798", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539798", "http://dx.doi.org/10.1109/CVPR.2010.5539798", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#HuM10"], "t": "Evaluation of stereo confidence indoors and outdoors", "v": "CVPR", "y": 2010, "rn": 20}, {"a": ["Marcus Mueller", "Frederik Zilly", "Peter Kauff"], "b": "", "cn": 4, "i": 50904654, "k": ["Bilateral Filtering", "Depth Map", "Non-linear Filtering", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5506336", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05506336"], "t": "Adaptive cross-trilateral depth map filtering", "v": "DTV-CON", "y": 2010, "rn": 10}, {"a": ["Guofeng Zhang", "Zilong Dong", "Jiaya Jia", "Liang Wan", "Tien-tsin Wong", "Hujun Bao"], "b": "Compared to still image editing, content-based video editing faces the additional challenges of maintaining the spatiotemporal consistency with respect to geometry. This brings up difficulties of seamlessly modifying video content, for instance, inserting or removing an object. In this paper, we present a new video editing system for creating spatiotemporally consistent and visually appealing refilming effects. Unlike the typical filming", "cn": 4, "i": 5133421, "k": ["3d model", "Depth Estimation", "Depth Map", "Image Editing", "Moving Object", "Video Editing", "Depth of Field", "Real Time"], "p": ["http://dx.doi.org/10.1109/TVCG.2009.47", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04906990", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4906990", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4906990", "http://www.cse.cuhk.edu.hk/%7eleojia/all_final_papers/refilming_tvcg09.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/tvcg/tvcg15.html#ZhangDJWWB09"], "t": "Refilming with Depth-Inferred Videos", "v": "TVCG", "y": 2009, "rn": 34}, {"a": ["Yi Xu", "Daniel Aliaga"], "b": "Modeling real-world scenes, beyond diffuse objects, plays an important role in computer graphics, virtual reality, and other commercial applications. One active approach is projecting binary patterns in order to obtain correspondence and reconstruct a densely sampled 3D model. In such structured-light systems, determining whether a pixel is directly illuminated by the projector is essential to decoding the patterns. When a", "cn": 4, "i": 5750443, "k": ["3d model", "Computer Graphic", "Geometric Model", "Indexing Terms", "Iterative Algorithm", "Lower and Upper Bound", "Pixel Classification", "Structured Light", "Three-dimensional Graphics and Realism", "Virtual Reality"], "p": ["http://dx.doi.org/10.1109/TVCG.2008.97", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04569840", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4569840", "http://www.informatik.uni-trier.de/~ley/db/journals/tvcg/tvcg15.html#XuA09", "http://www.cs.purdue.edu/cgvlab/papers/aliaga/tvcg08-ast.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4569840"], "t": "An Adaptive Correspondence Algorithm for Modeling Scenes with Strong Interreflections", "v": "TVCG", "y": 2009, "rn": 38}, {"a": ["Jonathan Starck", "Atsuto Maki", "Shohei Nobuhara", "Adrian Hilton", "Takashi Matsuyama"], "b": "Multiple-camera systems are currently widely used in research and development as a means of capturing and synthesizing realistic 3-D video content. Studio systems for 3-D production of human performance are reviewed from the literature, and the practical experience gained in developing prototype studios is reported across two research laboratories. System design should consider the studio backdrop for foreground matting, lighting", "cn": 4, "i": 14401084, "k": ["Active Vision", "Camera Calibration", "Human Performance", "Image Based Rendering", "Machine Vision", "Research and Development", "System Design", "View Synthesis", "Virtual Reality", "Free Viewpoint Video", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4801622", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04801622", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4801622", "http://dx.doi.org/10.1109/TCSVT.2009.2017406", "http://www.informatik.uni-trier.de/~ley/db/journals/tcsv/tcsv19.html#StarckMNHM09"], "t": "The Multiple-Camera 3-D Production Studio", "v": "TCSV", "y": 2009, "rn": 47}, {"a": ["Alexander Ladikos", "Selim Benhimane", "Nassir Navab"], "b": "With the increased presence of automated devices such as C-arms and medical robots and the introduction of a multitude of\n surgical tools, navigation systems and patient monitoring devices, collision avoidance has become an issue of practical value\n in interventional environments. In this paper, we present a real-time 3D reconstruction system for interventional environments\n which aims at predicting collisions by building", "cn": 4, "i": 4301009, "k": ["3d reconstruction", "3d representation", "3d video", "Collision Avoidance", "Medical Robotics", "Navigation System", "Patient Monitoring", "Real Time"], "p": ["http://www.springerlink.com/content/00450u36k4r02755", "http://www.springerlink.com/index/00450u36k4r02755.pdf", "http://dx.doi.org/10.1007/978-3-540-85990-1_63", "http://www.informatik.uni-trier.de/~ley/db/conf/miccai/miccai2008-2.html#LadikosBN08"], "t": "Real-Time 3D Reconstruction for Collision Avoidance in Interventional Environments", "v": "MICCAI", "y": 2008, "rn": 16}, {"a": ["Christopher Zach"], "b": "Reconstructing the 3D surface from a set of provided range images - acquired by active or passive sensors - is an important step to generate faithful virtual models of real objects or environments. Since several approaches for high quality fusion of range images are already known, the run- time efficiency of the respective methods are of increased interest. In this", "cn": 4, "i": 5894793, "k": ["Depth Map", "Energy Function", "Global Optimization", "Graphic Processing Unit", "multi-view stereo", "Range Image", "Surface Reconstruction", "Variational Formulation", "Gradient Descent"], "p": ["http://www.cc.gatech.edu/conferences/3DPVT08/Program/Papers/paper196.pdf", "http://www-video.eecs.berkeley.edu/Proceedings/3DPVT08/Papers/paper196.pdf"], "t": "Fast and High Quality Fusion of Depth Maps", "y": 2008, "rn": 31}, {"a": ["Mario Sormann", "Christopher Zach", "Joachim Bauer", "Konrad Karner", "Horst Bischof"], "b": "This paper proposes a fast 3D reconstruction approach for efficiently generating watertight 3D models from multiple short\n baseline views. Our method is based on the combination of a GPU-based plane-sweep approach, to compute individual dense depth\n maps and a subsequent robust volumetric depth map integration technique. Basically, the dense depth map values are transformed\n to a volumetric grid, which are", "cn": 4, "i": 2470269, "k": ["3d model", "3d reconstruction", "Depth Map", "Graph Cut", "Weighted Graph"], "p": ["http://www.springerlink.com/index/nr4764185518054v.pdf", "http://www.springerlink.com/content/nr4764185518054v", "http://dx.doi.org/10.1007/978-3-540-73040-8_40", "http://www.informatik.uni-trier.de/~ley/db/conf/scia/scia2007.html#SormannZBKB07"], "t": "Watertight Multi-view Reconstruction Based on Volumetric Graph-Cuts", "v": "", "y": 2007, "rn": 25}, {"a": ["Shigeki Sugimoto", "Masatoshi Okutomi"], "b": "In this paper, we propose a direct method for 3D surface reconstruction from stereo images. We reconstruct a 3D surface by estimating all depths of the vertices of a mesh composed of piecewise triangular patches on the reference (template) image. The analyses described in this paper subsume that the deformation of the mesh between the stereo images is specified by", "cn": 4, "i": 4247807, "k": ["Direct Method", "Surface Reconstruction", "Sum of Squared Difference"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270275", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270275", "http://dx.doi.org/10.1109/CVPR.2007.383250", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#SugimotoO07"], "t": "A Direct and Efficient Method for Piecewise-Planar Surface Reconstruction from Stereo Images", "v": "CVPR", "y": 2007, "rn": 10}, {"a": ["Kush Varshney", "Nikos Paragios", "Alain Kulski", "Remy Raymond", "Phillipe Hernigou", "Alain Rahmouni"], "b": "In total knee replacement surgery, also known as total knee arthro- plasty, prosthetics are implanted in the knee joint as treatment for progressive diseases such as arthritis or trauma. In this paper, we aim to recover the 3-D shape of bones and prosthetic devices in patients who have undergone total knee replacement. Such an ob- jective is addressed using a", "cn": 4, "i": 4289947, "k": ["Calculus of Variation", "Indexing Terms", "Knee Joint", "Level Set", "multi-view stereo", "Objective Function", "Total Knee Replacement", "X Rays", "X-ray Imaging", "Gradient Descent", "Level Set Method", "Progressive Disease"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04193494", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4193494", "http://www.informatik.uni-trier.de/~ley/db/conf/isbi/isbi2007.html#VarshneyPKRHR07", "http://dx.doi.org/10.1109/ISBI.2007.357060"], "t": "Multi-View Stereo Reconstruction of Total Knee Replacement from X-Rays", "v": "", "y": 2007, "rn": 13}, {"a": ["Patrick Labatut", "Renaud Keriven", "Jean-philippe Pons"], "b": "In this paper, we show the importance and feasibility of much faster multi-view stereo reconstruction algorithms re- lying almost exclusively on graphics hardware. Reconstruc- tion algorithms have been steadily improving in the last few years and several state-of-the-art methods are nowa- days reaching a very impressive level of quality. However all these modern techniques share a very lengthy computa- tional", "cn": 4, "i": 2412776, "k": ["Computer Vision", "Graphics Hardware", "Level Set", "multi-view stereo", "Reconstruction Algorithm"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2006.html#LabatutKP06", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04155801", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4155801", "http://certis.enpc.fr/publications/papers/063dpvt_a.pdf", "http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.62", "http://imagine.enpc.fr/publications/papers/063dpvt_a.pdf"], "t": "Fast Level Set Multi-View Stereo on Graphics Hardware", "v": "3DPVT", "y": 2006, "rn": 27}, {"a": ["Patrick Labatut", "Jean-Philippe Pons", "Renaud Keriven"], "b": "The recent widespread availability of urban imagery has lead to a growing demand for automatic modeling from multiple images. However, modern image-based modeling research has focused either on highly detailed reconstruc- tions of mostly small objects or on human-assisted simpli- fied modeling. This paper presents a novel algorithm which automatically outputs a simplified, segmented model of a scene from a", "cn": 4, "i": 6442578, "k": ["Compact Model", "Depth Map", "Geometric Feature", "image-based modeling", "multi-view stereo", "Point Cloud", "Surface Reconstruction"], "p": ["http://certis.enpc.fr/publications/papers/3DIM09b.pdf"], "t": "Hierarchical shape-based surface reconstruction for dense multi-view stereo", "y": 0, "rn": 29}, {"a": ["George Vogiatzis"], "b": "This paper addresses the problem of obtaining 3d de- tailed reconstructions of human faces in real-time and with inexpensive hardware. We present an algorithm based on a monocular multi-spectral photometric-stereo setup. This system is known to capture high-detailed deforming 3d sur- faces at high frame rates and without having to use any expensive hardware or synchronized light stage. However, the", "cn": 4, "i": 14318105, "k": ["3d model", "multi-view stereo", "Photometric Stereo", "Robust Estimator", "Structure From Motion", "Multi Spectral", "Real Time"], "p": ["http://www.george-vogiatzis.org/publications/3dpvt10.pdf"], "t": "Self-calibrating a real-time monocular 3d facial capture system", "y": 0, "rn": 19}, {"a": ["Makoto Kimura", "Masaaki Mochimaru", "Takeo Kanade"], "b": "Measurement of human body is useful for ergonomic design in manufacturing. We aim to accurately measure the shapes of human\n feet for the design of shoes, for which measuring the dynamic shape of the foot in motion is important because the foot deforms\n while walking or running. In this paper, we propose a method for measuring the anatomical feature cross-sections", "cn": 3, "i": 15231549, "k": ["3d measurement", "Cross Section", "Human Body", "multi-view stereo"], "p": ["http://www.springerlink.com/content/m546jhj636764916", "http://www.springerlink.com/index/m546jhj636764916.pdf", "http://www.springerlink.com/index/10.1007/s00138-009-0238-3", "http://www.springerlink.com/index/pdf/10.1007/s00138-009-0238-3", "http://dx.doi.org/10.1007/s00138-009-0238-3", "http://www.informatik.uni-trier.de/~ley/db/journals/mva/mva22.html#KimuraMK11"], "t": "3D measurement of feature cross-sections of foot while walking", "v": "MVA", "y": 2011, "rn": 16}, {"a": ["Jianguo Li", "Eric Li", "Yurong Chen", "Lin Xu", "Yimin Zhang"], "b": "Depth-map merging is one typical technique category for multi-view stereo (MVS) reconstruction. To guarantee accuracy, existing algorithms usually require either sub-pixel level stereo matching precision or continuous depth-map estimation. The merging of inaccurate depth-maps remains a challenging problem. This paper introduces a bundle optimization method for robust and accurate depth-map merging. In the method, depth-maps are generated using DAISY feature,", "cn": 3, "i": 39261412, "k": ["Depth Map", "Geometric Model", "High Resolution", "multi-core processor", "multi-view stereo", "Optimal Method", "Point Cloud", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5540004", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05540004", "http://dx.doi.org/10.1109/CVPR.2010.5540004", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#LiLCXZ10"], "t": "Bundled depth-map merging for multi-view stereo", "v": "CVPR", "y": 2010, "rn": 31}, {"a": ["Alexander Schick", "Rainer Stiefelhagen"], "b": "We present an approach to compute the visual hulls of multiple people in real-time in the presence of occlusions. We prove\n that the resulting visual hulls are correct and minimal under occlusions. Our proposed algorithm runs completely on the GPU\n with framerates up to 50fps for multiple people using only one computer equipped with off-the-shelf hardware. We also compare runtimes", "cn": 3, "i": 6032498, "k": ["Off The Shelf", "Real Time", "Visual Hull"], "p": ["http://www.springerlink.com/content/m2212r130316g534", "http://www.springerlink.com/index/m2212r130316g534.pdf", "http://dx.doi.org/10.1007/978-3-642-03798-6_38", "http://www.informatik.uni-trier.de/~ley/db/conf/dagm/dagm2009.html#SchickS09", "http://adsabs.harvard.edu/abs/2009LNCS.5748..372S"], "t": "Real-Time GPU-Based Voxel Carving with Systematic Occlusion Handling", "v": "", "y": 2009, "rn": 15}, {"a": ["Samuel Kadoury", "Farida Cheriet", "Hubert Labelle"], "b": "This paper presents a novel 3-D reconstruction method of the scoliotic spine using prior vertebra models with image-based information taken from biplanar X-ray images. We first propose a global modeling approach by exploiting the 3-D scoliotic curve reconstructed from a coronal and sagittal X-ray image in order to generate an approximate statistical model from a 3-D database of scoliotic patients", "cn": 3, "i": 13765916, "k": ["Clinical Assessment", "Deformable Template", "Experience Report", "image-based modeling", "Level Set", "Magnetic Resonance Image", "Qualitative Evaluation", "Similarity Measure", "Statistical Model", "Three Dimensional", "X Rays", "X-ray Imaging"], "p": ["http://dx.doi.org/10.1109/TMI.2009.2016756", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04804738", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4804738", "http://www.informatik.uni-trier.de/~ley/db/journals/tmi/tmi28.html#KadouryCL09"], "t": "Personalized X-Ray 3-D Reconstruction of the Scoliotic Spine From Hybrid Statistical and Image-Based Models", "v": "TMI", "y": 2009, "rn": 44}, {"a": ["Douglas Lanman", "Gabriel Taubin"], "b": "Over the last decade, digital photography has entered the mainstream with inexpensive, miniaturized cameras for consumer use. Digital projection is poised to make a similar breakthrough, with a variety of vendors offering small, low-cost projectors. As a result, active imaging is a topic of renewed interest in the computer graphics community. In particular, low-cost homemade 3D scanners are now within", "cn": 3, "i": 39244439, "k": ["3d scanning", "Computer Graphic", "Cultural Heritage", "Digital Photography", "Mathematical Software", "Rapid Prototyping", "web-based applications", "Off The Shelf"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1667247&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1667247"], "t": "Build your own 3D scanner: 3D photography for beginners", "y": 2009, "rn": 71}, {"a": ["Tony Tung", "Shohei Nobuhara", "Takashi Matsuyama"], "b": "This paper presents a novel approach to achieve accurate and complete multi-view reconstruction of dynamic scenes (or 3D videos). 3D videos consist in sequences of 3D models in motion captured by a surrounding set of video cameras. To date 3D videos are reconstructed using multiview wide baseline stereo (MVS) reconstruction techniques. However it is still tedious to solve stereo correspondence", "cn": 3, "i": 39265936, "k": ["3d model", "3d video", "Correspondence Problem", "Dynamic Scenes", "Motion Capture", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459384", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459384", "http://dx.doi.org/10.1109/ICCV.2009.5459384", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#TungNM09"], "t": "Complete multi-view reconstruction of dynamic scenes from probabilistic fusion of narrow and wide baseline stereo", "v": "ICCV", "y": 2009, "rn": 35}, {"a": ["Rogerio Feris", "Ramesh Raskar", "Longbin Chen", "Kar-han Tan", "Matthew Turk"], "b": "Abstract Traditional stereo matching,algorithms are limited in thei r ability to produce accurate results near depth discontinuities, due to partial occlusions and viola tion of smoothness constraints. In this paper, we use small baseline multi-flash illumination to produce a ric h set of feature maps that enable acquisition of discontinuity preserving point correspondences. First, f rom a single multi-flash camera,", "cn": 3, "i": 4404269, "k": ["Belief Propagation", "Depth Map", "Indexing Terms", "Specular Reflection", "Stereo Matching"], "p": ["http://ilab.cs.ucsb.edu/publications/PAMI2008.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4359302", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04359302", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4359302", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami30.html#FerisRCTT08", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.1136"], "t": "Multiflash Stereopsis: Depth-Edge-Preserving Stereo with Small Baseline Illumination", "v": "PAMI", "y": 2008, "rn": 46}, {"a": ["Ke Zheng", "Sing Kang", "Michael Cohen", "Richard Szeliski"], "b": "Representations for interactive photorealistic visualiz a- tion of scenes range from compact 2D panoramas to data- intensive 4D light fields. In this paper, we propose a tech- nique for creating a layered representation from a sparse se t of images taken with a hand-held camera. This representa- tion, which we call a layered depth panorama (LDP), al- lows the user", "cn": 3, "i": 4114211, "k": ["3d navigation", "Graph Cut", "Light Field", "multi-view stereo"], "p": ["http://dx.doi.org/10.1109/CVPR.2007.383295", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270320", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270320", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#ZhengKCS07"], "t": "Layered Depth Panoramas", "v": "CVPR", "y": 2007, "rn": 34}, {"a": ["Christoph Munkelt", "Michael Trummer", "Joachim Denzler", "Stefan Wenhardt"], "b": "The problem of planning the Next Best View (NBV) still poses many questions. However, the achieved meth- ods and algorithms are hard to compare, since research- ers use their own test objects for planning and recon- struction and compute specific quality measures. Con- sequently, these numbers make different statements about different objects. Thus, the quality of the results and the", "cn": 3, "i": 4346161, "k": ["3d reconstruction", "Quality Measures", "Next Best View"], "p": ["http://www.inf-cv.uni-jena.de/biborb/bibs/cv/papers/MuTr07.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/mva/mva2007.html#MunkeltTDW07", "http://b2.cvl.iis.u-tokyo.ac.jp/mva/proceedings/2007CD/papers/13-30.pdf"], "t": "Benchmarking 3D Reconstructions from Next Best View Planning", "v": "MVA", "y": 2007, "rn": 12}, {"a": ["Hongdong Li", "Richard Hartley"], "b": "A new tensor transfer-based novel view synthesis (NVS) method is proposed in this paper. As opposed to conventional tensor transfer methods which transfer the pixel from the real input views to the virtual novel view, our method operates inversely in the sense that it transfers a pixel from the novel view image back to the real images. This inverse tensor-transfer", "cn": 3, "i": 5031635, "k": ["Depth Map", "Multiple Views", "Stereo Matching", "Stereo Vision", "View Synthesis"], "p": ["http://users.rsise.anu.edu.au/~hongdong/SP_inversetensor.pdf", "http://www.sciencedirect.com/science/article/pii/S0923596506000634", "http://linkinghub.elsevier.com/retrieve/pii/S0923596506000634", "http://dx.doi.org/10.1016/j.image.2006.07.004", "http://www.informatik.uni-trier.de/~ley/db/journals/spic/spic21.html#LiH06"], "t": "Inverse tensor transfer with applications to novel view synthesis and multi-baseline stereo", "v": "SIGNAL PROCESS-IMAGE COMMUN", "y": 2006, "rn": 34}, {"a": ["S. El-Hakim", "Fabio Remondino", "Lorenzo Gonzo", "Francesca Voltolini"], "b": "Motivated by the need for fast, accurate, and high-resolution approach to document heritage and archaeological sites before they are removed or destroyed, the goal of this paper is to develop and demonstrate advanced image-based techniques to capture the fine 3D geometric details of such sites. The size of the site can be large and of any arbitrary shape which presents", "cn": 3, "i": 5599657, "k": ["3d modelling", "Data Capture", "Digital Camera", "High Resolution", "Laser Scanner", "Visual Performance"], "p": ["http://www.3dphotomodeling.org/CAA-Final.pdf", "http://www.photogrammetry.ethz.ch/general/persons/fabio/el-hakim_etal_CAA07.pdf"], "t": "Effective High Resolution 3D Geometric Reconstruction of Heritage and Archaeological Sites from Images", "y": 0, "rn": 23}, {"a": ["Benjamin Petit", "Jean-Denis Lesage", "Cl Menier", "Jean-sebastien Franco"], "b": "", "cn": 2, "i": 12133075, "k": ["3d model", "Remote Collaboration", "Real Time"], "p": ["http://hal.archives-ouvertes.fr/docs/00/43/64/67/PDF/petit09c.pdf", "http://perception.inrialpes.fr/Publications/2010/PLMAFRBF10/petit10a.pdf", "http://perception.inrialpes.fr/people/Boyer/Publications/ijdmb2010.pdf", "http://downloads.hindawi.com/journals/ijdmb/2010/247108.pdf", "http://www.hindawi.com/journals/ijdmb/2010/247108.html", "http://hal.inria.fr/inria-00436467/PDF/petit10a.pdf", "http://dx.doi.org/10.1155/2010/247108", "http://www.informatik.uni-trier.de/~ley/db/journals/ijdmbc/ijdmbc2010.html#PetitLMAFRBF10"], "t": "Multicamera Real-Time 3D Modeling for Telepresence and Remote Collaboration", "v": "", "y": 2010, "rn": 38}, {"a": ["Ramanarayan Vasudevan", "Zhong Zhou", "Gregorij Kurillo", "Edgar Lobaton", "Ruzena Bajcsy", "Klara Nahrstedt"], "b": "Though the variety of desktop real time stereo vision systems has grown considerably in the past several years, few make any verifiable claims about the accuracy of the algorithms used to construct 3D data or describe how the data generated by such systems, which is large in size, can be effectively distributed. In this paper, we describe a system that", "cn": 2, "i": 13982944, "k": ["3d environment", "3d reconstruction", "3d video", "Compression Ratio", "Point Cloud", "Stereo Vision", "Real Time"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05582538", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5582538", "http://dx.doi.org/10.1109/ICME.2010.5582538", "http://www.informatik.uni-trier.de/~ley/db/conf/icmcs/icme2010.html#VasudevanZKLBN10"], "t": "Real-time stereo-vision system for 3D teleimmersive collaboration", "v": "ICME(ICMCS)", "y": 2010, "rn": 16}, {"a": ["Zheng Lu", "Yu-Wing Tai", "Moshe Ben-Ezra", "Michael Brown"], "b": "We present an imaging framework to acquire 3D surface scans at ultra high-resolutions (exceeding 600 samples per mm2). Our approach couples a standard structured-light setup and photometric stereo using a large-format ultra-high-resolution camera. While previous approaches have employed similar hybrid imaging systems to fuse positional data with surface normals, what is unique to our approach is the significant asymmetry in", "cn": 2, "i": 39261295, "k": ["3d imaging", "3d scanning", "Geometric Constraints", "High Resolution", "High Resolution Imager", "Imaging System", "Photometric Stereo", "Structured Light", "Surface Reconstruction", "High Resolution Camera", "Low Resolution", "Multi Resolution"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539829", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539829", "http://dx.doi.org/10.1109/CVPR.2010.5539829", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#LuTBB10"], "t": "A framework for ultra high resolution 3D imaging", "v": "CVPR", "y": 2010, "rn": 18}, {"a": ["Yuping Lin", "G\u00e9rard Medioni", "Jongmoo Choi"], "b": "We propose a method to generate a highly accurate 3D face model from a set of wide-baseline images in a weakly calibrated setup. Our approach is purely data driven, and produces faithful 3D models without any pre-defined models, unlike other statistical model-based approaches. Our results do not rely upon a critical initialization step nor parameters for optimization steps. We process", "cn": 2, "i": 39261371, "k": ["3d model", "Bundle Adjustment", "Camera Motion", "Face Modeling", "Global Optimization", "Statistical Model", "Pure Data"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539793", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539793", "http://dx.doi.org/10.1109/CVPR.2010.5539793", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#LinMC10"], "t": "Accurate 3D face reconstruction from weakly calibrated wide baseline images with profile contours", "v": "CVPR", "y": 2010, "rn": 17}, {"a": ["Tai-Pang Wu", "Sai-Kit Yeung", "Jiaya Jia", "Chi-Keung Tang"], "b": "We propose tensor-based multiview stereo (TMVS) for quasi-dense 3D reconstruction from uncalibrated images. Our work is inspired by the patch-based multiview stereo (PMVS), a state-of-the-art technique in multiview stereo reconstruction. The effectiveness of PMVS is attributed to the use of 3D patches in the match-propagate-filter MVS pipeline. Our key observation is: PMVS has not fully utilized the valuable 3D geometric", "cn": 2, "i": 39261556, "k": ["3d reconstruction", "Closed Form Solution", "Quantitative Evaluation"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539796", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539796", "http://dx.doi.org/10.1109/CVPR.2010.5539796", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#WuYJT10"], "t": "Quasi-dense 3D reconstruction using tensor-based multiview stereo", "v": "CVPR", "y": 2010, "rn": 25}, {"a": ["Shubao Liu", "David Cooper"], "b": "In this paper, we present an approach to multi-view image-based 3D reconstruction by statistically inversing the ray-tracing based image generation process. The proposed algorithm is fast, accurate and does not need any initialization. The geometric representation is a discrete volume divided into voxels, with each voxel associated with two properties: opacity (shape) and color (appearance). The problem is then formulated", "cn": 2, "i": 39261571, "k": ["3d model", "3d reconstruction", "Belief Propagation", "Color Appearance", "Computational Complexity", "Efficient Algorithm", "Functional Form", "Image Generation", "Loopy Belief Propagation", "Map Estimation", "New Combination", "Random Variable", "Ray Tracing", "Sparse Representation", "Surface Reconstruction", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539790", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539790", "http://dx.doi.org/10.1109/CVPR.2010.5539790", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#LiuC10"], "t": "Ray Markov Random Fields for image-based 3D modeling: Model and efficient inference", "v": "CVPR", "y": 2010, "rn": 16}, {"a": ["Jean-Yves Guillemaut", "Muhammad Sarim", "Adrian Hilton"], "b": "Conventional stereoscopic video content production requires use of dedicated stereo camera rigs which is both costly and lacking video editing flexibility. In this paper, we propose a novel approach which only requires a small number of stan- dard cameras sparsely located around a scene to automatically convert the monocular inputs into stereoscopic streams. The approach combines a probabilistic spatio-temporal segmenta-", "cn": 2, "i": 39267410, "k": ["3d video", "Complex Dynamics", "Graph Cut", "Human Motion", "Indexing Terms", "Reconstruction Algorithm", "User Interaction", "Video Editing"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5652901", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05652901", "http://dx.doi.org/10.1109/ICIP.2010.5652901", "http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2010.html#GuillemautSH10", "http://personal.ee.surrey.ac.uk/Personal/J.Guillemaut/publications/10/GuillemautICIP10.pdf"], "t": "Stereoscopic content production of complex dynamic scenes using a wide-baseline monoscopic camera set-up", "v": "ICIP", "y": 2010, "rn": 15}, {"a": ["Ke Zheng", "R. Colburn", "Aseem Agarwala", "Maneesh Agrawala", "David Salesin", "Brian Curless", "Michael Cohen"], "b": "We present an approach to convert a small portion of a light field with extracted depth information into a cinematic effect with sim- ulated, smooth camera motion that exhibits a sense of 3D parallax. We develop a taxonomy of the cinematic conventions of these ef- fects, distilled from observations of documentary film footage and organized by the number of subjects", "cn": 2, "i": 4710462, "k": ["Camera Motion", "Computer Graphic", "Data Structure", "Data Type", "Image Based Rendering", "Image Editing", "Indexing Terms", "Light Field", "Methodology and Techniques", "Temporal Coherence", "User Study", "Depth of Field"], "p": ["http://doi.acm.org/10.1145/1555880.1555909", "http://grail.cs.washington.edu/projects/parallax/parallax_gi09.pdf", "https://research.microsoft.com/en-us/um/people/cohen/parallax_gi09.pdf", "http://colinzheng.org/wp-content/data/research/papers/parallax_gi09.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/graphicsinterface/graphicsinterface2009.html#ZhengCAASCC09", "https://research.microsoft.com/pubs/81645/parallax_gi09.pdf", "http://grail.cs.washington.edu/pub/papers/zheng2009ppc.pdf", "http://research.microsoft.com/en-us/um/people/cohen/parallax_gi09.pdf", "http://vis.berkeley.edu/papers/parallax/parallax_gi09.pdf", "http://research.microsoft.com/pubs/81645/parallax_gi09.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=81645", "http://www.cs.washington.edu/homes/alexco/ParallaxPhoto_GI2009_pre_print.pdf"], "t": "Parallax photography: creating 3D cinematic effects from stills", "v": "GI", "y": 2009, "rn": 35}, {"a": ["Michal Jancosek", "Tomas Pajdla"], "b": "This paper presents a segmentation based multi- view stereo reconstruction method. We address (i) dealing with uninformative texture in very homogeneous image ar- eas and (ii) processing of large images in affordable time. To avoid searching for optimal surface position and orien- tation based on uninformative texture, we (over)segment im- ages into segments of low variation of color and intensity", "cn": 2, "i": 5004336, "k": ["Image Segmentation", "multi-view stereo"], "p": ["http://cmp.felk.cvut.cz/~jancom1/JancosekCVWW09.pdf"], "t": "Segmentation based Multi-View Stereo", "y": 2009, "rn": 24}, {"a": ["Nader Salman", "Mariette Yvinec"], "b": "ABSTRACT Extracting a computer model of a real scene from a sequence of views, is one of the most challenging and fundamental problems in computer vision. Stereo vision algorithms allow us to extract from the images a sparse 3D point cloud on the scene surfaces. However, computing an accurate mesh of the scene based on such poor quality data points", "cn": 2, "i": 5429349, "k": ["3d point cloud", "Computer Model", "Computer Vision", "delaunay triangulation", "Depth Map", "High Resolution", "Multiple Views", "Object Model", "Point Cloud", "Stereo Vision", "Surface Reconstruction"], "p": ["http://doi.acm.org/10.1145/1542362.1542386", "http://portal.acm.org/ft_gateway.cfm?id=1542386&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1542386", "http://www.informatik.uni-trier.de/~ley/db/conf/compgeom/compgeom2009.html#SalmanY09"], "t": "High resolution surface reconstruction from overlapping multiple-views", "v": "SOCG", "y": 2009, "rn": 12}, {"a": ["Daniel Knoblauch", "Falko Kuester"], "b": "This paper introduces a new approach for volumetric visual hull reconstruction, using a voxel grid that focuses on the moving\n target object. This grid is continuously updated as a function of object location, orientation, and size. The benefit is a\n reduced amount of voxels that have to be evaluated or allocated towards capturing the target at higher resolution. This technique", "cn": 2, "i": 6044645, "k": ["Case Study", "Dynamic Data", "Hardware Accelerator", "Outlier Detection", "Visual Hull"], "p": ["http://www.springerlink.com/content/3652g2h32150v271", "http://www.springerlink.com/index/3652g2h32150v271.pdf", "http://dx.doi.org/10.1007/978-3-642-10520-3_19", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-2.html#KnoblauchK09"], "t": "Focused Volumetric Visual Hull with Color Extraction", "v": "ISVC", "y": 2009, "rn": 15}, {"a": ["Douglas Lanman", "Gabriel Taubin"], "b": "Over the last decade, digital photography has entered the mainstream. Inexpensive, miniaturized cameras are now routinely included in consumer electronics. Digital projection is poised to make a similar breakthrough, with a variety of vendors offering small, low-cost projectors. As a result, active imaging is a topic of renewed interest in the computer graphics community. In particular, low-cost homemade 3D scanners", "cn": 2, "i": 6050602, "k": ["3d scanning", "Computer Graphic", "Consumer Electronics", "Cultural Heritage", "Digital Photography", "Mathematical Software", "Rapid Prototyping", "web-based applications", "Off The Shelf"], "p": ["http://portal.acm.org/citation.cfm?id=1665819", "http://portal.acm.org/ft_gateway.cfm?id=1665819&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1665817.1665819", "http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph2009asiacourses.html#LanmanT09"], "t": "Build your own 3D scanner: optical triangulation for beginners", "v": "SIGGRAPH", "y": 2009, "rn": 71}, {"a": ["Tony Tung", "Takashi Matsuyama"], "b": "This paper presents a novel approach to skim and de- scribe 3D videos. 3D video is an imaging technology which consists in a stream of 3D models in motion captured by a synchronized set of video cameras. Each frame is composed of one or several 3D models, and therefore the acquisition of long sequences at video rate requires massive storage", "cn": 2, "i": 6368204, "k": ["3d model", "3d video", "Action Recognition", "Compression Ratio", "Markov Network", "Motion Capture", "Semantic Description", "Shape Descriptor", "Markov Model"], "p": ["http://vision.kuee.kyoto-u.ac.jp/japanese/happyou/pdf/Tung_2009_IC_104.pdf"], "t": "Topology dictionary with Markov model for 3D video content-based skimming and description", "v": "CVPR", "y": 2009, "rn": 29}, {"a": ["Bastian Goldluecke", "Daniel Cremers"], "b": "We study the scenario of a multiview setting, where several calibrated views of a textured object with known surface geometry are available. The objective is to estimate a diffuse texture map as precisely as possible. A superresolution image formation model based on the camera properties leads to a total variation energy for the desired texture map, which can be recovered", "cn": 2, "i": 39266011, "k": ["euler-lagrange equation", "High Resolution", "Image Formation", "image-based modeling", "Surface Geometry", "Texture Mapping", "Total Variation"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459378", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459378", "http://dx.doi.org/10.1109/ICCV.2009.5459378", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#GoldluckeC09"], "t": "Superresolution texture maps for multiview reconstruction", "v": "ICCV", "y": 2009, "rn": 25}, {"a": ["Jianxiong Xiao", "Jingni Chen", "Dit-yan Yeung", "Long Quan"], "b": "We propose a graph-based semi-supervised symmetric matching framework that performs dense matching between two uncalibrated wide-baseline images by exploiting the results of sparse matching as labeled data. Our method utilizes multiple sources of information including the underlying manifold struc- ture, matching preference, shapes of the surfaces in the scene, and global epipolar geometric constraints for occlusion handling. It can give", "cn": 2, "i": 4253841, "k": ["Geometric Constraints", "Graphic Processing Unit", "Stereo Matching"], "p": ["http://www.cse.ust.hk/~csxjx/publication/eccv08a.jianxiong_xiao_comp.pdf", "http://www.springerlink.com/content/x1672505170r1223", "http://dx.doi.org/10.1007/978-3-540-88690-7_2", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2008-3.html#XiaoCYQ08"], "t": "Learning Two-View Stereo Matching", "v": "ECCV", "y": 2008, "rn": 20}, {"a": ["Alexander Hornung", "Boyi Zeng", "Leif Kobbelt"], "b": "The Middlebury Multi-View Stereo evaluation (18) clearly shows that the quality and speed of most multi-view stereo algorithms depends significantly on the number and selection of input images. In general, not all input images contribute equally to the quality of the output model, since several images may often contain similar and hence overly redundant visual information. This leads to unnecessarily", "cn": 2, "i": 4704854, "k": ["multi-view stereo"], "p": ["http://dx.doi.org/10.1109/CVPR.2008.4587688", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587688", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587688", "http://www-i8.informatik.rwth-aachen.de/uploads/media/hornung_2008_cvpr.pdf", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/348.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#HornungZK08", "http://www-i8.informatik.rwth-aachen.de/uploads/media/hornung_2008_cvpr_01.pdf"], "t": "Image selection for improved Multi-View Stereo", "v": "CVPR", "y": 2008, "rn": 29}, {"a": ["Michael McCool"], "b": "Graphics processing units (GPUs) are the massively parallel high-performance processors used for graphics accelerators in personal computers. These processors have been driven to very high levels of performance and low price-points by the need for real-time computer graphics in mass-market gaming. However, GPUs are no longer specialized for computer graphics. Over the last five years, they have evolved a general-purpose", "cn": 2, "i": 27096219, "k": ["Computer Graphic", "Differential Equation", "Dynamic Program", "Edge Detection", "Graphic Processing Unit", "High Performance", "Image Interpolation", "Image Segmentation", "Iteration Method", "Linear Equations", "Market Game", "Pattern Recognition", "Personal Computer", "Programming Language", "Real-time Computing", "Sequence Alignment", "Signal Processing", "Hidden Markov Model"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4205095", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4205095", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04205095", "http://adsabs.harvard.edu/abs/2007ISPM...24..109M"], "t": "Signal Processing and General-Purpose Computing and GPUs [Exploratory DSP]", "v": "IEEE SIGNAL PROCESS MAG", "y": 2007, "rn": 5}, {"a": ["J Kilner", "J Starck", "A Hilton"], "b": "Generating free-viewpoint video in outdoor sports environ- ments is currently an unsolved problem due to difficulties in obtaining accurate background segmentation and cam- era calibration. This paper introduces a technique for the reconstruction of a scene in the presence of these errors. We tackle the issues of reconstruction completeness, and accuracy of surface shape and appearance. We introduce the concept", "cn": 2, "i": 4845191, "k": ["Data Fitting", "Deformable Model", "Quantitative Evaluation", "Free Viewpoint Video", "Leave One Out", "Visual Hull"], "p": [], "t": "Dual-Mode Deformable Models for Free-Viewpoint Video of Outdoor Sports Events", "y": 0, "rn": 18}, {"a": ["S. Ivekovic", "E. Trucco"], "b": "Image-based novel-view synthesis requires dense correspondences between the original views to produce a high quality synthetic view. In a wide-baseline stereo setup, de nse correspondences are difficult to achieve due to the significa nt change in viewpoint giving rise to a number of problems. To improve their quality, the original, incomplete dispari ty maps are usually interpolated to fill in", "cn": 2, "i": 6221643, "k": ["a priori knowledge", "View Synthesis"], "p": ["http://www.computing.dundee.ac.uk/staff/spela/SIvekovic_CVMP2007.pdf"], "t": "ARTICULATED 3-D MODELLING IN A WIDE-BASELINE DISPARITY SPACE", "y": 0, "rn": 31}, {"a": ["Y. Xiao", "R. Fisher", "M. Oscar"], "b": "Acquisition of dynamic dense 3D shape data is of increasing importance in computer vision with applications in various disciplines.\n In this paper, we investigate the performance of a unique high-speed range sensor based on the stereo vision principle for\n 3D shape acquisition of animals. The investigation reveals some characteristics of the current version of the sensor with\n respect to its", "cn": 1, "i": 15231555, "k": ["Computer Vision", "Data Acquisition", "Dynamic Scenes", "High Speed", "Performance Characterization", "Performance Evaluation", "Stereo Vision", "Time Varying"], "p": ["http://www.springerlink.com/content/ex1513431843h2g7", "http://www.springerlink.com/index/ex1513431843h2g7.pdf", "http://www.springerlink.com/index/10.1007/s00138-010-0265-0", "http://www.springerlink.com/index/pdf/10.1007/s00138-010-0265-0", "http://dx.doi.org/10.1007/s00138-010-0265-0", "http://www.informatik.uni-trier.de/~ley/db/journals/mva/mva22.html#XiaoFO11"], "t": "Performance characterization of a high-speed stereo vision sensor for acquisition of time-varying 3D shapes", "v": "MVA", "y": 2011, "rn": 23}, {"a": ["Maxime Lhuillier"], "b": "Recently, it was suggested that structure-from-motion be solved using generic tools which are exploitable for any kind of\n camera. The same challenge applies for the automatic reconstruction of 3D models from image sequences, which includes structure-from-motion.\n This article is a new step in this direction. First, a generic error model is introduced for central cameras. Second, this\n error model is", "cn": 1, "i": 15271330, "k": ["3d model", "Error Propagation", "Generalization Error", "Image Sequence", "image-based modeling", "Structure From Motion"], "p": ["http://www.springerlink.com/index/q6438n14974130g8.pdf", "http://www.springerlink.com/content/q6438n14974130g8", "http://www.springerlink.com/index/10.1007/s11263-010-0374-2", "http://www.springerlink.com/index/pdf/10.1007/s11263-010-0374-2", "http://dx.doi.org/10.1007/s11263-010-0374-2", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv91.html#Lhuillier11"], "t": "A Generic Error Model and Its Application to Automatic 3D Modeling of Scenes Using a Catadioptric Camera", "v": "IJCV", "y": 2011, "rn": 31}, {"a": ["Chenglei Wu", "Bennett Wilburn", "Yasuyuki Matsushita", "Christian Theobalt"], "b": "Multi-view stereo methods reconstruct 3D geometry from images well for sufficiently textured scenes, but often fail to recover high-frequency surface detail, particularly for smoothly shaded surfaces. On the other hand, shape-fromshading methods can recover fine detail from shading variations. Unfortunately, it is non-trivial to apply shape-fromshading alone to multi-view data, and most shading-based estimation methods only succeed under very restricted", "cn": 1, "i": 27810891, "k": ["Estimation Method", "High Frequency", "Laser Range Scanning", "multi-view stereo"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995388", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995388"], "t": "High-quality shape from multi-view stereo and shading under general illumination", "v": "CVPR", "y": 2011, "rn": 29}, {"a": ["Steffen Gauglitz", "Tobias H\u00f6llerer", "Matthew Turk"], "b": "Applications for real-time visual tracking can be found in many areas, including visual odometry and augmented reality. Interest\n point detection and feature description form the basis of feature-based tracking, and a variety of algorithms for these tasks\n have been proposed. In this work, we present (1) a carefully designed dataset of video sequences of planar textures with ground\n truth, which", "cn": 1, "i": 48822207, "k": ["Augmented Reality", "Interest Points", "Motion Blur", "Object Recognition", "Performance Measure", "Quantitative Evaluation", "Real-time Visualization", "Video Streaming", "visual odometry", "Visual Tracking", "Ground Truth"], "p": ["http://www.springerlink.com/content/k062m660066wl2j6", "http://www.springerlink.com/index/k062m660066wl2j6.pdf"], "t": "Evaluation of Interest Point Detectors and Feature Descriptors for Visual Tracking", "v": "IJCV", "y": 2011, "rn": 89}, {"a": ["Jonathan Balzer", "Sebastian Holer", "Jurgen Beyerer"], "b": "In deflectometry, the shape of mirror objects is recovered from distorted images of a calibrated scene. While remarkably high accuracies are achievable, state-of-the-art methods suffer from two distinct weaknesses: First, for mainly constructive reasons, these can only capture a few square centimeters of surface area at once. Second, reconstructions are ambiguous i.e. infinitely many surfaces lead to the same visual", "cn": 1, "i": 51107960, "k": ["Surface Area"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995346", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995346"], "t": "Multiview specular stereo reconstruction of large mirror surfaces", "v": "CVPR", "y": 2011, "rn": 17}, {"a": ["Tianfan Xue", "Jianzhuang Liu", "Xiaoou Tang"], "b": "Recovering 3D geometry from a single view of an object is an important and challenging problem in computer vision. Previous methods mainly focus on one specific class of objects without large topological changes, such as cars, faces, or human bodies. In this paper, we propose a novel single view reconstruction algorithm for symmetric piecewise planar objects that are not restricted", "cn": 1, "i": 51108017, "k": ["3d reconstruction", "Computer Vision", "Depth Map", "Human Body", "Object Reconstruction", "Reconstruction Algorithm", "Search Space", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995405", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995405"], "t": "Symmetric piecewise planar object reconstruction from a single image", "v": "CVPR", "y": 2011, "rn": 26}, {"a": ["Richard Newcombe", "Shahram Izadi", "Otmar Hilliges", "David Molyneaux", "David Kim", "Andrew Davison", "Pushmeet Kohli", "Jamie Shotton", "Steve Hodges", "Andrew Fitzgibbon"], "b": "We present a system for accurate real-time mapping of complex and arbitrary indoor scenes in variable lighting conditions, using only a moving low-cost depth camera and commodity graphics hardware. We fuse all of the depth data streamed from a Kinect sensor into a single global implicit surface model of the observed scene in real-time. The current sensor pose is simultaneously", "cn": 1, "i": 56925025, "k": ["Augmented Reality", "Computer Vision", "Data Stream", "Graphics Hardware", "Image Reconstruction", "Implicit Surface", "Iterative Closest Point", "Natural Scenes", "Simultaneous Localization and Mapping", "Surface Model", "Surface Reconstruction", "System Modelling", "Three Dimensional", "Iterative Closest Point Algorithm", "Level of Detail", "Real Time", "Real Time Systems"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06092378", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6092378", "http://research.microsoft.com/apps/pubs/default.aspx?id=155378", "http://research.microsoft.com/pubs/155378/ismar2011.pdf"], "t": "KinectFusion: Real-time dense surface mapping and tracking", "v": "ISMAR", "y": 2011, "rn": 28}, {"a": ["Thayne Coffman", "Alan Bovik"], "b": "We present an efficient method that computes dense stereo correspondences by stochastically sampling match quality values. Nonexhaustive sampling facilitates the use of quality metrics that take unique values at noninteger disparities. Depth estimates are iteratively refined with a stochastic cooperative search by perturbing the estimates, sampling match quality, and reweighting and aggregating the perturbations. The approach gains significant efficiencies when", "cn": 1, "i": 13332484, "k": ["Computational Geometry", "Depth Estimation", "Iterative Refinement", "Quality Evaluation", "Quality Metric", "Recursive Estimation", "Simulated Annealing", "Stereo Vision", "Stochastic Approximation"], "p": ["http://dx.doi.org/10.1109/TIP.2009.2035002", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05290144", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290144", "http://www.informatik.uni-trier.de/~ley/db/journals/tip/tip19.html#CoffmanB10", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5290144"], "t": "Efficient Stereoscopic Ranging via Stochastic Sampling of Match Quality", "v": "", "y": 2010, "rn": 26}, {"a": ["Kalin Kolev", "Thomas Pock", "Daniel Cremers"], "b": "\n In this work the weighted minimal surface model traditionally used in multiview stereo is revisited. We propose to generalize\n the classical photoconsistency-weighted minimal surface approach by means of an anisotropic metric which allows to integrate\n a specified surface orientation into the optimization process. In contrast to the conventional isotropic case, where all spatial\n directions are treated equally, the anisotropic metric", "cn": 1, "i": 13994810, "k": ["Convex Relaxation", "Image Sequence", "Minimal Surface", "primal-dual algorithm", "Saddle Point Problem"], "p": ["http://www.springerlink.com/index/j00433h8674734h8.pdf", "http://www.springerlink.com/content/j00433h8674734h8", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-3.html#KolevPC10", "http://dx.doi.org/10.1007/978-3-642-15558-1_39"], "t": "Anisotropic Minimal Surfaces Integrating Photoconsistency and Normal Information for Multiview Stereo", "v": "ECCV", "y": 2010, "rn": 22}, {"a": ["Arnav Bhavsar", "A. Rajagopalan"], "b": "Under stereo settings, the twin problems of image superresolution (SR) and high-resolution (HR) depth estimation are intertwined. The subpixel registration information required for image superresolution is tightly coupled to the 3D structure. The effects of parallax and pixel averaging (inherent in the downsampling process) preclude a priori estimation of pixel motion for superresolution. These factors also compound the correspondence problem", "cn": 1, "i": 14002093, "k": ["3d structure", "a priori estimate", "Correspondence Problem", "Depth Estimation", "Graph Cut", "High Resolution", "Integrated Approach", "Resolution Enhancement", "Low Resolution", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05444875", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5444875", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5444875", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami32.html#BhavsarR10", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2010.90"], "t": "Resolution Enhancement in Multi-Image Stereo", "v": "PAMI", "y": 2010, "rn": 31}, {"a": ["Derek Bradley", "Wolfgang Heidrich"], "b": "Reprojection error is a commonly used measure for comparing the quality of different camera calibrations, for example when choosing the best calibration from a set. While this measure is suitable for single cameras, we show that we can improve calibrations in a binocular or multi-camera setup by calibrating the cameras in pairs using a rectification error. The rectification error determines", "cn": 1, "i": 50891556, "k": ["Camera Calibration"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05479186", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5479186"], "t": "Binocular Camera Calibration Using Rectification Error", "v": "CRV", "y": 2010, "rn": 20}, {"a": ["Changhai Xu", "Benjamin Kuipers"], "b": "An intelligent agent, embedded in the physical world, will receive a high-dimensional ongoing stream of low-level sensory input. In order to understand and manipulate the world, the agent must be capable of learning high-level concepts. Object is one such concept. We are developing the Object Semantic Hierarchy (OSH), which consists of multiple representations with different ontologies. The OSH factors the", "cn": 1, "i": 50943112, "k": ["3d model", "High Dimensionality", "Intelligent Agent", "Multiple Representation", "Object Model", "Object Perception", "Object Representation", "Stochastic Model"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5578869", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05578869"], "t": "Towards the Object Semantic Hierarchy", "v": "ICDL", "y": 2010, "rn": 32}, {"a": ["Kush Varshney", "Nikos Paragios", "Jean-Francois Deux", "Alain Kulski", "Remy Raymond", "Phillipe Hernigou", "Alain Rahmouni"], "b": "Arthroplasty, the implantation of prostheses into joints, is a surgical procedure that is affecting a larger and larger number of patients over time. As a result, it is increasingly important to develop imaging techniques to non-invasively examine joints with prostheses after surgery, both statically and dynamically in 3-D. The static problem is considered here, with the aim to create a", "cn": 1, "i": 6154996, "k": ["Active Contour", "Indexing Terms", "Level Set", "multi-view stereo", "Multiple Views", "Shape Modeling", "Surgical Procedure", "X Rays", "X-ray Imaging", "Level Set Method"], "p": ["http://web.mit.edu/krv/www/pubs/VarshneyPDKRHR_tmi2009.pdf", "http://vision.mas.ecp.fr/pub/tmi08.pdf", "http://projects.csail.mit.edu/atemuri/wiki/images/2/28/VarshneyPDKRHR_tmi2008.pdf", "http://www.mas.ecp.fr/vision/Personnel/nikos/pub/tmi08.pdf", "http://www.mit.edu/~krv/pubs/VarshneyPDKRHR_tmi2009.pdf", "http://projects.csail.mit.edu/atemuri/wiki/images/2/2d/VarshneyPDKRHR_tmi2009.pdf"], "t": "Post-Arthroplasty Examination Using X-Ray Images", "y": 2009, "rn": 29}, {"a": ["J. Hullo", "P. Grussenmeyer", "S. Fares"], "b": "Since a couple of years, several commercial solutions of dense stereo matching have been developed. This process offers a really cheap, flexible and accurate solution to get 3D point clouds and textured models. The calibration of the camera allows a subpixellar correlation for correctly textured objects. In order to define the limits of such a process for cultural heritage applications,", "cn": 1, "i": 6770254, "k": ["3d point cloud", "Cultural Heritage", "Digital Elevation Model", "High Resolution Imager", "Laser Scanning", "Point Cloud", "Saudi Arabia", "Stereo Matching"], "p": ["http://cipa.icomos.org/fileadmin/papers/Kyoto2009/132-1.pdf?PHPSESSID=60c7a6cde09594d41fda85f22d33b903", "http://sites.google.com/site/jfhullophd/documents/Kyoto_132-1.pdf?attredirects=0"], "t": "PHOTOGRAMMETRY AND DENSE STEREO MATCHING APPROACH APPLIED TO THE DOCUMENTATION OF THE CULTURAL HERITAGE SITE OF KILWA (SAUDI ARABIA)", "y": 2009, "rn": 10}, {"a": ["Ke Zheng", "R. Colburn", "Aseem Agarwala", "Maneesh Agrawala", "David Salesin", "Brian Curless", "Michael Cohen"], "b": "This paper presents an approach to render novel views from input photographs, a task which is commonly referred to as image based rendering. We first compute dense view dependent depthmaps us- ing consistent segmentation. This method jointly computes multi- view stereo and segments input photographs while accounting for mixed pixels (matting). We take the images with depth as our input", "cn": 1, "i": 10591238, "k": ["Image Based Rendering", "multi-view stereo"], "p": ["http://grail.cs.washington.edu/projects/parallax/tr090302.pdf"], "t": "A Consistent Segmentation Approach to Image-based Rendering", "y": 2009, "rn": 19}, {"a": ["Cedric Cagniart", "CAMP Munich", "Edmond Boyer", "INRIA Grenoble", "Slobdodan Ilic"], "b": "In this paper we present a new method to capture the temporal evolution of a surface from multiple videos. By contrast to most current methods, we introduce an algo- rithm that uses no prior of the nature of tracked surface. In addition, it does not require sparse features to constrain the deformation but only relies on strictly geometric infor- mation", "cn": 1, "i": 13150462, "k": ["Large Deformation", "Mesh Deformation", "Reference Model", "Iterative Closest Point Algorithm"], "p": ["http://perception.inrialpes.fr/people/Boyer/Publications/3dim09.pdf"], "t": "Iterative Mesh Deformation for Dense Surface Tracking", "y": 2009, "rn": 16}, {"a": ["Daniel Aliaga", "Ji Zhang", "Mireille Boutin"], "b": "Many applications in computer graphics require detailed 3D digital models of real-world environments. The automatic and semi-automatic modeling of such spaces presents several fundamental challenges. In this work, we present an easy and robust camera-based acquisition approach for the modeling of 3D scenes which is a significant departure from current methods. Our approach uses a novel pose-free formulation for 3D", "cn": 1, "i": 13334213, "k": ["3d reconstruction", "Computer Graphic", "Image Based Rendering", "Texture Mapping"], "p": ["http://portal.acm.org/citation.cfm?doid=1640443.1640450", "http://portal.acm.org/citation.cfm?id=1640450", "http://portal.acm.org/ft_gateway.cfm?id=1640450&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1640443.1640450", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog29.html#AliagaZB09"], "t": "A framework for modeling 3D scenes using pose-free equations", "v": "TOG", "y": 2009, "rn": 33}, {"a": ["M. Gerke"], "b": "An increasing number of airborne image acquisition systems being equipped with multiple small- or medium size frame cameras are operational. The cameras normally cover different viewing directions. In contrast to vertical images, those oblique images have some specific properties, like a significantly varying image scale, and more occlusion through high raising objects, like buildings. However, the faces of buildings and", "cn": 1, "i": 13621943, "k": ["3d point cloud", "High Resolution", "Image Acquisition", "Noise Reduction", "Point Cloud", "Reference Point", "and Forward"], "p": ["http://www.isprs.org/proceedings/xxxviii/3-w4/pub/cmrt09_gerke.pdf"], "t": "DENSE MA TCHING IN HIGH RESOLUTION OBLIQUE AIRBORNE IMAGES", "y": 2009, "rn": 12}, {"a": ["B. Micusik", "J. Kosecka"], "b": "City environments often lack textured areas, contain repetitive structures, strong lighting changes and therefore are very difficult for standard 3D modeling pipelines. We present a novel unified framework for creating 3D city models which overcomes these difficulties by exploiting image segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. Given panoramic street view sequences, we", "cn": 1, "i": 50782794, "k": ["3d city model", "3d model", "3d reconstruction", "Bundle Adjustment", "Image Segmentation", "kd tree", "multi-view stereo", "Urban Environment"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206535", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206535"], "t": "Piecewise planar city 3D modeling from street view panoramic sequences", "v": "CVPR", "y": 2009, "rn": 19}, {"a": ["Guillaume Walck", "Michel Drouin"], "b": "This paper presents a complete 3D-reconstruction method optimized for online object modeling in the context of object grasping by a robot hand. The proposed solution is based on images captured by an eye-in-hand camera mounted on the robot arm and is an original combination of classical but simplified reconstruction methods. The different techniques used form a process that offers fast,", "cn": 1, "i": 50861541, "k": ["3d reconstruction", "Object Model", "Robot Arm", "Robot Hand"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05420748", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5420748"], "t": "Progressive 3D reconstruction of unknown objects using one eye-in-hand camera", "v": "ROBIO", "y": 2009, "rn": 23}, {"a": ["Vivek Kwatra", "Philippos Mordohai", "Rahul Narain", "Sashi Penta", "Mark Carlson", "Marc Pollefeys", "Ming Lin"], "b": "We present a technique for coupling simulated fluid phenomena that interact with real dynamic scenes captured as a binocular video sequence. We first process the binocular video sequence to obtain a complete 3D reconstruc- tion of the scene, including velocity information. We use stereo for the visible parts of 3D geometry and surface completion to fill the missing regions. We", "cn": 1, "i": 4362927, "k": ["Boundary Condition", "Dynamic Geometry", "Dynamic Scenes", "Fluid Simulation", "Optical Flow"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/cgf/cgf27.html#KwatraMNPCPL08", "http://dx.doi.org/10.1111/j.1467-8659.2008.01146.x", "http://www.blackwell-synergy.com/doi/abs/10.1111/j.1467-8659.2008.01146.x"], "t": "Fluid in Video: Augmenting Real Video with Simulated Fluids", "v": "CGF", "y": 2008, "rn": 40}, {"a": ["Oliver Tonet", "Francesco Focacci", "Marco Piccigallo", "Lorenza Mattei", "Claudio Quaglia", "Giuseppe Megali", "Barbara Mazzolai", "Paolo Dario"], "b": "", "cn": 1, "i": 4434513, "k": ["Augmented Reality", "High Resolution", "Robot Vision"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4456758", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04456758", "http://dx.doi.org/10.1109/TRO.2008.915430", "http://www.informatik.uni-trier.de/~ley/db/journals/trob/trob24.html#TonetFPMQMMD08"], "t": "Bio-inspired robotic dual-camera system for high-resolution vision", "v": "TRob", "y": 2008, "rn": 19}, {"a": ["M Shah"], "b": "", "cn": 1, "i": 4704669, "k": [], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587700", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587700", "http://longwood.cs.ucf.edu/~vision/papers/cvpr2008/6.pdf", "http://server.cs.ucf.edu/~vision/papers/cvpr2008/6.pdf", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/360.pdf", "http://dx.doi.org/10.1109/CVPR.2008.4587700", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#KhanS08"], "t": "Reconstructing non-stationary articulated objects in monocular video using silhouette information", "v": "CVPR", "y": 2008, "rn": 24}, {"a": ["Daniel Chen", "Brenden Chen", "George Mamic", "Clinton Fookes", "Sridha Sridharan"], "b": "Semi-automatic segmentation of still images has vast and varied practical applications. Recently, an approach \"GrabCut\" has managed to successfully build upon earlier approaches based on colour and gradient information in order to address the problem of efficient extraction of a foreground object in a complex environment. In this paper, we extend the GrabCut algorithm further by applying an unsupervised algorithm", "cn": 1, "i": 4705538, "k": ["Automatic Segmentation", "Gaussian Mixture"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4699997", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04699997", "http://dx.doi.org/10.1109/DICTA.2008.68", "http://www.informatik.uni-trier.de/~ley/db/conf/dicta/dicta2008.html#ChenCMFS08"], "t": "Improved GrabCut Segmentation via GMM Optimisation", "v": "DICTA", "y": 2008, "rn": 9}, {"a": ["Gabriel Taubin", "Daniel Crispell", "Douglas Lanman", "Peter Sibley", "Yong Zhao"], "b": "We propose a new primal-dual framework for representation, capture, processing, and display of piecewise smooth surfaces,\n where the dual space is the space of oriented 3D lines, or rays, as opposed to the traditional dual space of planes. An image capture process detects points on a depth discontinuity sweep\n from a camera moving with respect to an object, or from", "cn": 1, "i": 4751392, "k": ["Data Acquisition", "Dual Space", "Moving Object", "piecewise smooth", "Point Cloud", "Shape From Silhouette", "Variational Approach", "Time Dependent"], "p": ["http://www.springerlink.com/content/y40435022lg4337j", "http://www.springerlink.com/index/y40435022lg4337j.pdf", "http://dx.doi.org/10.1007/978-3-642-00826-9_9", "http://www.informatik.uni-trier.de/~ley/db/conf/etvc/etvc2008.html#TaubinCLSZ08"], "t": "Shape from Depth Discontinuities", "y": 2008, "rn": 29}, {"a": ["Yilei Zhang", "Minglun Gong", "Yee-hong Yang"], "b": "This paper presents a real-time multi-view stereo algorithm, which is based on local winner-take-all optimization. When computing the disparity maps for a given view, the algorithm performs 3 steps: cost volume generation, cost volume merging, and disparity selection. The main focus of this paper is on the second step and a new cost volume merging method is proposed, which combines", "cn": 1, "i": 6367972, "k": ["multi-view stereo", "Winner Take All", "Real Time"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CRV.2008.41", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4562101", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04562101", "http://www.informatik.uni-trier.de/~ley/db/conf/crv/crv2008.html#ZhangGY08"], "t": "Real-time Multi-view Stereo Algorithm using Adaptive-weight Parzen Window and Local Winner-take-all Optimization", "v": "CRV", "y": 2008, "rn": 14}, {"a": ["Daniel Vlasic", "Ilya Baran", "Wojciech Matusik", "Jovan Popovi\u0107"], "b": "Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work, we demonstrate a practical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video images that record a human performance from multiple viewpoints and an articulated template of the performer, our system captures the motion", "cn": 1, "i": 39243842, "k": ["Deformable Model", "Human Performance", "Motion Capture", "Software Systems", "Video Recording", "Visual Quality"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1360696&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1360696"], "t": "Articulated mesh animation from multi-view silhouettes", "v": "SIGGRAPH", "y": 2008, "rn": 40}, {"a": ["Y. Chan", "P. Delmas", "G. Gimel'farb", "R. Valkenburg"], "b": "The paper discusses initial steps towards efficient digital 3D modelling of a natural scene by fusing 3D range data from an active hand-held laser scanner and complementary passive stereo data from stereo pairs of images of the scene. The latter are formed by rectifying successive video frames captured by a calibrated built-in video camera of the scanner. Range data constrain", "cn": 1, "i": 50723865, "k": ["3d modelling", "Error Correction", "Error Detection", "Laser Scanner", "Natural Scenes", "Range Data", "Data Fusion", "Error Detection and Correction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04762128", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4762128"], "t": "On fusion of active range data and passive stereo data for 3D scene modelling", "v": "IVCNZ", "y": 2008, "rn": 6}, {"a": ["Adrien Auclair", "Laurent Cohen", "Nicole Vincent"], "b": "Computing high quality 3D models from multi-view stereo reconstruction is an active topic as can be seen in a recent review (15). Most approaches make the strong assumption that the surface is Lam- bertian. In the case of a car, this hypothesis is not satised. Cars contain transparent parts and metallic surfaces that are highly reective. To face these diculties,", "cn": 1, "i": 2470297, "k": ["3d model", "Feature Tracking", "Metallic Surface", "multi-view stereo", "Structure From Motion", "Surface Fitting", "Vanishing Point"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/scia/scia2007.html#AuclairCV07", "http://www.springerlink.com/content/t7j0jp5671218742", "http://www.springerlink.com/index/t7j0jp5671218742.pdf", "http://dx.doi.org/10.1007/978-3-540-73040-8_19", "http://www.ceremade.dauphine.fr/~cohen/mypapers/auclairSCIA07.pdf"], "t": "A Robust Approach for 3D Cars Reconstruction", "v": "", "y": 2007, "rn": 20}, {"a": ["Paul Merrell", "Philippos Mordohai", "Jan-michael Frahm", "Marc Pollefeys"], "b": "We present an evaluation methodology and data for large scale video-based 3D reconstruction. We evaluate the effects of several parameters and draw conclusions that can be useful for practical systems operating in uncon- trolled environments Unlike the benchmark datasets used for the binocular stereo and multi-view reconstruction eval- uations, which were collected under well-controlled condi- tions, our datasets are captured", "cn": 1, "i": 4271273, "k": ["3d reconstruction", "Depth Map", "Evaluation Methodology", "Large Scale", "Scene Reconstruction", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04409218", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4409218", "http://www.inf.ethz.ch/personal/pomarc/pubs/MerrellVRML07", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#MerrellMFP07", "http://www.cs.stevens.edu/~mordohai/public/Merrell_EvaluationLargeScaleReconstruction07.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4409218", "http://www.cs.unc.edu/~jmf/publications/vrml_merrell_mordohai_frahm_pollefeys.pdf"], "t": "Evaluation of Large Scale Scene Reconstruction", "v": "ICCV", "y": 2007, "rn": 18}, {"a": ["Philippe Lambert", "Jean-daniel Desch\u00eanes", "Patrick H\u00e9bert"], "b": "This paper adopts a sampling perspective to surface light field modeling. This perspective eliminates the need of us- ing the actual object surface in the surface light field defini- tion. Instead, the surface ought to provide only a parame- terization of the surface light field function that specifically reduces aliasing artifacts visible at rendering. To find that surface, we propose", "cn": 1, "i": 5142384, "k": ["Angular Distribution", "Light Field", "multi-view stereo", "Reflection Model"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2007.html#LambertDH07", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4296738", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04296738", "http://vision.gel.ulaval.ca/~hebert/pdf/Lambert07.pdf", "http://vision.gel.ulaval.ca/~plambert/publications/id698_3dim2007.pdf", "http://dx.doi.org/10.1109/3DIM.2007.6"], "t": "A Sampling Criterion for Optimizing a Surface Light Field", "v": "3DIM", "y": 2007, "rn": 22}, {"a": ["Andrei Zaharescu", "Edmond Boyer", "Radu Horaud"], "b": "Triangulated meshes have become ubiquitous discrete surface representations. In this paper, we address the problem of how to maintain the manifold properties of a surface while it undergoes strong deformations that may cause topological changes. We introduce a new self-intersection removal algorithm, TransforMesh, and propose a mesh evolution framework based on this algorithm. Numerous shape modeling applications use surface evolution", "cn": 0, "i": 14373860, "k": ["3d reconstruction", "Adaptive Mesh", "Computer Vision", "Deformable Objects", "Image Reconstruction", "Level Set", "Rough Surface", "Shape Modeling", "Smoothing Method", "Surface Model", "Surface Reconstruction", "Surface Representation", "Surface Roughness", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05482586", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5482586", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5482586", "http://dx.doi.org/10.1109/TPAMI.2010.116", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami33.html#ZaharescuBH11"], "t": "Topology-Adaptive Mesh Deformation for Surface Evolution, Morphing, and Multiview Reconstruction", "v": "PAMI", "y": 2011, "rn": 54}, {"a": ["Jui-Chiu Chiang", "Wei-Chih Chen", "Lien-Ming Liu", "Kuo-Feng Hsu", "Wen-Nung Lie"], "b": "Stereo video, targeting at matching what the humans see in the real world, offers depth perception on observed scenes. The problem of compressing such a huge amount of video data has received considerable attention in the past few years. Its chal- lenge comes from the much more complicated parameter selection (e.g., mode decision) process than single-channel video coding. To cope", "cn": 0, "i": 27101098, "k": ["Depth Perception", "Fast Motion Estimation", "Mode Decision", "Motion Estimation", "Parameter Selection", "Single Channel", "Three Dimensional", "Transform Coding", "Video Coding", "Video Compression", "Voltage Control", "Digital Multimedia Broadcasting", "Forward Backward"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5549872", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5549872", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05549872", "http://adsabs.harvard.edu/abs/2011ISTSP...5..309C"], "t": "A Fast H.264/AVC-Based Stereo Video Encoding Algorithm Based on Hierarchical Two-Stage Neural Classification", "v": "IEEE J SEL TOP SIGNAL PROCESS", "y": 2011, "rn": 13}, {"a": ["Jean-Yves Guillemaut", "Adrian Hilton"], "b": "Current state-of-the-art image-based scene reconstruction techniques are capable of generating high-fidelity 3D models when\n used under controlled capture conditions. However, they are often inadequate when used in more challenging environments such\n as sports scenes with moving cameras. Algorithms must be able to cope with relatively large calibration and segmentation errors\n as well as input images separated by a wide-baseline and", "cn": 0, "i": 39321370, "k": ["3d model", "Energy Function", "Experimental Evaluation", "Graph Cut", "Multiple Views", "Scene Reconstruction", "Free Viewpoint Video"], "p": ["http://www.springerlink.com/index/a070542517610153.pdf", "http://www.springerlink.com/content/a070542517610153", "http://dx.doi.org/10.1007/s11263-010-0413-z", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv93.html#GuillemautH11"], "t": "Joint Multi-Layer Segmentation and Reconstruction for Free-Viewpoint Video Applications", "v": "IJCV", "y": 2011, "rn": 75}, {"a": ["Daniel Cremers", "Kalin Kolev"], "b": "We propose a convex formulation for silhouette and stereo fusion in 3D reconstruction from multiple images. The key idea is to show that the reconstruction problem can be cast as one of minimizing a convex functional, where the exact silhouette consistency is imposed as convex constraints that restrict the domain of feasible functions. As a consequence, we can retain the", "cn": 0, "i": 39327348, "k": ["3d reconstruction", "Convex Domain", "Convex Function", "Convex Optimization", "Convex Relaxation", "Cost Function", "Efficient Algorithm", "Image Reconstruction", "image-based modeling", "Numerical Scheme", "Optimal Solution", "Parallel Implementation", "Shape Optimization", "Surface Area", "Surface Reconstruction", "Projection Onto Convex Sets", "Time Dependent"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05567114", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5567114", "http://dx.doi.org/10.1109/TPAMI.2010.174", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami33.html#CremersK11"], "t": "Multiview Stereo and Silhouette Consistency via Convex Functionals over Convex Domains", "v": "PAMI", "y": 2011, "rn": 30}, {"a": ["Kun Li", "Qionghai Dai", "Wenli Xu"], "b": "We propose a new markerless shape and motion capture approach from multiview video sequences. The shape recovery method consists of two steps: separating and merging. In the separating step, the depth map represented with a point cloud for each view is generated by solving a proposed variational model, which is regularized by four constraints to ensure the accuracy and completeness", "cn": 0, "i": 39329671, "k": ["Computer Model", "Depth Map", "Image Reconstruction", "Marching Cube", "Mesh Deformation", "Motion Capture", "Point Cloud", "Shape Recovery", "Solid Modeling", "Three Dimensional", "Variational Models"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05688302", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5688302", "http://dx.doi.org/10.1109/TCSVT.2011.2106251", "http://www.informatik.uni-trier.de/~ley/db/journals/tcsv/tcsv21.html#LiDX11"], "t": "Markerless Shape and Motion Capture From Multiview Video Sequences", "v": "TCSV", "y": 2011, "rn": 52}, {"a": ["S. Mirkamali", "P. Nagabhushan"], "b": " 3D modeling is an emerging trend both in the areas of machine vision and computer graphics. With the current 3D modeling systems the user can virtually travel around a scene and see the foreground objects. A D model would be more realistic if the user could also go into the depth of a scene from a specific view and see", "cn": 0, "i": 48014765, "k": ["3d model", "Computer Graphic", "Machine Vision"], "p": ["http://www.springerlink.com/index/37334474x6196ljt.pdf", "http://www.springerlink.com/content/37334474x6196ljt"], "t": "Depth-Wise Multi-layered 3D Modeling", "y": 2011, "rn": 24}, {"a": ["Kihwan Kim", "Sangmin Oh", "Jeonggyu Lee", "Irfan Essa"], "b": "We introduce methods for augmenting aerial visualizations of Earth (from tools such as Google Earth or Microsoft Virtual Earth) with dynamic information obtained from videos. Our goal is to make Augmented Earth Maps that visualize plausible live views of dynamic scenes in a city. We propose different approaches to analyze videos of pedestrians\n and cars in real situations, under differing", "cn": 0, "i": 48790956, "k": ["Dynamic Content", "Dynamic Information", "Dynamic Scenes", "Google Earth", "Missing Data", "Real-time Visualization", "Traffic Flow"], "p": ["http://www.springerlink.com/index/02q63031373n5445.pdf", "http://www.springerlink.com/content/02q63031373n5445"], "t": "Augmenting aerial earth maps with dynamic information from videos", "v": "", "y": 2011, "rn": 34}, {"a": ["Sebastian Lieberknecht", "Selim Benhimane", "Peter Meier", "Nassir Navab"], "b": "For natural interaction with augmented reality (AR) applications, good tracking technology is key. But unlike dense stereo,\n optical flow or multi-view stereo, template-based tracking which is most commonly used for AR applications lacks benchmark\n datasets allowing a fair comparison between state-of-the-art algorithms. Until now, in order to evaluate objectively and quantitatively\n the performance and the robustness of template-based tracking algorithms,", "cn": 0, "i": 48804184, "k": ["Augmented Reality", "Camera Motion", "Computer Vision", "Critical Parameter", "Image Sequence", "multi-view stereo", "Natural Interaction", "Object Detection", "Ground Truth", "Optical Flow"], "p": ["http://www.springerlink.com/content/a762158w86694220", "http://www.springerlink.com/index/a762158w86694220.pdf"], "t": "Benchmarking template-based tracking algorithms", "v": "", "y": 2011, "rn": 19}, {"a": ["Gabriel Brostow", "Carlos Hernandez", "George Vogiatzis", "Bjorn Stenger", "Roberto Cipolla"], "b": "", "cn": 0, "i": 48874089, "k": ["Image Color Analysis", "Photometric Stereo", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05719620", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5719620", "http://www.cs.ucl.ac.uk/staff/g.brostow/tmp/TPAMI-2010-04-0236-1.pdf"], "t": "Video Normals from Colored Lights", "v": "PAMI", "y": 2011, "rn": 65}, {"a": ["Edmond Boyer", "INRIA Rh", "Jean-sebastien Franco"], "b": "We present a novel probabilistic framework for rigid tracking and segmentation of shapes observed from multiple cameras. Most existing methods have focused on solving each of these problems individually, segmenting the shape assuming surface registration is solved, or conversely per- forming surface registration assuming shape segmentation or kinematic structure is known. We assume no prior kine- matic or registration knowledge", "cn": 0, "i": 48962411, "k": ["ex pectation maximization", "On The Fly"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995440", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995440", "http://hal.inria.fr/inria-00583131/PDF/paper541.pdf"], "t": "Learning Temporally Consistent Rigidities", "v": "CVPR", "y": 2011, "rn": 17}, {"a": ["Samuel Yang", "Guoan Zheng", "Seung Lee", "Changhuei Yang"], "b": "", "cn": 0, "i": 51034286, "k": ["Image Reconstruction", "Image Resolution", "Three Dimensional", "system on a chip"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5730062", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05730062"], "t": "Stereoscopic optofluidic on-chip microscope", "v": "IEEE/LEOS", "y": 2011, "rn": 4}, {"a": ["Jiawen Chen", "Sylvain Paris", "Jue Wang", "Wojciech Matusik", "Michael Cohen", "Fredo Durand"], "b": "This paper introduces the video mesh, a data structure for representing video as 2.5D \u201cpaper cutouts.\u201d The video mesh allows interactive editing of moving objects and modeling of depth, which enables 3D effects and post-exposure camera control. The video mesh sparsely encodes optical \ufffdow as well as depth, and handles occlusion using local layering and alpha mattes. Motion is described", "cn": 0, "i": 51040909, "k": ["Camera Control", "Computer Graphic", "Data Structure", "Moving Object", "Three Dimensional", "Video Editing"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5753118", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05753118"], "t": "The video mesh: A data structure for image-based three-dimensional video editing", "v": "ICCP", "y": 2011, "rn": 31}, {"a": ["Shuai Mu", "Chenxi Wang", "Ming Liu", "Dongdong Li", "Maohua Zhu", "Xiaoliang Chen", "Xiang Xie", "Yangdong Deng"], "b": "", "cn": 0, "i": 51042359, "k": ["Digital Signal Processing", "Embedded Computing", "Graphic Processing Unit", "Graphics Processors", "High Performance", "Parallel Computer", "Parallel Processing"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05763120", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5763120"], "t": "Evaluating the potential of graphics processors for high performance embedded computing", "y": 2011, "rn": 12}, {"a": ["Yanjun Qian", "Qionghai Dai", "Guihua Er"], "b": "Generating a polygonal mesh model from the point cloud is a critical step of many state-of-art MVS reconstruction algorithms, and influences the accuracy and visual quality of the final results significantly. The normal estimation and position adjustment of each point is required for this procedure. We present a mathematical analysis of the normal estimation approach, and propose two hypotheses to", "cn": 0, "i": 51059509, "k": ["Image Reconstruction", "Mathematical Analysis", "Mathematical Model", "Point Cloud", "Polygonal Meshes", "Principal Component Analysis", "Reconstruction Algorithm", "Surface Reconstruction", "Visual Quality"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5877161", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05877161"], "t": "Self-adaptive normal estimation and position adjustment for MVS reconstruction", "v": "DTV-CON", "y": 2011, "rn": 7}, {"a": ["C. Wang", "Z. Zhu", "S. Chan", "H. Shum"], "b": "This paper proposes a system for photorealistic interactive rendering of ancient Chinese artifacts for cultural heritage preservation using multiview images captured by a circular multiple-camera array. It employs 3D reconstruction and precomputed shadow field techniques to enable real-time relighting and object interaction. Moreover, Gabor features are employed to improve the robustness of line matching along epipolar lines and robust radial", "cn": 0, "i": 51067192, "k": ["3d model", "3d reconstruction", "Computer Graphic", "Computer Model", "Cultural Heritage", "Graphic Processing Unit", "Image Based Rendering", "Image Reconstruction", "Interactive Rendering", "Object Interaction", "Radial Basis Function", "Real Time Rendering", "Three Dimensional", "Real Time", "Real Time Systems"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05938187", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5938187"], "t": "Realistic and interactive image-based rendering of ancient chinese artifacts using a multiple camera array", "v": "ISCAS", "y": 2011, "rn": 15}, {"a": ["Christian Unger", "Eric Wahl", "Slobodan Ilic"], "b": "In vehicular applications based on motion-stereo using monocular side-looking cameras, pairs of images must usually be rectified very well, to allow the application of dense stereo methods. But also long-term installations of stereo rigs in vehicles require approaches that cope with the decalibration of the cameras. The need for such methods is further underlined by the fact that offline camera", "cn": 0, "i": 51067903, "k": ["Camera Calibration", "High Efficiency", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5940439", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05940439"], "t": "Efficient stereo matching for moving cameras and decalibrated rigs", "v": "IV", "y": 2011, "rn": 24}, {"a": ["Min Sun", "Shyam Kumar", "Gary Bradski", "Silvio Savarese"], "b": "", "cn": 0, "i": 51080315, "k": ["3d model", "3d reconstruction", "Design Automation", "Image Reconstruction", "Object Model", "Solid Modeling", "Surface Texture", "Three Dimensional", "Iterative Closest Point Algorithm"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955337", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955337"], "t": "Toward Automatic 3D Generic Object Modeling from One Single Image", "v": "3DIMPVT", "y": 2011, "rn": 38}, {"a": ["Ran Song", "Yonghuai Liu", "Ralph Martin", "Paul Rosin"], "b": "We propose a novel method based on higher order Conditional Random Field (CRF) for reconstructing surface models from multi-view data sets. This method is automatic and robust to inevitable scanning noise and registration errors involved in the stages of data acquisition and registration. By incorporating the information within the input data sets into the energy function more sufficiently than existing", "cn": 0, "i": 51080334, "k": ["Belief Propagation", "Computational Complexity", "Conditional Random Field", "Data Acquisition", "Data Model", "Energy Function", "Image Reconstruction", "Spatial Relation", "Surface Model", "Surface Reconstruction", "Three Dimensional", "Higher Order"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955356", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955356"], "t": "Higher Order CRF for Surface Reconstruction from Multi-view Data Sets", "v": "3DIMPVT", "y": 2011, "rn": 27}, {"a": ["Chris Budd", "Peng Huang", "Adrian Hilton"], "b": "In this paper we present a novel approach for temporal alignment of reconstructed mesh sequences with non-rigid surfaces to obtain a consistent representation. We propose a hierarchical scheme for non-sequential matching of frames across the sequence using shape similarity. This gives a tree structure which represents the optimal path for alignment of each frame in the sequence to minimize the", "cn": 0, "i": 51080336, "k": ["3d video", "Laplace Equation", "Optimal Path", "Shape Matching", "Shape Similarity", "Surface Fitting", "Surface Reconstruction", "Temporal Coherence", "Three Dimensional", "Tree Structure"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955358", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955358"], "t": "Hierarchical Shape Matching for Temporally Consistent 3D Video", "v": "3DIMPVT", "y": 2011, "rn": 14}, {"a": ["Michael Weinmann", "Christopher Schwartz", "Roland Ruiters", "Reinhard Klein"], "b": "In this work, we present a framework for multi- camera, multi-projector object acquisition based on structured light. This approach allows the reconstruction of an object without moving either the object or the acquisition setup, avoiding any registration of independent measurements. To overcome the resolution limitations of the individual projectors, we introduce a novel super-resolution scheme. By exploiting high dynamic range", "cn": 0, "i": 51080365, "k": ["Bundle Adjustment", "High Dynamic Range Imaging", "Image Reconstruction", "Image Resolution", "Point Cloud", "Structured Light", "Super Resolution", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955387", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955387"], "t": "A Multi-camera, Multi-projector Super-Resolution Framework for Structured Light", "v": "3DIMPVT", "y": 2011, "rn": 23}, {"a": ["Alan Brunton", "Jochen Lang", "Eric Dubois", "Chang Shu"], "b": "When reconstructing a specific type or class of object using stereo, we can leverage prior knowledge of the shape of that type of object. A popular class of object to reconstruct is the human face. In this paper we learn a statistical wavelet prior of the shape of the human face and use it to constrain stereo reconstruction within a", "cn": 0, "i": 51081181, "k": ["bayesian framework", "Graphic Processing Unit", "Parameter Space", "Point Cloud", "Prior Knowledge", "Shape Parameter", "Statistical Analysis"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05957581", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5957581"], "t": "Wavelet Model-based Stereo for Fast, Robust Face Reconstruction", "v": "CRV", "y": 2011, "rn": 24}, {"a": ["Avinash Sharma", "Radu Horaud", "Jan Cech", "Edmond Boyer"], "b": "D Shape matching is an important problem in computer vision. One of the major difficulties in finding dense corre- spondences between 3D shapes is related to the topological discrepancies that often arise due to complex kinematic mo- tions. In this paper we propose a shape matching method that is robust to such changes in topology. The algorithm starts from a", "cn": 0, "i": 51108065, "k": ["Computer Vision", "Global Change", "Heat Flow", "Heat Kernel", "Scale Space", "Shape Descriptor", "Shape Matching"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995455", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995455"], "t": "Topologically-robust 3D shape matching based on diffusion geometry and seed growing", "v": "CVPR", "y": 2011, "rn": 27}, {"a": ["Yusuke Yoshiyasu", "Nobutoshi Yamazaki"], "b": "In this paper, we present a novel technique that enables capturing of detailed 3D models from flash photographs integrating shading and silhouette cues. Our main contribution is an optimization framework which not only captures subtle surface details but also handles changes in topology. To incorporate normals estimated from shading, we employ a mesh-based deformable model using deformation gradient. This method", "cn": 0, "i": 51108183, "k": ["3d model", "Deformable Model", "Implicit Surface", "Photometric Stereo"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995576", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995576"], "t": "Topology-adaptive multi-view photometric stereo", "v": "CVPR", "y": 2011, "rn": 27}, {"a": ["Michal Jancosek", "Tomas Pajdla"], "b": "We propose a novel method for the multi-view reconstruction problem. Surfaces which do not have direct support in the input 3D point cloud and hence need not be photo-consistent but represent real parts of the scene (e.g. low-textured walls, windows, cars) are important for achieving complete reconstructions. We augmented the existing Labatut CGF 2009 method with the ability to cope", "cn": 0, "i": 51108298, "k": ["3d point cloud", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995693", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995693"], "t": "Multi-view reconstruction preserving weakly-supported surfaces", "v": "CVPR", "y": 2011, "rn": 6}, {"a": ["Zengtao Jiao", "Tianliang Liu", "Xiuchang Zhu"], "b": "", "cn": 0, "i": 51112116, "k": ["Approximation Method", "Computer Vision", "Depth Map", "Image Reconstruction", "Image Segmentation", "multi-view stereo", "Stereo Vision", "Three Dimensional", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6002119", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06002119"], "t": "Robust piecewise planar stereo with modified segmentation cues in urban scenes", "v": "ICMT", "y": 2011, "rn": 10}, {"a": ["Qing-Qing Yang", "Liang-Hao Wang", "Dong-Xiao Li", "Ming Zhang"], "b": "", "cn": 0, "i": 51117926, "k": ["Bilateral Filtering", "Edge Detection", "Image Resolution"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06005563", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6005563"], "t": "Hierarchical Joint Bilateral Filtering for Depth Post-Processing", "v": "ICIG", "y": 2011, "rn": 19}, {"a": ["Mark Gerrits", "Bert Decker", "Cosmin Ancuti", "Tom Haber", "Codruta Ancuti", "Tom Mertens", "Philippe Bekaert"], "b": "Depth information opens up a lot of possibilities for mean\u00ad ingful editing of photographs. So far, it has only been pos\u00ad sible to acquire depth information by either using additional hardware, restrictive scene assumptions or extensive manual input. We developed a novel user-assisted technique for cre\u00ad ating adequate depth maps with an intuitive stroke-based user interface. Starting from absolute depth", "cn": 0, "i": 51122689, "k": ["Depth Map", "User Interface", "Depth of Field"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06012006", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6012006"], "t": "Stroke-based creation of depth maps", "v": "ICME(ICMCS)", "y": 2011, "rn": 15}, {"a": ["D. Lam", "G. DeSouza"], "b": "In this paper, we present preliminary results towards the development of the Virtual Dermatologist: A 3D image and tactile database for virtual examination of dermatology patients. This system, which can be installed and operated by non- dermatologists in remotes areas where access to a dermatologist is difficult, will enhance and broaden the application of tele- healthcare, and it will greatly", "cn": 0, "i": 51132657, "k": ["3d imaging", "3d model", "General Practitioner", "Haptic Interface", "Malignant Melanoma", "Qualitative Data", "Skin Cancer", "Skin Disease", "Skin Lesion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06026768", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6026768"], "t": "Virtual Dermatologist: An application of 3D modeling to tele-healthcare", "y": 2011, "rn": 29}, {"a": ["Uland Wong", "Aaron Morris", "Colin Lea", "James Lee", "Chuck Whittaker", "Ben Garney", "Red Whittaker"], "b": "", "cn": 0, "i": 51148305, "k": ["Laser Radar"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6048626", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06048626"], "t": "Comparative evaluation of range sensing technologies for underground void modeling", "v": "IROS", "y": 2011, "rn": 13}, {"a": ["Donald Dansereau", "Ian Mahon", "Oscar Pizarro", "Stefan Williams"], "b": "Three closed-form solutions are proposed for six de- gree of freedom (6-DOF) visual odometry for light field cameras. The first approach breaks the problem into geometrically driven sub-problems with solutions adaptable to specific applications, while the second generalizes methods from optical flow to yield a more direct approach. The third solution integrates elements into a remarkably simple equation of plenoptic", "cn": 0, "i": 51148516, "k": ["Closed Form Solution", "Feature Extraction", "Feature Tracking", "General Methods", "Light Field", "Optical Sensor", "Three Dimensional", "visual odometry", "Optical Flow", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6048841", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06048841"], "t": "Plenoptic flow: Closed-form visual odometry for light field cameras", "v": "IROS", "y": 2011, "rn": 22}, {"a": ["Leilei Gao", "Lifeng Zhu", "Guoping Wang"], "b": "In conceptual design of models, designers usually express their ideas in curve networks, without generating final 3D surfaces. In this paper, we propose a method to utilize the structures and properties of curve networks to create mesh surfaces with controllable sharp features. We demonstrated our method on various curve networks, the created surfaces are both visually plausible and faithfully follow", "cn": 0, "i": 51156216, "k": ["Conceptual Design", "Model Design"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06062797", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6062797"], "t": "CurveNetSurf: Creating Surfaces from Curve Networks", "v": "CAD/Graphics", "y": 2011, "rn": 31}, {"a": ["Aljoscha Smolic", "Peter Kauff", "Sebastian Knorr", "Alexander Hornung", "Matthias Kunter", "Marcus Muller", "Manuel Lang"], "b": "This paper gives an overview of the state-of-the- art in 3-D video postproduction and processing as well as an outlook to remaining challenges and opportunities. First, fundamentals of stereography are outlined that set the rules for proper 3-D content creation. Manipulation of the depth composition of a given stereo pair via view synthesis is iden- tified as the key functionality", "cn": 0, "i": 51178404, "k": ["Depth Estimation", "Motion Pictures", "Signal Processing", "Three Dimensional", "View Synthesis", "Depth Image Based Rendering", "Real Time Systems"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05701641", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5701641"], "t": "Three-Dimensional Video Postproduction and Processing", "v": "PIEEE", "y": 2011, "rn": 86}, {"a": ["Chenglei Wu", "Yebin Liu", "Qionghai Dai", "Bennett Wilburn"], "b": "We propose a method to obtain a complete and accurate 3D model from multiview images captured under a variety of unknown illuminations. Based on recent results showing that for Lambertian objects, general illumination can be approximated well using low-order spherical harmonics, we develop a robust alternating approach to recover surface normals. Surface normals are initialized using a multi-illumination multiview stereo", "cn": 0, "i": 51183663, "k": ["3d model", "3d reconstruction", "Computer Model", "Harmonic Analysis", "Image Reconstruction", "Indexing Terms", "Optimal Method", "Photometric Stereo", "Shape Priors", "Spherical Harmonic", "Surface Reconstruction", "Synthetic Data", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5611506", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05611506"], "t": "Fusing Multiview and Photometric Stereo for 3D Reconstruction under Uncalibrated Illumination", "v": "TVCG", "y": 2011, "rn": 51}, {"a": ["Guofeng Zhang", "Hanqing Jiang", "Jin Huang", "Jiaya Jia", "Tien-Tsin Wong", "Kun Zhou", "Hujun Bao"], "b": "In this paper, we present a novel method to extract motion of a dynamic object from a video that is captured by a handheld camera, and apply it to a 3D character. Unlike the motion capture techniques, neither special sensors/trackers nor a controllable environment is required. Our system significantly automates motion imitation which is traditionally conducted by professional animators via", "cn": 0, "i": 51187760, "k": ["Deformable Model", "Indexing Terms", "Mesh Deformation", "Motion Capture", "Motion Tracking", "Optimization Problem", "Solid Modeling", "Target Tracking", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5887298", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05887298"], "t": "Motion Imitation with a Handheld Camera", "v": "TVCG", "y": 2011, "rn": 36}, {"a": ["Guillermo Gallego", "Anthony Yezzi", "Francesco Fedele", "Alvise Benetazzo"], "b": "We develop a novel remote sensing technique for the observation of waves on the ocean surface. Our method infers the 3-D waveform and radiance of oceanic sea states via a variational stereo imagery formulation. In this setting, the shape and radiance of the wave surface are given by minimizers of a composite energy functional that combines a photometric matching term", "cn": 0, "i": 51194645, "k": ["Energy Function", "Image Processing", "Image Reconstruction", "Mathematical Model", "Ocean Wave", "Optimality Condition", "Partial Differential Equation", "Remote Sensing", "Sea Surface", "Spectral Analysis", "Spectrum", "Stereo Vision", "Surface Reconstruction", "Surface Treatment", "Surface Wave", "Three-dimensional Reconstruction", "Variational Method"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05887409", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5887409"], "t": "A Variational Stereo Method for the Three-Dimensional Reconstruction of Ocean Waves", "v": "IEEE TRANS GEOSCI REMOT SEN", "y": 2011, "rn": 23}, {"a": ["Mike Christenson"], "b": "The ambiguous relationship between photography and architecture is one of constructed and re-constructed identity. As an exploration into this relationship, this article considers the construct of point-of-vew/field-of-view maps (or POV/FOV maps), diagrams which register photographers\u2019 positions, fields of view, and directions of view corresponding to photographs of an existing work of architecture. A POV/FOV map can be expected to differ", "cn": 0, "i": 57463876, "k": ["Field of View"], "p": ["http://dx.doi.org/10.1080/00038628.2011.582365"], "t": "On the architectural structure of photographic space", "v": "", "y": 2011, "rn": 7}, {"a": ["Yi Xu", "Daniel Aliaga"], "b": "Obtaining models of dynamic 3D objects is an important part of content generation for computer graphics. Numerous methods have been extended from static scenarios to model dynamic scenes. If the states or poses of the dynamic object repeat often during a sequence (but not necessarily periodically), we call such a repetitive motion. There are many objects, such as toys, machines,", "cn": 0, "i": 5636750, "k": ["Computer Graphic", "Difference Set", "Dynamic Scenes", "Geometric Model", "Indexing Terms", "Modeling Technique", "Numerical Method", "Scene Reconstruction", "Structured Light", "Three-dimensional Graphics and Realism", "Space Time"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5332229", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5332229", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05332229", "http://doi.ieeecomputersociety.org/10.1109/TVCG.2009.207", "http://www.informatik.uni-trier.de/~ley/db/journals/tvcg/tvcg16.html#XuA10", "http://www.cs.purdue.edu/cgvlab/papers/aliaga/tvcg09-rm.pdf", "http://www.cs.purdue.edu/homes/xu43/papers/tvcg09.pdf"], "t": "Modeling Repetitive Motions Using Structured Light", "v": "TVCG", "y": 2010, "rn": 40}, {"a": ["Yumo Yang", "Liuxin Zhang", "Yunde Jia"], "b": "\n Visibility estimation is one of the most difficult problems in multi-view reconstruction using volumetric approaches. In this\n paper, we present a novel approach called layer-constraint-based visibility (LCBV) to estimating visibility. Based on the\n layered state of a scene and photo-consistency constraint, this method can determine the more accurate visibility for every\n point in a scene. We use LCBV in multi-view", "cn": 0, "i": 6046946, "k": ["Error Analysis", "Graph Cut"], "p": ["http://www.springerlink.com/content/r2783247l74862qj", "http://www.springerlink.com/index/r2783247l74862qj.pdf", "http://dx.doi.org/10.1007/978-3-642-11301-7_5", "http://www.informatik.uni-trier.de/~ley/db/conf/mmm/mmm2010.html#YangZJ10"], "t": "Layer-Constraint-Based Visibility for Volumetric Multi-view Reconstruction", "v": "MMM", "y": 2010, "rn": 17}, {"a": ["Cedric Cagniart", "Edmond Boyer", "Slobodan Ilic"], "b": "In this paper we present a new method to capture the temporal evolution of a surface from multiple videos. By contrast to most current methods, our algorithm does not use any prior information on the nature of the tracked sur- face. In addition, it does not require sparse features to constrain the deformation but only relies on purely geo- metric", "cn": 0, "i": 7039102, "k": ["Iterative Closest Point", "Large Deformation", "Prior Information", "Reference Model"], "p": [], "t": "Suivi de Surface par D\u00e9formations It\u00e9ratives", "y": 2010, "rn": 16}, {"a": ["Li Guan", "Inria Sud-Ouest", "Edmond Boyer", "Marc Pollefeys", "Jean-sebastien Franco"], "b": "In this paper we investigate shape and motion retrieval in the context of multi-camera systems. We propose a new low- level analysis based on latent silhouette cues, particularly suited for low-texture and outdoor datasets. Our analysis does not rely on explicit surface representations, instead us- ing an EM framework to simultaneously update a set of vol- umetric voxel occupancy probabilities", "cn": 0, "i": 13160170, "k": ["3d scene analysis", "Motion Analysis", "Shape Modeling", "Surface Representation"], "p": ["http://hal.inria.fr/docs/00/46/30/31/PDF/cvpr2010.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539807", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539807", "http://dx.doi.org/10.1109/CVPR.2010.5539807", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#GuanFBP10", "http://hal.inria.fr/inria-00463031/PDF/1520.pdf"], "t": "Probabilistic 3D Occupancy Flow with Latent Silhouette Cues", "v": "CVPR", "y": 2010, "rn": 28}, {"a": ["Tomokazu Sato", "Naokazu Yokoya"], "b": "In this article, we propose an efficient method for estimating a depth map from long-baseline image sequences captured by a calibrated moving multi-camera system. Our concept for estimating a depth map is very simple; we integrate the counting of the total number of interest points (TNIP) in images with the original framework of multiple baseline stereo. Even by using a", "cn": 0, "i": 13337310, "k": ["Depth Estimation", "Depth Map", "Efficient Algorithm", "Hybrid Approach", "Image Sequence", "Interest Points", "Normalized Cross Correlation", "Similarity Measure", "Stereo Matching", "Sum of Squared Difference"], "p": ["http://linkinghub.elsevier.com/retrieve/pii/S104732031000026X", "http://www.sciencedirect.com/science/article/pii/S104732031000026X", "http://dx.doi.org/10.1016/j.jvcir.2010.02.006", "http://www.informatik.uni-trier.de/~ley/db/journals/jvcir/jvcir21.html#SatoY10"], "t": "Efficient hundreds-baseline stereo by counting interest points for moving omni-directional multi-camera system", "v": "JVCIR", "y": 2010, "rn": 21}, {"a": ["George Vogiatzis", "Carlos Hern\u00e1ndez"], "b": "\n Photometric Stereo is a powerful image based 3D reconstruction technique that has recently been used to obtain very high quality\n reconstructions. However, in its classic form, Photometric Stereo suffers from two main limitations: Firstly, one needs to\n obtain images of the 3D scene under multiple different illuminations. As a result the 3D scene needs to remain static during\n illumination changes,", "cn": 0, "i": 13339076, "k": ["3d reconstruction", "Deformable Objects", "Depth Map", "Moving Object", "Photometric Stereo", "Photometric Stereo Method"], "p": ["http://dx.doi.org/10.1007/978-3-642-12848-6_12", "http://www.springerlink.com/index/v842652l1w816432.pdf", "http://www.springerlink.com/content/v842652l1w816432", "http://www.informatik.uni-trier.de/~ley/db/series/sci/sci285.html#VogiatzisH10"], "t": "Practical 3D Reconstruction Based on Photometric Stereo", "y": 2010, "rn": 47}, {"a": ["Emanuele Rodol\u00e0", "Andrea Albarelli", "Andrea Torsello"], "b": "\n In this paper we introduce a robust matching technique that allows to operate a very accurate selection of corresponding feature\n points from multiple views. Robustness is achieved by enforcing global geometric consistency at an early stage of the matching\n process, without the need of ex-post verification through reprojection. Two forms of global consistency are proposed, but\n in both cases they", "cn": 0, "i": 13759896, "k": ["Bundle Adjustment", "Feature Matching", "Multiple Views"], "p": ["http://dx.doi.org/10.1007/978-3-642-14980-1_34", "http://www.springerlink.com/index/786460j8q55j1060.pdf", "http://www.springerlink.com/content/786460j8q55j1060", "http://www.informatik.uni-trier.de/~ley/db/conf/sspr/sspr2010.html#RodolaAT10"], "t": "A Game-Theoretic Approach to the Enforcement of Global Consistency in Multi-view Feature Matching", "v": "SSPR", "y": 2010, "rn": 16}, {"a": ["Liuxin Zhang", "Yunde Jia"], "b": "In this paper, we investigate the problem of determining the visible regions of multiple cameras in a 3D scene without a priori knowledge of the scene geometry. Our approach is based on a variational energy functional where both the unresolved visibility information of multiple cameras and the unknown scene geometry are included. We cast visibility estimation and scene geometry reconstruction", "cn": 0, "i": 14083778, "k": ["a priori knowledge", "Energy Function", "image-based modeling", "Implicit Surface", "euler lagrange", "Level Set Method"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597901", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05597901", "http://dx.doi.org/10.1109/ICPR.2010.883", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2010.html#ZhangJ10"], "t": "Visibility of Multiple Cameras in a Scene with Unknown Geometry", "v": "ICPR", "y": 2010, "rn": 10}, {"a": ["Emanuele Rodol\u00e0", "Andrea Albarelli", "Andrea Torsello"], "b": "In this paper we introduce a robust matching technique that allows very accurate selection of corresponding feature points from multiple views. Robustness is achieved by enforcing global geometric consistency at an early stage of the matching process, without the need of subsequent verification through reprojection. The global consistency is reduced to a pairwise compatibility making use of the size and", "cn": 0, "i": 14084717, "k": ["Bundle Adjustment", "Multiple Views"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597657", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05597657", "http://dx.doi.org/10.1109/ICPR.2010.23", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2010.html#RodolaAT10"], "t": "A Game-Theoretic Approach to Robust Selection of Multi-view Point Correspondence", "v": "ICPR", "y": 2010, "rn": 8}, {"a": ["Peng Song", "Xiaojun Wu", "Michael Wang"], "b": "This paper presents a volumetric stereo and silhouette fusion algorithm for acquiring high quality models from multiple calibrated\n photographs. Our method is based on computing and merging depth maps. Different from previous methods of this category, the\n silhouette information is also applied in our algorithm to recover the shape information on the textureless and occluded areas.\n The proposed algorithm starts", "cn": 0, "i": 15214001, "k": ["3d point cloud", "Depth Map", "image-based modeling", "multi-view stereo", "Point Cloud", "Quality Model", "Surface Reconstruction", "Test Methods", "Visual Hull"], "p": ["http://www.springerlink.com/content/qvj4h73183230u75", "http://www.springerlink.com/index/qvj4h73183230u75.pdf", "http://dx.doi.org/10.1007/s00371-010-0429-y", "http://www.informatik.uni-trier.de/~ley/db/journals/vc/vc26.html#SongWW10", "http://www.springerlink.com/index/10.1007/s00371-010-0429-y", "http://www.springerlink.com/index/pdf/10.1007/s00371-010-0429-y"], "t": "Volumetric stereo and silhouette fusion for image-based modeling", "v": "VC", "y": 2010, "rn": 33}, {"a": ["Ioan Cleju", "Dietmar Saupe"], "b": "In the process of digitizing the geometry and appearance of 3D objects, texture registration is a necessary step that solves\n the 2D\u20133D mapping between the 2D texture images and the 3D geometric model. For evaluation of texture registration with ground\n truth, accurate datasets can be obtained with a complex setup consisting of calibrated geometry and texture capture devices.\n We do", "cn": 0, "i": 15214025, "k": ["Computer Vision", "Distance Measure", "epipolar geometry", "Evaluation Measure", "Geometric Model", "Mutual Information", "Ground Truth"], "p": ["http://www.springerlink.com/content/y64ut461315r3477", "http://www.springerlink.com/index/y64ut461315r3477.pdf", "http://www.springerlink.com/index/10.1007/s00371-010-0427-0", "http://www.springerlink.com/index/pdf/10.1007/s00371-010-0427-0", "http://dx.doi.org/10.1007/s00371-010-0427-0", "http://www.informatik.uni-trier.de/~ley/db/journals/vc/vc26.html#ClejuS10"], "t": "Evaluation of texture registration by epipolar geometry", "v": "VC", "y": 2010, "rn": 15}, {"a": ["Ran Gal", "Yonathan Wexler", "Eyal Ofek", "Hugues Hoppe", "Daniel Cohen-Or"], "b": "We present an automatic method to recover high-resolution texture over an object shape by mapping detailed photographs onto its surface. Such high-resolution detail often reveals inaccuracies in geometry and registration, as well as lighting variations and surface reflections. Simple image projection results in visible seams on the surface. We minimize such seams using a global optimization that assigns compatible texture", "cn": 0, "i": 15257922, "k": ["Computer Graphic", "Global Optimization", "High Resolution", "Search Space"], "p": ["http://blackwell-synergy.com/doi/abs/10.1111/j.1467-8659.2009.01617.x", "http://dx.doi.org/10.1111/j.1467-8659.2009.01617.x", "http://www.informatik.uni-trier.de/~ley/db/journals/cgf/cgf29.html#GalWOHC10", "http://research.microsoft.com/apps/pubs/default.aspx?id=149306", "http://research.microsoft.com/pubs/149306/EGseamlessTextures_EGfinal.pdf"], "t": "Seamless Montage for Texturing Models", "v": "CGF", "y": 2010, "rn": 18}, {"a": ["Qingxu Dou", "Paolo Favaro"], "b": "We present a novel framework for multi-view stereo that poses the problem of recovering a 3D surface in the scene as a regularized minimal partition problem of the visibility function in the presence of clutter. We introduce a simple and robust method to integrate estimates from several views that tolerates both static and time-varying clutter. Our formulation does not rely", "cn": 0, "i": 39232626, "k": ["Generic Model", "Global Optimization", "Image Formation", "multi-view stereo", "Numerical Method", "Robust Method", "Time Varying", "Visual Hull"], "p": ["http://portal.acm.org/citation.cfm?id=1924592", "http://portal.acm.org/ft_gateway.cfm?id=1924592&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "A convex multi-view stereo formulation with robustness to occlusions and time-varying clutter", "y": 2010, "rn": 14}, {"a": ["Thabo Beeler", "Bernd Bickel", "Paul Beardsley", "Bob Sumner", "Markus Gross"], "b": "This paper describes a passive stereo system for capturing the 3D geometry of a face in a single-shot under standard light sources. The system is low-cost and easy to deploy. Results are submillimeter accurate and commensurate with those from state-of-the-art systems based on active lighting, and the models meet the quality requirements of a demanding domain like the movie industry.", "cn": 0, "i": 39244508, "k": ["Face Modeling", "Facial Expression", "Quality Requirement", "Spectrum", "Ground Truth"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1778777&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1778777"], "t": "High-quality single-shot capture of facial geometry", "y": 2010, "rn": 28}, {"a": ["Luca Ballan", "Gabriel Brostow", "Jens Puwein", "Marc Pollefeys"], "b": "We present an algorithm designed for navigating around a performance that was filmed as a \"casual\" multi-view video collection: real-world footage captured on hand held cameras by a few audience members. The objective is to easily navigate in 3D, generating a video-based rendering (VBR) of a performance filmed with widely separated cameras. Casually filmed events are especially challenging because they", "cn": 0, "i": 39244555, "k": ["Algorithm Design", "Camera Motion", "Interactive Rendering", "Photo Collection", "Shape From Silhouette", "Spatial Navigation", "View Interpolation", "Visual Cues"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1778824&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1778824"], "t": "Unstructured video-based rendering: interactive exploration of casually captured videos", "y": 2010, "rn": 65}, {"a": ["Michael Holroyd", "Jason Lawrence", "Todd Zickler"], "b": "We present a novel optical setup and processing pipeline for measuring the 3D geometry and spatially-varying surface reflectance of physical objects. Central to our design is a digital camera and a high frequency spatially-modulated light source aligned to share a common focal point and optical axis. Pairs of such devices allow capturing a sequence of images from which precise measurements", "cn": 0, "i": 39244566, "k": ["Digital Camera", "Focal Point", "High Frequency", "Reference Data"], "p": ["http://portal.acm.org/citation.cfm?id=1778836", "http://portal.acm.org/ft_gateway.cfm?id=1778836&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "A coaxial optical scanner for synchronous acquisition of 3D geometry and surface reflectance", "y": 2010, "rn": 45}, {"a": ["Aparna Taneja", "Luca Ballan", "Marc Pollefeys"], "b": "\n Dynamic scene modeling is a challenging problem in computer vision. Many techniques have been developed in the past to address\n such a problem but most of them focus on achieving accurate reconstructions in controlled environments, where the background\n and the lighting are known and the cameras are fixed and calibrated. Recent approaches have relaxed these requirements by\n applying these techniques", "cn": 0, "i": 39256462, "k": ["Color Model", "Computer Vision", "Dynamic Scenes", "Quantitative Evaluation", "Synthetic Data"], "p": ["http://www.springerlink.com/index/4235862580470676.pdf", "http://www.springerlink.com/content/4235862580470676", "http://dx.doi.org/10.1007/978-3-642-19318-7_48", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2010-3.html#TanejaBP10"], "t": "Modeling Dynamic Scenes Recorded with Freely Moving Cameras", "v": "ACCV", "y": 2010, "rn": 33}, {"a": ["Ama\u00ebl Delaunoy", "Emmanuel Prados", "Peter Belhumeur"], "b": "\n Helmholtz stereovision methods are limited to binocular stereovision or depth maps reconstruction. In this paper, we extend\n these methods to recover the full 3D shape of the objects of a scene from multiview Helmholtz stereopsis. Thus, we are able\n to reconstruct the complete three-dimensional shape of objects made of any arbitrary and unknown bidirectional reflectance\n distribution function. Unlike previous methods,", "cn": 0, "i": 39256616, "k": ["Depth Map", "Surface Representation", "Three Dimensional", "Triangular Mesh", "Bidirectional Reflectance Distribution Function", "Gradient Descent"], "p": ["http://www.springerlink.com/index/f606q17t12126444.pdf", "http://www.springerlink.com/content/f606q17t12126444", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2010-1.html#DelaunoyPB10", "http://dx.doi.org/10.1007/978-3-642-19315-6_4"], "t": "Towards Full 3D Helmholtz Stereovision Algorithms", "v": "ACCV", "y": 2010, "rn": 25}, {"a": ["Koen Douterloigne", "Sidharta Gautama", "Wilfried Philips"], "b": "\n Structure from motion based 3D reconstruction takes a lot of time for large scenes which consist of thousands of input images.\n We propose a method that speeds up the reconstruction of large scenes by partitioning it into smaller scenes, and then recombining\n those. The main benefit here is that each subscene can be optimized in parallel. We present a widely", "cn": 0, "i": 39256695, "k": ["3d reconstruction", "Structure From Motion"], "p": ["http://www.springerlink.com/content/u851274620886000", "http://www.springerlink.com/index/u851274620886000.pdf", "http://dx.doi.org/10.1007/978-3-642-17691-3_2", "http://www.informatik.uni-trier.de/~ley/db/conf/acivs/acivs2010-2.html#DouterloigneGP10"], "t": "Speeding Up Structure from Motion on Large Scenes Using Parallelizable Partitions", "v": "ACIVS", "y": 2010, "rn": 14}, {"a": ["Anne-Laure Chauve", "Patrick Labatut", "Jean-Philippe Pons"], "b": "In this paper, we present a novel method, the first to date to our knowledge, which is capable of directly and automatically producing a concise and idealized 3D representation from unstructured point data of complex cluttered real-world scenes, with a high level of noise and a significant proportion of outliers, such as those obtained from passive stereo. Our algorithm can", "cn": 0, "i": 39261218, "k": ["3d reconstruction", "3d representation", "Experimental Validation", "Large Scale", "Point Cloud", "Polygonal Meshes", "Vertical Structure"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539824", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539824", "http://dx.doi.org/10.1109/CVPR.2010.5539824", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#ChauveLP10"], "t": "Robust piecewise-planar 3D reconstruction and completion from large-scale unstructured point data", "v": "CVPR", "y": 2010, "rn": 31}, {"a": ["Tony Tung", "Takashi Matsuyama"], "b": "We present a novel approach that achieves segmentation of subject body parts in 3D videos. 3D video consists in a free-viewpoint video of real-world subjects in motion immersed in a virtual world. Each 3D video frame is composed of one or several 3D models. A topology dictionary is used to cluster 3D video sequences with respect to the model topology", "cn": 0, "i": 39267859, "k": ["3d model", "3d video", "Automatic Segmentation", "Shape Matching", "Free Viewpoint Video", "Virtual Worlds"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05652541", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5652541", "http://dx.doi.org/10.1109/ICIP.2010.5652541", "http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2010.html#TungM10"], "t": "3D video performance segmentation", "v": "ICIP", "y": 2010, "rn": 20}, {"a": ["Yanli Wan", "Zhenjiang Miao", "Zhen Tang"], "b": "This paper presents a new approach to reconstruct 3D dense point cloud from uncalibrated wide-baseline images. It includes three steps: acquiring quasi-dense point correspondences, recovering structure from motion, and reconstructing the 3D dense point cloud. We present a two level propagation algorithm. The first level is implemented in the 2D image space and the second level is in the 3D", "cn": 0, "i": 39291408, "k": ["Point Cloud", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05495399", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5495399", "http://dx.doi.org/10.1109/ICASSP.2010.5495399", "http://www.informatik.uni-trier.de/~ley/db/conf/icassp/icassp2010.html#WanMT10"], "t": "Reconstruction of dense point cloud from uncalibrated widebaseline images", "v": "ICASSP", "y": 2010, "rn": 10}, {"a": ["Koen Douterloigne", "Sidharta Gautama", "Wilfried Philips"], "b": "Our surroundings change all the time. Applications that require 3D models of a changing terrain, such as urban planning, are becoming ever more demanding with respect to the cost to create them and the accuracy of the result. A novel, cheap and fast solution for this problem is given by a UAV to take aerial images of the terrain in", "cn": 0, "i": 39296062, "k": ["3d model", "3d reconstruction", "Aerial Image", "Model Matching", "Structure From Motion", "Urban Planning", "On The Fly"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5651391", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05651391", "http://dx.doi.org/10.1109/IGARSS.2010.5651391", "http://www.informatik.uni-trier.de/~ley/db/conf/igarss/igarss2010.html#DouterloigneGP10"], "t": "On the accuracy of 3D landscapes from UAV image data", "v": "IGARSS", "y": 2010, "rn": 8}, {"a": ["Thayne Coffman", "Alan Bovik"], "b": "We explore the use of Distributed Ray Tracing (DRT), an anti-aliasing technique from computer graphics, in multi-view computational stereo. As an example, we study ABM, a multi-view stereo algorithm based on a set of Hough transform accumulation operations. Augmenting ABM with DRT improves both internal signal quality and reconstruction accuracy. Results are given for both fundamental and complex \u201csuper-resolution reconstruction\u201d", "cn": 0, "i": 50893271, "k": ["Computer Graphic", "Distributed Ray Tracing", "multi-view stereo", "Super Resolution", "Ground Sample Distance", "Hough Transform"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05483892", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5483892"], "t": "Multi-view stereo ranging via Distributed Ray Tracing", "v": "", "y": 2010, "rn": 11}, {"a": ["Miquel Casamitjana", "M. P\u00e9rez", "Joan Aranda", "Eduard Montseny", "Enric Mart\u00edn"], "b": "A new method for obtaining a three-dimensional volumetric reconstruction from a set of views improving the classical Shape from Silhouette method (SFS) is presented. SFS approaches can be easily accelerated through hardware and software techniques but they are very sensible to errors arising during calibration and segmentation processes so they present difficulties when dealing with real images. This paper proposes", "cn": 0, "i": 50944138, "k": ["3d reconstruction", "Decision Rule", "Shape From Silhouette", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05584453", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5584453"], "t": "Reliable 3D reconstruction extending pixel-level certainty measures", "v": "", "y": 2010, "rn": 13}, {"a": ["Lukas Gruber", "Steffen Gauglitz", "Jonathan Ventura", "Stefanie Zollmann", "Manuel Huber", "Michael Schlegel", "Gudrun Klinker", "Dieter Schmalstieg", "T. Ho\u0308llerer"], "b": "We describe the design and implementation of a physical and virtual model of an imaginary urban scene-the \u201cCity of Sights\u201d- that can serve as a backdrop or \u201cstage\u201d for a variety of Augmented Reality (AR) research. We argue that the AR research community would benefit from such a standard model dataset which can be used for evaluation of such AR", "cn": 0, "i": 50986294, "k": ["Augmented Reality", "Design and Implementation", "Tracking System", "Use Case", "User Interface Design", "Ground Truth", "Standard Model"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5643564", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05643564"], "t": "The City of Sights: Design, construction, and measurement of an Augmented Reality stage set", "v": "ISMAR", "y": 2010, "rn": 37}, {"a": ["Guangyu Mu", "Miao Liao", "Ruigang Yang", "Dantong Ouyang", "Zhiwen Xu", "Xiaoxin Guo"], "b": "We propose a fast and simple application system of 3D model reconstruction. We acquire range images by using a combination of a regular camera and two types of depth sensors. The reconstruction of a 3D model consists of four key steps: (i) Initial alignment either feature tracking or the 4-points congruent sets algorithm is used to align surfaces captured at", "cn": 0, "i": 50987973, "k": ["3d model", "Feature Tracking", "Iterative Closest Point", "Range Image", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05658733", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5658733"], "t": "Complete 3D model reconstruction using two types of depth sensors", "v": "ICIS", "y": 2010, "rn": 18}, {"a": ["Peng Song", "Xiaojun Wu", "Michael Wang", "Jianhuang Wu"], "b": "This paper presents an algorithm for acquiring high-quality models from multiple calibrated photographs by computing and merging depth maps. The algorithm first computes depth maps from multi-view stereo using a proposed expansion-based approach that returns a 3D point cloud with noisy and redundant information. Then the estimated depth maps are merged into an accurate surface model by a cleaning, downsampling,", "cn": 0, "i": 50989064, "k": ["3d point cloud", "Depth Map", "multi-view stereo", "Quality Model", "Surface Model", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5651253", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05651253"], "t": "Expansion-based depth map estimation for multi-view stereo", "v": "IROS", "y": 2010, "rn": 19}, {"a": ["Guangyu Mu", "Miao Liao", "Ruigang Yang", "Dantong Ouyang", "Zhiwen Xu", "Xiaoxin Guo"], "b": "We propose a fast and simple application system of 3D model reconstruction. We acquire range images by using a combination of a regular camera and a depth sensor. The reconstruction of a 3D model consists of four key steps: (i) Initial alignment either feature tracking or the 4-points congruent sets algorithm is used to align surfaces captured at different frames.", "cn": 0, "i": 50991186, "k": ["3d model", "Feature Tracking", "Iterative Closest Point", "Range Image", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5656808", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05656808"], "t": "Complete 3D model reconstruction using a depth sensor", "y": 2010, "rn": 13}, {"a": ["Ryo Furukawa", "Ryusuke Sagawa", "Hiroshi Kawasaki", "Kazuhiro Sakashita", "Yasushi Yagi", "Naoki Asada"], "b": "In this paper, we propose an active scanning system using multiple projectors and cameras to acquire a dense entire shape of the object with a single scan (a.k.a. ones hot scan). One of the potential application of the system is to capture a moving object with high frame-rate. Since the pattern used for ones hot scan is usually complicated and", "cn": 0, "i": 51003106, "k": ["3d measurement", "Active Sensing", "Dynamic Scenes", "Moving Object", "Reconstruction Algorithm", "Shape Reconstruction", "Structured Light"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05673766", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5673766"], "t": "One-shot Entire Shape Acquisition Method Using Multiple Projectors and Cameras", "v": "PSIVT", "y": 2010, "rn": 18}, {"a": ["J. Ruttle", "M. Manzke", "R. Dahyot"], "b": "We present a statistical framework to merge the information from silhouettes segmented in multiple view images to infer the 3D shape of an object. The approach is generalising the robust but discrete modelling of the visual hull by using the concept of averaged likelihoods. One resulting advantage of our framework is that the objective function is continuous and therefore an", "cn": 0, "i": 51015671, "k": ["Kernel Density Estimate", "Multiple Views", "Objective Function", "Parallel Processing", "Shape From Silhouette", "newton raphson", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693097", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05693097"], "t": "Smooth Kernel Density Estimate for Multiple View Reconstruction", "v": "CVMP", "y": 2010, "rn": 18}, {"a": ["C. Budd", "A. Hilton"], "b": "In this paper we present a method to automatically introduce temporal consistency into a sequence of meshes reconstructed from multi-view video. We combine a number of advantages of previous work to produce a robust algorithm. Our approach uses SIFT features in each camera view combined with geometric information to produce accurate frame to frame correspondence. Coupling this with both volumetric", "cn": 0, "i": 51015674, "k": ["3d video", "Shape Matching", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05693102", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693102"], "t": "Temporal Alignment of 3D Video Sequences Using Shape and Appearance", "v": "CVMP", "y": 2010, "rn": 11}, {"a": ["Viet Nghiem", "Jianfei Cai", "Jianmin Zheng"], "b": "Most of the previous multi-view reconstruction algorithms focus on minimizing reconstruction distortion, i.e. reconstructing a 3D model as close to the real object as possible, and rely on subsequent simplification process to control the reconstruction rate for practical usage. In this paper, in addition to reconstruction distortion, we directly consider the reconstruction rate in wide-baseline multi-view reconstruction. In particular, we", "cn": 0, "i": 51015813, "k": ["3d model", "3d reconstruction", "Mesh Optimization", "Mesh Refinement", "Rate Distortion", "Rate Distortion Optimization", "Reconstruction Algorithm", "Visual Quality"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05693029", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5693029"], "t": "Rate-Distortion Optimized Progressive 3D Reconstruction from Multi-view Images", "v": "PG", "y": 2010, "rn": 20}, {"a": ["Daniel Clark", "S. Ivekovic\u030c"], "b": "It is well known that any 3-D state estimate computed from stereo camera measurements is corrupted by heteroscedastic noise due to the nature of the perspective projection. It is also well understood that the image measurements used to estimate the 3-D state are inherently noisy. Despite the wealth of research in this area, the accurate statistical characterisation of the uncertainty", "cn": 0, "i": 51022457, "k": ["Cramer Rao Lower Bound", "Perspective Projection", "State Estimation", "Statistical Estimation", "3 dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05712095", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5712095"], "t": "The Cramer-Rao Lower Bound for 3-D state estimation from rectified stereo cameras", "y": 2010, "rn": 17}, {"a": ["Jinwook Choi", "Dongbo Min", "Kwanghoon Sohn"], "b": "We propose a novel framework for upconversion of depth video resolution in both spatial and time domains considering spatial and temporal coherences. Although the Time-of-Flight (TOF) sensor which is widely used in computer vision fields provides depth video in realtime, it also provides a low resolution and a low frame-rate depth video. We propose a cheaper solution that enhances depth", "cn": 0, "i": 51175158, "k": ["Ccd Camera", "Charged Couple Device", "Computer Vision", "Motion Compensated", "Temporal Coherence", "Video Coding", "3 dimensional", "Low Resolution", "Time Domain", "Time of Flight"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5681132", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05681132"], "t": "2D-plus-depth based resolution and frame-rate up-conversion technique for depth video", "v": "IEEE TRANS CONSUM ELECTRON", "y": 2010, "rn": 23}, {"a": ["Xiaoduan Feng", "Yebin Liu", "Qionghai Dai"], "b": "In many multi-view stereo (MVS) algorithms, a point-cloud evolution is performed, based on the matching process. For most of them, an assumption is usually employed for the matching, which indicates that the matching windows have the same shape. This assumption lays a great limit to the quality of the reconstructed result. To improve the point- cloud obtained from other algorithms,", "cn": 0, "i": 5725872, "k": ["Indexing Terms", "multi-view stereo", "Point Cloud"], "p": ["http://media.au.tsinghua.edu.cn/Groupmembers/yebin.files/ICME09-FengXiaoduan.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05202647", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5202647", "http://dx.doi.org/10.1109/ICME.2009.5202647", "http://www.informatik.uni-trier.de/~ley/db/conf/icmcs/icme2009.html#FengLD09"], "t": "Point-cloud refinement via exact matching", "v": "ICME(ICMCS)", "y": 2009, "rn": 10}, {"a": ["Peter Sturm", "Ama\u00ebl Delaunoy", "Pau Gargallo", "Emmanuel Prados", "Kuk-Jin Yoon"], "b": "This paper gives an overview of works done in our group on 3D and appearance modeling of objects, from images. The backbone\n of our approach is to use what we consider as the principled optimization criterion for this problem: to maximize photoconsistency\n between input images and images rendered from the estimated surface geometry and appearance. In initial works, we have", "cn": 0, "i": 6030162, "k": ["Cost Function", "General Solution", "Surface Geometry"], "p": ["http://dx.doi.org/10.1007/978-3-642-10268-4_82", "http://www.springerlink.com/index/k815390223356236.pdf", "http://www.springerlink.com/content/k815390223356236", "http://www.informatik.uni-trier.de/~ley/db/conf/ciarp/ciarp2009.html#SturmDGPY09", "http://adsabs.harvard.edu/abs/2009LNCS.5856..695S"], "t": "3D and Appearance Modeling from Images", "v": "CIARP", "y": 2009, "rn": 9}, {"a": ["Oliver Vogel", "Levi Valgaerts", "Michael Breu\u00df", "Joachim Weickert"], "b": "Although shape from shading (SfS) has been studied for almost four decades, the performance of most methods applied to real-world\n images is still unsatisfactory: This is often caused by oversimplified reflectance and projection models as well as by ignoring\n light attenuation and nonconstant albedo behavior. We address this problem by proposing a novel approach that combines three\n powerful concepts: (i)", "cn": 0, "i": 6032507, "k": ["adaptive thresholding", "Anisotropic Diffusion", "Edge Enhancement", "Light Attenuation", "Perspective Projection", "Shape From Shading"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/dagm/dagm2009.html#VogelVBW09", "http://www.springerlink.com/index/v643983756567p27.pdf", "http://www.springerlink.com/content/v643983756567p27", "http://dx.doi.org/10.1007/978-3-642-03798-6_20", "http://adsabs.harvard.edu/abs/2009LNCS.5748..191V"], "t": "Making Shape from Shading Work for Real-World Images", "v": "", "y": 2009, "rn": 25}, {"a": ["Reinhard Koch", "Ingo Schiller", "Bogumil Bartczak", "Falko Kellner", "Kevin K\u00f6ser"], "b": "This work discusses an approach to seamlessly integrate real and virtual scene content by on-the-fly 3D scene modeling and\n dynamic scene interaction. The key element is a ToF-depth camera, accompanied by color cameras, mounted on a pan-tilt head.\n The system allows to scan the environment for easy 3D reconstruction, and will track and model dynamically moving objects\n like human actors", "cn": 0, "i": 6032540, "k": ["3d reconstruction", "Dynamic Scenes", "Mixed Reality", "Moving Object", "On The Fly"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/dagm/dyn3d2009.html#KochSBKK09", "http://www.springerlink.com/content/r4266127pgu71150", "http://www.springerlink.com/index/r4266127pgu71150.pdf", "http://dx.doi.org/10.1007/978-3-642-03778-8_10", "http://adsabs.harvard.edu/abs/2009LNCS.5742..126K"], "t": "MixIn3D: 3D Mixed Reality with ToF-Camera", "v": "", "y": 2009, "rn": 22}, {"a": ["Chris Hermans", "Yannick Francken", "Tom Cuypers", "Philippe Bekaert"], "b": "We present a novel method for 3D shape acquisition, based on mobile structured light. Unlike classical structured light methods,\n in which a static projector illuminates the scene with dynamic illumination patterns, mobile structured light employs a moving\n projector translated at a constant velocity in the direction of the projector\u2019s horizontal axis, emitting static or dynamic\n illumination. For our approach, a", "cn": 0, "i": 6044548, "k": ["Information Retrieval", "Structured Light"], "p": ["http://www.springerlink.com/content/n1123nuhl6293r5v", "http://www.springerlink.com/index/n1123nuhl6293r5v.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-1.html#HermansFCB09", "http://dx.doi.org/10.1007/978-3-642-10331-5_78"], "t": "Depth from Encoded Sliding Projections", "v": "ISVC", "y": 2009, "rn": 30}, {"a": ["Daniel Knoblauch", "Mauricio Hess-flores", "Mark Duchaineau", "Falko Kuester"], "b": "A correspondence and camera error analysis for dense correspondence applications such as structure from motion is introduced.\n This provides error introspection, opening up the possibility of adaptively and progressively applying more expensive correspondence\n and camera parameter estimation methods to reduce these errors. The presented algorithm evaluates the given correspondences\n and camera parameters based on an error generated through simple triangulation.", "cn": 0, "i": 6044565, "k": ["Error Analysis", "Parameter Estimation", "Structure From Motion", "High Pass Filter"], "p": ["http://www.springerlink.com/content/q41jr345803nh360", "http://www.springerlink.com/index/q41jr345803nh360.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-1.html#KnoblauchHDK09", "http://dx.doi.org/10.1007/978-3-642-10331-5_67", "http://www.osti.gov/servlets/purl/970147/"], "t": "Factorization of Correspondence and Camera Error for Unconstrained Dense Correspondence Applications", "v": "ISVC", "y": 2009, "rn": 12}, {"a": ["Kenji Terabayashi", "Yuki Hashimoto", "Kazunori Umeda"], "b": "In this paper, detection of pedestrian groups and counting of the number of pedestrians in each group using \"subtraction stereo\" are discussed. Subtraction stereo is a stereo vision method that focuses on the movement of objects to make a stereo camera robust and pro- duces range images for moving regions. Pedestrian groups are detected with a standard labeling, and three", "cn": 0, "i": 6044654, "k": ["Range Image", "Stereo Vision", "Three Dimensional"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-2.html#TerabayashiHU09", "http://www.springerlink.com/content/p24315q2q5218n4g", "http://www.springerlink.com/index/p24315q2q5218n4g.pdf", "http://www.mech.chuo-u.ac.jp/umedalab/publications/pdf/2009/200911_terabayashi_ISVC2009_count.pdf", "http://dx.doi.org/10.1007/978-3-642-10520-3_51"], "t": "Measurement of Pedestrian Groups Using Subtraction Stereo", "v": "ISVC", "y": 2009, "rn": 11}, {"a": ["Jian Zhang", "Fei Mai", "Yeung Hung", "Graziano Chesi"], "b": "This paper presents a new algorithm for 3D shape recovery from an image sequence captured under circular motion. The algorithm\n recovers the 3D shape by reconstructing a set of 3D rim curves, where a 3D rim curve is defined by the two frontier points\n arising from two views. The idea consists of estimating the position of each point of the", "cn": 0, "i": 6044655, "k": ["3d model", "Cross Correlation", "epipolar geometry", "Image Sequence", "Multiple Views", "Shape Recovery"], "p": ["http://www.springerlink.com/content/34up1931g367n7q5", "http://www.springerlink.com/index/34up1931g367n7q5.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-2.html#ZhangMHC09", "http://dx.doi.org/10.1007/978-3-642-10520-3_44"], "t": "3D Model Reconstruction from Turntable Sequence with Multiple View Triangulation", "v": "ISVC", "y": 2009, "rn": 20}, {"a": ["Henrik Aan\u00e6s", "Klas Josephson", "Francois Anton", "Jakob B\u00e6rentzen", "Fredrik Kahl"], "b": "In this paper we describe how we can do camera resectioning from a box with unknown dimensions, i.e. determine the camera model, assuming that image pixels are square. This assumption is equivalent to assuming that the camera has an aspect ratio of one and zero skew, and this holds for most \u2014 if not all \u2014 digital cameras. Our proposed", "cn": 0, "i": 6049624, "k": ["Bundle Adjustment", "Digital Camera", "Linear Constraint", "3 dimensional", "Aspect Ratio"], "p": ["http://www.springerlink.com/index/h1w2606147441m41.pdf", "http://www.springerlink.com/content/h1w2606147441m41", "http://dx.doi.org/10.1007/978-3-642-02230-2_27", "http://www.informatik.uni-trier.de/~ley/db/conf/scia/scia2009.html#AanaesJABK09", "http://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=1392838&fileOId=1392842", "http://luur.lub.lu.se/luur?func=downloadFile&recordOId=1392838&fileOId=1392842", "http://www.maths.lth.se/matematiklth/vision/publdb/reports/pdf/aanaes-josephson-etal-scia-09.pdf"], "t": "Camera Resectioning from a Box", "v": "", "y": 2009, "rn": 15}, {"a": ["Shuntaro Yamazaki", "Srinivasa Narasimhan", "Simon Baker", "Takeo Kanade"], "b": "Acquiring 3D models of intricate objects (like tree branches, bicycles and insects) is a challenging task due to severe self-occlusions,\n repeated thin structures, and surface discontinuities. In theory, a shape-from-silhouettes (SFS) approach can overcome these\n difficulties and reconstruct visual hulls that are close to the actual shapes, regardless of the complexity of the object.\n In practice, however, SFS is highly", "cn": 0, "i": 6076352, "k": ["3d model", "epipolar geometry", "Imaging System", "Projective Reconstruction", "Shape From Silhouette", "Visual Hull"], "p": ["http://www.springerlink.com/content/r33247p326n16126", "http://dx.doi.org/10.1007/s11263-008-0170-4", "http://www.springerlink.com/index/10.1007/s11263-008-0170-4", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv81.html#YamazakiNBK09", "http://www.springerlink.com/index/pdf/10.1007/s11263-008-0170-4", "http://research.microsoft.com/apps/pubs/default.aspx?id=69511", "http://research.microsoft.com/pubs/69511/the-ijcv-08.pdf"], "t": "The Theory and Practice of Coplanar Shadowgram Imaging for Acquiring Visual Hulls of Intricate Objects", "v": "IJCV", "y": 2009, "rn": 29}, {"a": ["Marc-antoine Drouin", "Martin Trudeau", "S\u00e9bastien Roy"], "b": "This paper presents a novel algorithm that improves the localization of disparity discontinuities of disparity maps obtained\n by multi-baseline stereo. Rather than associating a disparity label to every pixel of a disparity map, it associates a position\n to every disparity discontinuity. This formulation allows us to find an approximate solution to a 2D labeling problem with\n robust smoothing term by", "cn": 0, "i": 6076383, "k": ["Approximate Solution", "Dynamic Program", "Large Classes"], "p": ["http://www.springerlink.com/content/3r52q124458693x0", "http://www.springerlink.com/index/3r52q124458693x0.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv83.html#DrouinTR09", "http://www.springerlink.com/index/10.1007/s11263-009-0223-3", "http://dx.doi.org/10.1007/s11263-009-0223-3", "http://www.springerlink.com/index/pdf/10.1007/s11263-009-0223-3"], "t": "Improving Border Localization of Multi-Baseline Stereo Using Border-Cut", "v": "IJCV", "y": 2009, "rn": 45}, {"a": ["Bo Shu", "Xianjie Qiu", "Zhaoqi Wang"], "b": "In this paper, we present a multi-view stereo based shaped modeling method. Using images captured from different viewpoints, our approach can provide objects' 3d models with high fidelity details automatically and efficiently. We firstly use a strict plane based sweep stereo method via GPU to compute quasi-dense depth maps which usually have many holes. Then, a simplified patch based surface", "cn": 0, "i": 6176568, "k": ["3d model", "Depth Map", "image-based modeling", "multi-view stereo", "Shape Modeling"], "p": ["http://vr.ict.ac.cn/paper/2009/Image%20based%20modeling%20via%20plane%20sweep%20based%20surface%20growing.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05170158", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5170158"], "t": "Image based modeling via plane sweep based surface growing", "v": "", "y": 2009, "rn": 16}, {"a": ["Dao Lam", "Ruizhi Hong", "Guilherme Desouza"], "b": "This paper presents a method for multi-view 3D modeling of human bodies using virtual stereopsis. The algorithm expands and improves the method used in, but unlike that method, our approach does not require multiple calibrated cameras and/or carefully-positioned turn tables. Instead, an algorithm using SIFT feature extraction is employed and an accurate motion estimation is performed to calculate the position", "cn": 0, "i": 6470443, "k": ["3d model", "Camera Motion", "Cost Effectiveness", "Feature Extraction", "Human Body", "Motion Estimation"], "p": ["http://dx.doi.org/10.1109/IROS.2009.5354040", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5354040", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05354040", "http://www.informatik.uni-trier.de/~ley/db/conf/iros/iros2009.html#LamHD09"], "t": "3D human modeling using virtual multi-view stereopsis and object-camera motion estimation", "v": "IROS", "y": 2009, "rn": 18}, {"a": ["Guangwei Yang", "Yebin Liu"], "b": "We present a 3D object relighting technique for multiview-multi-lighting (MVML) image sets. Our relighting technique is a fusion of multi-view stereo (MVS) technique and image based relighting (IBL) technique. The MVML dataset consists of multiple camera view with each view filmed under multiple time-multiplex illumination modes. A multi-view 3D reconstruction algorithm is first applied using traditional multi-view stereo algorithm. After", "cn": 0, "i": 13298247, "k": ["3d reconstruction", "multi-view stereo", "Texture Mapping", "Real Time"], "p": ["http://dx.doi.org/10.1109/ICME.2009.5202649", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5202649", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05202649", "http://www.informatik.uni-trier.de/~ley/db/conf/icmcs/icme2009.html#YangL09"], "t": "3D object relighting based on multi-view stereo and image based lighting techniques", "v": "ICME(ICMCS)", "y": 2009, "rn": 16}, {"a": ["Chenglei Wu", "Yebin Liu", "Xiangyang Ji", "Qionghai Dai"], "b": "This paper addresses the problem of complete and detailed 3D model reconstruction of objects filmed by multiple cameras under varying illumination. Firstly, initial normal maps are obtained to enhance the correspondence mapping. Then, the depth for every pixel is estimated by combining photometric constraint with occlusion robust photo-consistency. Finally, after filtering the point cloud, a Poisson surface reconstruction is applied", "cn": 0, "i": 13299883, "k": ["3d model", "Depth Estimation", "multi-view stereo", "Photometric Stereo", "Point Cloud", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5202648", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05202648", "http://dx.doi.org/10.1109/ICME.2009.5202648", "http://www.informatik.uni-trier.de/~ley/db/conf/icmcs/icme2009.html#WuLJD09"], "t": "Multi-view reconstruction under varying illumination conditions", "v": "ICME(ICMCS)", "y": 2009, "rn": 13}, {"a": ["Kush Varshney", "Nikos Paragios", "Jean-Fran\u00e7ois Deux", "Alain Kulski", "R\u00e9my Raymond", "Phillipe Hernigou", "Alain Rahmouni"], "b": "Arthroplasty, the implantation of prostheses into joints, is a surgical procedure that is affecting a larger and larger number of patients over time. As a result, it is increasingly important to develop imaging techniques to noninvasively examine joints with prostheses after surgery, both statically and dynamically in 3-D. The static problem is considered here, with the aim to create a", "cn": 0, "i": 13765786, "k": ["Active Contour", "Level Set", "multi-view stereo", "Multiple Views", "Shape Modeling", "Surgical Procedure", "Three Dimensional", "X Rays", "X-ray Imaging", "Level Set Method"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4556621", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4556621", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04556621", "http://dx.doi.org/10.1109/TMI.2008.927341", "http://www.informatik.uni-trier.de/~ley/db/journals/tmi/tmi28.html#VarshneyPDKRHR09"], "t": "Postarthroplasty Examination Using X-Ray Images", "v": "TMI", "y": 2009, "rn": 27}, {"a": ["Daniel Vlasic", "Pieter Peers", "Ilya Baran", "Paul Debevec", "Jovan Popovi\u0107", "Szymon Rusinkiewicz", "Wojciech Matusik"], "b": "We describe a system for high-resolution capture of moving 3D geometry, beginning with dynamic normal maps from multiple views. The normal maps are captured using active shape-from-shading (photometric stereo), with a large lighting dome providing a series of novel spherical lighting configurations. To compensate for low-frequency deformation, we perform multi-view matching and thin-plate spline deformation on the initial surfaces obtained", "cn": 0, "i": 39245335, "k": ["High Resolution", "Multiple Views", "Photometric Stereo", "Shape From Shading", "Temporal Resolution", "Low Frequency", "Thin Plate Spline"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1618520&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1618520"], "t": "Dynamic shape capture using multi-view photometric stereo", "y": 2009, "rn": 53}, {"a": ["Ali Bigdelou", "Alexander Ladikos", "Nassir Navab"], "b": "We propose a novel algorithm for incrementally reconstructing the visual hull in dy- namic scenes by exploiting temporal consistency. Using the difference in the silhouette images between two frames we can efficiently locate the scene parts that have to be up- dated using ray casting. By only concentrating on the parts of the scene that have to be checked for", "cn": 0, "i": 39258428, "k": ["Perforation", "Ray Casting", "Visual Hull"], "p": ["http://www.bmva.org/bmvc/2009/Papers/Paper198/Abstract198.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2009.html#BigdelouLN09", "http://www.bmva.org/bmvc/2009/Papers/Paper198/Paper198.pdf"], "t": "Incremental Visual Hull Reconstruction", "v": "BMVC", "y": 2009, "rn": 19}, {"a": ["Chenglei Wu", "Xun Cao", "Qionghai Dai"], "b": "We present an algorithm that fuses Multi-view stereo (MVS) and photometric stereo to reconstruct 3D model of objects filmed by multiple cameras under varying illuminations. Firstly, we obtain the surface normal scaled by albedo for each view through photometric stereo techniques. Then, based on the scaled normal, a new correspondence matching method, namely surface-consistency metric, is proposed to acquire accurate", "cn": 0, "i": 50758931, "k": ["3d model", "3d reconstruction", "Matching Method", "multi-view stereo", "Photometric Stereo", "Point Cloud", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05069625", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5069625"], "t": "Accurate 3D reconstruction via surface-consistency", "v": "DTV-CON", "y": 2009, "rn": 12}, {"a": ["Tao Li", "Xiangyang Ji", "Qionghai Dai"], "b": "Depth maps are playing an important role in the multi-view system. For multi-view, depth maps can be used not only for image-based rendering (IBR), but also for multi-view stereo reconstruction by merging depth maps into 3D models. In this paper, we propose a novel approach to recover depth maps for multi-view. The most contribution of our work is the combination", "cn": 0, "i": 50758937, "k": ["3d model", "Belief Propagation", "Depth Map", "Image Based Rendering", "multi-view stereo", "Multiple Views", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5069633", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05069633"], "t": "Depth map recovery for multi-view using belief propagation", "v": "DTV-CON", "y": 2009, "rn": 9}, {"a": ["Xiaoduan Feng", "Yebin Liu", "Qionghai Dai"], "b": "More and more multi-luminance image acquisition systems are designed for relighting. Besides the basic purpose of the multi-luminance images, they can also be adopted to enhance the performance of multi-view stereo. By fusing the point-clouds from images under different luminance setups, a good model of the object can be achieved, with high robustness to image noise, shadows and high-lights. This", "cn": 0, "i": 50758944, "k": ["Image Acquisition", "multi-view stereo", "Point Cloud", "High Light"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5069640", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05069640"], "t": "Multi-view stereo using multi-luminance images", "v": "DTV-CON", "y": 2009, "rn": 7}, {"a": ["Ryo Furuakwa", "Kenji Inose", "Hiroshi Kawasaki"], "b": "Range scanners using projector-camera systems have been studied actively in recent years as methods for measuring 3D shapes accurately and cost-effectively. To acquire an entire 3D shape of an object with such systems, the shape of the object should be captured from multiple directions and the set of captured shapes should be aligned using algorithms such as ICPs. Then, the", "cn": 0, "i": 50782721, "k": ["Bundle Adjustment", "Cost Effectiveness", "Relative Position", "Shape Modeling"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05204318", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5204318"], "t": "Multi-view reconstruction for projector camera systems based on bundle adjustment", "v": "CVPR", "y": 2009, "rn": 18}, {"a": ["Christopher Zach", "Marc Niethammer", "Jan-Michael Frahm"], "b": "Convex and continuous energy formulations for low level vision problems enable efficient search procedures for the corresponding globally optimal solutions. In this work we extend the well-established continuous, isotropic capacity-based maximal flow framework to the anisotropic setting. By using powerful results from convex analysis, a very simple and efficient minimization procedure is derived. Further, we show that many important properties", "cn": 0, "i": 50782824, "k": ["Convex Analysis", "Global Optimization", "Markov Random Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206565", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206565"], "t": "Continuous maximal flows and Wulff shapes: Application to MRFs", "v": "CVPR", "y": 2009, "rn": 26}, {"a": ["Kalin Kolev", "Daniel Cremers"], "b": "We introduce a convex relaxation framework to optimally minimize continuous surface ratios. The key idea is to minimize the continuous surface ratio by solving a sequence of convex optimization problems. We show that such minimal ratios are superior to traditionally used minimal surface formulations in that they do not suffer from a shrinking bias and no longer require the choice", "cn": 0, "i": 50782866, "k": ["3d reconstruction", "Convex Optimization", "Convex Relaxation", "Minimal Surface", "Multiple Views", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206608", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206608"], "t": "Continuous ratio optimization via convex relaxation with applications to multiview 3D reconstruction", "v": "CVPR", "y": 2009, "rn": 21}, {"a": ["Chris Hermans", "Yannick Francken", "Tom Cuypers", "Philippe Bekaert"], "b": "In this paper we present a novel method for 3D structure acquisition, based on structured light. Unlike classical structured light methods, in which a static projector illuminates a scene with time-varying illumination patterns, our technique makes use of a moving projector emitting a static striped illumination pattern. This projector is translated at a constant velocity, in the direction of the", "cn": 0, "i": 50782868, "k": ["3d structure", "Image Sequence", "Specular Reflection", "Structured Light", "Subsurface Scattering", "Dominant Frequency", "Time Varying"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206610", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206610"], "t": "Depth from sliding projections", "v": "CVPR", "y": 2009, "rn": 22}, {"a": ["Yebin Liu", "Xun Cao", "Qionghai Dai", "Wenli Xu"], "b": "Depth-map merging approaches have become more and more popular in multi-view stereo (MVS) because of their flexibility and superior performance. The quality of depth map used for merging is vital for accurate 3D reconstruction. While traditional depth map estimation has been performed in a discrete manner, we suggest the use of a continuous counterpart. In this paper, we first integrate", "cn": 0, "i": 50782968, "k": ["3d model", "3d reconstruction", "Depth Estimation", "Depth Map", "First Integral", "multi-view stereo", "Normalized Cross Correlation", "Variational Method", "Free Viewpoint Video"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206712", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206712"], "t": "Continuous depth estimation for multi-view stereo", "v": "CVPR", "y": 2009, "rn": 28}, {"a": ["Andrei Zaharescu", "Edmond Boyer", "Kiran Varanasi", "R. Horaud"], "b": "In this paper we revisit local feature detectors/descriptors developed for 2D images and extend them to the more general framework of scalar fields defined on 2D manifolds. We provide methods and tools to detect and describe features on surfaces equiped with scalar functions, such as photometric information. This is motivated by the growing need for matching and tracking photometric surfaces", "cn": 0, "i": 50783003, "k": ["3d reconstruction", "Feature Detection", "Local Features", "Scalar Field"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206748", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206748"], "t": "Surface feature detection and description with applications to mesh matching", "v": "CVPR", "y": 2009, "rn": 25}, {"a": ["Brandon Smith", "Li Zhang", "Hailin Jin"], "b": "We propose a novel formulation of stereo matching that considers each pixel as a feature vector. Under this view, matching two or more images can be cast as matching point clouds in feature space. We build a nonparametric depth smoothness model in this space that correlates the image features and depth values. This model induces a sparse graph that links", "cn": 0, "i": 50783046, "k": ["Dynamic Scenes", "Feature Space", "Feature Vector", "Graph Cut", "Image Features", "Image Segmentation", "Nonparametric Smoothing", "Point Cloud", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206793", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206793"], "t": "Stereo matching with nonparametric smoothness priors in feature space", "v": "CVPR", "y": 2009, "rn": 34}, {"a": ["Sebastian Schuon", "Christian Theobalt", "James Davis", "S. Thrun"], "b": "Depth maps captured with time-of-flight cameras have very low data quality: the image resolution is rather limited and the level of random noise contained in the depth maps is very high. Therefore, such flash lidars cannot be used out of the box for high-quality 3D object scanning. To solve this problem, we present LidarBoost, a 3D depth superresolution method that", "cn": 0, "i": 50783057, "k": ["Data Quality", "Depth Map", "High Resolution", "Image Resolution", "Random Noise", "Low Resolution", "Time of Flight"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206804", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206804"], "t": "LidarBoost: Depth superresolution for ToF 3D shape scanning", "v": "CVPR", "y": 2009, "rn": 11}, {"a": ["Tony Tung", "Takashi Matsuyama"], "b": "This paper presents a novel approach to skim and describe 3D videos. 3D video is an imaging technology which consists in a stream of 3D models in motion captured by a synchronized set of video cameras. Each frame is composed of one or several 3D models, and therefore the acquisition of long sequences at video rate requires massive storage devices.", "cn": 0, "i": 50783076, "k": ["3d model", "3d video", "Action Recognition", "Compression Ratio", "Markov Network", "Motion Capture", "Semantic Annotation", "Semantic Description", "Shape Descriptor", "Markov Model"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206823", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206823"], "t": "Topology dictionary with Markov model for 3D video content-based skimming and description", "v": "CVPR", "y": 2009, "rn": 26}, {"a": ["Yongjian Xi", "Ye Duan", "Hongkai Zhao"], "b": "3D point data acquired from laser scan or stereo vision can be quite noisy. A preprocessing step is often needed before a surface reconstruction algorithm can be applied. In this paper, we propose a nonparametric approach for noisy point data preprocessing. In particular, we proposed an anisotropic kernel based nonparametric density estimation method for outlier removal, and a hill-climbing line", "cn": 0, "i": 50797818, "k": ["Data Preprocessing", "Hill Climbing", "Laser Scanning", "Line Search", "Nonparametric Density Estimation", "Stereo Vision", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5246900", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05246900"], "t": "A nonparametric approach for noisy point data preprocessing", "y": 2009, "rn": 20}, {"a": ["Fanyu Kong", "Jindong Tan"], "b": "A new general 3D object model is required in the literature of smart camera networks to facilitate future research. This paper presents a novel hierarchical and structural 3D model description which is well-suited for both events detection and real-time free view-point surveillance. With this 3D model, sparse points are used to reconstruct objects. In addition, the state of the model", "cn": 0, "i": 50808790, "k": ["3d model", "Camera Network", "Data Flow", "Data Structure", "Event Detection", "Object Model", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5289379", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05289379"], "t": "A 3D object model for wireless camera networks with network constraints", "y": 2009, "rn": 32}, {"a": ["Simon Baker", "Daniel Scharstein", "J. Lewis", "Stefan Roth", "Michael Black", "Richard Szeliski"], "b": "The quantitative evaluation of optical flow algorithms by Barron et al. (1994) led to significant advances in performance. The challenges for optical flow algorithms today go beyond the datasets and evaluation methods proposed in that paper. Instead, they center on problems associated with complex natural scenes, including nonrigid motion, real sensor noise, and motion discontinuities. We propose a new set", "cn": 0, "i": 61401166, "k": ["Evaluation Method", "Evaluation Methodology", "Natural Scenes", "Quantitative Evaluation", "Ground Truth", "Next Generation", "Optical Flow"], "p": ["http://research.microsoft.com/apps/pubs/default.aspx?id=117766", "http://research.microsoft.com/pubs/117766/ofevaltr2.pdf"], "t": "A Database and Evaluation Methodology for Optical Flow", "y": 2009, "rn": 76}, {"a": ["Martin Habbecke", "Leif Kobbelt"], "b": "While many techniques for the 3D reconstruction of small to medium sized objects have been proposed in recent years, the reconstruction of entire scenes is still a challenging task. This is especially true for indoor environments where existing active reconstruction techniques are usually quite expensive and passive, image-based techniques tend to fail due to high scene complexities, difficult lighting situations,", "cn": 0, "i": 4318040, "k": ["3d reconstruction", "Depth Map", "Indoor Environment", "Laser Pointer", "Sampling Technique"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1364933&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1364933", "http://www.informatik.uni-trier.de/~ley/db/conf/sma/spm2008.html#HabbeckeK08", "http://doi.acm.org/10.1145/1364901.1364933"], "t": "Laser brush: a flexible device for 3D reconstruction of indoor scenes", "v": "SMA", "y": 2008, "rn": 30}, {"a": ["Doron Tal", "Ilan Shimshoni", "Ayellet Tal"], "b": "Augmented reality is concerned with combining real-world data, such as images, with artifcial data. Texture replacement is one such task. It is the process of painting a new texture over an existing textured image patch, such that depth cues are maintained. This paper proposes a general and automatic approach for performing texture replacement, which is based on multiview stereo techniques", "cn": 0, "i": 4323413, "k": ["Augmented Reality", "Estimation Algorithm"], "p": ["http://portal.acm.org/citation.cfm?id=1450619", "http://portal.acm.org/ft_gateway.cfm?id=1450619&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1450579.1450619", "http://www.informatik.uni-trier.de/~ley/db/conf/vrst/vrst2008.html#TalST08"], "t": "Image-based texture replacement using multiview images", "v": "VRST", "y": 2008, "rn": 30}, {"a": ["Yoshihisa Shinagawa", "Minh Do"], "b": "We present a novel stereo algorithm which performs sur- face reconstruction from planar camera arrays. It incorpo- rates the merits of both generic camera arrays and rectified binocular setups, recovering large surfaces like the forme r and performing efficient computations like the latter. Firs t, we introduce a rectification algorithm which gives freedom in the design of camera arrays and", "cn": 0, "i": 4704521, "k": ["Layered Depth Image", "multi-view stereo", "Data Fusion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587425", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587425", "http://dx.doi.org/10.1109/CVPR.2008.4587425", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#MaitreSD08", "http://www.ifp.illinois.edu/%7Eminhdo/publications/multiview_stereo_cvpr08.pdf", "http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/085.pdf"], "t": "Symmetric multi-view stereo reconstruction from planar camera arrays", "v": "CVPR", "y": 2008, "rn": 25}, {"a": ["Nirmalya Ghosh", "Bir Bhanu"], "b": "In a video sequence with a 3D rigid object moving, changing shapes of the 2D projections provide interrelated spatio-temporal cues for incremental 3D shape reconstruction. This paper describes a probabilistic approach for intelligent view-integration to build 3D model of vehicles from traffic videos collected from an uncalibrated static camera. The proposed Bayesian net framework allows the handling of uncertainties in", "cn": 0, "i": 4716442, "k": [".net framework", "3d model", "3d shape reconstruction", "Indexing Terms", "Probabilistic Approach"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2008.html#GhoshB08", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4711964", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04711964", "http://www-video.eecs.berkeley.edu/Proceedings/ICIP2008/pdfs/0001152.pdf", "http://dx.doi.org/10.1109/ICIP.2008.4711964"], "t": "Bayesian based 3D shape reconstruction from video", "v": "ICIP", "y": 2008, "rn": 14}, {"a": ["Adrien Auclair", "Nicole Vincent", "Laurent Cohen"], "b": "This paper proposes a novel algorithm to reconstruct a 3D surface from a calibrated set of images. In a first pass, it uses Scale Invariant Features Transform (SIFT) descriptor corre- spondences to drive the deformation of a mesh toward the true object surface. We introduce a method to handle the fact that these local descriptors are computed at positions that", "cn": 0, "i": 4716717, "k": ["Indexing Terms", "multi-view stereo", "Scale Invariant Feature Transform", "lucas kanade"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4711724", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04711724", "http://dx.doi.org/10.1109/ICIP.2008.4711724", "http://www.ceremade.dauphine.fr/~cohen/mypapers/auclairICIP08.pdf", "http://www-video.eecs.berkeley.edu/Proceedings/ICIP2008/pdfs/0000193.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2008.html#AuclairVC08"], "t": "Using point correspondences without projective deformation for multi-view stereo reconstruction", "v": "ICIP", "y": 2008, "rn": 8}, {"a": ["Matthew Grum", "Adrian Bors"], "b": "In this paper we present a new approach for mod- elling multiple object scenes using images taken from various viewpoints. The voxel representation produced by the space carving is used for estimating the param- eters of radial basis function functions (RBFs). A new methodology is proposed for correcting the modelling errors within the RBF framework, by enforcing consis- tency with", "cn": 0, "i": 4718130, "k": ["Multiple Objectives", "Radial Basis Function"], "p": ["http://dx.doi.org/10.1109/ICPR.2008.4760980", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04760980", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4760980", "http://www-users.cs.york.ac.uk/~adrian/Papers/Conferences/ICPR08a.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2008.html#GrumB08"], "t": "Enforcing image consistency in multiple 3-D object modelling", "v": "ICPR", "y": 2008, "rn": 11}, {"a": ["Masahiro Toyoura", "Masaaki Iiyama", "Takuya Funatomi", "Koh Kakusho", "Michihiko Minoh"], "b": "", "cn": 0, "i": 4718669, "k": ["3d shape reconstruction"], "p": ["http://www.iiyama-lab.org/publication/miru2008-toyo.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4761591", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04761591", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2008.html#ToyouraIFKM08", "http://dx.doi.org/10.1109/ICPR.2008.4761591"], "t": "3D Shape Reconstruction from Incomplete Silhouettes in Multiple Frames", "y": 2008, "rn": 34}, {"a": ["Shuda Li", "Kwan-Yee Wong", "Dirk Schnieders"], "b": "This paper deals with the problems of scene illumination estimation and shape recovery from an image sequence of a smooth textureless object. A novel method that exploits the surface points estimated from the silhouettes for recovering the scene illumination is introduced. Those surface points are acquired by a dual space approach and filtered according to their rank errors. Selected surface", "cn": 0, "i": 5337353, "k": ["Closed Form Solution", "Dual Space", "Image Sequence", "Point Estimation", "Shape Recovery", "Visual Hull"], "p": ["http://i.cs.hku.hk/~sdirk/paper/bmvc2008.pdf", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/papers/245.pdf", "http://i.cs.hku.hk/~kykwong/publications/sli_bmvc08.pdf", "http://www.bmva.org/bmvc/2008/papers/245.pdf", "http://www.bmva.org/bmvc/2008/papers/237.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2008.html#LiWS08"], "t": "Using Illumination Estimated from Silhouettes to Carve Surface Details on Visual Hull", "v": "BMVC", "y": 2008, "rn": 18}, {"a": ["Alex Rav-Acha", "Pushmeet Kohli", "Carsten Rother", "Andrew Fitzgibbon"], "b": "We introduce a new representation for video which facilitates a number of common editing tasks. The representation has some of the power of a full reconstruction of 3D surface models from video, but is designed to be easy to recover from a priori unseen and uncalibrated footage. By modelling the image-formation process as a 2D-to-2D transformation from an object's texture", "cn": 0, "i": 39243763, "k": ["Deformable Objects", "Image Formation", "Motion Estimation", "Surface Model", "Texture Mapping", "Video Editing"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1360616&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1360616"], "t": "Unwrap mosaics: a new representation for video editing", "y": 2008, "rn": 35}, {"a": ["Derek Bradley", "Tiberiu Popa", "Alla Sheffer", "Wolfgang Heidrich", "Tamy Boubekeur"], "b": "A lot of research has recently focused on the problem of capturing the geometry and motion of garments. Such work usually relies on special markers printed on the fabric to establish temporally coherent correspondences between points on the garment's surface at different times. Unfortunately, this approach is tedious and prevents the capture of off-the-shelf clothing made from interesting fabrics. In", "cn": 0, "i": 39243844, "k": ["Image Processing", "Motion Capture", "Surface Reconstruction", "Temporal Coherence", "Off The Shelf"], "p": ["http://portal.acm.org/citation.cfm?id=1360698", "http://portal.acm.org/ft_gateway.cfm?id=1360698&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "Markerless garment capture", "y": 2008, "rn": 30}, {"a": ["Ioana Gheta", "Michael Heizmann", "Jurgen Beyerer"], "b": "This contribution presents a fusion method for multivariate stereo and spectral series with the purpose of obtaining 3D information. The image series are gained using a camera array with spectral filters. In order to register them, features that are invariant with respect to the intensity values in the images are extracted. The fusion approach is region based and uses characteristics", "cn": 0, "i": 50684450, "k": ["Energy Function", "Image Fusion", "Watershed Transform"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4632420", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04632420"], "t": "Bayesian fusion of multivariate image to obtain depth information", "y": 2008, "rn": 12}, {"a": ["Bo Xiang", "Xiaopeng Zhang", "Wei Ma", "Hongbin Zhang"], "b": "We present an algorithm to automatically extract skeletons for branched volumes by shape decomposition. First, a region growing strategy is adopted based on a distance transformation to decompose a volume into several meaningful components with simple topological structures. Then, the skeleton of each component is individually extracted. Finally, the skeletons of all the components are integrated and a structural skeleton", "cn": 0, "i": 50701322, "k": ["Distance Transform", "Region Growing", "Volume Data"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4662984", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04662984"], "t": "Skeletonization of Branched Volume by Shape Decomposition", "v": "CCPR", "y": 2008, "rn": 21}, {"a": ["Pau Gargallo", "Peter Sturm", "Sergi Pujades"], "b": "This paper presents an occupancy based generative model of stereo and multi-view stereo images. In this model, the space is divided into empty and occupied regions. The depth of a pixel is naturally de- termined from the occupancy as the depth of the first occupied point in its viewing ray. The color of a pixel corresponds to the color of", "cn": 0, "i": 4230452, "k": ["Depth Map", "Generic Model", "Message Passing", "multi-view stereo"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2007-2.html#GargalloSP07", "http://www.springerlink.com/index/cq7g337054260318.pdf", "http://www.springerlink.com/content/cq7g337054260318", "http://dx.doi.org/10.1007/978-3-540-76390-1_37"], "t": "An Occupancy-Depth Generative Model of Multi-view Images", "v": "ACCV", "y": 2007, "rn": 16}, {"a": ["Chang Yuan", "G\u00e9rard Medioni"], "b": "We present a novel approach to inferring 3D volumetric shape of both moving objects and static background from video sequences shot by a moving camera, with the assump- tion that the objects move rigidly on a ground plane. The 3D scene is divided into a set of volume elements, termed as voxels, organized in an adaptive octree structure. Each voxel", "cn": 0, "i": 4247932, "k": ["Graph Cut", "Moving Object"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2007.html#YuanM07", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04270315", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4270315", "http://iris.usc.edu/Outlines/papers/2007/yuan-medi-cvpr07.pdf", "http://dx.doi.org/10.1109/CVPR.2007.383290", "http://iris.usc.edu/~cyuan/cvpr07.pdf"], "t": "Inferring 3D Volumetric Shape of Both Moving Objects and Static Background Observed by a Moving Camera", "v": "CVPR", "y": 2007, "rn": 21}, {"a": ["Chang Yuan"], "b": "Acknowledgments My first thanks go to my advisor, Professor G\u00b4erard Medioni, who has guided me through every aspect of academic research and helped me build a high-level perspective of the computer vision field. My PhD research would not be accomplished without his enlightening ideas, insightful comments and warm support. I appreciate the constructive advice and precious experience shared by Professor", "cn": 0, "i": 4550549, "k": ["Computer Vision", "Motion Segmentation", "Moving Object", "Table of Contents"], "p": [], "t": "MOTION SEGMENTATION AND DENSE RECONSTRUCTION OF SCENES CONTAINING MOVING OBJECTS OBSERVED BY A MOVING CAMERA", "y": 2007, "rn": 78}, {"a": ["Gang Li", "Yakup Genc", "Steven Zucker"], "b": "A limitation of the state-of-art multi-view reconstruction algorithms is in their ability to handle scenes with very lit- tle texture or a lot of clutter. Texture-less scenes with clutter are traditionally difficult for dense multi-view stereo meth- ods. Feature-based stereo algorithms, in particular, edge- based methods, are better suited for these scenes. The suc- cess of the edge-based reconstruction heavily", "cn": 0, "i": 4592213, "k": ["Geometric Constraints", "multi-view stereo", "Prior Information", "Reconstruction Algorithm", "Spatial Coherence", "Three Dimensional"], "p": ["http://dx.doi.org/10.1109/3DIM.2007.35", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4296774", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04296774", "http://cs-www.cs.yale.edu/homes/li-gang/publication/3dim07.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2007.html#LiGZ07"], "t": "Multi-View Edge-based Stereo by Incorporating Spatial Coherence", "v": "3DIM", "y": 2007, "rn": 24}, {"a": ["Alan Brunton", "Stefanie Wuhrer", "Chang Shu"], "b": "Geometric models created from range sensors are usu- ally incomplete. Considerable effort has been made to fix this problem, ranging from manual repairing to geometric interpolation. We propose using multi-view stereo to com- plete such models. Our approach is practical and conve- nient because when scanning and object or environment one usually takes photographs to texture the resulting model. By", "cn": 0, "i": 4825115, "k": ["3d model", "Boundary Condition", "Boundary Value Problem", "Classical Solution", "Digital Image", "Geometric Model", "image-based modeling", "Interpolation Method", "Local Minima", "Mesh Deformation", "multi-view stereo", "Shape From Shading", "Variational Formulation", "Level Set Method"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2007.html#BruntonWS07", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4296769", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04296769", "http://cg.scs.carleton.ca/~swuhrer/Publications/ImageModelComplete.pdf", "http://dx.doi.org/10.1109/3DIM.2007.29", "http://www.site.uottawa.ca/~abrunton/publications/holefill_3dim07.pdf"], "t": "Image-based Model Completion", "v": "3DIM", "y": 2007, "rn": 18}, {"a": ["Jean-daniel Desch\u00eanes", "Philippe Lambert", "Simon Perreault", "Nicolas Martel-brisson", "Nathaniel Zoso", "Andr\u00e9 Zaccarin", "Patrick H\u00e9bert", "Samuel Bouchard", "Cl\u00e9ment Gosselin"], "b": "This paper presents the full proof of concept of a system for capturing the light field of an object. It is based on a single high resolution camera that is moved all around the object on a cable-driven end-effector. The main advantages of this system are its scalability and low interference with scene lighting. The camera is accurately positioned along", "cn": 0, "i": 6026384, "k": ["Light Field", "Parallel Mechanism", "High Resolution Camera", "Proof of Concept", "Visual Hull"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2007.html#DeschenesLPMZZHBG07", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4296777", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04296777", "http://dx.doi.org/10.1109/3DIM.2007.4"], "t": "A Cable-driven Parallel Mechanism for Capturing Object Appearance from Multiple Viewpoints", "v": "3DIM", "y": 2007, "rn": 11}, {"a": ["Cevahir \u00c7", "Aydin Alatan"], "b": "A novel multi-view region-based dense depth map estimation problem is presented, based on a modified plane-sweeping strategy. In this approach, the whole scene is assumed to be region-wise planar. These planar regions are defined by back-projections of the over-segmented homogenous color regions on the images and the plane parameters are determined by angle-sweeping at different depth levels. The position and", "cn": 0, "i": 10447707, "k": ["Cost Function", "Depth Map", "Indexing Terms", "multi-view stereo", "Search Algorithm"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4298869", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04298869", "http://www-video.eecs.berkeley.edu/Proceedings/ICIP2007/pdfs/0500213.pdf"], "t": "Region-Based Dense Depth Extraction from Multi-View Video", "v": "SIU", "y": 2007, "rn": 12}, {"a": ["Noah Snavely", "Steven Seitz", "Richard Szeliski"], "b": "There are billions of photographs on the Inter- net, comprising the largest and most diverse photo collec- tion ever assembled. How can computer vision researchers exploit this imagery? This paper explores this question from the standpoint of 3D scene modeling and visualization. We present structure-from-motion and image-based rendering algorithms that operate on hundreds of images downloaded as a result of", "cn": 0, "i": 61402248, "k": ["3d model", "3d navigation", "3d scene analysis", "Computer Vision", "Image Based Rendering", "Image Search", "Photo Collection", "Structure From Motion"], "p": [], "t": "Modeling the World from Internet Photo Collections", "y": 2007, "rn": 76}, {"a": ["W. Hansen", "L. Goola"], "b": "In this paper we want to start the discussion on whether image based 3-D modelling techniques and especially multi-view stereo can possibly be used to replace LIDAR systems for outdoor 3D data acquisition. Two main issues have to be addressed in this context: (i) camera self-calibration and (ii) dense multi-view depth estimation. To investigate both, we have acquired test data", "cn": 0, "i": 4494100, "k": ["3d model", "Close Range Photogrammetry", "Data Acquisition", "Depth Estimation", "Distance Measure", "Generic Model", "multi-view stereo", "Point Cloud", "Time of Flight"], "p": ["http://www.pf.bv.tum.de/isprs/pia07/pubb/PIA07_Strecha_et_al.pdf", "http://www.ipk.bv.tum.de/isprs/pia07/pubb/PIA07_Strecha_et_al.pdf"], "t": "MULTI-VIEW STEREO AND LIDAR FOR OUTDOOR SCENE MODELLING", "y": 0, "rn": 16}, {"a": ["Kuk-Jin Yoon", "Pau Gargallo", "Peter Sturm"], "b": "In this paper, we present a variational method that re- covers both the shape and the reflectance of the Lambertian scene using multiple images. Although we consider only Lambertian surfaces in this paper, the proposed method, which is global and completely model based, is the first and unavoidable stage for reaching a shape and reflectance es- timation method for non-Lambertian", "cn": 0, "i": 4808315, "k": ["Shape From Shading", "Variational Method"], "p": ["http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Inproceedings@1176ddd04d5_20ade1/p35.pdf", "http://hal.archives-ouvertes.fr/docs/00/26/49/03/PDF/p35.pdf"], "t": "Toward Global and Model based Multiview Stereo Methods for Shape and Reflectance Estimation", "y": 0, "rn": 29}, {"a": ["Neil Birkbeck", "Martin Jagersand", "Dana Cobzas"], "b": "Abstract We propose a method that makes standard turntable-based vision acquisi- tion a practical method for recovering models of human,geometry. A human subject typically exhibits some unintended joint motion while rotating on a turntable. Ignoring such motion causes shape-from-silhouette to excessively carve the model, resulting in loss of geometry (especially on limbs). We uti- lize silhouette cues and appearance consistency", "cn": 0, "i": 4930886, "k": ["Cost Effectiveness", "Human Subjects", "Laser Scanning", "Rigid Body", "Shape From Silhouette"], "p": ["http://www.cs.ualberta.ca/TechReports/2009/TR09-03/TR09-03.pdf"], "t": "Tracking human joint motion for turntable-based static model reconstruction", "y": 0, "rn": 30}, {"a": ["Colin Zheng"], "b": "", "cn": 0, "i": 4982892, "k": [], "p": ["http://colinzheng.org/wp-content/data/research/papers/thesis_uw08.pdf", "http://grail.cs.washington.edu/theses/ZhengPhd.pdf"], "t": "Parallax Photography: Creating 3D Motions from Stills", "y": 0, "rn": 107}, {"a": ["J. Kilner"], "b": "", "cn": 0, "i": 4989268, "k": ["Free Viewpoint Video"], "p": ["http://personal.ee.surrey.ac.uk/Personal/J.Kilner/Kilner06TransferReport.pdf"], "t": "Free-Viewpoint Video for Outdoor Sporting Events", "y": 0, "rn": 45}, {"a": ["V. Krishna"], "b": "Acknowledgments I would like to thank my supervisor Dr. P.J. Narayanan for his support and guidance through the past  ve years. I am thankful to him for introducing me to the world of computer,graphics. I would like to thank my parents for their support and motivation. Last but not the least, I would like to thank all the members of", "cn": 0, "i": 5197409, "k": ["3d structure", "Computer Graphic", "Computer Vision", "Image Based Rendering", "Machine Learning", "Pattern Recognition", "Video Streaming", "information tech nology"], "p": ["http://cvit.iiit.ac.in/thesis/vkrishnaMS2006/vkrishnaThesis2006.pdf"], "t": "DGTk: A Data Generation Toolkit", "y": 0, "rn": 14}, {"a": ["Patrick Labatut", "Jean-Philippe Pons", "Renaud Keriven"], "b": "Abstract We present a novel method,to reconstruct the 3D shape of a scene from seve- ral calibrated images. Our motivation is that most existing multi-view stereovi- sion approaches require some knowledge,of the scene extent and often even of its approximate,geometry,(e.g.visual hull). This makes these approaches mainly suited to compact objects admitting a tight enclosing box, imaged on a simple or", "cn": 0, "i": 5429013, "k": ["3d point cloud", "Compact Object", "Large Scale", "Multiple Views", "Surface Reconstruction", "Visual Hull"], "p": ["http://certis.enpc.fr/publications/papers/07certis34.pdf"], "t": "Voronoi Features Cut for Surface Reconstruction from Multiple Views", "y": 0, "rn": 43}, {"a": ["Bellmann Anke", "Hellwich Olaf", "Rodehorst Volker", "Yilmaz Ulas"], "b": "In this study, we present our benchmark dataset for performance evaluation of shape-from-X algorithms and a test procedure for evaluating the reconstruction results. Our aim is to support an objective comparison of different surface reconstruction approaches and to provide an informative basis for the combination of reconstruction methods.", "cn": 0, "i": 5752145, "k": ["Performance Evaluation", "Surface Reconstruction"], "p": ["http://www.isprs.org/congresses/beijing2008/proceedings/3b_pdf/13.pdf"], "t": "A BENCHMARK DATASET FOR PERFORMANCE EVALUATION OF SHAPE-FROM-X ALGORITHMS", "y": 0, "rn": 17}, {"a": ["Kuk-Jin Yoon", "Emmanuel Prados", "Peter Sturm", "Ama\u00ebl Delaunoy", "Pau Gargallo"], "b": "Abstract: We develop a variational method to recover both the shape and the reflectance of a scene surface(s) using multiple images, assuming that illumination conditions are fixed and known in ad- vance. Scene and image formation are modeled,with known,information about cameras and illumi- nants, and scene recovery is achieved by minimizing a global cost functional with respect to both shape", "cn": 0, "i": 6018085, "k": ["Cost Function", "Image Formation", "Specular Reflection", "Synthetic Data", "Variational Method"], "p": ["http://perception.inrialpes.fr/Publications/2007/YPSDG07/YoonPradosSturmDelaunoyGargallo-rr6309.pdf", "http://hal.inria.fr/docs/00/17/53/49/PDF/RR-6309.pdf"], "t": "Shape and Reflectance Recovery using Multiple Images with Known Illumination Conditions", "y": 0, "rn": 27}, {"a": ["Philippe Lambert", "Patrick H\u00e9bert"], "b": "This paper proposes a robust algorithm that finds a proxy surface from a series of calibrated pictures of an object without assuming any of its reflectance properties. This proxy is optimized to reduce view interpolation errors by globally minimizing the frequency criterion proposed in (1). The generality of this setting makes robustness par- ticularly difficult to achieve since no model", "cn": 0, "i": 6556036, "k": ["Global Analysis", "multi-view stereo", "Robust Estimator", "View Interpolation"], "p": ["http://vision.gel.ulaval.ca/~hebert/pdf/lambert09.pdf"], "t": "Robust Multi-View Stereo without Matching", "y": 0, "rn": 8}, {"a": ["Pier Dragotti", "Mike Brookes"], "b": "This paper presents a categorisation of image-based modelling (IBM) algorithms based on their approach to the IBM problem. This categorisation groups the algorithms into three classes, surface reduction, depth map and sparse point algorithms. We then cover a further four key considerations or aspects related to choosing and designing an IBM algorithm, scene type, prior information, type of features and", "cn": 0, "i": 6655884, "k": ["Depth Map", "multi-view stereo", "Prior Information", "Similarity Measure"], "p": ["http://www.seasdtc.com/events/2009_conference/downloads/pdf/sensor_exploitation/A9_(SEN003)_paper.pdf", "http://www.ee.ic.ac.uk/hp/staff/dmb/pubs/dragotti2009.pdf", "http://www.ee.imperial.ac.uk/hp/staff/dmb/pubs/dragotti2009.pdf"], "t": "A Review of Image-Based Modelling Techniques", "y": 0, "rn": 16}, {"a": ["Hideo Saito"], "b": "Abstract  Research ,on  image ,processing  and  computer ,vision  for  multiple  viewpoint ,images ,has  extensively  been  performed in recent years.  Free viewpoint image generation has especially been attracting a great deal of attention, because is can be applied to highly immersive visual communications and broadcasting in the next generation.  In this article, I would like to introduce related researches to free", "cn": 0, "i": 6737488, "k": ["Camera Calibration", "Computer Vision", "Image Generation", "Mixed Reality", "Shape Recovery", "Visual Communication", "Next Generation"], "p": ["http://www.viri.osakac.ac.jp/symposium07/saito.pdf"], "t": "Free Viewpoint Image Generation from Multiple Viewpoint Images and its Application to Mixed Reality Presentation", "y": 0, "rn": 16}, {"a": ["Kush Varshneya", "Nikos Paragios", "Alain Kulski", "Remy Raymond", "Phillipe Hernigou", "Alain Rahmouni"], "b": "In total knee replacement surgery, also known as total knee arthro- plasty, prosthetics are implanted in the knee joint as treatment for progressive diseases such as arthritis or trauma. In this paper, we aim to recover the 3-D shape of bones and prosthetic devices in patients who have undergone total knee replacement. Such an ob- jective is addressed using a", "cn": 0, "i": 10401368, "k": ["Calculus of Variation", "Indexing Terms", "Knee Joint", "Level Set", "multi-view stereo", "Objective Function", "Total Knee Replacement", "X Rays", "X-ray Imaging", "Gradient Descent", "Level Set Method", "Progressive Disease"], "p": ["http://vision.mas.ecp.fr/pub/isbi07-01.pdf", "http://web.mit.edu/krv/www/pubs/VarshneyPKRHR_isbi2007.pdf", "http://www.mit.edu/~krv/pubs/VarshneyPKRHR_isbi2007.pdf", "http://stuff.mit.edu/people/krv/pubs/VarshneyPKRHR_isbi2007.pdf", "http://mit.edu/krv/www/pubs/VarshneyPKRHR_isbi2007.pdf", "http://projects.csail.mit.edu/atemuri/wiki/images/d/d4/VarshneyPKRHR_isbi2007.pdf", "http://www.mas.ecp.fr/vision/Personnel/nikos/pub/isbi07-01.pdf"], "t": "MULTI-VIEW STEREO RECONSTRUCTION OF TOTAL KNEE REPLACEMENT FROM X-RAYS", "y": 0, "rn": 13}, {"a": ["Branislav Mi", "Jana Ko"], "b": "City environments often lack textured areas, contain repetitive structures, strong lighting changes and there- fore are very difficult for standard 3D modeling pipelines. We present a novel unified framework for creating 3D city models which overcomes these difficulties by exploiting im- age segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. Given panoramic street view", "cn": 0, "i": 11438603, "k": ["3d city model", "3d model", "3d reconstruction", "Bundle Adjustment", "multi-view stereo", "Urban Environment"], "p": ["http://ai.stanford.edu/~micusik/Papers/Micusik-Kosecka-CVPR09.pdf", "http://cs.gmu.edu/~kosecka/Publications/Micusik-Kosecka-CVPR09.pdf"], "t": "Piecewise Planar City 3D Modeling from Street View Panoramic Sequences", "y": 0, "rn": 20}, {"a": ["Branislav ik"], "b": "Man-made environments possess many regularities which can be efficiently exploited for 3D dense reconstruction from multiple widely separated views. We present an approach utilizing properties of piecewise planarity and restricted num- ber of plane orientations to suppress the ambiguities causing failures of standard dense stereo methods. We formulate the problem of the 3D reconstruction in MRF framework built on an", "cn": 0, "i": 11554041, "k": ["3d reconstruction"], "p": ["http://cs.gmu.edu/~kosecka/Publications/Micusik-Kosecka-GMUTechRep08.pdf"], "t": "Multi-view Superpixel Stereo in Man-made Environments", "y": 0, "rn": 16}, {"a": ["Aydin Alatan"], "b": "A novel multi-view region-based dense depth map estimation problem is presented, based on a modified plane-sweeping strategy. In this approach, the whole scene is assumed to be region-wise planar. These planar regions are defined by back-projections of the over- segmented homogenous color regions on the images and the plane parameters are determined by angle-sweeping at different depth levels. The position", "cn": 0, "i": 11656471, "k": ["Cost Function", "Depth Map", "Search Algorithm"], "p": ["http://www.eee.metu.edu.tr/~cevahir/siu2007.pdf"], "t": "\u00c7OKLU V\u0130DEO G\u00d6R\u00dcNT\u00dcS\u00dcNDEN B\u00d6L\u00dcT TABANLI SIK DER\u0130NL\u0130K HAR\u0130TASI \u00c7IKARIMI REGION-BASED DENSE DEPTH EXTRACTION FROM MULTI-VIEW VIDEO", "y": 0, "rn": 12}, {"a": ["Douglas Lanman", "Daniel Hauagge", "Gabriel Taubin"], "b": "We present a new method for reconstructing the 3-D sur- face of an opaque object from the motion of its depth dis- continuities, when viewed under orthographic projection as the object undergoes rigid rotation on a turntable. A novel shape completion scheme is introduced to fill in gaps in the recovered surface, which would otherwise be impossi- ble to reconstruct", "cn": 0, "i": 13362371, "k": ["Point Source"], "p": ["http://mesh.brown.edu/dlanman/research/3DIM%202009/Lanman-orthoflash-3DIM-2009.pdf"], "t": "Shape from Depth Discontinuities under Orthographic Projection", "y": 0, "rn": 28}, {"a": ["Mark Keck", "James Davis"], "b": "In this work we propose algorithms to learn the locations of static occlusions and reason about both static and dynamic occlusion\n scenarios in multi-camera scenes for 3D surveillance (e.g.,\u00a0reconstruction, tracking). We will show that this leads to a computer system which is able to more effectively track (follow)\n objects in video when they are obstructed from some of the views.", "cn": 0, "i": 48223353, "k": ["Probabilistic Model", "Markov Random Field", "Visual Hull"], "p": ["http://www.springerlink.com/index/p34v307m1778111r.pdf", "http://www.springerlink.com/content/p34v307m1778111r"], "t": "Recovery and Reasoning About Occlusions in 3D Using Few Cameras with Applications to 3D Tracking", "v": "IJCV", "y": 0, "rn": 47}, {"a": ["Andrea Albarelli", "Emanuele Rodol\u00e0", "Andrea Torsello"], "b": "Most Structure from Motion pipelines are based on the iterative refinement of an initial batch of feature correspondences.\n Typically this is performed by selecting a set of match candidates based on their photometric similarity; an initial estimate\n of camera intrinsic and extrinsic parameters is then computed by minimizing the reprojection error. Finally, outliers in the\n initial correspondences are filtered by", "cn": 0, "i": 48329627, "k": ["Game Theory", "Geometric Constraints", "Image Features", "Iterative Refinement", "Parameter Estimation", "Structure From Motion", "Theoretical Framework"], "p": ["http://www.springerlink.com/index/v5638h451x873432.pdf", "http://www.springerlink.com/content/v5638h451x873432"], "t": "Imposing Semi-Local Geometric Constraints for Accurate Correspondences Selection in Structure from Motion: A Game-Theoretic Perspective", "v": "IJCV", "y": 0, "rn": 42}, {"a": ["Ama\u00ebl Delaunoy", "Emmanuel Prados"], "b": "This article tackles the problem of using variational methods for evolving 3D deformable surfaces. We give an overview of\n gradient descent flows when the shape is represented by a triangular mesh-based surface, and we detail the gradients of two\n generic energy functionals which embody a number of energies used in mesh processing and computer vision. In particular, we\n show how", "cn": 0, "i": 48380463, "k": ["3d reconstruction", "Computer Vision", "Energy Function", "Energy Use", "Gradient Flow", "Multiple Views", "Triangle Mesh", "Triangular Mesh", "Variational Method", "Gradient Descent"], "p": ["http://www.springerlink.com/index/y0743619115g1114.pdf", "http://www.springerlink.com/content/y0743619115g1114"], "t": "Gradient Flows for Optimizing Triangular Mesh-based Surfaces: Applications to 3D Reconstruction Problems Dealing with\u00a0Visibility", "v": "IJCV", "y": 0, "rn": 51}, {"a": ["Arnav Bhavsar", "A. Rajagopalan"], "b": "Traditional depth estimation methods typically exploit the effect of either the variations in internal parameters such as aperture and focus (as in depth from defocus), or variations in extrinsic parameters such as position and orientation of the camera (as in stereo). When operating off-the-shelf\n (OTS) cameras in a general setting, these parameters influence the depth of field (DOF) and field", "cn": 0, "i": 48394773, "k": ["Belief Propagation", "Camera Motion", "Depth Estimation", "Depth Map", "Image Acquisition", "image inpainting", "Motion Parallax", "multi-view stereo", "Depth From Defocus", "Depth of Field", "Field of View", "Off The Shelf"], "p": ["http://www.springerlink.com/index/1216q321887522w4.pdf", "http://www.springerlink.com/content/1216q321887522w4"], "t": "Towards Unrestrained Depth Inference with Coherent Occlusion Filling", "v": "IJCV", "y": 0, "rn": 43}, {"a": ["Adrian Hilton", "Jean-Yves Guillemaut", "Joe Kilner", "Oliver Grau", "Graham Thomas"], "b": "\n Free-viewpoint video in sports TV production presents a challenging problem involving the conflicting requirements of broadcast\n picture quality with video-rate generation of novel views, together with practical problems in developing robust systems for\n cost effective deployment at live events.To date most multiple view video systems have been developed for studio applications\n with a fixed capture volume, controlled illumination and backgrounds.", "cn": 0, "i": 48537691, "k": ["Cost Effectiveness", "Football", "Multiple Views", "Visual Quality", "Free Viewpoint Video"], "p": ["http://www.springerlink.com/index/h82wjw81966gr131.pdf", "http://www.springerlink.com/content/h82wjw81966gr131"], "t": "Free-Viewpoint Video for TV Sport Production", "y": 0, "rn": 44}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "\n This article presents an algorithm to achieve accurate camera calibration for 3D reconstruction/visualization systems observing\n static scenes. The advent of high-resolution digital cameras, and sophisticated 3D reconstruction algorithms such as multi-view\n stereo offer the promise of unprecedented geometric fidelity in image-based modeling tasks, but it also puts unprecedented\n demands on camera calibration to fulfill these promises. Camera calibration is an", "cn": 0, "i": 48712078, "k": ["3d reconstruction", "Bundle Adjustment", "Camera Calibration", "Digital Camera", "High Resolution", "image-based modeling", "multi-view stereo", "Visual System"], "p": ["http://www.springerlink.com/index/u145m326h853mr1t.pdf", "http://www.springerlink.com/content/u145m326h853mr1t"], "t": "Combining Multi-view Stereo and Bundle Adjustment for Accurate Camera Calibration", "y": 0, "rn": 19}, {"a": ["Yasutaka Furukawa", "Jean Ponce"], "b": "\n This article proposes a novel approach to nonrigid, markerless motion capture from synchronized video streams acquired by\n calibrated cameras. The instantaneous geometry of the observed scene is represented by a polyhedral mesh with fixed topology.\n The initial mesh is constructed in the first frame using the publicly available PMVS software for multi-view stereo (Furukawa\n and Ponce, PMVS, 2008). Its deformation", "cn": 0, "i": 48743464, "k": ["Motion Capture", "multi-view stereo", "Time Use", "Video Streaming"], "p": ["http://www.springerlink.com/index/vn133336q3k6w775.pdf", "http://www.springerlink.com/content/vn133336q3k6w775"], "t": "Dense 3D Motion Capture from Synchronized Video Streams", "y": 0, "rn": 22}, {"a": ["George Vogiatzis", "Carlos Hern\u00e1ndez"], "b": "This paper addresses the problem of obtaining 3d detailed reconstructions of human faces in real-time and with inexpensive\n hardware. We present an algorithm based on a monocular multi-spectral photometric-stereo setup. This system is known to capture\n high-detailed deforming 3d surfaces at high frame rates and without having to use any expensive hardware or synchronized light\n stage. However, the main challenge", "cn": 0, "i": 48799660, "k": ["3d model", "Diffuse Reflectance", "Motion Capture", "multi-view stereo", "Non-linear Optimization", "Photometric Stereo", "Reflection Model", "Structure From Motion", "Multi Spectral"], "p": ["http://www.springerlink.com/index/6v66603qv30j4823.pdf", "http://www.springerlink.com/content/6v66603qv30j4823"], "t": "Self-calibrated, Multispectral Photometric Stereo for 3D Face Capture", "v": "IJCV", "y": 0, "rn": 26}, {"a": ["Charlotte Boden", "Abhir Bhalerao"], "b": "\n The ability to model 3D objects from monocular video allows for a number of very useful applications, for instance: 3D face\n recognition, fast prototyping and entertainment. At present there are a number of methods available for 3D modelling from\n this and similar data. However many of them are either not robust when presented with real world data, or tend to", "cn": 0, "i": 48802092, "k": ["3d face recognition", "3d model", "3d modelling", "Structure From Motion", "Surface Reconstruction"], "p": ["http://www.springerlink.com/index/8r122g274wh16860.pdf", "http://www.springerlink.com/content/8r122g274wh16860"], "t": "Surface Reconstruction of Rotating Objects from Monocular Video", "y": 0, "rn": 14}, {"a": ["Holger Graf", "Leon Hazke", "Svenja Kahn", "Cornelius Malerczyk"], "b": "\n In this paper we present a new framework for an accelerated 3D reconstruction of deformable objects within a multi-view setup.\n It is based on a new memory management and an enhanced algorithm pipeline of the well known Image-Based Visual Hull (IBVH)\n algorithm that enables efficient and fast reconstruction results and opens up new perspectives for the scalability of time\n consuming", "cn": 0, "i": 48818384, "k": ["3d reconstruction", "Deformable Objects", "Memory Management", "Real Time", "Visual Hull"], "p": ["http://www.springerlink.com/content/j0633x847hm1n216", "http://www.springerlink.com/index/j0633x847hm1n216.pdf"], "t": "Accelerated Real-Time Reconstruction of 3D Deformable Objects from Multi-view Video Channels", "y": 0, "rn": 17}, {"a": ["Kiriakos Kutulakos", "Steven Seitz"], "b": "In this paper we consider the problem of computing the 3D shape of an unknown, arbitrarily-shaped scene from multiple photographs taken at known but arbitrarily-distributed viewpoints. By studying the equivalence class of all 3D shapes that reproduce the input photographs, we prove the existence of a special member of this class, the photo hull, that (1) can be computed directly", "cn": 686, "i": 79541, "k": ["multi-view stereo", "Shape From Silhouette", "Shape Representation", "Visual Hull", "Shape Recovery"], "p": ["http://www.cs.utoronto.ca/~kyros/pubs/00.ijcv.carve.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=791235", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00791235", "http://www.loria.fr/~berger/CoursVision/spaceCarving.pdf", "http://www.cs.cmu.edu/~seitz/course/SIGG99/papers/kutu98.pdf", "http://ece.uic.edu/~ssankar1/sriram/papers/16.pdf", "https://www.cs.drexel.edu/~kon/advcompvis/papers/Kutulakos_ICCV99.pdf", "http://www.cs.drexel.edu/~kon/advcompvis/papers/Kutulakos_ICCV99.pdf", "http://www.ri.cmu.edu/pub_files/pub1/kutulakos_k_n_1998_2/kutulakos_k_n_1998_2.pdf", "http://www.vision.caltech.edu/tutorial/papers/kutulakos98theory.pdf", "http://mesh.brown.edu/3dpgp-2008/pdfs/kutulakosseitz-may98-tr692.pdf", "http://mesh.caltech.edu/ee148/refs/KutulakosSeitz-May98-tr692.pdf", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Kutulakos-space-carving-99.pdf", "http://www.ece.uic.edu/%7essankar1/sriram/papers/16.pdf", "http://www1.cs.columbia.edu/~changyin/paper2read/SeitzICCV1999.pdf", "http://www.cs.toronto.edu/%7ekyros/pubs/00.ijcv.carve.pdf", "http://reference.kfupm.edu.sa/content/t/h/a_theory_of_shape_by_space_carving__27629.pdf", "http://mesh.brown.edu/en193s08%2D2003/refs/KutulakosSeitz-May98-tr692.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv1999-1.html#KutulakosS99", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Kutulakos-IJCV-00.pdf"], "t": "A Theory of Shape by Space Carving", "v": "IJCV", "y": 2000, "rn": 82}, {"a": ["Aldo Laurentini"], "b": "Many algorithms for both identifying and reconstructing a 3-D object are based on the 2-D silhouettes of the object. In general, identifying a nonconvex object using a silhouette-based approach implies neglecting some features of its surface as identification clues. The same features cannot be reconstructed by volume intersection techniques using multiple silhouettes of the object. This paper addresses the problem", "cn": 678, "i": 800968, "k": ["Computer Vision", "Convex Hull", "Image Understanding", "Indexing Terms", "Shape Recognition", "Visual Hull"], "p": ["http://computer.org/tpami/tp1994/i0150abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=273735", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00273735", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami16.html#Laurentini94", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=273735"], "t": "The Visual Hull Concept for Silhouette-Based Image Understanding", "v": "PAMI", "y": 1994, "rn": 20}, {"a": ["J. Bouguet"], "b": "", "cn": 571, "i": 1919161, "k": ["Camera Calibration"], "p": [], "t": "Camera calibration toolbox for matlab", "y": 2003, "rn": 0}, {"a": ["Steven Seitz", "Charles Dyer"], "b": "A novel scene reconstruction technique is presented, different from previous approaches in its ability to cope with large changes in visibility and its modeling of intrinsic scene color and texture information. The method avoids image corre- spondence problems by working in a discretized scene space whose voxels are traversed in a fixed visibility ordering. This strategy takes full account of", "cn": 547, "i": 65765, "k": ["Scene Reconstruction"], "p": ["http://www.springerlink.com/content/w83h9164434576n6", "http://www.springerlink.com/index/w83h9164434576n6.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=609462", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00609462", "http://ftp.cs.wisc.edu/computer-vision/repository/PDF/seitz.1999.ijcv.pdf", "http://mesh.brown.edu/3DPGP-2008/pdfs/SeitzDyer-ijcv99.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr1997.html#SeitzD97", "http://www.cs.hunter.cuny.edu/~ioannis/3DP_F03/PAPERS/seitz.1997.cvpr.pdf", "http://computer.org/proceedings/cvpr/7822/78221067abs.htm", "http://www.cs.virginia.edu/~gfx/Courses/2007/ComputerVisionFall/papers/seitz.pdf", "http://www.cs.cmu.edu/~seitz/papers/cvpr97.pdf", "http://www.cs.washington.edu/homes/seitz/papers/cvpr97.pdf", "http://www.multires.caltech.edu/teaching/courses/3DP/papers/SeitzDyer.pdf", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Seitz-IJCV-99.pdf", "http://www.cs.washington.edu/homes/seitz/papers/ijcv99.pdf", "http://www1.cs.columbia.edu/~allen/PHOTOPAPERS/seitz.long.pdf", "http://www.cs.cmu.edu/~seitz/papers/ijcv99.pdf", "http://www.cs.cmu.edu/afs/cs.cmu.edu/user/seitz/www/papers/ijcv99.pdf", "http://www.vision.caltech.edu/tutorial/papers/seitz.1999.ijcv.pdf", "http://mesh.caltech.edu/ee148/refs/SeitzDyer-ijcv99.pdf", "http://www.hunter.cuny.edu/cs/Faculty/Stamos/3DP_F03/PAPERS/seitz.1997.cvpr.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2007/ComputerVision/papers/seitz.pdf"], "t": "Photorealistic Scene Reconstruction by Voxel Coloring", "v": "CVPR", "y": 1997, "rn": 54}, {"a": ["Masatoshi Okutomi", "Takeo Kanade"], "b": "A stereo matching method that uses multiple stereo pairs with various baselines generated by a lateral displacement of a camera to obtain precise distance estimates without suffering from ambiguity is presented. Matching is performed simply by computing the sum of squared-difference (SSD) values. The SSD functions for individual stereo pairs are represented with respect to the inverse distance and are", "cn": 538, "i": 800299, "k": ["Distance Estimation", "Distance Function", "Image Matching", "Indexing Terms", "Mathematical Analysis", "Stereo Matching", "Sum of Squared Difference", "Depth Estimation"], "p": ["http://www.computer.org/tpami/tp1993/i0353abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=206955", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00206955", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=139662", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00139662", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami15.html#OkutomiK93", "http://www.umiacs.umd.edu/~pturaga/ENEE731/papers/Stereo/OkutomiKanade1993.pdf", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Okutomi93.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=206955"], "t": "A Multiple-Baseline Stereo", "v": "PAMI", "y": 1993, "rn": 12}, {"a": ["C. Zitnick", "Sing Kang", "Matthew Uyttendaele", "Simon Winder", "Richard Szeliski"], "b": "The ability to interactively control viewpoint while watching a video is an exciting application of image-based rendering. The goal of our work is to render dynamic scenes with interactive viewpoint control using a relatively small number of video cameras. In this paper, we show how high-quality video-based rendering of dynamic scenes can be accomplished using multiple synchronized video streams combined", "cn": 475, "i": 1232819, "k": ["Color Segmentation", "Computer Vision", "Dynamic Scenes", "Image Based Rendering", "image-based modeling and rendering", "Video Streaming", "View Interpolation", "View Synthesis", "Space Time"], "p": ["http://doi.acm.org/10.1145/1015706.1015766", "http://portal.acm.org/citation.cfm?doid=1015706.1015766", "http://research.microsoft.com/en-us/um/people/larryz/zitnicksig04.pdf", "http://research.microsoft.com/pubs/64201/ZitnickSig04.pdf", "http://portal.acm.org/citation.cfm?id=1015706.1015766", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog23.html#ZitnickKUWS04", "http://www.cs.ucl.ac.uk/staff/S.Prince/4C75/ZitnickSig04.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=64201"], "t": "High-quality video view interpolation using a layered representation", "v": "TOG", "y": 2004, "rn": 46}, {"a": ["Vladimir Kolmogorov", "Ramin Zabih"], "b": "We address the problem of computing the 3-dimensional shape of an arbitrary scene from a set of images taken at known view- points. Multi-camera scene reconstruction is a natural generalization of the stereo matching problem. However, it is much more difficult than stereo, primarily due to the difficulty of reasoning about visibility. In this paper, we take an approach that", "cn": 351, "i": 72820, "k": ["Energy Function", "Energy Minimization", "Experimental Data", "Graph Cut", "Scene Reconstruction", "Stereo Matching", "3 dimensional"], "p": ["http://www.springerlink.com/content/jj0kbdbttjgd86qm", "http://www.springerlink.com/index/jj0kbdbttjgd86qm.pdf", "http://www.cs.ucl.ac.uk/staff/V.Kolmogorov/papers/KZ-ECCV02-recon.pdf", "http://www.cs.ucf.edu/courses/cap6412/spr2005/KZ-ECCV02-recon.pdf", "http://www.cs.cornell.edu/People/vnk/papers/KZ-ECCV02-recon.pdf", "http://www.cs.cornell.edu/%7erdz/papers/kz-eccv02-recon.pdf"], "t": "Multi-camera Scene Reconstruction via Graph Cuts", "v": "ECCV", "y": 2002, "rn": 33}, {"a": ["S\u00e9bastien Roy", "Ingemar Cox"], "b": "This paper describes a new algorithm for solving the N-camera stereo correspondence problem by transforming it into a maximum-flow problem. Once solved, the minimum-cut associated to the maximum-flow yields a disparity surface for the whole image at once. This global approach to stereo analysis provides a more accurate and coherent depth map than the traditional line-by-line stereo. Moreover, the optimality", "cn": 312, "i": 523961, "k": ["Correspondence Problem", "Depth Estimation", "Depth Map", "Dynamic Program", "Maximum Flow", "Minimum Cut", "Line By Line"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=710763", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00710763", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv1998.html#RoyC98"], "t": "A Maximum-Flow Formulation of the N-Camera Stereo Correspondence Problem", "v": "ICCV", "y": 1998, "rn": 7}, {"a": ["Olivier Faugeras", "Renaud Keriven"], "b": "We present a novel geometric approach for solving the stereo problem for an arbitrary number of images (&amp;ges;2). It is based upon the definition of a variational principle that must be satisfied by the surfaces of the objects in the scene and their images. The Euler-Lagrange equations that are deduced from the variational principle provide a set of partial differential", "cn": 274, "i": 1681336, "k": ["euler-lagrange equation", "Geometric Approach", "Indexing Terms", "Level Set", "Multiple Objectives", "Partial Differential Equation", "Satisfiability", "Variational Principle", "Level Set Method"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/tip/tip7.html#FaugerasK98", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=661183", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00661183", "http://www.cs.ualberta.ca/~jag/papersVis2/levsetReadGr/FK98stereo.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=661183", "http://dx.doi.org/10.1109/83.661183", "http://adsabs.harvard.edu/abs/1998ITIP....7..336F"], "t": "Variational principles, surface evolution, PDEs, level set methods, and the stereo problem", "v": "", "y": 1998, "rn": 25}, {"a": ["Daniel Wood", "Daniel Azuma", "Ken Aldinger", "Brian Curless", "Tom Duchamp", "David Salesin", "Werner Stuetzle"], "b": "A surface light field is a function that assigns a color to each ray originating on a surface. Surface light fields are well suited to constructing virtual images of shiny objects under complex lighting conditions. This paper presents a framework for construction, compression, interactive rendering, and rudimentary editing of surface light fields of real objects. Generalization of vector quantization and", "cn": 235, "i": 247412, "k": ["Functional Analysis", "Image Based Rendering", "Interactive Rendering", "Light Field", "Principal Component Analysis", "Surface Geometry", "Vector Quantizer", "Level of Detail"], "p": ["http://www.stat.washington.edu/people/wxs/Siggraph-00/siggraph2000.pdf", "http://portal.acm.org/ft_gateway.cfm?id=344925&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=344925", "http://www.soe.ucsc.edu/classes/cmps290b/Fall05/readings/siggraph2000-wood-slf.pdf", "http://www.ics.uci.edu/~gopi/ICS280Win02/SurfaceLightField.pdf", "http://www.cs.ucsb.edu/%7Eholl/CS595B/handouts/SIGGRAPH2000/p287-wood.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2006/DataDriven/bib/ibr/wood00.pdf", "http://www1.cs.columbia.edu/~ravir/6998/papers/p287-wood.pdf", "http://www.cs.berkeley.edu/~ravir/6998/papers/p287-wood.pdf", "http://portal.acm.org/citation.cfm?id=344779.344925", "https://www.stat.washington.edu/people/wxs/Siggraph-00/siggraph2000.pdf", "http://plenoptic.com/uw/siggraph2000-slf.pdf", "http://grail.cs.washington.edu/projects/slf/papers/siggraph2000-wood-slf.pdf", "http://www.stat.washington.edu/wxs/Siggraph-00/siggraph2000.pdf"], "t": "Surface light fields for 3D photography", "v": "SIGGRAPH", "y": 2000, "rn": 37}, {"a": ["Charles Stewart"], "b": "", "cn": 184, "i": 16462346, "k": ["Computer Vision", "Fundamental Matrix", "Parameter Estimation", "Range Image", "Retinal Imaging", "Robust Statistics"], "p": ["http://link.aip.org/link/SIREAD/v41/i3/p513/s1&Agg=doi", "http://adsabs.harvard.edu/abs/1999SIAMR..41..513S"], "t": "Robust Parameter Estimation in Computer Vision", "v": "SIAM REV", "y": 1999, "rn": 0}, {"a": ["Pascal Fua", "Yvan Leclerc"], "b": " Our goal is to reconstruct both the shape and reflectance properties of surfaces from multipleimages. We argue that an object-centered representation is most appropriate for this purposebecause it naturally accommodates multiple sources of data, multiple images (includingmotion sequences of a rigid object), and self-occlusions. We then present a specific objectcenteredreconstruction method and its implementation. The method begins with an initialestimate", "cn": 164, "i": 270327, "k": ["Surface Reconstruction"], "p": ["http://www.springerlink.com/index/10.1007/BF01428192", "http://www.springerlink.com/index/m8005853512t0258.pdf", "http://www.springerlink.com/content/m8005853512t0258", "http://www.springerlink.com/index/pdf/10.1007/BF01428192", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv16.html#FuaL95"], "t": "Object-centered surface reconstruction: Combining multi-image stereo and shading", "v": "IJCV", "y": 1995, "rn": 55}, {"a": ["Richard Szeliski", "Polina Golland"], "b": "This paper formulates and solves a new variant of the stereo correspondence problem: simultaneously recovering the dis- parities, true colors, and opacities of visible surface elements. This problem arises in newer applications of stereo recon- struction, such as view interpolation and the layering of real imagery with synthetic graphics for special effects and virtual studio applications. While this problem is", "cn": 157, "i": 207949, "k": ["3d reconstruction", "3d representation", "Correspondence Problem", "Energy Minimization", "Stereo Matching", "View Interpolation", "Foreground Background"], "p": ["http://www.springerlink.com/content/h5370t480x418757", "http://www.springerlink.com/index/h5370t480x418757.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=710766", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00710766", "http://dx.doi.org/10.1023/A:1008192912624", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv32.html#SzeliskiG99", "https://research.microsoft.com/pubs/75678/szeliski-iccv98.pdf", "http://research.microsoft.com/pubs/64218/Szeliski-IJCV99.pdf", "https://research.microsoft.com/pubs/64218/Szeliski-IJCV99.pdf", "http://people.csail.mit.edu/polina/papers/SzeliskiGolland_IJCV99.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=75678", "http://research.microsoft.com/apps/pubs/default.aspx?id=64218"], "t": "Stereo Matching with Transparency and Matting", "v": "ICCV", "y": 1998, "rn": 65}, {"a": ["Wei-Chao Chen", "Jean-Yves Bouguet", "Michael Chu", "Radek Grzeszczuk"], "b": "A light field parameterized on the surface offers a natural and intuitive description of the view-dependent appearance of scenes with complex reflectance properties. To enable the use of surface light fields in real-time rendering we develop a compact representation suitable for an accelerated graphics pipeline. We propose to approximate the light field data by partitioning it over elementary surface primitives", "cn": 139, "i": 27413, "k": ["Compact Representation", "Compression Algorithm", "Graphics Hardware", "Image Based Rendering", "Image Compression", "Light Field", "Personal Computer", "Real Time Rendering", "Rendering Hardware", "Texture Mapping"], "p": ["http://doi.acm.org/10.1145/566654.566601", "http://portal.acm.org/ft_gateway.cfm?id=566601&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=566601", "http://portal.acm.org/citation.cfm?id=566654.566601", "http://portal.acm.org/citation.cfm?doid=566654.566601", "http://doi.acm.org/10.1145/566570.566601", "http://portal.acm.org/citation.cfm?id=566570.566601"], "t": "Light field mapping: efficient representation and hardware rendering of surface light fields", "v": "TOG", "y": 2002, "rn": 46}, {"a": ["Charles Stewart"], "b": "Estimation techniques in computer vision applications must estimate accurate model pa- rameters despite small-scale noise in the data, occasional large-scale measurement errors (outliers), and measurements from multiple populations in the same data set. Increas- ingly, robust estimation techniques, some borrowed from the statistics literature and oth- ers described in the computer vision literature, have been used in solving these parameter", "cn": 134, "i": 2023565, "k": ["Computer Vision", "Fundamental Matrix", "Influence Function", "Large Scale", "Least Median of Squares", "Measurement Error", "Motion Analysis", "Parameter Estimation", "Range Image", "Retinal Imaging", "Robust Estimator", "Robust Statistics", "Surface Model", "Transformation Model", "Intensity Measure"], "p": ["http://www.apl.jhu.edu/Notes/Beser/525759/Stewart1.pdf"], "t": "Robust Parameter Estimation in Computer Vision", "y": 1999, "rn": 79}, {"a": ["Gregory Slabaugh", "W. Culbertson", "Thomas Malzbender", "Ronald Schafer"], "b": "Scene reconstruction, the task of generating a 3D model of a scene given multiple 2D photographs taken of the scene, is an old and difficult problem in computer vision. Since its introduction, scene reconstruction has found application in many fields, including robotics, virtual reality, and entertainment. Volumetric models are a natural choice for scene reconstruction. Three broad classes of volumetric", "cn": 104, "i": 2201175, "k": ["3d model", "Computer Vision", "Scene Reconstruction", "Virtual Reality"], "p": ["http://www.eg.org/EG/DL/WS/VG01/Slabaugh.pdf", "http://www.cs.ualberta.ca/~jag/papersVis2/modelrec/SlabaughSurveyVolum.pdf", "http://reference.kfupm.edu.sa/content/h/e/hewlett_packard_laboratories_78312.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/vg/vg2001.html#SlabaughCMS01", "http://www.hpl.hp.com/personal/Tom_Malzbender/papers/VolReconSurvey.pdf", "http://www1.cs.columbia.edu/~allen/PHOTOPAPERS/SlabaughSurveyVolum.pdf", "http://www.hpl.hp.com/research/mmsl/publications/vision/VolReconSurvey.pdf"], "t": "A Survey of Methods for Volumetric Scene Reconstruction from Photographs", "v": "VG", "y": 2001, "rn": 62}, {"a": ["Charles Dyer"], "b": "\n A review of methods for volumetric scene reconstruction from multiple views is presented. Occupancy descriptions of the voxels\n in a scene volume are constructed using shape-from-silhouette techniques for binary images, and shape-from-photo-consistency\n combined with visibility testing for color images.", "cn": 85, "i": 141881, "k": ["Binary Image", "Color Image", "Multiple Views", "Scene Reconstruction", "Shape From Silhouette"], "p": ["http://www.springerlink.com/content/g6667r26566816h1"], "t": "Volumetric Scene Reconstruction from Multiple Views", "y": 0, "rn": 63}, {"a": ["Kiriakos Kutulakos"], "b": "This paper introduces a new multi-view reconstruction problem called approximate -view stereo. The goal of this problem is to recover a one- parameter family of volumes that are increasingly tighter supersets of an unknown, arbitrarily-shaped 3D scene. By studying 3D shapes that reproduce the input pho- tographs up to a special image transformation called a shuffle transformation ,w e prove", "cn": 84, "i": 101211, "k": ["Multiple Views"], "p": ["http://www.cs.utoronto.ca/~kyros/pubs/00.eccv.approx.pdf", "http://www.springerlink.com/content/cw5l2wxtajwe7ffp", "http://www.springerlink.com/index/cw5l2wxtajwe7ffp.pdf"], "t": "Approximate N-View Stereo", "v": "ECCV", "y": 2000, "rn": 32}, {"a": ["James Lee", "Assaf Naor"], "b": "We show that any embedding of the level k diamond graph of Newman and Rabi- novich (6) into Lp, 1 &lt; p \u2022 2, requires distortion at least p k(p \u00a1 1) + 1. An imme- diate corollary is that there exist arbitrarily large n-point sets X \u00b5 L1 such that any D-embedding of X into 'd1 requires d \u201a", "cn": 67, "i": 16834, "k": ["Dimension Reduction", "Functional Analysis"], "p": ["http://arxiv.org/abs/math/0407520", "http://springerlink.metapress.com/openurl.asp?genre=article&id=doi:10.1007/s00039-004-0473-8", "http://www.springerlink.com/index/pdf/10.1007/s00039-004-0473-8", "http://research.microsoft.com/en-us/um/redmond/groups/theory/naor/homepage%20files/diamond1.pdf", "http://www.cs.ust.hk/mjg_lib/bibs/EmbeddingsCourse/Papers/L1Space/LowerBound/lee03embedding.pdf", "http://www.cs.washington.edu/homes/jrl/papers/diamond1.pdf", "http://adsabs.harvard.edu/abs/2004math......7520L"], "t": "Embedding the diamond graph in Lp and dimension reduction in L1", "v": "IEEE Pers. Commun.", "y": 2003, "rn": 8}, {"a": ["Hideo Saito", "Takeo Kanade"], "b": "This paper proposes a new scheme for multi-image pro- jective reconstruction based on a projective grid space. The projective grid space is defined by two basis views and the fundamental matrix relating these views. Given fundamen- tal matrices relating other views to each of the two basis views, this projective grid space can be related to any view. In the", "cn": 66, "i": 299310, "k": ["Fundamental Matrix", "Projective Reconstruction", "Shape Reconstruction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00784607", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=784607"], "t": "Shape Reconstruction in Projective Grid Space from Large Number of Images", "v": "CVPR", "y": 1999, "rn": 19}, {"a": ["Hailin Jin", "Stefano Soatto", "Anthony Yezzi"], "b": "Abstract We consider the problem,of estimating the shape and radiance of an object from a calibrated set of views under the assumption,that the reflectance of the object is nonLambertian. Unlike traditional stereo, we do not solve the correspondence,problem by comparing,image-to-image. Instead, we exploit a rank constraint on the radiance tensor field of the surface in space, and use it to", "cn": 64, "i": 1788278, "k": ["Correspondence Problem", "Image Based Rendering", "image-based modeling", "multi-view stereo"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1211351", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01211351", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2003-1.html#JinSY03", "http://vision.ucla.edu/~hljin/papers/cvpr03.pdf", "http://csdl.computer.org/comp/proceedings/cvpr/2003/1900/01/190010171abs.htm", "http://www.vision.ucla.edu/~hljin/papers/cvpr03.pdf", "http://www.ece.gatech.edu/research/labs/lccv/docs/cvpr_Multiview_Stereo_Beyond_Lambert.pdf", "http://www.vision.cs.ucla.edu/papers/jinSY03cvpr.pdf"], "t": "Multi-view Stereo Beyond Lambert", "v": "CVPR", "y": 2003, "rn": 27}, {"a": ["Ye Duan", "Liu Yang", "Hong Qin", "Dimitris Samaras"], "b": "In this paper, we propose a new PDE-based methodology for deformable surfaces that is capable of automatically evolving its shape to capture the geometric boundary of the data and simultaneously dis- cover its underlying topological structure. Our model can handle multiple types of data (such as volumetric data, 3D point clouds and 2D image data), using a common mathematical framework.", "cn": 61, "i": 509993, "k": ["3d point cloud", "level-set approach", "Local Adaptation", "Minimal Surface", "model-based approach", "Multiple Views", "partial dierential equation", "Shape Reconstruction", "Visual Quality"], "p": ["http://www.springerlink.com/index/xvd5bltewbnww7va.pdf", "http://www.springerlink.com/content/xvd5bltewbnww7va", "http://springerlink.metapress.com/openurl.asp?genre=article&issn=0302-9743&volume=3023&spage=238", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2004-3.html#DuanYQS04", "http://www.cs.sunysb.edu/~ial/content/papers/2004/duan-eccv2004.pdf", "http://www.ann.jussieu.fr/~frey/papers/reconstruction/Duan%20Y.,%20Shape%20reconstruction%20from%203d%20and%202d%20data.pdf", "http://www.cs.missouri.edu/~duanye/eccv-04.pdf", "http://www.cs.sunysb.edu/~vislab/papers/eccv-04.pdf", "http://www.cs.stonybrook.edu/~qin/research/eccv-04.pdf", "http://alum.cs.sunysb.edu/~qin/research/eccv-04.pdf", "http://www.cs.sunysb.edu/~qin/research/eccv-04.pdf"], "t": "Shape Reconstruction from 3D and 2D Data Using PDE-Based Deformable Surfaces", "v": "ECCV", "y": 2004, "rn": 38}, {"a": ["Sudipta Sinha", "Marc Pollefeys"], "b": "This paper describes a novel approach for reconstructing a closed continuous surface of an object from multiple cali- brated color images and silhouettes. Any accurate recon- struction must satisfy (1) photo-consistency and (2) silhou- ette consistency constraints. Most existing techniques treat these cues identically in optimization frameworks where sil- houette constraints are traded off against photo-consistency and smoothness priors. Our", "cn": 60, "i": 1796558, "k": ["Color Image", "Geometric Graph", "Graph Cut", "Maximum Flow", "Minimum Cut", "Satisfiability", "Visual Hull"], "p": ["http://doi.ieeecomputersociety.org/10.1109/ICCV.2005.159", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01541277", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1541277", "http://www.inf.ethz.ch/personal/pomarc/pubs/SinhaICCV05.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2005-1.html#SinhaP05", "http://www.cs.unc.edu/%7emarc/pubs/SinhaICCV05.pdf"], "t": "Multi-View Reconstruction Using Photo-consistency and Exact Silhouette Constraints: A Maximum-Flow Formulation", "v": "ICCV", "y": 2005, "rn": 21}, {"a": ["Olivier Faugeras", "E. Bras-mehlman", "Jean-daniel Boissonnat"], "b": "", "cn": 60, "i": 697459, "k": ["delaunay triangulation"], "p": ["http://linkinghub.elsevier.com/retrieve/pii/000437029090098K", "http://www.informatik.uni-trier.de/~ley/db/journals/ai/ai44.html#FaugerasBB90"], "t": "Representing Stereo Data with the Delaunay Triangulation", "v": "AI", "y": 1990, "rn": 0}, {"a": ["Richard Szeliski"], "b": "This paper presents a new methodology for evaluating the quality of motion estimation and stereo correspondence algo- rithms. Motivated by applications such as novel view gener- ation and motion-compensated compression, we suggest that the ability to predict new views or frames is a natural metric for evaluating such algorithms. Our new metric has several advantages over comparing algorithm outputs to", "cn": 57, "i": 523954, "k": ["Motion Compensated", "Motion Estimation", "Prediction Error", "Quality Metric", "Ground Truth", "Motion Compensated Prediction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=790301", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00790301", "http://computer.org/proceedings/iccv/0164/vol%202/01640781abs.htm", "http://research.microsoft.com/pubs/75683/Szeliski-ICCV99.pdf", "https://research.microsoft.com/pubs/75683/szeliski-iccv99.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=75683"], "t": "Prediction Error as a Quality Metric for Motion and Stereo", "v": "ICCV", "y": 1999, "rn": 52}, {"a": ["Jean-philippe Pons", "Renaud Keriven", "Olivier Faugeras"], "b": "In this paper, we present a new variational method for multi-view stereovision and non-rigid three-dimensional motion estimation from multiple video sequences. Our method minimizes the prediction error of the shape and mo- tion estimates. Both problems then translate into a generic image registration task. The latter is entrusted to a similar- ity measure chosen depending on imaging conditions and scene", "cn": 55, "i": 1788983, "k": ["Dynamic Scenes", "Efficient Implementation", "Hardware Implementation", "Image Registration", "Image Sequence", "large dataset", "Motion Estimation", "Prediction Error", "Three Dimensional", "Variational Method", "Graphics Processor Unit"], "p": ["http://imagine.enpc.fr/publications/papers/05cvpr_b.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01467528", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1467528", "http://www.cs.ualberta.ca/~jag/papersVis2/modelrec/pons-kerivenDynamicCVPR05.pdf", "http://certis.enpc.fr/publications/papers/05cvpr_b.pdf", "http://webdocs.cs.ualberta.ca/~jag/papersVis2/modelrec/pons-kerivenDynamicCVPR05.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2005-2.html#PonsKF05", "http://dx.doi.org/10.1109/CVPR.2005.227"], "t": "Modelling Dynamic Scenes by Registering Multi-View Image Sequences", "v": "CVPR", "y": 2005, "rn": 18}, {"a": ["Pau Gargallo", "Peter Sturm"], "b": "This paper addresses the problem of reconstructing the geometry and albedo of a Lambertian scene, given some fully calibrated images acquired with wide baselines. In order to completely model the input data, we propose to represent the scene as a set of colored depth maps, one per input image. We formulate the problem as a Bayesian MAP problem which leads", "cn": 49, "i": 1788985, "k": ["3d model", "Depth Map", "Energy Minimization"], "p": ["http://artis.imag.fr/Projets/Cyber-II/Publications/GargalloSturm-cvpr05.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01467536", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1467536", "http://orasis2005.univ-bpclermont.fr/papers/019.pdf", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Inproceedings@1176ddd04d5_1c6d011/GargalloSturm-orasis05.pdf", "http://perception.inrialpes.fr/people/gargallo/papers/gargallo05modelisation.pdf", "http://perception.inrialpes.fr/Publications/2005/GS05/GargalloSturm-cvpr05.pdf", "http://dx.doi.org/10.1109/CVPR.2005.84", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2005-2.html#GargalloS05", "http://perception.inrialpes.fr/people/gargallo/papers/gargallo05bayesian.pdf", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Inproceedings@1176ddd04d5_159e6f8/GargalloSturm-cvpr05.pdf"], "t": "Bayesian 3D Modeling from Images Using Multiple Depth Maps", "v": "CVPR", "y": 2005, "rn": 22}, {"a": ["Hailin Jin", "Stefano Soatto", "Anthony Yezzi"], "b": "We address the problem of estimating the three-dimensional shape and complex appearance of a scene from a calibrated set of views under fixed illumination. Our approach relies on a rank condition that must be satisfied when the scene exhibits \u201cspecular + diffuse\u201d reflectance characteristics. This constraint is used to define a cost functional for the discrepancy between the measured images", "cn": 47, "i": 2503300, "k": ["image-based modeling and rendering", "multi-view stereo", "Shape Reconstruction", "Variational Method", "Level Set Method", "Cost Function", "Diffuse Reflectance", "Optimal Estimation", "Satisfiability", "Three Dimensional"], "p": ["http://www.vision.cs.ucla.edu/papers/jinSY05IJCV.pdf", "http://www.springerlink.com/content/x4508k2224260gj2", "http://dx.doi.org/10.1007/s11263-005-6876-7", "http://www.vision.cs.ucla.edu/old/papers/jinSY04-IJCV-final-2.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv63.html#JinSY05", "http://www.ece.gatech.edu/research/labs/lccv/docs/ijcv_Multiview_stereo_reconstruction.pdf", "http://vision.ucla.edu/old/papers/jinSY04-IJCV-final-2.pdf", "http://vision.ucla.edu/papers/jinSY05IJCV.pdf", "http://www.springerlink.com/index/10.1007/s11263-005-6876-7", "http://www.springerlink.com/index/pdf/10.1007/s11263-005-6876-7"], "t": "Multi-View Stereo Reconstruction of Dense Shape and Complex Appearance", "v": "IJCV", "y": 2005, "rn": 46}, {"a": ["Gregory Slabaugh", "W. Culbertson", "Thomas Malzbender", "Mark Stevens", "Ronald Schafer"], "b": "In this paper, we present methods for 3D volumetric reconstruction of visual scenes photographed by multiple calibrated cameras placed at arbitrary viewpoints. Our goal is to generate a 3D model that can be rendered to syn- thesize new photo-realistic views of the scene. We improve upon existing voxel coloring / space carving approaches by introducing new ways to compute visibility", "cn": 47, "i": 1714699, "k": ["3d model", "Color Space", "Large Scale", "Scene Reconstruction"], "p": ["http://www.gregslabaugh.name/publications/ijcv_volumetric.pdf", "http://www.springerlink.com/index/l3t21665052007j0.pdf", "http://www.springerlink.com/content/l3t21665052007j0", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv57.html#SlabaughCMSS04", "http://dx.doi.org/10.1023/B:VISI.0000013093.45070.3b", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000013093.45070.3b"], "t": "Methods for Volumetric Reconstruction of Visual Scenes", "v": "IJCV", "y": 2004, "rn": 55}, {"a": ["Peter Eisert", "Eckehard Steinbach", "Bernd Girod"], "b": "In this paper we present a volumetric method for the 3-D reconstruction of real world objects from multiple calibrated camera views. The representation of the objects is fully volume-based and no explicit surface description is needed. The approach is based on multi-hypothesis tests of the voxel model back-projected into the image planes. All camera views are incorporated in the reconstruction", "cn": 47, "i": 2017516, "k": ["Hypothesis Test", "Image Features", "overcomplete representation", "Visual Quality", "Data Fusion"], "p": ["http://www.nt.e-technik.uni-erlangen.de/LNT_I/publications/web/lnt1999_002.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=757599", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00757599", "http://www.nt.e-technik.uni-erlangen.de/LMS/publications/web/lnt1999_002.pdf", "http://www-nt.e-technik.uni-erlangen.de/lms/publications/web/lnt1999_002.pdf", "http://www.lnt.de/LMS/publications/web/lnt1999_002.pdf", "http://www.lnt.de/LNT_I/publications/web/lnt1999_002.pdf"], "t": "Multi-hypothesis, volumetric reconstruction of 3-D objects from multiple calibrated camera views", "v": "ICASSP", "y": 1999, "rn": 9}, {"a": ["Richard Szeliski"], "b": "This paper presents a new approach to computing dense depth and motion estimates from multiple images. Rather than computing a single depth or motion map from such a collection, we associate motion or depth estimates with each image in the collection (or at least some subset of the im- ages). This has the advantage that the depth or motion of", "cn": 43, "i": 506608, "k": ["Depth Estimation", "Depth Map", "Global Optimization", "Motion Estimation", "Natural Variation", "View Interpolation", "Motion Compensated Prediction"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr1999.html#Szeliski99", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00786933", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=786933", "http://research.microsoft.com/pubs/75681/Szeliski-CVPR99.pdf", "http://computer.org/proceedings/cvpr/0149/volume1/01491157abs.htm", "https://research.microsoft.com/pubs/69882/tr-99-19.pdf", "http://research.microsoft.com/pubs/69882/tr-99-19.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=69882"], "t": "A Multi-View Approach to Motion and Stereo", "v": "CVPR", "y": 1999, "rn": 73}, {"a": ["Thomas Bonfort", "Peter Sturm"], "b": "We present an novel algorithm that reconstructs voxels of a general 3D specular surface from multiple images of a cal- ibrated camera. A calibrated scene (i.e. points whose 3D coordinates are known) is reflected by the unknown specu- lar surface onto the image plane of the camera. For every viewpoint, surface normals are associated to the voxels tra- versed by", "cn": 41, "i": 1796355, "k": ["Decision Process"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-1.html#BonfortS03", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238401", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238401", "http://perception.inrialpes.fr/Publications/2003/BS03c/bs03.pdf", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0591_bonfort.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/01/195010591abs.htm"], "t": "Voxel Carving for Specular Surfaces", "v": "ICCV", "y": 2003, "rn": 17}, {"a": ["Ruigang Yang", "Marc Pollefeys", "Greg Welch"], "b": "We present two extensions to the Space Carving frame- work. The first is a progressive scheme to better reconstruct surfaces lacking sufficient textures. The second is a novel photo-consistency measure that is valid for both specular and diffuse surfaces, under unknown lighting conditions.", "cn": 40, "i": 1796394, "k": [], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238399", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238399", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0576_yang.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/01/195010576abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-1.html#YangPW03"], "t": "Dealing with Textureless Regions and Specular Highlights - A Progressive Space Carving Scheme Using a Novel Photo-consistency Measure", "v": "ICCV", "y": 2003, "rn": 30}, {"a": ["Andrew Prock", "Charles Dyer"], "b": " Techniques for constructing three-dimensionalscene models from two-dimensional images areoften slow and unsuitable for interactive, realtimeapplications. In this paper we explorethree methods of enhancing the performance ofthe voxel coloring reconstruction method. Thefirst approach uses texture mapping to leveragehardware acceleration. The second approachuses spatial coherence and a coarse-to-fine strategyto focus computation on the filled partsof scene space. Finally, the...", "cn": 40, "i": 369733, "k": ["Spatial Coherence", "Texture Mapping", "Real Time"], "p": [], "t": "Towards Real-Time Voxel Coloring", "y": 1998, "rn": 3}, {"a": ["James Diebel", "Sebastian Thrun", "Michael Br\u00fcnig"], "b": "We present a Bayesian technique for the reconstruction and subsequent decimation of 3D surface models from noisy sensor data. The method uses oriented probabilistic models of the measurement noise and combines them with feature-enhancing prior probabilities over 3D surfaces. When applied to surface reconstruction, the method simultaneously smooths noisy regions while enhancing features such as corners. When applied to surface", "cn": 36, "i": 2175082, "k": ["bayesian method", "Computer Animation", "Measurement Noise", "Probabilistic Model", "Surface Model", "Surface Reconstruction"], "p": ["http://portal.acm.org/citation.cfm?doid=1122501.1122504", "http://portal.acm.org/ft_gateway.cfm?id=1122504&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1122504", "http://doi.acm.org/10.1145/1122501.1122504", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog25.html#DiebelTB06"], "t": "A Bayesian method for probable surface reconstruction and decimation", "v": "TOG", "y": 2006, "rn": 27}, {"a": ["John Isidoro", "Stan Sclaroff"], "b": "An iterative method for reconstructing a 3D polygonal mesh and color texture map from multiple views of an object is presented. In each iteration, the method first estimates a texture map given the current shape estimate. The texture map and its associated residual error image are obtained via maximum a posteriori estimation and reprojection of the multiple views into texture", "cn": 36, "i": 1796473, "k": ["Computational Complexity", "Iteration Method", "Multiple Views", "Polygonal Meshes", "Satisfiability", "Shape Estimation", "Texture Mapping", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238645", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238645", "http://www.tsi.enst.fr/~bloch/VOIR/iccv03/1335_isidoro.pdf", "http://www.cs.bu.edu/techreports/pdf/2003-017-visual-hull-stochastic-refinement.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/02/195021335abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-2.html#IsidoroS03"], "t": "Stochastic Refinement of the Visual Hull to Satisfy Photometric and Silhouette Consistency Constraints", "v": "ICCV", "y": 2003, "rn": 23}, {"a": ["Stefano Soatto", "Anthony Yezzi", "Hailin Jin"], "b": "To what extent can three-dimensional shapeand radiance be inferred from a collection of images? Can the two be es- timated separately while retaining optimality? How should the optimality criterion be computed? When is it necessary to employ an explicit model of the reflectance properties of a scene? In this paper we introduce a separation principle for shape and radiance estimation", "cn": 32, "i": 1796455, "k": ["Computer Graphic", "Cost Function", "multi-view stereo", "Separation Principle", "Three Dimensional"], "p": ["http://www.cs.ualberta.ca/~jag/papersVis2/modelrec/SoattoICCV03radiance.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238454", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238454", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/02/195020974abs.htm", "http://vision.ucla.edu/papers/soattoYJ02cvpr.pdf", "http://www.ece.gatech.edu/research/labs/lccv/docs/iccv_Tales_of_Shape_and_Radiance.pdf", "http://www.cs.ualberta.ca/~jag/papersVis2/levsetReadGr/SoattoJin03radiance.pdf", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0974_soatto.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-2.html#SoattoYJ03", "http://webdocs.cs.ualberta.ca/~jag/papersVis2/modelrec/SoattoICCV03radiance.pdf", "http://www.vision.cs.ucla.edu/papers/soattoYJ02cvpr.pdf", "http://www.tsi.enst.fr/~bloch/VOIR/iccv03/0974_soatto.pdf"], "t": "Tales of Shape and Radiance in Multi-view Stereo", "v": "ICCV", "y": 2003, "rn": 18}, {"a": ["D. Wood", "D. Azuma", "K. Aldinger", "B. Curless", "T. Duchamp", "D. Salesin", "W. Stuetzle"], "b": "A surface light field is a function that assigns a color to each ray originating on a surface. Surface light fields are well suited to constructing virtual images of shiny objects under complex lighting conditions. This paper presents a framework for construc-tion, compression, interactive rendering, and rudimentary editing of surface light fields of real objects. Generalizations of vector quantization and", "cn": 32, "i": 3823005, "k": ["Computer Graphic", "Image Generation", "Interactive Rendering", "Light Field", "Principal Component Analysis", "Surface Geometry", "Vector Quantizer", "Level of Detail"], "p": [], "t": "Surface light elds for 3D photography", "v": "SIGGRAPH", "y": 1996, "rn": 29}, {"a": ["Adrien Treuille", "Aaron Hertzmann", "Steven Seitz"], "b": "This paper presents an algorithm for voxel-based reconstruc- tion of objects with general re ectance properties from multiple cali- brated views. It is assumed that one or more reference objects with known geometry are imaged under the same lighting and camera condi- tions as the object being reconstructed. The unknown object is recon- structed using a radiance basis inferred from", "cn": 28, "i": 509923, "k": [], "p": ["http://www.springerlink.com/index/j8j8kf9aaary6jbf.pdf", "http://www.springerlink.com/content/j8j8kf9aaary6jbf", "http://springerlink.metapress.com/openurl.asp?genre=article&issn=0302-9743&volume=3022&spage=457", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2004-2.html#TreuilleHS04"], "t": "Example-Based Stereo with General BRDFs", "v": "ECCV", "y": 2004, "rn": 20}, {"a": ["Rahul Bhotika", "David Fleet", "Kiriakos Kutulakos"], "b": "Abstract. This paper studies the inference of 3D shape from a set of,noisy photos. We derive a probabilistic framework,to specify what one can infer about 3D shape for arbitrarily-shaped, Lambertian scenes and arbitrary viewpoint configurations. Based on formal definitions of visibility, occupancy, emptiness, and photo-consistency, the theoretical development yields a formulation of the Photo Hull Distribution, the tightest probabilistic bound", "cn": 27, "i": 509818, "k": ["Reconstruction Algorithm"], "p": ["http://www.springerlink.com/content/f1h2qfd15qa5la1l", "http://www.springerlink.com/index/f1h2qfd15qa5la1l.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2002-3.html#BhotikaFK02", "http://link.springer.de/link/service/series/0558/bibs/2352/23520112.htm", "http://www.cs.utoronto.ca/~kyros/pubs/02.eccv.occupancy.pdf", "http://www.cs.utoronto.ca/~fleet/research/Papers/eccv02-prob.pdf", "http://www.cs.toronto.edu/~kyros/pubs/02.eccv.occupancy.pdf", "http://www.cs.toronto.edu/%7efleet/research/Papers/eccv02-prob.pdf"], "t": "A Probabilistic Theory of Occupancy and Emptiness", "v": "ECCV", "y": 2002, "rn": 25}, {"a": ["Silvio Savaresef", "Holly Rushmeier", "Fausto Bernardini", "Pietro Perona"], "b": "The shape of an object may be estimated by observing the shad- ows on its surface. We present a method that is robust with re- spect to a conservative classification of shadow regions. Assum- ing that a conservative estimate of the object shape is available, we analyze images of the object illuminated with known point light sources taken from known", "cn": 26, "i": 523881, "k": ["Multiple Views", "Proof of Correctness", "Shape From Silhouette"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=937517", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00937517", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2001-1.html#SavareseRBP01"], "t": "Shadow Carving", "v": "ICCV", "y": 2001, "rn": 12}, {"a": ["Alyn Rockwood", "Jim Winget"], "b": "In order to construct a 3D model from a collection of 2D images of an object, an energy function is defined between the object's images and corresponding images of an articulated mesh in three dimensions. Repeated adjustment of the mesh to minimize the energy function results in a mesh that produces images which closely approximate the input images, that is", "cn": 24, "i": 722872, "k": ["3d model", "Computer Vision", "Energy Function", "Large Scale", "Local Minima", "Model Building", "Object Reconstruction", "Reverse Engineering", "Simulated Annealing", "Three Dimensional", "Three Dimensions"], "p": ["http://www.sciencedirect.com/science/article/pii/S0010448596000565", "http://linkinghub.elsevier.com/retrieve/pii/S0010448596000565", "http://www.informatik.uni-trier.de/~ley/db/journals/cad/cad29.html#RockwoodW97", "http://dx.doi.org/10.1016/S0010-4485(96)00056-5"], "t": "Three-dimensional object reconstruction from two-dimensional images", "v": "CAD", "y": 1997, "rn": 4}, {"a": ["A. Broadhurst", "T. Drummond", "R. Cipolla"], "b": "", "cn": 23, "i": 2387649, "k": [], "p": [], "t": "A probabilistic framework for the Space Carving algorithm", "v": "ICCV", "y": 2001, "rn": 0}, {"a": ["Tianli Yu", "Ning Xu", "Narendra Ahuja"], "b": "We consider the problem of estimating the 3D shape and reflectance properties of an object made of a single material from a calibrated set of multiple views. To model reflectance, we propose a View Independent Reflectance Map (VIRM) and derive it from Torrance- Sparrow BRDF model. Reflectance estimation then amounts to estimat- ing VIRM parameters. We represent object shape using", "cn": 22, "i": 1790105, "k": ["Cost Function", "Global Constraint", "Multiple Views", "Shape Estimation", "Shape From Shading"], "p": ["http://www.springerlink.com/index/txg1cavffqcty4r5.pdf", "http://www.springerlink.com/content/txg1cavffqcty4r5"], "t": "Shape and View Independent Reflectance Map from Multiple Views", "v": "ECCV", "y": 2004, "rn": 6}, {"a": ["Jeremy Bonet", "Paul Viola"], "b": "This paper examines the problem of reconstructing a voxelized representation of 3D space from a series of im- ages. An iterative algorithm is used to find the scene model which jointly explains all the observed images by determin- ing which region of space is responsible for each of the ob- servations. The current approach formulates the problem as one of", "cn": 22, "i": 2050675, "k": ["Iterative Algorithm"], "p": ["http://www.debonet.com/Research/Publications/1999/DeBonet-ICCV99-Poxels.pdf"], "t": "Poxels: Probabilistic Voxelized Volume Reconstruction", "y": 1999, "rn": 5}, {"a": ["Anastasios Manessis", "Adrian Hilton", "Phil Palmer", "Philip Mclauchlan", "Xinquan Shen"], "b": "In this paper we present a geometric theory for reconstruction of surface models from sparse 3D data captured from N camera views which are consistent with the data visibility. Sparse 3D measurements of real scenes are readily estimated from image sequences using structure-from-motion techniques. Currently there is no general method for reconstruction of 3D models of arbitrary scenes from sparse", "cn": 20, "i": 506934, "k": ["3d measurement", "3d model", "3d structure", "Consistency Model", "Data Capture", "General Methods", "Image Sequence", "Sparse Data", "Structure From Motion", "Surface Model"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=854938", "http://computer.org/proceedings/cvpr/0662/Volume%202/06622666abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2000.html#ManessisHPMS00"], "t": "Reconstruction of Scene Models from Sparse 3D Structure", "v": "CVPR", "y": 2000, "rn": 0}, {"a": ["George Vogiatzis", "Philip Torr", "Steven Seitz", "Roberto Cipolla"], "b": "This paper generalizes Markov Random Field ( MRF) stereo methods to the generation of surface relief (height) fields rather than disparity or depth maps. This generaliza- tion enables the reconstruction of complete object models using the same algorithms that have been previously used to compute depth maps in binocular stereo. In contrast to traditional dense stereo where the parametrization is", "cn": 18, "i": 4394569, "k": ["Belief Propagation", "Depth Map", "Object Model", "Quantitative Evaluation", "Markov Random Field", "Visual Hull"], "p": ["http://linkinghub.elsevier.com/retrieve/pii/S0262885607000741", "http://www.sciencedirect.com/science/article/pii/S0262885607000741", "http://www.informatik.uni-trier.de/~ley/db/journals/ivc/ivc26.html#VogiatzisTSC08", "http://dx.doi.org/10.1016/j.imavis.2007.01.006"], "t": "Reconstructing relief surfaces", "v": "IVC", "y": 2008, "rn": 25}, {"a": ["Camillo Taylor"], "b": "This paper describes an approach to recovering surface models of complex scenes from the quasi-sparse data re- turned by a feature based stereo system. The method can be used to merge stereo results obtained from different view- points into a single coherent surface mesh. The technique proceeds by exploiting the freespace theorem which pro- vides a principledmechanismfor reasoningaboutthe struc- ture", "cn": 18, "i": 1796400, "k": ["Sparse Data", "Surface Model", "Surface Reconstruction"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238338", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0184_taylor.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/01/195010184abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-1.html#Taylor03"], "t": "Surface Reconstruction from Feature Based Stereo", "v": "ICCV", "y": 2003, "rn": 16}, {"a": ["Gregory Slabaugh", "Thomas Malzbender", "W. Culbertson", "Ronald Schafer"], "b": " Voxel coloring methods reconstruct a three-dimensional volumetric surface model from a set of calibrated twodimensionalphotographs taken of a scene. In this paper, we recast voxel coloring as an optimization problem, thesolution of which strives to minimize reprojection error, which measures how well projections of the reconstructedscene reproduce the photographs. The reprojection error, defined in image space, guides the refinement of", "cn": 17, "i": 168121, "k": ["Optimization Problem", "Surface Model", "Three Dimensional"], "p": [], "t": "Improved Voxel Coloring Via Volumetric Optimization", "v": "SIP", "y": 2000, "rn": 0}, {"a": ["Shang-hua Teng"], "b": "", "cn": 17, "i": 740167, "k": [], "p": ["http://linkinghub.elsevier.com/retrieve/pii/002001909090094E"], "t": "Space Efficient Processor Identity Protocol", "v": "IPL", "y": 1990, "rn": 1}, {"a": ["Simon Baker", "Terence Sim", "Takeo Kanade"], "b": "The complete set of measurements that could ever be used by a passive 3D vision algorithm is the plenoptic function or light-field. We give a concise characterization of when the light-field of a Lambertian scene uniquely determines its shape and, conversely, when the shape is inherently ambiguous. In particular, we show that stereo computed from the light-field is ambiguous if", "cn": 16, "i": 800376, "k": ["3d shape reconstruction", "3d vision", "Light Field", "plenoptic function", "Shape From Silhouette", "Indexing Terms"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1159949", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1159949", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01159949", "http://computer.org/tpami/tp2003/i0100abs.htm", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami25.html#BakerSK03", "http://www.comp.nus.edu/~tsim/shape-light-field.pdf", "http://reference.kfupm.edu.sa/content/w/h/when_is_the_shape_of_a_scene_unique_give_365537.pdf"], "t": "When Is the Shape of a Scene Unique Given Its Light-Field: A Fundamental Theorem of 3D Vision?", "v": "PAMI", "y": 2003, "rn": 21}, {"a": ["Marc-antoine Drouin", "Martin Trudeau", "S\u00e9bastien Roy"], "b": "This paper presents a new model to overcome the occlu- sion problems coming from wide baseline multiple camera stereo. Rather than explicitly modeling occlusions in the matching cost function, it detects occlusions in the depth map obtained from regular efficient stereo matching algo- rithms. Occlusions are detected as inconsistencies of the depth map by computing the visibility of the map", "cn": 14, "i": 1788763, "k": ["Cost Function", "Depth Map", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01467289", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1467289", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2005-1.html#DrouinTR05", "http://dx.doi.org/10.1109/CVPR.2005.168", "http://www.iro.umontreal.ca/~drouim/pub/drouin-stereocvpr05.pdf", "http://mir13.iro.umontreal.ca/wordpress/wp-content/uploads/2008/09/drouin-stereocvpr05.pdf"], "t": "Geo-Consistency for Wide Multi-Camera Stereo", "v": "CVPR", "y": 2005, "rn": 26}, {"a": ["T. Fromherz", "M. Bichsel"], "b": "", "cn": 12, "i": 2049930, "k": ["Cue Integration"], "p": [], "t": "Shape from Multiple Cues: Integrating Local Brightness Information", "v": "ICYCS", "y": 1995, "rn": 0}, {"a": ["Gang Zeng", "Sylvain Paris", "Long Quan", "Fran\u00e7ois Sillion"], "b": "This paper introduces a new method for surface recon- struction from multiple calibrated images. The primary contribution of this work is the notion of local prior to com- bine the flexibility of the carving approach with the accu- racy of graph-cut optimization. A progressive refinement scheme is used to recover the topology and reason the vis- ibility of the object.", "cn": 11, "i": 1796724, "k": ["Graph Cut", "Image Sequence", "Level Set", "Surface Reconstruction"], "p": ["https://artis.imag.fr/Publications/2005/ZPQS05/Zeng_05_Local_Prior.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01544861", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1544861", "http://artis.inrialpes.fr/Publications/2005/ZPQS05/Zeng_05_Local_Prior.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2005-2.html#ZengPQS05", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Inproceedings@1172c0fd434_e0bea9/Zeng_05_Local_Prior.pdf", "http://groups.csail.mit.edu/graphics/pubs/iccv2005_localprior_zeng.pdf", "http://artis.imag.fr/Publications/2005/ZPQS05/Zeng_05_Local_Prior.pdf", "http://doi.ieeecomputersociety.org/10.1109/ICCV.2005.196", "http://www.cis.pku.edu.cn/faculty/vision/zeng/pdf/ZengPQS05iccv.pdf"], "t": "Progressive Surface Reconstruction from Images Using a Local Prior", "v": "ICCV", "y": 2005, "rn": 35}, {"a": ["Jean-philippe Pons", "Renaud Keriven", "Olivier Faugeras", "Gerardo Hermosillo"], "b": "We present a common variational framework for dense depth recovery and dense three-dimensional motion field estimation from multiple video sequences, which is robust to camera spectral sensitivity differences and illumination changes. For this purpose, we first show that both problems reduce to a generic image matching problem after backpro- jecting the input images onto suitable surfaces. We then solve this", "cn": 10, "i": 1796416, "k": ["Image Matching", "Similarity Measure", "Spectral Sensitivity", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238402", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238402", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-1.html#PonsKFH03", "http://imagine.enpc.fr/publications/papers/03iccv_a.pdf", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0597_pons.pdf"], "t": "Variational Stereovision and 3D Scene Flow Estimation with Statistical Similarity Measures", "v": "ICCV", "y": 2003, "rn": 26}, {"a": ["L. Zhang", "S. Seitz"], "b": "", "cn": 9, "i": 3212341, "k": ["Shape Recovery", "Surface Deformation"], "p": [], "t": "Image-based multiresolution shape recovery by surface deformation", "v": "", "y": 2001, "rn": 0}, {"a": ["Y. Furukawa", "J. Ponce"], "b": "", "cn": 7, "i": 4113604, "k": [], "p": [], "t": "High - delity image - based mod - eling", "y": 2006, "rn": 0}, {"a": ["Tolga Tasdizen", "Ross Whitaker"], "b": "Abstract For surface reconstruction problems with noisy and incomplete range data, a Bayesian esti - mation approach can improve the overall quality of the surfaces The Bayesian approach to surface estimation relies on a likelihood term, which ties the surface estimate to the input data, and the prior, which ensures surface smoothness or continuity This paper introduces a new high", "cn": 5, "i": 1071913, "k": ["Anisotropic Diffusion", "bayesian approach", "Geometric Feature", "Image Processing", "Level Set", "Numerical Technique", "Partial Differential Equation", "Quantitative Analysis", "Range Data", "Robust Estimator", "Surface Deformation", "Surface Reconstruction", "Higher Order", "Second Order"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1300558", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1300558", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01300558", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami26.html#TasdizenW04", "http://www.sci.utah.edu/~tolga/pubs/UUCS-02-016.pdf", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2004.31", "http://www.cs.utah.edu/research/techreports/2002/pdf/UUCS-02-016.pdf"], "t": "Higher-Order Nonlinear Priors for Surface Reconstruction", "v": "PAMI", "y": 2004, "rn": 53}, {"a": ["Klas Josephson", "Martin Byr\u00f6d"], "b": "This paper presents a solution to the problem of pose es- timation in the presence of heavy radial distortion and a po- tentially large number of outliers. The main contribution is an algorithm that solves for radial distortion, focal length and camera pose using a minimal set of four point corre- spondences between 3D world points and image points. We", "cn": 5, "i": 5678802, "k": ["Bundle Adjustment", "Pose Estimation", "Radial Distortion"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206756", "http://www.maths.lth.se/vision/publdb/reports/pdf/josephson-byrod-ccvpr-09.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#JosephsonB09", "http://www.maths.lth.se/matematiklth/vision/publdb/reports/pdf/josephson-byrod-ccvpr-09.pdf"], "t": "Pose estimation with radial distortion and unknown focal length", "v": "CVPR", "y": 2009, "rn": 18}, {"a": ["Tudor Nicosevici", "Nuno Gracias", "Shahriar Negahdaripour", "Rafael Garc\u00eda"], "b": "", "cn": 5, "i": 13255522, "k": ["Three Dimensional"], "p": ["http://dx.doi.org/10.1002/rob.20305", "http://doi.wiley.com/10.1002/rob.20305", "http://www.informatik.uni-trier.de/~ley/db/journals/jfr/jfr26.html#NicoseviciGNG09"], "t": "Efficient three-dimensional scene modeling and mosaicing", "v": "JFR", "y": 2009, "rn": 30}, {"a": ["Julien Rabin", "Julie Delon", "Yann Gousseau"], "b": "This paper focuses on the matching of local features between images. Given a set of query descriptors and a database of candidate descriptors, the goal is to decide which ones should be matched. This is a crucial issue, since the matching procedure is often a preliminary step for object detection or image matching. In practice, this matching step is often", "cn": 4, "i": 13255826, "k": ["Dissimilarity Measure", "earth mover's distance", "Euclidean Distance", "Image Database", "Image Matching", "Local Features", "Object Detection", "Statistical Analysis", "Statistical Approach", "Time Complexity", "Nearest Neighbor"], "p": ["http://dx.doi.org/10.1137/090751359", "http://www.informatik.uni-trier.de/~ley/db/journals/siamis/siamis2.html#RabinDG09", "http://perso.telecom-paristech.fr/~gousseau/matching.pdf", "http://link.aip.org/link/SJISBI/v2/i3/p931/s1&Agg=doi"], "t": "A Statistical Approach to the Matching of Local Features", "v": "SIAM J IMAGING SCI", "y": 2009, "rn": 36}, {"a": ["Zilong Dong", "Guofeng Zhang", "Jiaya Jia", "Hujun Bao"], "b": "We present a novel keyframe selection and recognition method for robust markerless real-time camera tracking. Our system contains an ofine module to select features from a group of reference images and an online module to match them to the input live video in order to quickly esti- mate the camera pose. The main contribution lies in con- structing an optimal", "cn": 3, "i": 5829152, "k": ["Parallel Computer", "Real Time"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459273", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459273", "http://www.cse.cuhk.edu.hk/~leojia/all_final_papers/realtimetracking.pdf", "http://www.cad.zju.edu.cn/home/gfzhang/projects/realtimetracking/realtimetracking.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459273", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#DongZJB09"], "t": "Keyframe-based real-time camera tracking", "v": "ICCV", "y": 2009, "rn": 33}, {"a": ["Matthew Bolitho", "Michael Kazhdan", "Randal Burns", "Hugues Hoppe"], "b": "In this work we describe a parallel implementation of the Poisson Surface Reconstruction algorithm based on multigrid domain decomposition. We compare implementations using different models of data-sharing between processors and show that a parallel implementation with distributed memory provides the best scalability. Using our method, we are able to parallelize the reconstruction of models from one billion data points on", "cn": 3, "i": 6044558, "k": ["Computer Vision", "Data Sharing", "Distributed Memory", "Domain Decomposition", "Graphics Hardware", "large dataset", "massive datasets", "multi-core processor", "Parallel Architecture", "Parallel Implementation", "Photo Collection", "Point Cloud", "Reconstruction Algorithm", "Surface Reconstruction"], "p": ["http://www.springerlink.com/index/875mj3650888xq62.pdf", "http://www.springerlink.com/content/875mj3650888xq62", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2009-1.html#BolithoKBH09", "http://dx.doi.org/10.1007/978-3-642-10331-5_63", "http://research.microsoft.com/en-us/um/people/hoppe/parallelrecon.pdf"], "t": "Parallel Poisson Surface Reconstruction", "v": "ISVC", "y": 2009, "rn": 21}, {"a": ["Takeshi Kurashima", "Tomoharu Iwata", "Go Irie", "Ko Fujimura"], "b": "The ability to create geotagged photos enables people to share their personal experiences as tourists at specific locations and times. Assuming that the collection of each photographer's geotagged photos is a sequence of visited locations, photo-sharing sites are important sources for gathering the location histories of tourists. By following their location sequences, we can find representative and diverse travel routes", "cn": 2, "i": 39226128, "k": ["Behavior Modeling", "Photo Sharing", "Prediction Accuracy", "Travel Behavior", "United States", "User Preferences", "Markov Model"], "p": ["http://portal.acm.org/citation.cfm?id=1871513", "http://portal.acm.org/ft_gateway.cfm?id=1871513&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1871437.1871513", "http://www.informatik.uni-trier.de/~ley/db/conf/cikm/cikm2010.html#KurashimaIIF10"], "t": "Travel route recommendation using geotags in photo sharing sites", "v": "CIKM", "y": 2010, "rn": 25}, {"a": ["Marcel Br\u00fcckner", "Ferid Bajramovic", "Joachim Denzler"], "b": "Detecting image pairs with a common field of view is an important prerequisite for many computer vision tasks. Typically, common local features are used as a criterion for identifying such image pairs. This approach, however, requires a reliable method for matching features, which is generally a very di cult problem - especially in situations with a wide baseline or ambiguities", "cn": 2, "i": 6368054, "k": ["Computer Vision", "Dissimilarity Measure", "Feature Matching", "Geometric Constraints", "Local Features", "Field of View", "False Positive Rate"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206810", "http://www.inf-cv.uni-jena.de/biborb/bibs/cv/papers/Bruckner09:GAP.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#BrucknerBD09"], "t": "Geometric and probabilistic image dissimilarity measures for common field of view detection", "v": "CVPR", "y": 2009, "rn": 12}, {"a": ["Kai Ni", "Hailin Jin", "Frank Dellaert"], "b": "Figure 1. RANSAC can be significantly sped up if modified to take advantage of additional grouping information between features, e.g., as provided by optical flow based clustering. Left: one of the two images for which we seek epipolar geometry, with inlier and outlier correspondences overlaid in blue and red respectively. Middle and Right: Two largest groups of tentative correspondences after", "cn": 2, "i": 6385092, "k": ["Binomial Model", "epipolar geometry", "Mixture Model", "Optical Flow"], "p": ["http://www.vision.ucla.edu/~hljin/papers/iccv09-groupsac.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459241", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459241", "http://www.cc.gatech.edu/~nikai/assets/Ni09iccv.pdf", "http://dx.doi.org/10.1109/ICCV.2009.5459241", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#NiJD09"], "t": "GroupSAC: Efficient consensus in the presence of groupings", "v": "ICCV", "y": 2009, "rn": 20}, {"a": ["Martin Byr\u00f6d", "Kalle \u00c5str\u00f6m"], "b": "Bundle adjustment is a key component of almost any feature based 3D reconstruction system, used to compute accurate estimates of calibration parameters and structure and motion configurations. These problems tend to be very large, often involving thousands of variables. Thus, efficient optimization methods are crucial. The traditional Levenberg Marquardt algorithm with a direct sparse solver can be efficiently adapted to", "cn": 2, "i": 6579055, "k": ["3d reconstruction", "Bundle Adjustment", "Computational Complexity", "Conjugate Gradient", "Iteration Method", "Optimal Method", "Structure and Motion", "Gauss Seidel", "levenberg marquardt"], "p": ["http://www.maths.lth.se/matematiklth/personal/byrod/papers/byrod_astrom_bmvc_09.pdf", "http://www.bmva.org/bmvc/2009/Papers/Paper096/Abstract096.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2009.html#ByrodA09"], "t": "Bundle Adjustment using Conjugate Gradients with Multiscale Preconditioning", "v": "BMVC", "y": 2009, "rn": 14}, {"a": ["William Feighery"], "b": "In recent decades, scholars working from a variety of disciplinary, transdisciplinary and adisciplinary perspectives have focused on photographic images as a rich source of research data. Much of the work on photography in tourism studies has been concerned primarily with the analysis of the content of photographic representations. Studies which examine the production and distribution of \u2018stock\u2019 photographs in place", "cn": 2, "i": 42659283, "k": ["Social Relation"], "p": ["http://dx.doi.org/10.1080/14766820903259485", "http://www.informaworld.com/openurl?genre=article&doi=10.1080/14766820903259485&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3"], "t": "Tourism, stock photography and surveillance: a Foucauldian interpretation", "v": "", "y": 2009, "rn": 41}, {"a": ["Bernhard Zeisl", "Pierre Georgel", "Florian Schweiger", "Eckehard Steinbach", "Nassir Navab"], "b": "Image feature points are the basis for numerous computer vision tasks, such as pose estimation or object detection. State of the art algorithms detect features that are invari- ant to scale and orientation changes. While feature detectors and descriptors have been widely studied in terms of stability and repeatability, their localisation error has often been assumed to be uniform and", "cn": 2, "i": 4963388, "k": ["Bundle Adjustment", "Covariance Estimation", "Image Features", "Invariant Feature", "Numerical Computation", "Object Detection", "Pose Estimation"], "p": ["http://ar.in.tum.de/pub/zeisl2009bmvc/zeisl2009bmvc.pdf", "http://wwwnavab.in.tum.de/pub/zeisl2009bmvc/zeisl2009bmvc.pdf"], "t": "Estimation of Location Uncertainty for Scale Invariant Feature Points", "v": "BMVC", "y": 0, "rn": 18}, {"a": ["Alexandre Karpenko", "Parham Aarabi"], "b": "In this paper, we present a large database of over 50,000 user-labeled videos collected from YouTube. We develop a compact representation called \"tiny videos\" that achieves high video compression rates while retaining the overall visual appearance of the video as it varies over time. We show that frame sampling using affinity propagation\u2014an exemplar-based clustering algorithm\u2014achieves the best trade-off between compression", "cn": 1, "i": 14373795, "k": ["Cluster Algorithm", "Compact Representation", "Content Based Retrieval", "Data Mining", "Image Classification", "Large Data Sets", "Nearest Neighbor Method", "Nearest Neighbor Search", "Video Compression", "Video Retrieval", "Affinity Propagation"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5487525", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05487525", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5487525", "http://dx.doi.org/10.1109/TPAMI.2010.118", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami33.html#KarpenkoA11"], "t": "Tiny Videos: A Large Data Set for Nonparametric Video Retrieval and Frame Classification", "v": "PAMI", "y": 2011, "rn": 21}, {"a": ["Mohammed Fathy", "Ashraf Hussein", "Mohammed Tolba"], "b": "The fundamental matrix (FM) describes the geometric relations that exist between two images of the same scene. Different error criteria are used for estimating FMs from an input set of correspondences. In this paper, the accuracy and efficiency aspects of the different error criteria are studied. We mathematically and experimentally proved that the most popular error criterion, the symmetric epipolar", "cn": 1, "i": 39327733, "k": ["epipolar geometry", "Fundamental Matrix", "Mathematical Analysis", "Randomized Algorithm", "Structure and Motion"], "p": ["http://www.sciencedirect.com/science/article/pii/S0167865510003235", "http://dx.doi.org/10.1016/j.patrec.2010.09.019", "http://www.informatik.uni-trier.de/~ley/db/journals/prl/prl32.html#FathyHT11"], "t": "Fundamental matrix estimation: A study of error criteria", "v": "PRL", "y": 2011, "rn": 12}, {"a": ["Mauricio Diaz", "Peter Sturm"], "b": "Access to the scene irradiance is a desirable feature in many computer vision algorithms. Applications like BRDF estimation, relighting or augmented reality need measurements of the object's photometric properties and the simplest method to get them is using a camera. However, the \ufffdrst step necessary to achieve this goal is the computation of the function that relates scene irradiance to", "cn": 1, "i": 51040908, "k": ["Approximate Solution", "Augmented Reality", "Computer Vision", "Ill-posed Problem", "linear functionals", "Linear Least Square", "Photo Collection", "Radiometric Calibration", "Response Function", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05753117", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5753117"], "t": "Radiometric calibration using photo collections", "v": "ICCP", "y": 2011, "rn": 24}, {"a": ["Sid Bao", "Silvio Savarese"], "b": "Conventional rigid structure from motion (SFM) addresses the problem of recovering the camera parameters (motion) and the 3D locations (structure) of scene points, given observed 2D image feature points. In this paper, we propose a new formulation called Semantic Structure From Motion (SSFM). In addition to the geometrical constraints provided by SFM, SSFM takes advantage of both semantic and geometrical", "cn": 1, "i": 51108072, "k": ["Geometric Constraints", "Image Features", "Object Detection", "Pose Estimation", "Semantic Information", "Structure and Motion", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995462", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995462"], "t": "Semantic structure from motion", "v": "CVPR", "y": 2011, "rn": 31}, {"a": ["Jan Heller", "Michal Havlena", "Akihiro Sugimoto", "Tomas Pajdla"], "b": "This paper presents a novel method for so-called handeye calibration. Using a calibration target is not possible for many applications of hand-eye calibration. In such situations Structure-from-Motion approach of hand-eye calibration is commonly used to recover the camera poses up to scaling. The presented method takes advantage of recent results in the L\u221e-norm optimization using SecondOrder Cone Programming (SOCP) to", "cn": 1, "i": 51108234, "k": ["Experimental Validation", "Global Optimization", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995629", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995629"], "t": "Structure-from-motion based hand-eye calibration using L\u221e minimization", "v": "CVPR", "y": 2011, "rn": 17}, {"a": ["Udo Frese", "Ren\u00e9 Wagner", "Thomas R\u00f6fer"], "b": "This paper gives a brief overview on the Simultaneous Localization and Mapping (SLAM) problem from the perspective of using\n SLAM for an application as opposed to the common view in SLAM research papers that focus on investigating SLAM itself.\n \n \n We discuss different ways of using SLAM with increasing difficulty: for creating a map prior to operation, as a black-box\n localization", "cn": 1, "i": 15213464, "k": ["Local System", "Research Paper", "Simultaneous Localization and Mapping", "Visual Features"], "p": ["http://www.springerlink.com/content/p052055h1377gp85", "http://www.springerlink.com/index/p052055h1377gp85.pdf", "http://dx.doi.org/10.1007/s13218-010-0040-4", "http://www.informatik.uni-trier.de/~ley/db/journals/ki/ki24.html#FreseWR10", "http://www.springerlink.com/index/10.1007/s13218-010-0040-4", "http://www.springerlink.com/index/pdf/10.1007/s13218-010-0040-4"], "t": "A SLAM Overview from a User's Perspective", "v": "KI", "y": 2010, "rn": 33}, {"a": ["Vivek Singh", "Mingyan Gao", "Ramesh Jain"], "b": "Huge amounts of social multimedia is being created daily by a combination of globally distributed disparate sensors, including human-sensors (e.g. tweets) and video cameras. Taken together, this represents information about multiple aspects of the evolving world. Understanding the various events, patterns and situations emerging in such data has applications in multiple domains. We develop abstractions and tools to decipher various", "cn": 1, "i": 39235919, "k": ["Media Processing", "Social Media"], "p": ["http://portal.acm.org/citation.cfm?id=1874030", "http://portal.acm.org/ft_gateway.cfm?id=1874030&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://dl.acm.org/citation.cfm?id=1874030", "http://doi.acm.org/10.1145/1873951.1874030", "http://www.informatik.uni-trier.de/~ley/db/conf/mm/mm2010.html#SinghGJ10"], "t": "Social pixels: genesis and evaluation", "v": "MM", "y": 2010, "rn": 21}, {"a": ["Michael Yang", "Yanpeng Cao", "Wolfgang F\u00f6rstner", "John McDonald"], "b": "\n This paper presents a novel scheme for automatically aligning two widely separated 3D scenes via the use of viewpoint invariant\n features. The key idea of the proposed method is following. First, a number of dominant planes are extracted in the SfM 3D\n point cloud using a novel method integrating RANSAC and MDL to describe the underlying 3D geometry in urban", "cn": 1, "i": 39273961, "k": ["3d point cloud", "Feature Matching", "Image Features", "Image Matching", "Invariant Feature", "Method Integration"], "p": ["http://www.springerlink.com/content/965n1538641t2811", "http://www.springerlink.com/index/965n1538641t2811.pdf", "http://dx.doi.org/10.1007/978-3-642-17289-2_63", "http://www.informatik.uni-trier.de/~ley/db/conf/isvc/isvc2010-1.html#YangCFM10"], "t": "Robust Wide Baseline Scene Alignment Based on 3D Viewpoint Normalization", "v": "ISVC", "y": 2010, "rn": 23}, {"a": ["Timothy Liu", "Matthew Carlberg", "George Chen", "Jacky Chen", "John Kua", "Avideh Zakhor"], "b": "Automated 3D modeling of building interiors is useful in applications such as virtual reality and entertainment. Using a human-operated backpack system equipped with 2D laser scanners and inertial measurement units (IMU), we develop scan matching based algorithms to localize the backpack in complex indoor environments such as a T-shaped corridor intersection, a staircase, and two indoor hallways from two separate", "cn": 1, "i": 50985963, "k": ["3d model", "3d point cloud", "Data Acquisition", "Image Based Rendering", "Indoor Environment", "Inertial Measurement Unit", "Laser Scanner", "Laser Scanning", "Pose Estimation", "Scan Matching", "Virtual Reality"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05646820", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5646820"], "t": "Indoor localization and visualization using a human-operated backpack system", "v": "IPIN", "y": 2010, "rn": 27}, {"a": ["Wan Arif", "Wan Ahmad", "Azrai Abdullah", "Subarna Sivapalan"], "b": "The high demand to improve the quality of the presentation in the knowledge sharing field is to compete with rapidly growing\n technology. The needs for development of technology based learning and training lead to an idea to develop an Oil and Gas\n Plant Virtual Environment (OGPVE) for the benefit of our future. Panoramic Virtual Reality learning based environment is essential", "cn": 1, "i": 6062656, "k": ["Image Acquisition", "Knowledge Sharing", "Oil and Gas", "Panoramic Image", "Technical Writing", "Virtual Environment", "Virtual Reality", "3 dimensional", "Field of View"], "p": ["http://www.springerlink.com/content/p5m6582204v31013", "http://www.springerlink.com/index/p5m6582204v31013.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/ivic/ivic2009.html#ArifANAS09", "http://dx.doi.org/10.1007/978-3-642-05036-7_38"], "t": "Designing 3 Dimensional Virtual Reality Using Panoramic Image", "v": "IVIC", "y": 2009, "rn": 14}, {"a": ["Li Shen", "Ping Tan"], "b": "We extend photometric stereo to make it work with in- ternet images, which are typically associated with differ- ent viewpoints and significant noise. For popular tourism sites, thousands of images can be obtained from internet search engines. With these images, our method computes the global illumination for each image and the surface ori- entation at some scene points. The illumination", "cn": 1, "i": 6139720, "k": ["Global Illumination", "Photometric Stereo", "Search Engine", "Weather Condition"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206732", "http://www.ece.nus.edu.sg/stfpage/eletp/Papers/cvpr09_outdoorps.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#ShenT09"], "t": "Photometric stereo and weather estimation using internet images", "v": "CVPR", "y": 2009, "rn": 14}, {"a": ["Alexandre Karpenko", "Parham Aarabi"], "b": "This paper presents a new method for video and image categorization based on a database of over 50,000 videos collected from YouTube and down-sampled to tiny size. The categorization results achieved by tiny videos are compared with the tiny images framework for a variety of recognition tasks. The tiny images dataset consists of 80 million images collected from the Internet.", "cn": 1, "i": 13760298, "k": ["large dataset"], "p": ["http://doi.ieeecomputersociety.org/10.1109/ISM.2009.74", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05363624", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5363624", "http://www.informatik.uni-trier.de/~ley/db/conf/ism/ism2009.html#KarpenkoA09"], "t": "Tiny Videos: A Large Dataset for Image and Video Frame Categorization", "v": "ISM", "y": 2009, "rn": 11}, {"a": ["Bin Qiu", "Liren Zhang", "H. Wu"], "b": "This paper describes some investigation made into multi-step ahead prediction on the traffic intensity of digital video sources coded with hybrid motion compensation/differential pulse code modulation/discrete cosine transform (MC/DPCM/DCT) method. Although current coding standards recommend constant bit rate (CBR) output by means of a smoothing buffer, the method inherently produces variable bit rate (VBR) output, and VBR transmission is necessary", "cn": 1, "i": 50098360, "k": ["Atm Networks", "Congestion Control", "Digital Video", "Discrete Cosine Transform", "Fuzzy Logic", "Motion Compensated", "Prediction Method", "Propagation Delay", "Source Code", "Constant Bit Rate", "Differential Pulse Code Modulation", "Usage Parameter Control", "Variable Bit Rate"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00652269", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=652269"], "t": "Fuzzy multi-step ahead prediction of VBR video sources", "v": "ICICS", "y": 1997, "rn": 23}, {"a": ["Christopher Schwartz", "Reinhard Klein"], "b": "In Computer Graphics as well as in Computer Vision and Autonomous Navigation, Structure from Motion is a com- mon method to register cameras. Usually several steps are involved with bundle-adjustment as the final one. A good initial estimation of camera positions is of crucial impor- tance for the success of the bundle-adjustment and is the core component of any Structure", "cn": 1, "i": 6463412, "k": ["3d scene analysis", "Autonomous Navigation", "Bundle Adjustment", "Computer Graphic", "Connected Component", "Structure From Motion"], "p": ["http://www.cescg.org/CESCG-2009/papers/Bonn-Schwartz-Christopher.pdf", "http://cg.cs.uni-bonn.de/aigaion2root/attachments/schwartz-2009-improvesfm.pdf"], "t": "Improving Initial Estimations for Structure from Motion Methods", "y": 0, "rn": 19}, {"a": ["Qiang Hao", "Rui Cai", "Zhiwei Li", "Lei Zhang", "Yanwei Pang", "Feng Wu"], "b": "In this paper, we study the problem of landmark recognition and propose to leverage 3D visual phrases to improve the performance. A 3D visual phrase is a triangular facet on the surface of a reconstructed 3D landmark model. In contrast to existing 2D visual phrases which are mainly based on co-occurrence statistics in 2D image planes, such 3D visual phrases", "cn": 0, "i": 61402021, "k": ["3d visualization", "False Positive", "Spatial Structure"], "p": ["http://research.microsoft.com/apps/pubs/default.aspx?id=167612", "http://research.microsoft.com/pubs/167612/3dvisualphrase_cvpr2012.pdf"], "t": "3D Visual Phrases for Landmark Recognition", "y": 2012, "rn": 24}, {"a": ["Lo\u00efc Simon", "Olivier Teboul", "Panagiotis Koutsourakis", "Nikos Paragios"], "b": "In this paper we tackle the problem of 3D modeling for urban environment using a modular, flexible and powerful approach driven\n from procedural generation. To this end, typologies of architectures are modeled through shape grammars that consist of a\n set of derivation rules and a set of shape/dictionary elements. Appearance (from statistical point of view with respect to\n the individual", "cn": 0, "i": 15271315, "k": ["3d model", "Architectural Style", "Building Model", "Point of View", "Score Function", "Supervised Learning", "Urban Environment", "On The Fly", "Random Walk"], "p": ["http://www.springerlink.com/index/r8358n91573u56n3.pdf", "http://www.springerlink.com/content/r8358n91573u56n3", "http://www.springerlink.com/index/10.1007/s11263-010-0370-6", "http://www.springerlink.com/index/pdf/10.1007/s11263-010-0370-6", "http://dx.doi.org/10.1007/s11263-010-0370-6", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv93.html#SimonTKP11"], "t": "Random Exploration of the Procedural Space for Single-View 3D Modeling of Buildings", "v": "IJCV", "y": 2011, "rn": 41}, {"a": ["Wonwoo Lee", "Woontack Woo", "Edmond Boyer"], "b": "In this paper, we present a method for extracting consistent foreground regions when multiple views of a scene are available. We propose a framework that automatically identifies such regions in images under the assumption that, in each image, background and foreground regions present different color properties. To achieve this task, monocular color information is not sufficient and we exploit the", "cn": 0, "i": 48871459, "k": ["a priori knowledge", "Background Subtraction", "Image Color Analysis", "Image Segmentation", "Multiple Views", "Satisfiability", "Three Dimensional", "User Interaction"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05639011", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5639011"], "t": "Silhouette Segmentation in Multiple Views", "v": "PAMI", "y": 2011, "rn": 40}, {"a": ["Evren Imre", "Jean-Yves Guillemaut", "Adrian Hilton"], "b": "", "cn": 0, "i": 51080347, "k": ["Camera Calibration", "Computer Model", "Dynamic Scenes", "Heuristic Algorithm", "Structure From Motion", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955369", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955369"], "t": "Calibration of Nodal and Free-Moving Cameras in Dynamic Scenes for Post-Production", "v": "3DIMPVT", "y": 2011, "rn": 24}, {"a": ["Anders Dahl", "Henrik Aan\u00e6s", "Kim Pedersen"], "b": "", "cn": 0, "i": 51080355, "k": ["Feature Extraction", "Interest Points"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05955377", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5955377"], "t": "Finding the Best Feature Detector-Descriptor Combination", "v": "3DIMPVT", "y": 2011, "rn": 24}, {"a": ["Shuntaro Yamazaki", "Masaaki Mochimaru", "Takeo Kanade"], "b": "We propose a method for geometric calibration of an active vision system, composed of a projector and a camera, using structured light projection. Unlike existing methods of self-calibration for projector-camera systems, our method estimates the intrinsic parameters of both the projector and the camera as well as extrinsic parameters except a global scale without any calibration apparatus such as a", "cn": 0, "i": 51098559, "k": ["Active Vision", "Camera Calibration", "Fundamental Matrix", "Gray Code", "Mathematical Model", "Matrix Decomposition", "Phase Shift", "Structured Light"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05981781", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5981781"], "t": "Simultaneous self-calibration of a projector and a camera using structured light", "v": "CVPR", "y": 2011, "rn": 21}, {"a": ["Mohamed Tamaazousti", "Vincent Gay-Bellile", "Sylvie Collette", "Steve Bourgeois", "Michel Dhome"], "b": "We address the challenging issue of camera localization in a partially known environment, i.e. for which a geometric 3D model that covers only a part of the observed scene is available. When this scene is static, both known and unknown parts of the environment provide constraints on the camera motion. This paper proposes a nonlinear refinement process of an initial", "cn": 0, "i": 51107972, "k": ["3d model", "Camera Motion", "Object Tracking", "Structure From Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995358", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995358"], "t": "NonLinear refinement of structure from motion reconstruction by taking advantage of a partial knowledge of the environment", "v": "CVPR", "y": 2011, "rn": 16}, {"a": ["Richard Hartley", "Khurrum Aftab", "Jochen Trumpf"], "b": "We consider the problem of rotation averaging under the L1 norm. This problem is related to the classic FermatWeber problem for finding the geometric median of a set of points in IR n . We apply the classical Weiszfeld algorithm to this problem, adapting it iteratively in tangent spaces of SO(3) to obtain a provably convergent algorithm for finding the", "cn": 0, "i": 51108350, "k": ["Line Search"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05995745", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5995745"], "t": "L1 rotation averaging using the Weiszfeld algorithm", "v": "CVPR", "y": 2011, "rn": 23}, {"a": ["Foteini Ioakeimidou", "Alex Olwal", "Axel Nordberg", "Hans Holst"], "b": "Image-guided surgery (IGS) often depends on X-ray imaging, since pre-operative MRI, CT and PET scans do not provide an up-to-date internal patient view during the operation. X-rays introduce hazardous radiation, but long exposures for monitoring are often necessary to increase accuracy in critical situations. Surgeons often also take multiple X-rays from different angles, as X-rays only provide a distorted 2D", "cn": 0, "i": 51114381, "k": ["3d visualization", "Biomedical Imaging", "Data Visualization", "Image Guided Surgery", "Interactive Visualization", "Motion Tracking", "Patient Safety", "Three Dimensional", "X Rays", "X-ray Imaging"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5999129", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05999129"], "t": "3D Visualization and interaction with spatiotemporal X-ray data to minimize radiation in image-guided surgery", "v": "CBMS", "y": 2011, "rn": 10}, {"a": ["Kai Jiang", "Peng Wang", "Nenghai Yu"], "b": "In this paper, we propose a method: ContextRank, which utilizes the vast quantity of geotagged photos in photo sharing website to recommend travel locations. To enhance the personalized recommendation performance, our method exploits different context information of photos, such as textual tags, geotags, visual information, and user similarity. Contex- tRank first detects landmarks from photos' GPS locations, and estimates the", "cn": 0, "i": 51117991, "k": ["Context Information", "Global Position System", "Learning To Rank", "Photo Sharing", "User Preferences"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6005632", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06005632"], "t": "ContextRank: Personalized Tourism Recommendation by Exploiting Context Information of Geotagged Web Photos", "v": "ICIG", "y": 2011, "rn": 14}, {"a": ["Javier Civera", "Dorian Galvez-Lopez", "L. Riazuelo", "Juan Tardos", "J. Montiel"], "b": "Monocular SLAM systems have been mainly fo- cused on producing geometric maps just composed of points or edges; but without any associated meaning or semantic content. In this paper, we propose a semantic SLAM algorithm that merges in the estimated map traditional meaningless points with known objects. The non-annotated map is built using only the information extracted from a monocular", "cn": 0, "i": 51148028, "k": ["Image Sequence", "Information Extraction", "Object Model", "Object Recognition", "Simultaneous Localization and Mapping", "Solid Modeling", "Three Dimensional", "Real Time"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6048293", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06048293"], "t": "Towards semantic SLAM using a monocular camera", "v": "IROS", "y": 2011, "rn": 24}, {"a": ["Wenwu Zhu", "Chong Luo", "Jianfeng Wang", "Shipeng Li"], "b": "", "cn": 0, "i": 51180108, "k": ["Cloud Computing", "Multimedia Communication", "Quality of Service"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5754008", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05754008", "http://adsabs.harvard.edu/abs/2011ISPM...28...59Z"], "t": "Multimedia Cloud Computing", "v": "IEEE SIGNAL PROCESS MAG", "y": 2011, "rn": 19}, {"a": ["Marcio Cabral", "Nicolas Bonneel", "Sylvain Lefebvre", "George Drettakis"], "b": "We present an image-based approach to relighting photographs of tree canopies. Our goal is to minimize capture overhead; thus the only input required is a set of photographs of the tree taken at a single time of day, while allowing relighting at any other time. We first analyze lighting in a tree canopy both theoretically and using simulations. From this", "cn": 0, "i": 51187750, "k": ["Approximation Method", "Computer Graphic", "Computer Model", "Image Based Rendering", "Participating Media", "Spherical Harmonic", "Time of Day", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5620896", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05620896"], "t": "Relighting Photographs of Tree Canopies", "v": "TVCG", "y": 2011, "rn": 34}, {"a": ["Ana Santos", "V. Jr."], "b": "uCom enables remote users to be visually aware of each other using \"spatial displays\"' live views of a remote space assembled according to an estimate of the remote space's layout. Remote video views from multiple viewpoints are shown individually or in a 3D collage representation that is faithful to the scene geometry. A multi-display setup integrates always-on visual connections of", "cn": 0, "i": 13302522, "k": ["Spatial Context", "Visual Awareness"], "p": ["http://doi.acm.org/10.1145/1753846.1754119", "http://portal.acm.org/ft_gateway.cfm?id=1754119&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1754119", "http://www.informatik.uni-trier.de/~ley/db/conf/chi/chi2010a.html#SantosB10"], "t": "uCom: spatial displays for visual awareness of remote locations", "v": "CHI", "y": 2010, "rn": 8}, {"a": ["Eleanor Rieffel", "Don Kimber", "Jim Vaughan"], "b": "Creating virtual models of real spaces and objects is cumbersome and time\nconsuming. This paper focuses on the problem of geometric reconstruction from\nsparse data obtained from certain image-based modeling approaches. A number of\nelegant and simple-to-state problems arise concerning when the geometry can be\nreconstructed. We describe results and counterexamples, and list open problems.", "cn": 0, "i": 13326182, "k": ["Computational Geometry", "image-based modeling", "Sparse Data"], "p": ["http://adsabs.harvard.edu/abs/2010arXiv1003.3499R", "http://arxiv.org/abs/1003.3499", "http://www.informatik.uni-trier.de/~ley/db/journals/corr/corr1003.html#abs-1003-3499"], "t": "Geometric reconstruction from point-normal data", "v": "CORR", "y": 2010, "rn": 17}, {"a": ["Jaekwang Lee", "Chang-Joon Park"], "b": "\n This paper proposes an algorithm to detect unnecessary image pairs for efficient structure from motion. Since image pair with\n small baseline is considered as a poor condition for reconstruction, we focus on computing cameras closely located. We address\n a term, \u201cremoteness\u201d which indicates the distance between two images in this paper. The remoteness is not affected by image\u2019s intrinsic parameters", "cn": 0, "i": 13761077, "k": ["Large Scale", "Structure From Motion"], "p": ["http://dx.doi.org/10.1007/978-3-642-15399-0_14", "http://www.springerlink.com/content/766gpr7u6uw66810", "http://www.springerlink.com/index/766gpr7u6uw66810.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iwec/icec2010.html#LeeP10"], "t": "Unnecessary Image Pair Detection for a Large Scale Reconstruction", "v": "ICEC", "y": 2010, "rn": 14}, {"a": ["Chia-Ming Cheng", "Xiao-An Hsu", "Shang-Hong Lai"], "b": "The video-plus-depth format has been widely used for representing the 3D scene due to its main advantage of compatibility to image format. In practice, the depth inconsistency may lead to unsatisfactory view synthesis results. In this paper, we propose a new structure-from-motion (SfM) technique, called locally temporal bundle adjustment (LTBA), to handle the dynamic scenes as well as the static", "cn": 0, "i": 13996292, "k": ["Bundle Adjustment", "Camera Motion", "Depth Map", "Dynamic Scenes", "Image Formation", "Structure From Motion", "View Synthesis"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05583375", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5583375", "http://dx.doi.org/10.1109/ICME.2010.5583375", "http://www.informatik.uni-trier.de/~ley/db/conf/icmcs/icme2010.html#ChengHL10"], "t": "A novel structure-from-motion strategy for refining depth map estimation and multi-view synthesis in 3DTV", "v": "ICME(ICMCS)", "y": 2010, "rn": 17}, {"a": ["En Peng", "Patrick Peursum", "Ling Li", "Svetha Venkatesh"], "b": "\n In this paper, we present a real-time obstacle detection system for the mobility improvement for the visually impaired using\n a handheld Smartphone. Though there are many existing assistants for the visually impaired, there is not a single one that\n is low cost, ultra-portable, non-intrusive and able to detect the low-height objects on the floor. This paper proposes a system\n to", "cn": 0, "i": 13997094, "k": ["Field Trial", "Monocular Vision", "Obstacle Detection", "Visual Impairment", "Real Time"], "p": ["http://www.springerlink.com/content/m665n180l1710tv6", "http://www.springerlink.com/index/m665n180l1710tv6.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/uic/uic2010.html#PengPLV10", "http://dx.doi.org/10.1007/978-3-642-16355-5_45"], "t": "A Smartphone-Based Obstacle Sensor for the Visually Impaired", "v": "UIC", "y": 2010, "rn": 14}, {"a": ["Toru Tamaki", "Shunsuke Tanigawa", "Yuji Ueno", "Bisser Raytchev", "Kazufumi Kaneda"], "b": "In this paper we propose a method for matching the scales of 3D point clouds. 3D point sets of the same scene obtained by 3D reconstruction techniques usually differ in scales. To match scales, we propose a keyscale that characterizes the scale of a given 3D point cloud. By performing PCA of spin images over different scales, a keyscale is", "cn": 0, "i": 14084027, "k": ["3d point cloud", "3d reconstruction", "cumulant"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5597540", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05597540", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2010.html#TamakiTURK10", "http://dx.doi.org/10.1109/ICPR.2010.850"], "t": "Scale Matching of 3D Point Clouds by Finding Keyscales with Spin Images", "v": "ICPR", "y": 2010, "rn": 14}, {"a": ["Samuel Hasinoff", "Fredo Durand", "William Freeman"], "b": "We propose a new system for editing personal photo collections, inspired by search-and-replace editing for text. In our system, local edits specified by the user in a single photo (e.g., using the \"clone brush\" tool) can be propagated automatically to other photos in the same collection, by matching the edited region across photos. To achieve this, we build on tools", "cn": 0, "i": 14140376, "k": ["Computer Vision", "Image Matching", "Photo Collection"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5585099", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05585099", "http://people.csail.mit.edu/hasinoff/pubs/hasinoff-searchreplace-2010.pdf"], "t": "Search-and-Replace Editing for Personal Photo Collections", "v": "ICCP", "y": 2010, "rn": 28}, {"a": ["Yanyun Qu", "Cheng Chen", "Yanyun Cheng", "Zejian Yuan"], "b": "Millions of place-specified photos are uploaded on the internet. Modeling and representing the landmark is very important for landmark retrieval and auto-annotation. In this paper, we aim at collecting images with a specific landmark and labeling the landmark in the images. We propose a weakly supervised labeling approach based on both textual and visual features. Firstly, we cluster the raw", "cn": 0, "i": 39231779, "k": ["k-means clustering", "Local Features", "Multiple Instance Learning", "Supervised Learning", "Visual Features"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=1937748&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1937748"], "t": "Weakly supervised landmark labeling in searched data", "y": 2010, "rn": 18}, {"a": ["Zuzana Kukelova", "Martin Bujnak", "Tom\u00e1s Pajdla"], "b": "\n In this paper we provide new simple closed-form solutions to two minimal absolute pose problems for the case of known vertical\n direction. In the first problem we estimate absolute pose of a calibrated camera from two 2D-3D correspondences and a given\n vertical direction. In the second problem we assume camera with unknown focal length and radial distortion and estimate its", "cn": 0, "i": 39256559, "k": ["Closed Form Solution", "Inertial Measurement Unit", "Linear Equations", "Radial Distortion", "Vanishing Point"], "p": ["http://www.springerlink.com/content/m012m78244081306", "http://www.springerlink.com/index/m012m78244081306.pdf", "http://dx.doi.org/10.1007/978-3-642-19309-5_17", "http://www.informatik.uni-trier.de/~ley/db/conf/accv/accv2010-2.html#KukelovaBP10"], "t": "Closed-Form Solutions to Minimal Absolute Pose Problems with Known Vertical Direction", "v": "ACCV", "y": 2010, "rn": 18}, {"a": ["Nicolas Herrero", "Jose-Luis Landabaso", "Guillermo Gallego", "Jose-Carlos Pujol-Alcolado"], "b": "In this paper, a novel and approach for obtaining 3D models from video sequences captured with hand-held cameras is addressed. We define a pipeline that robustly deals with different types of sequences and acquiring devices. Our system follows a divide and conquer approach: after a frame decimation that pre-conditions the input sequence, the video is split into short-length clips. This", "cn": 0, "i": 39267849, "k": ["3d model", "3d reconstruction", "Divide and Conquer", "Feature Tracking", "Structure and Motion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5652179", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05652179", "http://dx.doi.org/10.1109/ICIP.2010.5652179", "http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2010.html#HerreroLGP10"], "t": "In-loop feature tracking for structure and motion with out-of-core optimization", "v": "ICIP", "y": 2010, "rn": 11}, {"a": ["Wilson Leoputra", "Tele Tan", "Svetha Venkatesh"], "b": "In this paper, we present a novel scene change detection algorithm for mobile camera platforms. Our approach integrates sparse 3D scene background modelling and dense 2D image background modelling into a unified framework. The 3D scene background modelling identifies inconsistent clusters over time in a set of 3D cloud points as the scene changes. The 2D image background modelling further", "cn": 0, "i": 39286046, "k": ["3d video", "Background Subtraction", "Scene Change Detection", "Cloud Point"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5707222", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05707222", "http://dx.doi.org/10.1109/ICARCV.2010.5707222", "http://www.informatik.uni-trier.de/~ley/db/conf/icarcv/icarcv2010.html#LeoputraTV10"], "t": "A unified 2D-3D video scene change detection framework for mobile camera platforms", "v": "ICARCV", "y": 2010, "rn": 23}, {"a": ["Yoram Gat", "Igor Kozintsev", "Oscar Nestares"], "b": "We discuss the problem of fusing the information in a video stream with synchronized streams of location and orientation data obtained from sensors attached to the video camera. We are interested in using this information for the reconstruction of camera trajectory and observed scenery from consumer videos with the objective of visualizing those in a 3D virtual environment. We review", "cn": 0, "i": 50919800, "k": ["3d virtual environment", "Data Stream", "Video Streaming"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5543781", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05543781"], "t": "Fusing image data with location and orientation sensor data streams for consumer video applications", "v": "CVPR", "y": 2010, "rn": 23}, {"a": ["Alexander Sorokin", "Dmitry Berenson", "Siddhartha Srinivasa", "Martial Hebert"], "b": "For successful deployment, personal robots must adapt to ever-changing indoor environments. While dealing with novel objects is a largely unsolved challenge in AI, it is easy for people. In this paper we present a framework for robot supervision through Amazon Mechanical Turk. Unlike traditional models of teleoperation, people provide semantic information about the world and subjective judgements. The robot then", "cn": 0, "i": 50988860, "k": ["Indoor Environment", "Semantic Information"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5650464", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05650464"], "t": "People helping robots helping people: Crowdsourcing for grasping novel objects", "v": "IROS", "y": 2010, "rn": 9}, {"a": ["Kaimin Yu", "Zhiyong Wang", "Li Zhuo", "Dagan Feng"], "b": "Large amount of labeled training data is required to develop robust and effective facial expression analysis methods. However, obtaining such data is typically a tedious and time-consuming task that is proportional to the size of the database. Due to the rapid advance of Internet and Web technologies, it is now feasible to collect a tremendous number of images with potential", "cn": 0, "i": 51015970, "k": ["Active Learning", "Affective Computing", "Facial Expression", "Facial Expression Analysis", "Facial Expression Recognition", "Image Search", "Web Search Engine", "Web Technology"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5692613", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05692613"], "t": "Harvesting Web Images for Realistic Facial Expression Recognition", "v": "DICTA", "y": 2010, "rn": 20}, {"a": ["Vinod Khare", "Alper Yilmaz", "O. Mendoza-Schrok"], "b": "Image registration has traditionally been performed by estimating parametric transformation between two images. In this paper, we extend the standard approach to multiple images and adopt the photogrammetric process to improve accuracy of registration. In particular, we use a multi-head camera mount providing multiple non-overlapping images per time epoch and use multiple epochs which increase the number of images to", "cn": 0, "i": 51022527, "k": ["Bundle Block Adjustment", "Image Registration"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5712936", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05712936"], "t": "Precise image registration and occlusion labeling", "v": "NAECON", "y": 2010, "rn": 8}, {"a": ["Mauricio D\u00edaz", "Peter Sturm"], "b": "When we look at images taken from outdoor scenes, much of the information perceived is due to the ligthing conditions. In these scenes, the solar beams interact with the atmosphere and create a global illumination that determines the way we perceive objets in the world. Lately, exploration of the sky like the main illuminance component has began to be explored", "cn": 0, "i": 6030280, "k": ["Color Space", "Computer Vision", "Gaussian Mixture Model", "Global Illumination", "Photo Collection"], "p": ["http://dx.doi.org/10.1007/978-3-642-10268-4_6", "http://www.springerlink.com/content/yn31177m0q522267", "http://www.springerlink.com/index/yn31177m0q522267.pdf", "http://perception.inrialpes.fr/Publications/2009/DS09/DiazSturm_ciarp2009.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/ciarp/ciarp2009.html#DiazS09", "http://adsabs.harvard.edu/abs/2009LNCS.5856...53D"], "t": "Finding Images with Similar Lighting Conditions in Large Photo Collections", "v": "CIARP", "y": 2009, "rn": 18}, {"a": ["Yanpeng Cao", "John Mcdonald"], "b": "Given a set of unsorted views captured in a wide area, an effective solution is proposed for image self-organization. The method starts with an initialization step where a small number of key frame pairs are selected to set up a global reference. Given a query image we automatically relate it to the existing key frames based on their pair-wise similarity", "cn": 0, "i": 6063628, "k": ["Feature Detection", "Self Organization"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/wiamis/wiamis2009.html#CaoM09", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5031461", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05031461", "http://doi.ieeecomputersociety.org/10.1109/WIAMIS.2009.5031461"], "t": "Self-organizaiton for images from a moving camera", "v": "WIAMIS", "y": 2009, "rn": 6}, {"a": ["Shuang He", "Yue Qi", "Fei Hou"], "b": "This paper presents a novel approach to quick reconstruction of cameras and quasi-dense geometry from unordered photos of a scene. With three reconstruction goals: reliable camera postures, high-density scene geometry, and a low cost of time, our approach consists of two stages: pairwise relating and two-tier reconstruction. At the first stage, to obtain better putative matches, we impose bidirectional feature", "cn": 0, "i": 6453708, "k": ["Degeneration", "Feature Matching", "High Density"], "p": ["http://doi.ieeecomputersociety.org/10.1109/CSIE.2009.970", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5170722", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05170722", "http://www.informatik.uni-trier.de/~ley/db/conf/csie/csie2009-6.html#HeQH09"], "t": "Quick Reconstruction of Cameras and Quasi-dense Geometry from Unordered Photos", "v": "CSIE", "y": 2009, "rn": 13}, {"a": ["Yong Heo", "Kyoung Lee", "Sang Lee"], "b": "In this paper, we propose a new method that infers accu- rate depth maps and color-consistent images between ra- diometrically varying stereo images, simultaneously. In general, stereo matching and performing color consis- tency between stereo images are a chicken-and-egg prob- lem. Color consistency enhances the performance of stereo matching, while accurate correspondences from stereo dis- parities improve color consistency between", "cn": 0, "i": 39265973, "k": ["Color Space", "Depth Map", "Mutual Information", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05459396", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459396", "http://dx.doi.org/10.1109/ICCV.2009.5459396", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2009.html#HeoLL09", "http://cv.snu.ac.kr/publication/conf/2009/SCDM_iccv2009.pdf"], "t": "Simultaneous color consistency and depth map estimation for radiometrically varying stereo images", "v": "ICCV", "y": 2009, "rn": 19}, {"a": ["Yong Heo", "Kyoung Lee", "Sang Lee"], "b": "Radiometric variations between input images can seriously degrade the performance of stereo matching algorithms. In this situation, mutual information is a very popular and powerful measure which can find any global relationship of intensities between two input images taken from unknown sources. The mutual information-based method, however, is still ambiguous or erroneous as regards local radiometric variations, since it only", "cn": 0, "i": 50782766, "k": ["Color Image", "Color Space", "Mutual Information", "Power Measurement", "Spatial Information", "Stereo Matching"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206507", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206507"], "t": "Mutual information-based stereo matching combined with SIFT descriptor in log-chromaticity color space", "v": "CVPR", "y": 2009, "rn": 13}, {"a": ["Li Shen", "Ping Tan"], "b": "We extend photometric stereo to make it work with internet images, which are typically associated with different viewpoints and significant noise. For popular tourism sites, thousands of images can be obtained from internet search engines. With these images, our method computes the global illumination for each image and the surface orientation at some scene points. The illumination information can then", "cn": 0, "i": 50782988, "k": ["Global Illumination", "Photometric Stereo", "Search Engine", "Weather Condition"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206732", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206732"], "t": "Photometric stereo and weather estimation using internet images", "v": "CVPR", "y": 2009, "rn": 13}, {"a": ["Klas Josephson", "Martin Byrod"], "b": "This paper presents a solution to the problem of pose estimation in the presence of heavy radial distortion and a potentially large number of outliers. The main contribution is an algorithm that solves for radial distortion, focal length and camera pose using a minimal set of four point correspondences between 3D world points and image points. We use a RANSAC", "cn": 0, "i": 50783011, "k": ["Bundle Adjustment", "Pose Estimation", "Radial Distortion"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206756", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206756"], "t": "Pose estimation with radial distortion and unknown focal length", "v": "CVPR", "y": 2009, "rn": 16}, {"a": ["Marcel Br\u00fcckner", "Ferid Bajramovic", "Joachim Denzler"], "b": "Detecting image pairs with a common field of view is an important prerequisite for many computer vision tasks. Typically, common local features are used as a criterion for identifying such image pairs. This approach, however, requires a reliable method for matching features, which is generally a very difficult problem, especially in situations with a wide baseline or ambiguities in the", "cn": 0, "i": 50783063, "k": ["Computer Vision", "Dissimilarity Measure", "False Positive", "Feature Matching", "Geometric Constraints", "Local Features", "Field of View", "False Positive Rate"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206810", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206810"], "t": "Geometric and probabilistic image dissimilarity measures for common field of view detection", "v": "CVPR", "y": 2009, "rn": 12}, {"a": ["Peter Cho", "Soonmin Bae", "Fredo Durand"], "b": "We extend recent automated computer vision algorithms to reconstruct the global three-dimensional structures for photos and videos shot at fixed points in outdoor city environments. Mosaics of digital stills and embedded videos are georegistered by matching a few of their 2D features with 3D counterparts in aerial ladar imagery. Once image planes are aligned with world maps, abstract urban knowledge", "cn": 0, "i": 50867169, "k": ["Augmented Reality", "Computer Vision", "Fixed Point", "Smart Phone", "Three-dimensional Structure", "Video Streaming"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05466321", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5466321"], "t": "Image-based querying of urban photos and videos", "v": "AIPR", "y": 2009, "rn": 10}, {"a": ["H. Borjeson", "C. Bergljung", "L. Olsson"], "b": "Narrowband measurements at 1700 MHz have been performed in two different urban environments with antennas below roof level. From these data fading characteristics have been extracted and analysed. For the long fading, period below 5 \u03bb, variance and correlation (autocorrelation) have been calculated and analysed concerning differences between line-of-sight and non-line-of-sight with the transmitter, different streets and distance between receiver", "cn": 0, "i": 49931784, "k": ["Urban Environment", "Line of Sight", "Non Line of Sight"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=279845"], "t": "Fading characteristics in outdoor microcell at 1700 MHz", "v": "PIMRC", "y": 1992, "rn": 16}, {"a": ["William Grady", "Pat O'Brien"], "b": "", "cn": 0, "i": 5715456, "k": ["Digital Earth"], "p": ["http://www.wpi.edu/Pubs/E-project/Available/E-project-050509-114006/unrestricted/DEW_Final.pdf"], "t": "Increasing Participation of Citizen Scientists in the Digital Earth Watch Project", "y": 0, "rn": 13}, {"a": ["Christian Lipski", "Denis Bose", "Martin Eisemann", "Kai Berger", "Marcus Magnor"], "b": "Over the past years, Structure-from-Motion calibration algorithms have become widely popular for many applications in com- puter graphics. From an unordered set of photographs, they manage to robustly estimate intrinsic and extrinsic camera parame- ters for each image. One major drawback is the quadratic computation time of existing algorithms. This paper presents di fferent strategies to overcome this problem by", "cn": 0, "i": 6892613, "k": ["Bundle Adjustment", "Camera Calibration", "Structure From Motion"], "p": ["http://graphics.tu-bs.de/people/berger/files/papers/B37-full.pdf"], "t": "Sparse Bundle Adjustment Speedup Strategies", "y": 0, "rn": 11}, {"a": ["KLAS JOSEPHSON"], "b": "", "cn": 0, "i": 14332654, "k": [], "p": ["http://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=1051275&fileOId=1152273"], "t": "NEW RESULTS ON TRIANGULATION, POLYNOMIAL EQUATION SOLVING AND THEIR APPLICATION IN GLOBAL LOCALIZATION", "y": 0, "rn": 22}, {"a": ["Franz Leberl"], "b": "\n In March 2005, at the occasion of his 50th birthday, Bill Gates went public with his \u201cVirtual Earth Vision\u201d for local search\n in the Internet and stated: \"You\u2019ll be walking around in downtown London and be able to see the shops, the stores, see what the traffic is like. Walk in\n a shop and navigate the merchandise. Not in the", "cn": 0, "i": 47673760, "k": ["3d city model", "3d model", "Aerial Photography", "Anonymous Communication", "Laser Scanner", "Storage Capacity", "Urban Space", "Virtual Reality", "Local Search"], "p": ["http://www.springerlink.com/content/h453858w784101l1", "http://www.springerlink.com/index/h453858w784101l1.pdf"], "t": "Human Habitat Data in 3D for the Internet", "y": 0, "rn": 5}, {"a": ["Ferid Bajramovic", "Marcel Br\u00fcckner", "Joachim Denzler"], "b": "We propose a novel minimum uncertainty approach to relative pose selection for multi-camera self-calibration. We show how\n this discrete global optimization problem can be expressed as a shortest triangle paths problem. For the latter, we present\n an efficient algorithm and prove its correctness. It has several advantages compared to a similar approach of Verg\u00e9s-Llah\u00ed,\n Moldovan and Wada. In quantitative experiments", "cn": 0, "i": 48050520, "k": ["Bundle Adjustment", "Discrete Optimization", "Efficient Algorithm", "Global Optimization"], "p": ["http://www.springerlink.com/index/b352n0h055k24524.pdf", "http://www.springerlink.com/content/b352n0h055k24524"], "t": "An Efficient Shortest Triangle Paths Algorithm Applied to Multi-camera Self-calibration", "v": "JMIV", "y": 0, "rn": 30}, {"a": ["Henrik Aan\u00e6s", "Anders Dahl", "Kim Pedersen"], "b": "Not all interest points are equally interesting. The most valuable interest points lead to optimal performance of the computer\n vision method in which they are employed. But a measure of this kind will be dependent on the chosen vision application. We\n propose a more general performance measure based on spatial invariance of interest points under changing acquisition parameters\n by measuring", "cn": 0, "i": 48491054, "k": ["Building Material", "Computer Vision", "Fruit and Vegetables", "Industrial Robots", "Interest Points", "Object Recognition", "Performance Evaluation", "Performance Measure", "Scale Space", "Structured Light", "maximally stable extremal region"], "p": ["http://www.springerlink.com/index/e315081774457204.pdf", "http://www.springerlink.com/content/e315081774457204"], "t": "Interesting Interest Points", "v": "IJCV", "y": 0, "rn": 55}, {"a": ["Mauricio Diaz", "Peter Sturm"], "b": "\n We address the problem of jointly estimating the scene illumination, the radiometric camera calibration and the reflectance\n properties of an object using a set of images from a community photo collection. The highly ill-posed nature of this problem\n is circumvented by using appropriate representations of illumination, an empirical model for the nonlinear function that relates\n image irradiance with intensity values", "cn": 0, "i": 48844328, "k": ["3d model", "Camera Calibration", "Empirical Model", "Non-linear Optimization", "Photo Collection", "Radiometric Calibration", "Response Function"], "p": ["http://www.springerlink.com/content/qk1833l70q733p18", "http://www.springerlink.com/index/qk1833l70q733p18.pdf"], "t": "Exploiting Image Collections for Recovering Photometric Properties", "y": 0, "rn": 20}, {"a": ["Iain McEwan"], "b": "", "cn": 0, "i": 49321167, "k": ["Nuclear Hormone Receptor"], "p": ["http://www.sciencedirect.com/science/article/pii/S030372071100517X"], "t": "Nuclear hormone receptors: Allosteric switches", "v": "MOL CELL ENDOCRINOL", "y": 0, "rn": 9}, {"a": ["Martin Fischler", "Robert Bolles"], "b": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model\r\n\tto experimental data is introduced. RANSAC is capable of interpreting/smoothing\r\n\tdata containing a significant percentage of gross errors, and is\r\n\tthus ideally suited for applications in automated image analysis\r\n\twhere interpretation is based on the data provided by error-prone\r\n\tfeature detectors. A major portion of this paper describes the", "cn": 3650, "i": 771993, "k": ["Experimental Data", "Image Analysis", "Model Fitting", "Random Sampling"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/cacm/cacm24.html#FischlerB81", "http://portal.acm.org/citation.cfm?id=358692", "http://portal.acm.org/citation.cfm?doid=358669.358692", "http://www1.cs.columbia.edu/~belhumeur/courses/compPhoto/ransac.pdf", "http://www.cs.cmu.edu/%7Ebiorobotics/motion/www/papers/sbp_papers/f/p381-fischler.pdf", "http://www.cs.cmu.edu/~motionplanning/papers/sbp_papers/f/p381-fischler.pdf", "http://www.ai.sri.com/pubs/files/836.pdf", "http://leibniz.iimas.unam.mx/~yann/Vision/Fischler81.pdf", "http://www.cis.rit.edu/~cnspci/references/dip/fischler1981.pdf", "http://staff.fh-hagenberg.at/burger/Projects/robust-line-detection/fischler-ransac.pdf", "http://www.cs.huji.ac.il/course/2005/impr/articles/fischler-ransac.pdf", "http://portal.acm.org/citation.cfm?id=358669.358692", "http://www.tu-chemnitz.de/etit/proaut/paperdb/download/fischler81.pdf", "http://www.cs.cmu.edu/afs/cs.cmu.edu/misc/mosaic/common/omega/Web/People/motionplanning/papers/sbp_papers/f/p381-fischler.pdf", "http://graphics.stanford.edu/courses/cs164-09-spring/Handouts/papers_RANSAC.pdf", "http://www.cs.ait.ac.th/~mdailey/cvreadings/Fischler-RANSAC.pdf", "http://glorfindel.mavrinac.com/~aaron/school/pdf/fischler81_ransac.pdf", "http://www.inf.fu-berlin.de/lehre/SS08/PrGM/download/ransac.pdf", "http://www.cs.cmu.edu/~biorobotics/papers/sbp_papers/f/p381-fischler.pdf"], "t": "Random Sample Consensus: A Paradigm for Model Fitting with Applicationsto Image Analysis and Automated Cartography", "v": "CACM", "y": 1981, "rn": 7}, {"a": ["Christopher Harris", "Mike Stephens"], "b": "", "cn": 3335, "i": 1277722, "k": [], "p": ["http://www.bmva.org/bmvc/1988/avc-88-023.pdf", "http://www.cis.rit.edu/~cnspci/references/dip/harris1988.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=66122"], "t": "A Combined Corner and Edge Detector", "y": 1988, "rn": 5}, {"a": ["Marc Levoy", "Pat Hanrahan"], "b": "A number of techniques have been proposed for flying through scenes by redisplaying previously rendered or digitized views. Techniques have also been proposed for interpolating between views by warping input images, using depth information or correspondences between multiple images. In this paper, we describe a simple and robust method for generating new views from arbitrary camera positions without depth information", "cn": 1568, "i": 107461, "k": ["Digital Image", "Image Based Rendering", "Light Field", "Light Field Rendering", "Robust Method", "Vector Quantizer", "Real Time"], "p": ["http://portal.acm.org/citation.cfm?id=237199", "http://portal.acm.org/ft_gateway.cfm?id=237199&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=237170.237199", "http://doi.acm.org/10.1145/237170.237199", "http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1996.html#LevoyH96"], "t": "Light Field Rendering", "v": "SIGGRAPH", "y": 1996, "rn": 29}, {"a": ["Carlo Tomasi", "Takeo Kanade"], "b": "Inferring scene geometry and camera motion from a stream of images is possible in principle, but is an ill-conditioned problem when the objects are distant with respect to their size. We have developed a factorization method that can overcome this difficulty by recovering shape and motion under orthography without computing depth as an intermediate step.An image stream can be represented", "cn": 1100, "i": 3737239, "k": ["Camera Motion", "Factorization Method", "Singular Value Decomposition"], "p": ["http://www.springerlink.com/index/q3546r1363324l8r.pdf", "http://www.springerlink.com/content/q3546r1363324l8r"], "t": "Shape and motion from image streams under orthography: a factorization method", "v": "IJCV", "y": 1992, "rn": 25}, {"a": ["Krystian Mikolajczyk", "Cordelia Schmid"], "b": "In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results : (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure", "cn": 1091, "i": 1714728, "k": ["Affine Transformation", "Interest Points", "Iterative Algorithm", "Large Scale", "Local Features", "Local Structure", "Scale Invariance"], "p": ["http://pages.cs.wisc.edu/~dyer/ai-qual/mikolajczyk-ijcv04.pdf", "http://www.springerlink.com/index/h37t7833m7037173.pdf", "http://www.springerlink.com/content/h37t7833m7037173", "http://dx.doi.org/10.1023/B:VISI.0000027790.02288.f2", "http://users.ece.gatech.edu/~hamblen/4006/projects/spr05/Swan/files/mikolajc_ijcv2004.pdf", "http://cs.gmu.edu/~zduric/cs774/Papers/MikolajczykSchmid-Features-IJCV.pdf", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Article@11777a7ff07_19ae873/mikolajczyk_ijcv2004.pdf", "http://glorfindel.mavrinac.com/~aaron/school/pdf/mikolajczyk04_saipd.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv60.html#MikolajczykS04", "http://www.cse.unr.edu/~bebis/CS773C/ObjectRecognition/Papers/Mikolajczyk04a.pdf", "http://lear.inrialpes.fr/pubs/2004/MS04/mikolajczyk_ijcv2004.pdf", "http://www.ece.lsu.edu/gunturk/EE7700/mikolajczyk_ijcv2004.pdf", "http://www.diku.dk/OLD/undervisning/2008-2009/2008-2009_b1_3dcv/mikolajczyk_ijcv2004.pdf", "http://www1.idc.ac.il/toky/CompPhoto-09/Handouts/mikolajczyk_ijcv2004.pdf", "http://www.photonscope.com/TechnicalReference/disc2/scale%20&%20affine%20invariant%20interest%20point%20detectors.pdf", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000027790.02288.f2"], "t": "Scale & Affine Invariant Interest Point Detectors", "v": "IJCV", "y": 2004, "rn": 47}, {"a": ["H. Longuet-higgins"], "b": "A simple algorithm for computing the three-dimensional structure of a scene from a correlated pair of perspective projections is described here, when the spatial relationship between the two projections is unknown. This problem is relevant not only to photographic surveying1 but also to binocular vision2, where the non-visual information available to the observer about the orientation and focal length of", "cn": 1073, "i": 1286329, "k": ["Correspondence Problem", "Perspective Projection", "Relative Orientation", "Retinal Imaging", "Spatial Relationships", "Three Dimensional", "Three-dimensional Structure"], "p": ["http://www.nature.com/doifinder/10.1038/293133a0", "http://research.microsoft.com/apps/pubs/default.aspx?id=66311"], "t": "A computer algorithm for reconstructing a scene from two projections", "v": "", "y": 1981, "rn": 0}, {"a": ["Leonard McMillan", "Gary Bishop"], "b": "Image-based rendering is a powerful new approach for generating real-time photorealistic computer graphics. It can provide convinc- ing animations without an explicit geometric representation. We use the \"plenoptic function\" of Adelson and Bergen to provide a concise problem statement for image-based rendering paradigms, such as morphing and view interpolation. The plenoptic function is a param- eterized function for describing everything", "cn": 921, "i": 392049, "k": ["Computer Graphic", "Image Based Rendering", "plenoptic function", "View Interpolation", "Real Time"], "p": ["http://portal.acm.org/citation.cfm?id=218398", "http://portal.acm.org/ft_gateway.cfm?id=218398&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.cs.columbia.edu/~ravir/6998/papers/p39-mcmillan.pdf"], "t": "Plenoptic Modeling: An Image-Based Rendering System", "v": "SIGGRAPH", "y": 1995, "rn": 35}, {"a": ["Jiri Matas", "Ondrej Chum", "Martin Urban", "Tom\u00e1s Pajdla"], "b": "Thewide-baseline stereo problem, i.e. the problem of establishing\r\n\tcorrespondences between a pair of images taken from different viewpoints\r\n\tis studied. A new set of image elements that are put into correspondence,\r\n\tthe so called extremal regions, is introduced. Extremal regions possess\r\n\thighly desirable properties: the set is closed under 1. continuous\r\n\t(and thus projective) transformation of image coordinates and 2.", "cn": 810, "i": 498973, "k": ["maximally stable extremal region"], "p": ["http://www.cise.ufl.edu/class/cis6930fa07atc/Papers/matas.pdf", "http://www.bmva.ac.uk/bmvc/2002/papers/113/full_113.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2002.html#MatasCUP02", "http://cmp.felk.cvut.cz/~matas/papers/matas-bmvc02.pdf", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/2002/papers/113/full_113.pdf", "http://vis.uky.edu/~dnister/Teaching/CS684Fall2005/matas_bmvc2002.pdf", "http://cmp.felk.cvut.cz/~wbsdemo/demo/publications/matas-bmvc02.pdf", "http://www.vis.uky.edu/~dnister/Teaching/CS684Fall2005/matas_bmvc2002.pdf", "http://www.cse.psu.edu/~rcollins/CSE597E/papers/matas_bmvc2002.pdf", "http://www.bmva.org/bmvc/2002/papers/113/full_113.pdf", "http://reference.kfupm.edu.sa/content/r/o/robust_wide_baseline_stereo_from_maximal_117339.pdf", "http://www-dsp.elet.polimi.it/VA-TLC/Articoli/matas_bmvc2002-Robust%20wide%20baseline%20stereo%20from%20maximally%20stable%20extremal%20regions.pdf"], "t": "Robust wide baseline stereo from maximally stable extremal regions", "v": "BMVC", "y": 2002, "rn": 19}, {"a": ["Josef Sivic", "Andrew Zisserman"], "b": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a setof viewpoint invariantregion descriptorsso thatrecog- nition can proceed successfully despite changes in view- point, illumination and partial occlusion. The temporal continuity of the video within a shot is used", "cn": 790, "i": 1796435, "k": ["File System", "Text Retrieval", "Full Length"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-2.html#SivicZ03", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238663", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238663", "http://www.optimization.ca/Learning/Research/files/sivic03.pdf", "http://www.cse.iitd.ac.in/~abhinav/datamining/papers/sivic03.pdf", "http://www.mmp.rwth-aachen.de/teaching/cvws08/additional/sivic03.pdf", "http://www.cs.utsa.edu/~qitian/seminar/Spring08/04_11_08/sivic03.pdf", "http://web.cs.swarthmore.edu/~turnbull/cs97/f08/paper/sivic03.pdf", "http://www.cse.iitd.ernet.in/~abhinav/datamining/papers/sivic03.pdf", "http://www.vis.uky.edu/~dnister/Teaching/CS684Fall2005/sivic03.pdf", "http://web.cs.swarthmore.edu/~turnbull/cs97/f09/paper/sivic03.pdf", "http://www.cise.ufl.edu/class/cis6930fa07atc/Papers/Sivic03.pdf", "http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/sivic03.pdf", "http://www.robots.ox.ac.uk/~vgg/publications/papers/sivic03.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/02/195021470abs.htm"], "t": "Video Google: A Text Retrieval Approach to Object Matching in Videos", "v": "ICCV", "y": 2003, "rn": 21}, {"a": ["Krystian Mikolajczyk", "Tinne Tuytelaars", "Cordelia Schmid", "Andrew Zisserman", "Jiri Matas", "Frederik Schaffalitzky", "Timor Kadir", "Luc Gool", "J. Matas"], "b": "The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector", "cn": 770, "i": 2386436, "k": [], "p": ["http://www.caip.rutgers.edu/~meer/TEACHTOO/PAPERS/mikolajczyk05.pdf", "http://www.springerlink.com/content/744376233t370532", "http://www.springerlink.com/index/744376233t370532.pdf", "http://www.eecs.berkeley.edu/~yang/courses/cs294-6/papers/MikolajczykK_A%20comparison%20of%20affine%20region%20detectors.pdf", "http://www.cse.psu.edu/~rcollins/CSE597E/papers/vibes_ijcv2004.pdf", "http://inst.eecs.berkeley.edu/~cs294-6/fa06/papers/MikolajczykK_A%20comparison%20of%20affine%20region%20detectors.pdf", "http://www-inst.eecs.berkeley.edu/~cs294-6/fa06/papers/MikolajczykK_A%20comparison%20of%20affine%20region%20detectors.pdf", "http://vision.ai.uiuc.edu/%7Esintod/AffineRegionDetectors_IJCV05.pdf", "http://www.springerlink.com/index/10.1007/s11263-005-3848-x", "http://www.springerlink.com/index/pdf/10.1007/s11263-005-3848-x"], "t": "A Comparison of Affine Region Detectors", "v": "IJCV", "y": 2005, "rn": 48}, {"a": ["Shenchang Chen", "Lance Williams"], "b": "Image-space simplifications have been used to accelerate the calculation of computer graphic images since the dawn of visual simulation. Texture mapping has been used to provide a means by which images may themselves be used as display primitives. The work reported by this paper endeavors to carry this concept to its logical extreme by using interpolated images to portray three-dimensional", "cn": 689, "i": 289602, "k": ["3d representation", "Computer Graphic", "Image Synthesis", "Motion Blur", "Motion Compensated", "Personal Computer", "Range Data", "Soft Shadow", "Texture Mapping", "Three Dimensional", "View Interpolation", "Virtual Environment", "Virtual Reality", "Visual Simulation", "Real Time"], "p": ["http://www1.cs.columbia.edu/~ravir/6998/papers/p279-chen.pdf", "http://portal.acm.org/citation.cfm?id=166153", "http://portal.acm.org/ft_gateway.cfm?id=166153&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://kucg.korea.ac.kr/seminar/2001/src/pa-01-50-02.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1993.html#ChenW93", "http://www.cs.princeton.edu/courses/archive/fall02/cs526/papers/chen93.pdf", "http://www.cs.arizona.edu/classes/cs534/p279-chen.pdf", "http://www.cs.princeton.edu/courses/archive/spring2001/cs598b/papers/chen93.pdf", "http://lawlor.cs.uaf.edu/~olawlor/projects/2004/thesis/ref/chen93interpolation.pdf", "http://www.cs.ucl.ac.uk/staff/j.mortensen/papers/ibr/Chen_S_E__View_Interpolation_for_Image_Synthesis__SIGGRAPH1993.pdf", "http://www.cs.uaf.edu/~olawlor/academic/thesis/ref/chen93interpolation.pdf", "http://www1.cs.columbia.edu/~belhumeur/courses/appearance/chen93view.pdf", "http://www.cs.princeton.edu/courses/archive/spr01/cs598b/papers/chen93.pdf", "http://www1.cs.columbia.edu/~belhumeur/courses/biometrics/2006/appearance/chen93view.pdf", "http://charm.cs.uiuc.edu/users/olawlor/academic/thesis/ref/chen93interpolation.pdf", "http://lawlor.cs.uaf.edu/users/olawlor/projects/2004/thesis/ref/chen93interpolation.pdf", "http://lawlor.cs.uaf.edu/users/olawlor/academic/thesis/ref/chen93interpolation.pdf", "http://www.cs.umd.edu/class/spring2005/cmsc828v/papers/p279-chen.pdf", "http://lawlor.cs.uaf.edu/~olawlor/academic/thesis/ref/chen93interpolation.pdf"], "t": "View interpolation for image synthesis", "v": "SIGGRAPH", "y": 1993, "rn": 23}, {"a": ["Sunil Arya", "David Mount", "Nathan Netanyahu", "Ruth Silverman", "Angela Wu"], "b": " Consider a set S of n data points in real d-dimensional space, R^d, ehere distances are measured using any Minkowski metric. In nearest...", "cn": 559, "i": 8858, "k": ["Optimal Algorithm", "Approximate Nearest Neighbor"], "p": ["https://www.cs.umd.edu/~mount/Papers/dist.pdf", "http://www.cs.ust.hk/faculty/arya/pub/JACM.pdf", "http://orion.math.iastate.edu/reu/2001/nearest_neighbor/p891-arya.pdf", "http://graphics.stanford.edu/courses/cs468-06-fall/Papers/03%20AMNSW%20-%20JACM.pdf", "http://people.sc.fsu.edu/~burkardt/isu/reu_2001/nearest_neighbor/p891-arya.pdf", "https://graphics.stanford.edu/courses/cs468-06-fall/Papers/03%20AMNSW%20-%20JACM.pdf", "http://www.cs.umd.edu/~mount/Papers/dist.pdf", "http://www-graphics.stanford.edu/courses/cs468-06-fall/Papers/03%20AMNSW%20-%20JACM.pdf", "http://www-hci.stanford.edu/courses/cs468-06-fall/Papers/03%20AMNSW%20-%20JACM.pdf", "http://www.cs.umd.edu/users/mount/Papers/dist.pdf"], "t": "An Optimal Algorithm for Approximate Nearest Neighbor Searching in Fixed Dimensions", "v": "JACM", "y": 1994, "rn": 77}, {"a": ["Sunil Arya", "David Mount", "Nathan Netanyahu", "Ruth Silverman", "Angela Wu"], "b": "Consider a set of S of n data points  in real d-dimensional space, Rd, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess S into a data structure, so that given any query point q \u2208 Rd, is the closest point of S to q can be reported quickly. Given any positive real \u03b5, data", "cn": 546, "i": 787050, "k": ["Approximate Algorithm", "Data Structure", "K Nearest Neighbor", "Nearest Neighbor Search", "Optimal Algorithm", "Approximate Nearest Neighbor", "Nearest Neighbor"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/jacm/AryaMNSW98.html", "http://portal.acm.org/ft_gateway.cfm?id=293348&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=293348", "http://portal.acm.org/citation.cfm?doid=293347.293348", "http://www.informatik.uni-trier.de/~ley/db/journals/jacm/jacm45.html#AryaMNSW98", "http://portal.acm.org/citation.cfm?id=293347.293348", "http://doi.acm.org/10.1145/293347.293348"], "t": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions", "v": "JACM", "y": 1998, "rn": 70}, {"a": ["Richard Hartley"], "b": "The fundamental matrix is a basic tool in the analysis of scenes taken with two uncalibrated cameras, and the eight-point algorithm is a frequently cited method for computing the fundamental matrix from a set of eight or more point matches. It has the advantage of simplicity of implementation. The prevailing view is, however, that it is extremely susceptible to noise", "cn": 490, "i": 799809, "k": ["Condition Number", "Fundamental Matrix", "Image Indexing", "Iterative Algorithm", "Stereo Vision"], "p": ["http://www.computer.org/tpami/tp1997/i0580abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=601246", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00601246", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami19.html#Hartley97a", "http://www.tecgraf.puc-rio.br/~mgattass/ra/ref/StereoRendering/hartleyIEEE97.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=601246", "http://www.cs.ucl.ac.uk/staff/S.Prince/4C75/hartley.pdf"], "t": "In Defense of the Eight-Point Algorithm", "v": "PAMI", "y": 1997, "rn": 29}, {"a": ["Luis Ahn", "Laura Dabbish"], "b": "We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in", "cn": 481, "i": 450101, "k": ["Computer Game", "Computer Vision", "Image Search", "Interactive System", "Knowledge Acquisition", "Online Game", "Visual Impairment", "World Wide Web"], "p": ["http://cs.wellesley.edu/~cs315/Papers/vonAhn-ESP.pdf", "http://portal.acm.org/citation.cfm?id=985733", "http://portal.acm.org/ft_gateway.cfm?id=985733&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/985692.985733", "http://portal.acm.org/citation.cfm?id=985692.985733", "http://nrl.iis.sinica.edu.tw/Web2.0/presentation/ESP.pdf", "http://www-2.cs.cmu.edu/~biglou/ESP.pdf", "https://www.aaai.org/Papers/Symposia/Spring/2005/SS-05-03/SS05-03-014.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/chi/chi2004.html#AhnD04", "http://www.aaai.org/Papers/Symposia/Spring/2005/SS-05-03/SS05-03-014.pdf", "http://courses.ischool.berkeley.edu/i290-1/s04/readings/ESP.pdf", "http://www.cs.cmu.edu/~biglou/ESP.pdf", "http://www.informatik.uni-freiburg.de/~ki/teaching/ws0910/gamesem/ahn-dabbish-2004.pdf", "http://www.cs.duke.edu/courses/cps296.3/spring07/ESP.pdf", "http://www.aladdin.cs.cmu.edu/papers/pdfs/y2004/esp.pdf", "http://www.cs.cmu.edu/afs/cs.cmu.edu/misc/mosaic/common/omega/Web/People/biglou/ESP.pdf", "http://www.cs.duke.edu/courses/spring07/cps296.3/ESP.pdf"], "t": "Labeling images with a computer game", "v": "CHI", "y": 2004, "rn": 9}, {"a": ["Steven Seitz", "Charles Dyer"], "b": "Image morphing techniques can generate compelling 2D transitions between images. However, differences in object pose or viewpoint often cause unnatural distortions in image morphs that are difficult to correct manually. Using basic principles of projective geometry, this paper introduces a simple extension to image morphing that cor- rectly handles 3D projective camera and scene transformations. The technique, called view morphing,", "cn": 444, "i": 285131, "k": ["Image Warping", "Projective Geometry", "View Interpolation", "View Synthesis"], "p": ["http://portal.acm.org/ft_gateway.cfm?id=237196&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=237196", "http://doi.acm.org/10.1145/237170.237196", "http://www-2.cs.cmu.edu/%7eseitz/papers/sigg96.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/siggraph/siggraph1996.html#SeitzD96", "http://portal.acm.org/citation.cfm?id=237170.237196", "http://www.cs.princeton.edu/courses/archive/spring01/cs598b/papers/seitz96.pdf"], "t": "View morphing", "v": "SIGGRAPH", "y": 1996, "rn": 22}, {"a": ["Steven Feiner", "Blair Macintyre", "Tobias H\u00f6llerer", "Anthony Webster"], "b": "We describe a prototype system that combines together the overlaid 3D graphics of augmented reality with the untethered freedom of mobile computing. The goal is to explore how these two technologies might together make possible wearable computer systems that can support users in their everyday interactions with the world. We introduce an application that presents information about our univer- sity's", "cn": 414, "i": 553615, "k": ["3d display", "3d graphics", "Augmented Reality", "Head Tracking", "Mobile Augmented Reality", "Mobile Computer", "Urban Environment", "Virtual Environment", "Wearable Computer"], "p": ["http://www.springerlink.com/index/t553412326742258.pdf", "http://www.springerlink.com/content/t553412326742258", "http://computer.org/proceedings/iswc/8192/81920074abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iswc/iswc1997.html#FeinerMHW97", "http://www.informatik.uni-trier.de/~ley/db/journals/puc/puc1.html#FeinerMHW97", "http://www.springerlink.com/index/10.1007/BF01682023", "http://www.springerlink.com/index/pdf/10.1007/BF01682023"], "t": "A Touring Machine: Prototyping 3D Mobile Augmented Reality Systems for Exploring the Urban Environment", "v": "PUC", "y": 1997, "rn": 32}, {"a": ["Carlo Tomasi", "Takeo Kanade"], "b": "", "cn": 382, "i": 4389503, "k": ["Factorization Method"], "p": ["http://dx.doi.org/10.1007/BF00129684", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv9.html#TomasiK92"], "t": "Shape and motion from image streams under orthography: a factorization method", "v": "IJCV", "y": 1992, "rn": 23}, {"a": ["Richard Hartley", "Andrew Zisserman"], "b": "", "cn": 359, "i": 3428182, "k": ["Multiple View Geometry"], "p": ["http://axiom.anu.edu.au/~hartley/Papers/CVPR99-tutorial/tutorial.pdf", "http://users.rsise.anu.edu.au/%7ehartley/Papers/CVPR99-tutorial/tutorial-screen.pdf", "http://www.dis.uniroma1.it/~visiope/Slide2009/hartley&zisserman.pdf", "http://www.lasmea.univ-bpclermont.fr/Personnel/Adrien.Bartoli/Classes/VIRO/Tutorial_Hartley_Zisserman.pdf", "http://axiom.anu.edu.au/~hartley/Papers/CVPR99-tutorial/tutorial-screen.pdf", "http://www.lasmea.univ-bpclermont.fr/Personnel/Adrien.Bartoli/Classes/Resources/Tutorial_Hartley_Zisserman.pdf", "http://users.rsise.anu.edu.au/~hartley/Papers/CVPR99-tutorial/tutorial.pdf"], "t": "Multiple View Geometry", "v": "IJCV", "y": 2000, "rn": 15}, {"a": ["Marc Pollefeys", "Luc Gool", "Maarten Vergauwen", "Frank Verbiest", "Kurt Cornelis", "Jan Tops", "Reinhard Koch"], "b": "In this paper a complete system to build visual models from camera images is presented. The system can deal with uncalibrated image sequences acquired with a hand-held camera. Based on tracked or matched features the relations between multiple views are computed. From this both the structure of the scene and the motion of the camera are retrieved. The ambiguity on", "cn": 352, "i": 1714693, "k": ["3d reconstruction", "Image Based Rendering", "Image Sequence", "multi-view stereo", "Multiple Views", "Projective Reconstruction", "Structure From Motion", "Surface Geometry", "Visual Modeling"], "p": ["http://www.mip.informatik.uni-kiel.de/tiki-download_file.php?fileId=474", "http://www.springerlink.com/content/p5vk01158rk14252", "http://www.springerlink.com/index/p5vk01158rk14252.pdf", "http://dx.doi.org/10.1023/B:VISI.0000025798.50602.3a", "http://www.umiacs.umd.edu/~pturaga/ENEE731/papers/MoreFiltering/Pollefeys2004.pdf", "http://pages.cs.wisc.edu/~dyer/ai-qual/pollefeys-ijcv04.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv59.html#PollefeysGVVCTK04", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/Pollefeys-model-04.pdf", "http://cvg-pub.inf.ethz.ch/WebBIB/papers/2004/pollefeysIJCV04final.pdf", "http://www.cs.unc.edu/~marc/pubs/PollefeysIJCV04.pdf", "http://cs.unc.edu/~marc/pubs/PollefeysIJCV04.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2006/DataDriven/bib/ibm/pollefeys04.pdf", "http://www.inf.ethz.ch/personal/pomarc/pubs/PollefeysIJCV04.pdf", "http://www1.cs.columbia.edu/~allen/PHOTOPAPERS/PollefeysIJCV04.pdf", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000025798.50602.3a"], "t": "Visual Modeling with a Hand-Held Camera", "v": "IJCV", "y": 2004, "rn": 77}, {"a": ["Kristen Grauman", "Trevor Darrell"], "b": "Discriminative learning is challenging when examples are sets of features, and the sets vary in cardinality and lack any sort of meaningful ordering. Kernel-based classifica- tion methods can learn complex decision boundaries, but a kernel over unordered set inputs must somehow solve for correspondences - generally a computationally expen- sive task that becomes impractical for large set sizes. We present", "cn": 324, "i": 1796633, "k": ["Discrimination Learning", "Image Features", "Kernel Function", "Object Recognition", "Optimal Solution", "Positive Definite", "Multi Resolution"], "p": ["http://www.eecs.umich.edu/~silvio/teaching/EECS598/papers/grauman_darrell_iccv2005.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1544890", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01544890", "http://www.vision.jhu.edu/reading_group/2005%20Grauman.pdf", "http://www.cs.utexas.edu/~grauman/papers/grauman_darrell_iccv2005.pdf", "http://vision.jhu.edu/reading_group/2005%20Grauman.pdf", "http://doi.ieeecomputersociety.org/10.1109/ICCV.2005.239", "http://vis.uky.edu/~dnister/Teaching/CS684Fall2005/grauman_darrell_iccv05.pdf"], "t": "The Pyramid Match Kernel: Discriminative Classification with Sets of Image Features", "v": "ICCV", "y": 2005, "rn": 32}, {"a": ["Adam Baumberg", "Surrey GU"], "b": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches.", "cn": 302, "i": 120814, "k": ["Feature Matching", "Image Features", "Linear Transformation", "Prior Knowledge", "Robust Method", "Stereo Matching", "Structure From Motion"], "p": ["http://glorfindel.mavrinac.com/~aaron/school/pdf/baumberg00_relfm.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=855899", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00855899", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2000.html#Baumberg00"], "t": "Reliable Feature Matching Across Widely Separated Views", "v": "CVPR", "y": 2000, "rn": 23}, {"a": ["Timor Kadir", "Michael Brady"], "b": "Many computer vision problems can be considered to consist of two main tasks: the extraction of image content descriptions and their subsequent matching. The appropriate choice of type and level of description is of course task dependent, yet it is generally accepted that the low-level or so called early vision layers in the Human Visual System are context independent. This", "cn": 273, "i": 784352, "k": ["Computer Vision", "Feature Extraction", "Image Database", "Image Retrieval", "Object Recognition", "Scale Space", "Human Visual System"], "p": ["http://robotics.caltech.edu/readinggroup/vision/BradyScale.pdf", "http://home.in.tum.de/~osendorf/mlcv/papers/BradyScale.pdf", "http://www.cse.psu.edu/~rcollins/CSE597E/papers/Kadirijcv_SalScale.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv45.html#KadirB01"], "t": "Saliency, Scale and Image Description", "v": "IJCV", "y": 2001, "rn": 43}, {"a": ["Robert Fergus", "Fei-fei Li", "Pietro Perona", "Andrew Zisserman"], "b": "Current approaches to object category recognition require datasets of training images to be manually prepared, with varying degrees of supervision. We present an approach that can learn an object category from just its name, by uti- lizing the raw output of image search engines available on the Internet. We develop a new model, TSI-pLSA, which extends pLSA (as applied to", "cn": 271, "i": 1796766, "k": ["Image Search", "Learning Object", "Scale Invariance", "Search Engine"], "p": ["http://eprints.pascal-network.org/archive/00001128/01/fergus05a.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01544937", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1544937", "http://www.cise.ufl.edu/class/cis6930fa07atc/Papers/Fergus05.pdf", "http://doi.ieeecomputersociety.org/10.1109/ICCV.2005.142", "http://people.csail.mit.edu/fergus/papers/fergus_google.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2005-2.html#FergusFPZ05", "http://vision.cs.princeton.edu/documents/FergusFei-FeiPeronaZisserman_ICCV05.pdf", "http://twiki.di.uniroma1.it/pub/Estrinfo/Materiale/learning_object_Categories_from_Googles_Image_Search.pdf", "http://cs.stanford.edu/groups/vision/documents/FergusFei-FeiPeronaZisserman_ICCV05.pdf", "http://visionlab.ece.uiuc.edu/documents/FergusFei-FeiPeronaZisserman_ICCV05.pdf"], "t": "Learning Object Categories from Google's Image Search", "v": "ICCV", "y": 2005, "rn": 24}, {"a": ["Kerry Rodden", "Kenneth Wood"], "b": "In this paper we present and discuss the findings of a study that investigated how people manage their collections of digital photographs. The six-month, 13-participant study included interviews, questionnaires, and analysis of usage statistics gathered from an instrumented digital photograph management tool called Shoebox. Alongside simple browsing features such as folders, thumbnails and timelines, Shoebox has some advanced multimedia features:", "cn": 217, "i": 450709, "k": ["Content Based Image Retrieval", "Digital Photography", "Image Browsing", "Management Tool", "Speech Recognition"], "p": ["http://portal.acm.org/citation.cfm?id=642611.642682", "http://portal.acm.org/citation.cfm?id=642682", "http://portal.acm.org/ft_gateway.cfm?id=642682&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.informatik.uni-trier.de/~ley/db/conf/chi/chi2003.html#RoddenW03", "http://pages.cpsc.ucalgary.ca/~saul/wiki/uploads/HCIPapers/rodden-digphotos-chi03.pdf", "http://doi.acm.org/10.1145/642611.642682", "http://osiris.sunderland.ac.uk/ncaf/htm/pubs/Wood_chi2003-kr-krw-published.pdf", "http://adammikeal.org/courses/chi/files/sum1.manage_digital_photos.pdf", "http://web.mit.edu/bentley/www/mobile/papers/rodden2003.pdf", "http://web.mit.edu/21w.789/www/spring2006/papers/rodden2003.pdf"], "t": "How do people manage their digital photographs?", "v": "CHI", "y": 2003, "rn": 20}, {"a": ["L. Chew"], "b": "Given a set of n vertices in the plane together with a set of noncrossing edges, the constrained Delaunay triangulation (CDT) is the triangulation of the vertices with the following properties: (1) the prespecified edges are included in the triangulation, and (2) it is as close as possible to the Delaunay triangulation. We show that the CDT can be built", "cn": 197, "i": 652475, "k": ["constrained delaunay triangulation", "delaunay triangulation", "Divide and Conquer", "Finite Element Method", "Motion Planning", "Spanning Tree", "Time Use", "Euclidean Minimum Spanning Tree"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/compgeom/compgeom87.html#Chew87", "http://portal.acm.org/citation.cfm?id=41981", "http://portal.acm.org/ft_gateway.cfm?id=41981&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=41958.41981", "http://doi.acm.org/10.1145/41958.41981", "http://dl.acm.org/citation.cfm?id=41981"], "t": "Constrained Delaunay triangulations", "v": "SOCG", "y": 1987, "rn": 6}, {"a": ["Tinne Tuytelaars", "Luc Gool"], "b": "Invariant regions' are self-adaptive image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions can be extracted directly from a single image. They are then described by a set of invariant features, which makes it relatively easy to match them between views, even under wide baseline conditions. In this", "cn": 193, "i": 1714694, "k": ["epipolar geometry", "Invariant Feature", "Local Features", "Stereo Matching"], "p": ["http://www.springerlink.com/content/x31851327471jw3g", "http://www.springerlink.com/index/x31851327471jw3g.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv59.html#TuytelaarsG04", "http://dx.doi.org/10.1023/B:VISI.0000020671.28016.e8", "http://vis.uky.edu/~dnister/Teaching/CS684Fall2005/tuytelaars_ijcv2004.pdf", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/B:VISI.0000020671.28016.e8"], "t": "Matching Widely Separated Views Based on Affine Invariant Regions", "v": "IJCV", "y": 2004, "rn": 28}, {"a": ["H. Moravec"], "b": "", "cn": 187, "i": 1986915, "k": [], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1456952"], "t": "The Stanford Cart and the CMU Rover", "v": "PIEEE", "y": 1983, "rn": 0}, {"a": ["Jiri Matas", "Ondrej Chum", "Martin Urban", "Tom\u00e1s Pajdla"], "b": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2)", "cn": 170, "i": 2150695, "k": ["Average Distance", "Detection Algorithm", "epipolar geometry", "Linear Complexity", "Similarity Measure", "maximally stable extremal region"], "p": ["http://linkinghub.elsevier.com/retrieve/pii/S0262885604000435", "http://www.sciencedirect.com/science/article/pii/S0262885604000435", "http://dx.doi.org/10.1016/j.imavis.2004.02.006", "http://www.informatik.uni-trier.de/~ley/db/journals/ivc/ivc22.html#MatasCUP04"], "t": "Robust wide-baseline stereo from maximally stable extremal regions", "v": "IVC", "y": 2004, "rn": 4}, {"a": ["Richard Szeliski", "Ramin Zabih", "Daniel Scharstein", "Olga Veksler", "Vladimir Kolmogorov", "Aseem Agarwala", "Marshall Tappen", "Carsten Rother"], "b": "One of the most exciting advances in early vision has been the development of efficient energy minimization algorithms. Many early vision tasks require labeling each pixel with some quantity such as depth or texture. While many such problems can be elegantly expressed in the language of Markov Random Fields (MRF's), the resulting energy minimization problems were widely viewed as intractable.", "cn": 165, "i": 2427508, "k": ["Benchmark Problem", "Energy Function", "Energy Minimization", "Graph Cut", "Interactive Segmentation", "Iterated Conditional Mode", "Loopy Belief Propagation", "Machine Learning", "Message Passing", "Optimal Method", "Markov Random Field"], "p": ["http://www.springerlink.com/index/d173073726316r32.pdf", "http://www.springerlink.com/content/d173073726316r32", "http://dx.doi.org/10.1007/11744047_2", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2006-2.html#SzeliskiZSVKATR06", "http://research.microsoft.com/apps/pubs/default.aspx?id=67896", "http://research.microsoft.com/pubs/67896/szsvkatr-eccv06.pdf"], "t": "A Comparative Study of Energy Minimization Methods for Markov Random Fields", "v": "ECCV", "y": 2006, "rn": 48}, {"a": ["Andrew Lippman"], "b": "", "cn": 165, "i": 884065, "k": ["Computer Graphic"], "p": ["http://portal.acm.org/citation.cfm?id=800250.807465", "http://portal.acm.org/citation.cfm?id=965105.807465"], "t": "Movie-maps: An application of the optical videodisc to computer graphics", "v": "", "y": 1980, "rn": 0}, {"a": ["Kentaro Toyama", "Ron Logan", "Asta Roseway"], "b": "We describe an end-to-end system that capitalizes on geographic location tags for digital photographs. The World Wide Media eXchange (WWMX) database indexes large collections of image media by several pieces of metadata including timestamp, owner, and critically, location stamp. The location where a photo was shot is important because it says much about its semantic content, while being relatively easy", "cn": 150, "i": 438956, "k": ["Authoring Tool", "Data Structure", "Digital Image", "Digital Photography", "Image Database", "Indexation"], "p": ["http://doi.acm.org/10.1145/957013.957046", "http://portal.acm.org/citation.cfm?id=957046", "http://portal.acm.org/ft_gateway.cfm?id=957046&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=957013.957046", "http://www.informatik.uni-trier.de/~ley/db/conf/mm/mm2003.html#ToyamaLR03"], "t": "Geographic location tags on digital images", "v": "MM", "y": 2003, "rn": 25}, {"a": ["James Hays", "Alexei Efros"], "b": "", "cn": 148, "i": 4415678, "k": [], "p": ["http://doi.acm.org/10.1145/1276377.1276382", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog26.html#HaysE07"], "t": "Scene completion using millions of photographs", "v": "TOG", "y": 2007, "rn": 0}, {"a": ["Cordelia Schmid", "Andrew Zisserman"], "b": "This paper presents a new method for matching individ- ual line segments between images. The method uses both greylevel information and the multiple view geometric rela- tions between the images. For image pairs epipolar geome- try facilitates the computation of a cross-correlation based matching score for putative line correspondences. For im- age triplets cross-correlation matching scores are used in conjunction", "cn": 134, "i": 216768, "k": ["Cross Correlation", "Multiple Views", "Long Range"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr1997.html#SchmidZ97", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=609397", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00609397"], "t": "Automatic line matching across views", "v": "CVPR", "y": 1997, "rn": 25}, {"a": ["Matthew Cooper", "Jonathan Foote", "Andreas Girgensohn", "Lynn Wilcox"], "b": "We present similarity-based methods to cluster digital photos by time and image content. The approach is general, unsupervised, and makes minimal assumptions regarding the structure or statistics of the photo collection. We present results for the algorithm based solely on temporal similarity, and jointly on temporal and content-based similarity. We also describe a supervised algorithm based on learning vector quantization.", "cn": 106, "i": 438921, "k": ["Learning Vector Quantization", "Photo Collection", "Test Collection"], "p": ["https://eprints.kfupm.edu.sa/68487/1/68487.pdf", "http://portal.acm.org/citation.cfm?id=957093", "http://portal.acm.org/ft_gateway.cfm?id=957093&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.fxpal.com/publications/FXPAL-PR-05-316.pdf", "http://doi.acm.org/10.1145/957013.957093", "http://www.fxpal.com/publications/FXPAL-PR-03-215.pdf", "http://reference.kfupm.edu.sa/content/t/e/temporal_event_clustering_for_digital_ph_3577154.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/mm/mm2003.html#CooperFGW03", "http://portal.acm.org/citation.cfm?id=957013.957093"], "t": "Temporal event clustering for digital photo collections", "v": "MM", "y": 2003, "rn": 27}, {"a": ["James Hays", "Alexei Efros"], "b": "What can you do with a million images? In this paper, we present a new image completion algorithm powered by a huge database of photographs gathered from the Web. The algorithm patches up holes in images by finding similar image regions in the database that are not only seamless, but also semantically valid. Our chief insight is that while the", "cn": 105, "i": 4361726, "k": ["Image Completion"], "p": ["http://portal.acm.org/citation.cfm?doid=1400181.1400202", "http://portal.acm.org/ft_gateway.cfm?id=1400202&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1400202", "http://www.informatik.uni-trier.de/~ley/db/journals/cacm/cacm51.html#HaysE08", "http://doi.acm.org/10.1145/1400181.1400202"], "t": "Scene completion using millions of photographs", "v": "CACM", "y": 2008, "rn": 23}, {"a": ["R Szeliski"], "b": "", "cn": 98, "i": 14570985, "k": ["Nonlinear Least Squares"], "p": ["http://linkinghub.elsevier.com/retrieve/doi/10.1006/jvci.1994.1002"], "t": "Recovering 3D Shape and Motion from Image Streams Using Nonlinear Least Squares", "v": "JVCIR", "y": 1994, "rn": 0}, {"a": ["Mor Naaman", "Yee Song", "Andreas Paepcke", "Hector Garcia-Molina"], "b": "We describe PhotoCompas, a system that utilizes the time and location information embedded in digital photographs to automatically organize a personal photo collection PhotoCompas produces browseable location and event hierarchies for the collection. These hierarchies are created using algorithms that interleave time and location to produce an organization that mimics the way people think about their photo collections. In addition,", "cn": 97, "i": 902742, "k": ["Case Study", "Information Embedding", "Photo Collection"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/jcdl/jcdl2004.html#NaamanSPG04", "http://portal.acm.org/ft_gateway.cfm?id=996366&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=996366", "http://portal.acm.org/citation.cfm?id=996350.996366", "http://doi.acm.org/10.1145/996350.996366", "http://ilpubs.stanford.edu:8090/766/1/2004-27.pdf", "http://ilpubs.stanford.edu:8090/673/1/2004-7.pdf"], "t": "Automatic organization for digital photographs with geographic coordinates", "v": "JCDL", "y": 2004, "rn": 22}, {"a": ["Anthony Dick", "Philip Torr", "Roberto Cipolla"], "b": "This paper describes the automatic acquisition of three dimensional ar- chitectural models from short image sequences. The approach is Bayesian and model based. Bayesian methods necessitate the formulation of a prior distribution; however designing a generative model for buildings is a dif- cult task. In order to overcome this a building is described as a set of walls together with", "cn": 97, "i": 1714708, "k": ["bayesian method", "Generic Model", "Image Sequence", "Object Recognition", "Prior Distribution", "Structure and Motion", "Three Dimensional"], "p": ["http://www.springerlink.com/content/u58m38v878732w52", "http://www.springerlink.com/index/u58m38v878732w52.pdf", "http://dx.doi.org/10.1023/B:VISI.0000029665.07652.61", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv60.html#DickTC04"], "t": "Modelling and Interpretation of Architecture from Several Images", "v": "IJCV", "y": 2004, "rn": 43}, {"a": ["J. Nocedal", "S. Wright"], "b": "", "cn": 91, "i": 2031616, "k": ["Operations Research"], "p": [], "t": "Springer Series in Operations Research", "y": 1999, "rn": 0}, {"a": [], "b": "", "cn": 83, "i": 6104354, "k": ["Multiple View Geometry"], "p": ["http://dx.doi.org/10.1007/978-0-387-73003-5_876", "http://www.informatik.uni-trier.de/~ley/db/reference/bio/m.html#X09xd"], "t": "Multiple View Geometry", "y": 2009, "rn": 0}, {"a": ["Christoph Strecha", "Tinne Tuytelaars", "Luc Gool"], "b": "This paper describes a PDE-based method for dense depth extraction from multiple wide-baseline images. Em- phasis lies on the usage of only a small amount of images. The integration of these multiple wide-baseline views is guided by the relative confidence that the system has in the matching to different views. This weighting is fine-grained in that it is determined for", "cn": 80, "i": 1796523, "k": ["Information Exchange"], "p": ["http://www.cs.ualberta.ca/~jag/papersVis2/modelrec/StrechaICCV03stereo.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238627", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238627", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/02/195021194abs.htm", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/1194_strecha.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-2.html#StrechaTG03", "http://www.tsi.enst.fr/~bloch/VOIR/iccv03/1194_strecha.pdf", "http://infoscience.epfl.ch/record/128500/files/iccv_2003.pdf"], "t": "Dense Matching of Multiple Wide-baseline Views", "v": "ICCV", "y": 2003, "rn": 27}, {"a": [], "b": "", "cn": 76, "i": 1979733, "k": ["Image Matching"], "p": [], "t": "A feature based correspondence algorithm for image matching", "y": 1986, "rn": 0}, {"a": ["Mor Naaman", "Yee Song", "Andreas Paepcke", "Hector Garcia-Molina"], "b": "We describe PhotoCompas, a system that utilizes the time and location information embedded in digital photographs to automatically organize a personal photo collection. PhotoCompas produces browseable location and event hierarchies for the collection. These hierarchies are created using algorithms that interleave time and location to produce an organization that mimics the way people think about their photo collections. In addition,", "cn": 74, "i": 50368399, "k": ["Case Study", "Information Embedding", "Photo Collection"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01336098", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1336098"], "t": "Automatic organization for digital photographs with geographic coordinates", "v": "JCDL", "y": 2004, "rn": 59}, {"a": ["Jean-fran\u00e7ois Lalonde", "Derek Hoiem", "Alyosha Efros", "Carsten Rother", "John Winn", "Antonio Criminisi"], "b": "", "cn": 60, "i": 4415720, "k": ["Machine Learning"], "p": ["http://portal.acm.org/citation.cfm?doid=1276377.1276381", "http://www.informatik.uni-trier.de/~ley/db/journals/tog/tog26.html#LalondeHERWC07", "http://doi.acm.org/10.1145/1276377.1276381", "http://research.microsoft.com/apps/pubs/default.aspx?id=72429", "http://research.microsoft.com/pubs/72429/criminisi_siggraph_07.pdf"], "t": "Photo clip art", "v": "TOG", "y": 2007, "rn": 0}, {"a": ["Minas Spetsakis", "Yiannis Aloimonos"], "b": "One of the main issues in the area of motion estimation given the correspondences of some features in a sequence of images is sensitivity to error in the input. The main way to attack the problem, as with several other problems in science and engineering, is redundancy in the data. Up to now all the algorithms developed either used two", "cn": 59, "i": 2072090, "k": ["Eigenvalues", "Motion Estimation", "Side Effect", "Visual Motion Perception", "Mean Square"], "p": ["http://www.springerlink.com/content/r4434nu65p612x38", "http://www.springerlink.com/index/r4434nu65p612x38.pdf", "http://www.springerlink.com/index/10.1007/BF00115698", "http://www.springerlink.com/index/pdf/10.1007/BF00115698"], "t": "A multi-frame approach to visual motion perception", "v": "IJCV", "y": 1991, "rn": 11}, {"a": ["Matthew Brown", "David Lowe"], "b": "This paper presents a system for fully automatic recog- nition and reconstruction of 3D objects in image databases. We pose the object recognition problem as one of finding consistent matches between all images, subject to the con- straint that the images were taken from a perspective cam- era. We assume that the objects or scenes are rigid. For each image", "cn": 58, "i": 1872713, "k": ["3d object recognition", "Bundle Adjustment", "Fundamental Matrix", "Image Database", "Local Features", "Object Recognition", "Structure and Motion"], "p": ["http://vision.ai.uiuc.edu/%7Esintod/3dim05.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01443228", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1443228", "http://doi.ieeecomputersociety.org/10.1109/3DIM.2005.81", "http://www.tu-chemnitz.de/etit/proaut/paperdb/download/brown05.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/3dim/3dim2005.html#BrownL05", "http://people.cs.ubc.ca/%7elowe/papers/brown05.pdf", "http://www.cs.virginia.edu/~gfx/Courses/2006/DataDriven/bib/ibm/brown05.pdf"], "t": "Unsupervised 3D Object Recognition and Reconstruction in Unordered Datasets", "v": "3DIM", "y": 2005, "rn": 17}, {"a": ["Mor Naaman", "Andreas Paepcke", "Hector Garcia-molina"], "b": "We describe LOCALE, a system that allows cooperating in- formation systems to share labels for photographs. Participating pho- tographs are enhanced with a geographic location stamp { the latitude and longitude where the photograph was taken. For a photograph with no label, LOCALE can use the shared information to assign a label based on other photographs that were taken in", "cn": 57, "i": 650543, "k": ["System Performance", "User Cooperation"], "p": ["http://www.springerlink.com/content/v45v5w2h6yqey85l", "http://www.springerlink.com/index/v45v5w2h6yqey85l.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/coopis/coopis2003.html#NaamanPG03", "http://ilpubs.stanford.edu:8090/756/1/2003-62.pdf", "http://springerlink.metapress.com/openurl.asp?genre=article&issn=0302-9743&volume=2888&spage=196"], "t": "From Where to What: Metadata Sharing for Digital Photographs with Geographic Coordinates", "v": "CoopIS", "y": 2003, "rn": 9}, {"a": ["John Oliensis"], "b": "We present a fast, robust algorithm for multi-frame structure from motion from point features which works for general motion and large perspective effects. The algorithm is for point features but easily extends to a direct method based on image intensities. Experiments on synthetic and real sequences show that the algorithm gives results nearly as accurate as the maximum likelihood estimate", "cn": 54, "i": 1989291, "k": ["Direct Method", "Experimental Study", "Local Minima", "Maximum Likelihood Estimate", "Optimal Estimation", "Perspective Projection", "Structure From Motion", "Theoretical Analysis"], "p": ["http://dx.doi.org/10.1023/A:1008139920864", "http://www.springerlink.com/content/m54p320715617762", "http://www.springerlink.com/index/m54p320715617762.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv34.html#Oliensis99", "http://www.cs.stevens.edu/~oliensis/updatedgenjournpaper.pdf"], "t": "A Multi-Frame Structure-from-Motion Algorithm under Perspective Projection", "v": "IJCV", "y": 1999, "rn": 70}, {"a": ["Maarten Vergauwen", "Luc Gool"], "b": "The use of 3D information in the field of cultural heritage is increasing year by year. From this field comes a large demand\n for cheaper and more flexible ways of 3D reconstruction. This paper describes a web-based 3D reconstruction service, developed\n to relieve those needs of the cultural heritage field. This service consists of a pipeline that starts with the", "cn": 51, "i": 2510621, "k": ["3d reconstruction", "Camera Calibration", "Cultural Heritage"], "p": ["http://www.springerlink.com/content/h67x437m85m02731", "http://www.springerlink.com/index/h67x437m85m02731.pdf", "http://dx.doi.org/10.1007/s00138-006-0027-1", "http://www.informatik.uni-trier.de/~ley/db/journals/mva/mva17.html#VergauwenG06", "http://www.springerlink.com/index/10.1007/s00138-006-0027-1", "http://www.springerlink.com/index/pdf/10.1007/s00138-006-0027-1"], "t": "Web-based 3D Reconstruction Service", "v": "MVA", "y": 2006, "rn": 13}, {"a": ["David Nist\u00e9r"], "b": "This paper considers projective reconstruction with a hierarchical computational structure of trifocal tensors that integrates feature tracking and geometrical validation of the feature tracks. The algorithm was embedded into a system aimed at completely automatic Euclidean reconstruction from uncalibrated handheld amateur video sequences. The algorithm was tested as part of this system on a number of sequences grabbed directly from", "cn": 51, "i": 4253634, "k": ["Building Block", "Bundle Adjustment", "Feature Tracking", "Projective Reconstruction"], "p": ["http://www.springerlink.com/content/lx9w8mpc3ncavw81", "http://www.springerlink.com/index/lx9w8mpc3ncavw81.pdf", "http://www.vis.uky.edu/~dnister/Publications/2000/HierachyTensors/trifocal_tensors.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2000-1.html#Nister00", "http://link.springer.de/link/service/series/0558/bibs/1842/18420649.htm"], "t": "Reconstruction from Uncalibrated Sequences with a Hierarchy of Trifocal Tensors", "v": "ECCV", "y": 2000, "rn": 37}, {"a": ["Daniel Aliaga", "Thomas Funkhouser", "Dimah Yanovsky", "Ingrid Carlbom"], "b": "A long-standing research problem in computer graphics is to reproduce the visual experience of walking through a large photorealistic environment interactively. On one hand, traditional geometry-based rendering systems fall short of simulating the visual realism of a complex environment. On the other hand, image-based rendering systems have to date been unable to capture and store a sampled representation of a", "cn": 38, "i": 660625, "k": ["Computer Graphic", "Image Based Rendering", "Indoor Environment", "Omnidirectional Image", "plenoptic function", "Rendering System", "Specular Reflection", "Frames Per Second", "Real Time"], "p": ["http://portal.acm.org/citation.cfm?id=602150", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01183792", "http://portal.acm.org/ft_gateway.cfm?id=602150&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183792", "http://csdl.computer.org/comp/proceedings/visualization/2002/7498/00/7498aliagaabs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/visualization/visualization2002.html#AliagaFYC02", "http://portal.acm.org/citation.cfm?id=602099.602150"], "t": "Sea of images", "v": "", "y": 2002, "rn": 40}, {"a": ["Marc Pollefeys", "Luc Gool"], "b": "How computers can automatically build realistic 3D models from 2D images acquired with a handheld camera.", "cn": 36, "i": 776850, "k": ["3d model"], "p": ["http://portal.acm.org/citation.cfm?doid=514236.514263", "http://portal.acm.org/citation.cfm?id=514263"], "t": "From images to 3D models", "v": "CACM", "y": 2002, "rn": 12}, {"a": ["Timor Kadir", "Michael Brady"], "b": "Many computer vision problems can be considered to consist of two main tasks: the extraction of image content descriptions and their subsequent matching. The appropriate choice of type and level of description is of course task dependent, yet it is generally accepted that the low-level or so called early vision layers in the Human Visual System are context independent.", "cn": 26, "i": 15271083, "k": ["Computer Vision", "Feature Extraction", "Image Database", "Scale Space", "Human Visual System"], "p": ["http://www.springerlink.com/index/t45n2g8543574026.pdf", "http://www.springerlink.com/content/t45n2g8543574026", "http://www.springerlink.com/openurl.asp?id=doi:10.1023/A:1012460413855"], "t": "Saliency, Scale and Image Description", "v": "IJCV", "y": 2001, "rn": 36}, {"a": ["Bj\u00f6rn Johansson", "Roberto Cipolla"], "b": "We describe an automatic system for pose-estimation from a single image in a city scene. Each building has a model consisting of a number of parallel planes associ- ated with it. The homographies for the best match of the planes to the image is estimated automatically for each of the possible buildings. We show how the estimation of ho- mographies", "cn": 22, "i": 2364112, "k": ["Pose Estimation", "Search Space"], "p": ["http://mi.eng.cam.ac.uk/reports/svr-ftp/cipolla_iasted02.pdf"], "t": "A System for Automatic Pose-Estimation from a Single Image in a City Scene", "y": 2002, "rn": 12}, {"a": ["Duncan Robertson", "Roberto Cipolla"], "b": "This paper describes an interactive system for creating geometric models from many uncalibrated images of architectural scenes.\n In this context, we must solve the structure from motion problem given only few and noisy feature correspondences in non-sequential\n views. By exploiting the strong constraints obtained by modelling a map as a single affine view of the scene, we are able\n to", "cn": 20, "i": 509689, "k": ["Geometric Model", "Interactive System", "Large Scale", "Linear Equations", "Reference Point", "Structure From Motion"], "p": ["http://www.springerlink.com/content/cbn3w9rkxvxu18le", "http://www.springerlink.com/index/cbn3w9rkxvxu18le.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2002-2.html#RobertsonC02", "http://link.springer.de/link/service/series/0558/bibs/2351/23510155.htm"], "t": "Building Architectural Models from Many Views Using Map Constraints", "v": "ECCV", "y": 2002, "rn": 17}, {"a": ["Daniel Aliaga", "Thomas Funkhouser", "Dimah Yanovsky", "Ingrid Carlbom"], "b": "Our sea of images approach provides new methods for acquiring, analyzing, representing, and rendering photorealistic models of complex indoor environments. We present our image-based rendering walk-through system based on the sea of images approach. We describe the system and give results for its implementation in three environments of different sizes and types.", "cn": 18, "i": 1594255, "k": ["Image Based Rendering", "Indoor Environment"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1242379", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01242379", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1242379", "http://csdl.computer.org/comp/mags/cg/2003/06/g6022abs.htm", "http://www.informatik.uni-trier.de/~ley/db/journals/cga/cga23.html#AliagaFYC03", "http://www.cs.purdue.edu/cgvlab/papers/aliaga/cga03.pdf", "http://www.cs.princeton.edu/~funk/cga03.pdf"], "t": "Sea of Images: A Dense Sampling Approach for Rendering Large Indoor Environments", "v": "CGA", "y": 2003, "rn": 15}, {"a": ["Rieko Kadobayashi", "Katsumi Tanaka"], "b": "We propose a new photo search method that uses three-dimensional (3D) viewpoints as queries. 3D viewpoint-based image retrieval is especially useful for searching collections of archaeological photographs,which contain many different images of the same object. Our method is designed to enable users to retrieve images that contain the same object but show a different view, and to browse groups of", "cn": 15, "i": 1842384, "k": ["3d model", "Digital Archive", "Image Retrieval", "Query By Example", "Search Method", "Three Dimensional"], "p": ["http://portal.acm.org/citation.cfm?id=1076158", "http://portal.acm.org/ft_gateway.cfm?id=1076158&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://doi.acm.org/10.1145/1076034.1076158", "http://www.informatik.uni-trier.de/~ley/db/conf/sigir/sigir2005.html#KadobayashiT05", "http://portal.acm.org/citation.cfm?id=1076034.1076158"], "t": "3D viewpoint-based photo search and information browsing", "v": "SIGIR", "y": 2005, "rn": 2}, {"a": ["Neil McCurdy", "William Griswold"], "b": "Realityflythrough is a telepresence/tele-reality system that works in the dynamic, uncalibrated environments typically associated with ubiquitous computing. By harnessing networked mobile video cameras, it allows a user to remotely and immersively explore a physical space. RealityFlythrough creates the illusion of complete live camera coverage in a physical environment. This paper describes the architecture of RealityFlythrough, and evaluates it along three", "cn": 15, "i": 1850038, "k": ["Network Mobility", "Physical Environment", "System Architecture", "Three Dimensions", "Ubiquitous Computing", "User Requirements"], "p": ["http://doi.acm.org/10.1145/1067170.1067172", "http://portal.acm.org/ft_gateway.cfm?id=1067172&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://portal.acm.org/citation.cfm?id=1067172", "https://www.usenix.org/publications/library/proceedings/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://db.usenix.org/publications/library/proceedings/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://www.usenix.org/events/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://www.realityflythrough.com/files/mobisys_paper.pdf", "http://portal.acm.org/citation.cfm?id=1067170.1067172", "https://www.usenix.org/events/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/mobisys/mobisys2005.html#McCurdyG05", "https://db.usenix.org/publications/library/proceedings/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://www.usenix.org/publications/library/proceedings/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://db.usenix.org/events/mobisys05/tech/full_papers/mccurdy/mccurdy.pdf", "http://www.liderazgoymercadeo.com/edicion94/mobisys_paper.pdf"], "t": "A systems architecture for ubiquitous video", "v": "MobiSys", "y": 2005, "rn": 15}, {"a": ["Daniel Aliaga", "Dimah Yanovsky", "Thomas Funkhouser", "Ingrid Carlbom"], "b": "Image-based rendering (IBR) systems enable virtual walkthroughs of photorealistic environments by warping and combining reference images to novel viewpoints under interactive user control. A significant challenge in such systems is to automatically compute image correspondences that enable accurate image warping.In this paper, we describe a new algorithm for computing a globally consistent set of image feature correspondences across a wide", "cn": 15, "i": 17385, "k": ["Feature Tracking", "Image Based Rendering", "Image Features", "Image Warping", "Omnidirectional Image", "Real Time"], "p": ["http://doi.acm.org/10.1145/641480.641511", "http://portal.acm.org/citation.cfm?id=641511", "http://portal.acm.org/ft_gateway.cfm?id=641511&type=pdf&CFID=29576336&CFTOKEN=51534192", "http://www.cs.purdue.edu/cgvlab/papers/aliaga/i3d03.pdf", "http://reference.kfupm.edu.sa/content/i/n/interactive_image_based_rendering_using__580601.pdf"], "t": "Interactive image-based rendering using feature globalization", "v": "I3D", "y": 2003, "rn": 22}, {"a": ["Hiroya Tanaka", "Masatoshi Arikawa", "Ryosuke Shibasaki"], "b": "This paper proposes a new style tool, a 3-D photo collage system, to manage new style of digital cities. This system allows\n ordinary people to create, publish, share and navigate pseudo 3-D spaces using perspective photos on the Web. We present a\n framework of the 3-D photo collage system and characteristics of a prototype system based on it. Finally, some", "cn": 7, "i": 647633, "k": ["Space Use", "Spatial Navigation"], "p": ["http://www.springerlink.com/content/kbv4wa91nm5qw8e9", "http://link.springer.de/link/service/series/0558/bibs/2362/23620305.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/digitalCities/digitalCities2001.html#TanakaAS01"], "t": "A 3-D Photo Collage System for Spatial Navigations", "v": "", "y": 2001, "rn": 0}, {"a": ["R. Grzeszczuk"], "b": "", "cn": 5, "i": 2368250, "k": ["image-based modeling"], "p": [], "t": "Course 44: Image-based modeling", "v": "SIGGRAPH", "y": 2002, "rn": 0}, {"a": ["M. Hannah"], "b": "", "cn": 4, "i": 4143357, "k": [], "p": [], "t": "Test results from SRI''''s stereo system", "y": 1988, "rn": 0}, {"a": ["Yuri Boykov", "Gareth Funka-lea"], "b": "Combinatorial graph cut algorithms have been successfully applied to a wide range of problems in vision and graphics. This paper focusses on possibly the simplest application of graph-cuts: segmentation of objects in image data. Despite its simplicity, this application epitomizes the best features of combinatorial graph cuts methods in vision: global optima, practical efficiency, numerical robustness, ability to fuse a", "cn": 290, "i": 2503356, "k": ["Boundary Regularity", "Combinatorial Optimization", "Energy Optimization", "Geodesic Active Contour", "Graph Cut", "Image Segmentation", "Level Set", "Medical Application", "Object Extraction", "Object Segmentation", "Topological Properties", "Visual Cues"], "p": ["http://www.csd.uwo.ca/~yuri/Papers/ijcv06.pdf", "http://www.springerlink.com/content/j3k24j8347k42425", "http://www.csd.uwo.ca/faculty/yuri/Papers/ijcv06.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv70.html#BoykovF06", "http://dx.doi.org/10.1007/s11263-006-7934-5", "http://www.csd.uwo.ca/~eschost/Teaching/07-08/CS445a/ijcv06.pdf", "http://www.springerlink.com/index/10.1007/s11263-006-7934-5", "http://www.springerlink.com/index/pdf/10.1007/s11263-006-7934-5"], "t": "Graph Cuts and Efficient ND Image Segmentation", "v": "IJCV", "y": 2006, "rn": 76}, {"a": ["Jonathan Starck", "Adrian Hilton"], "b": "Digital content production traditionally requires highly skilled artists and animators to first manually craft shape and appearance models and then instill the models with a believable performance. Motion capture technology is now increasingly used to record the articulated motion of a real human performance to increase the visual realism in animation. Motion capture is limited to recording only the skeletal", "cn": 87, "i": 4362653, "k": ["Computer Game", "Digital Content", "Graphics Hardware", "Human Animation", "Human Body", "Human Performance", "Indexing Terms", "Interactive Animation", "Motion Capture", "Scene Reconstruction", "Level of Detail"], "p": ["http://www.informatik.uni-trier.de/~ley/db/journals/cga/cga27.html#StarckH07", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04178157", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4178157", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4178157", "http://doi.ieeecomputersociety.org/10.1109/MCG.2007.68", "http://www.ee.surrey.ac.uk/CVSSP/VMRG/Publications/starck07cga.pdf"], "t": "Surface Capture for Performance-Based Animation", "v": "CGA", "y": 2007, "rn": 25}, {"a": ["Son Tran", "Larry Davis"], "b": "We describe a graph cut algorithm to recover the 3D ob- ject surface using both silhouette and foreground color information. The graph cut algorithm is used for optimization on a color consistency field. Constraints are added to improve its performance. These constraints are a set of predetermined locations that the true surface of the object is likely to pass through.", "cn": 41, "i": 2427514, "k": ["Background Subtraction", "Graph Cut", "Surface Reconstruction", "Synthetic Data"], "p": ["http://dx.doi.org/10.1007/11744047_17", "http://www.springerlink.com/index/3477k5281tr86801.pdf", "http://www.springerlink.com/content/3477k5281tr86801", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2006-2.html#TranD06"], "t": "3D Surface Reconstruction Using Graph Cuts with Surface Constraints", "v": "ECCV", "y": 2006, "rn": 13}, {"a": ["Vladimir Kolmogorov", "Yuri Boykov", "Carsten Rother"], "b": "The maximum flow algorithm for minimizing energy functions of binary variables has become a standard tool in computer vision. In many cases, unary costs of the energy depend linearly on parameter \u03bb. In this paper we study vi- sion applications for which it is important to solve the max- flow problem for different \u03bb's. An example is a weighting between", "cn": 37, "i": 4111826, "k": ["3d reconstruction", "Computer Vision", "Energy Function", "Image Segmentation", "Machine Learning", "Maximum Flow", "Vector Field", "Ground Truth", "Shortest Path"], "p": ["http://research.microsoft.com/pubs/70474/iccv07-ParaMaxFlow.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408910", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408910", "http://www.csd.uwo.ca/~yuri/Papers/iccv07_par_maxflow.pdf", "http://dx.doi.org/10.1109/ICCV.2007.4408910", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#KolmogorovBR07", "http://www.cs.ucl.ac.uk/staff/V.Kolmogorov/papers/KBR-ICCV07.pdf", "https://research.microsoft.com/pubs/70474/iccv07-paramaxflow.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=70474"], "t": "Applications of parametric maxflow in computer vision", "v": "ICCV", "y": 2007, "rn": 43}, {"a": ["Svetlana Lazebnik", "Yasutaka Furukawa", "Jean Ponce"], "b": " This thesis presents an image-based method for computing the visual hull of an objectbounded by a smooth surface and observed by a finite number of perspective cameras.The essential structure of the visual hull is projective: to compute an exact topological(combinatorial) description of its boundary, we do not need to know the Euclidean propertiesof the input cameras or of the scene.", "cn": 35, "i": 46262, "k": ["Computational Method", "Projective Differential Geometry", "Projective Geometry", "Projective Reconstruction", "Visual Hull"], "p": ["http://www.springerlink.com/content/r6xp55610107364u", "http://www.springerlink.com/index/r6xp55610107364u.pdf", "http://www.springerlink.com/index/10.1007/s11263-006-0008-x", "http://www.springerlink.com/index/pdf/10.1007/s11263-006-0008-x"], "t": "Projective Visual Hulls", "v": "IJCV", "y": 2007, "rn": 80}, {"a": ["Alexander Hornung", "Leif Kobbelt"], "b": "This paper presents a new volumetric stereo algorithm to reconstruct the 3D shape of an arbitrary object. Our method is based on finding the minimum cut in an octahedral graph structure embedded into the volumetric grid, which establishes a well defined relationship between the integrated photo-consistency function of a region in space and the corresponding edge weights of the embedded", "cn": 34, "i": 2167142, "k": ["Embedded Graph", "Graph Embedding", "Minimum Cut", "multi-view stereo"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-1.html#HornungK06", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1640798", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01640798", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.135"], "t": "Hierarchical Volumetric Multi-view Stereo Reconstruction of Manifold Surfaces based on Dual Graph Embedding", "v": "CVPR", "y": 2006, "rn": 20}, {"a": ["Carlos Hern\u00e1ndez", "Francis Schmitt", "Roberto Cipolla"], "b": "We present a new approach to camera calibration as a part of a complete and practical system to recover digital copies of sculpture from uncalibrated image sequences taken under turntable motion. In this paper we introduce the concept of the silhouette coherence of a set of silhouettes generated by a 3D object. We show how the maximization of the silhouette", "cn": 25, "i": 2512389, "k": ["3d model", "Camera Calibration", "Camera Motion", "Image Sequence", "Indexing Terms"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4042707", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04042707", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4042707", "http://carlos-hernandez.org/papers/hernandez_pami07.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami29.html#HernandezSC07", "http://mi.eng.cam.ac.uk/reports/svr-ftp/hernandez_pami06.pdf", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.42"], "t": "Silhouette Coherence for Camera Calibration under Circular Motion", "v": "PAMI", "y": 2007, "rn": 35}, {"a": ["Victor Lempitsky", "Yuri Boykov", "Denis Ivanov"], "b": "Visibility estimation is arguably the most dicult problem in dense 3D reconstruction from multiple arbitrary views. In this paper, we propose a simple new approach to estimating visibility based on position and orientation of local surface patches. Using our concept of oriented visibility, we present a new algorithm for multiview reconstruction based on exact global optimization of surface photoconsistency using", "cn": 25, "i": 2362113, "k": ["3d reconstruction", "Directed Graph", "Global Optimization", "Graph Cut", "image-based modeling"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2006-3.html#LempitskyBI06", "http://www.springerlink.com/content/r380pvmmgj1774kt", "http://www.springerlink.com/index/r380pvmmgj1774kt.pdf", "http://www.csd.uwo.ca/~yuri/Papers/eccv2006_oriented_vis.pdf"], "t": "Oriented Visibility for Multiview Reconstruction", "v": "ECCV", "y": 2006, "rn": 18}, {"a": ["Maria Klodt", "Thomas Schoenemann", "Kalin Kolev", "Marek Schikora", "Daniel Cremers"], "b": "Shape optimization is a problem which arises in numerous computer vision problems such as image segmentation and multiview re- construction. In this paper, we focus on a certain class of binary labeling problems which can be globally optimized both in a spatially discrete set- ting and in a spatially continuous setting. The main contribution of this paper is to present", "cn": 24, "i": 4253660, "k": ["Global Optimization", "Graph Cut", "Image Segmentation", "Numerical Computation", "Shape Optimization", "Higher Order"], "p": ["http://dx.doi.org/10.1007/978-3-540-88682-2_26", "http://www.springerlink.com/content/4553054m82875215", "http://www.springerlink.com/index/4553054m82875215.pdf", "http://cvpr.in.tum.de/pub/pub/KSKSC-08.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2008-1.html#KlodtSKSC08"], "t": "An Experimental Comparison of Discrete and Continuous Shape Optimization Methods", "v": "ECCV", "y": 2008, "rn": 34}, {"a": ["Jonathan Starck", "Gregor Miller", "Adrian Hilton"], "b": "This paper presents a novel volumetric reconstruction technique that com- bines shape-from-silhouette with stereo photo-consistency in a global op- timisation that enforces feature constraints across multiple views. Human shape reconstruction is considered where extended regions of uniform ap- pearance, complex self-occlusions and sparse feature cues represent a chal- lenging problem for conventional reconstruction techniques. A unified ap- proach is introduced", "cn": 20, "i": 4470192, "k": ["Graph Cut", "Image Features", "Multiple Views", "Satisfiability", "Shape From Silhouette", "Shape Reconstruction", "Left Right"], "p": ["http://www.ee.surrey.ac.uk/CVSSP/VMRG/Publications/starck06bmvc.pdf", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/2006/papers/415.pdf", "http://www.bmva.ac.uk/bmvc/2006/papers/415.pdf", "http://www.macs.hw.ac.uk/bmvc2006/papers/415.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2006.html#StarckMH06"], "t": "Volumetric Stereo with Silhouette and Feature Constraints", "v": "BMVC", "y": 2006, "rn": 14}, {"a": ["Andrew Delong", "Yuri Boykov"], "b": "Global optimisation via s-t graph cuts is widely used in computer vision and graphics. To obtain high-resolution output, graph cut methods must construct massive N-D grid-graphs containing billions of vertices. We show that when these graphs do not fit into physical memory, cur- rent max-flow/min-cut algorithms\u2014the workhorse of graph cut methods\u2014are totally impractical. Others have resorted to banded or hierarchical", "cn": 19, "i": 4704573, "k": ["Approximation Method", "Computer Vision", "Global Optimisation", "Graph Cut", "High Resolution", "Local Minima", "Maximum Flow", "Medical Image"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4587464", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04587464", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2008.html#DelongB08", "http://dx.doi.org/10.1109/CVPR.2008.4587464", "http://www.csd.uwo.ca/~adelong3/pub/08-CVPR-maxflow.pdf", "http://www.csd.uwo.ca/faculty/yuri/Papers/cvpr08.pdf", "http://ftp.csd.uwo.ca/People/gradstudents/adelong3/pub/08-CVPR-maxflow.pdf"], "t": "A Scalable graph-cut algorithm for ND grids", "v": "CVPR", "y": 2008, "rn": 22}, {"a": ["Zinovi Tauber", "Ze-nian Li", "Mark Drew"], "b": "Image-based rendering takes as input multiple images of an object and generates photorealistic images from novel viewpoints. This approach avoids explicitly modeling scenes by replacing the modeling phase with an object re- construction phase. Reconstruction is achieved in two pos- sible ways: recovering 3D point locations using multiview stereo techniques, or reasoning about consistency of each voxel in a discretized", "cn": 17, "i": 3687918, "k": ["3d model", "Boundary Condition", "Digital Image", "Image Based Rendering", "image inpainting", "Indexing Terms", "Is Research", "Point Location"], "p": ["http://www.cs.sfu.ca/people/Faculty/Drew/ftp/SMCC07/3disocclusion.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4252259", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04252259", "http://doi.ieeecomputersociety.org/10.1109/TSMCC.2006.886967", "http://www.informatik.uni-trier.de/~ley/db/journals/tsmc/tsmcc37.html#TauberLD07", "http://www.cs.sfu.ca/~li/papers-on-line/Zinovi-SMC-07.pdf", "http://www.cs.sfu.ca/research/groups/VML/pubs/drew-disocclusion_by_inpainting-SFU_TR06-04.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4252259", "https://www.cs.sfu.ca/~li/papers-on-line/Zinovi-SMC-07.pdf", "http://www2.fas.sfu.ca/pub/cs/TR/2006/CMPT2006-04.pdf"], "t": "Review and Preview: Disocclusion by Inpainting for Image-Based Rendering", "v": "TSMC", "y": 2007, "rn": 86}, {"a": ["Kalin Kolev", "Maria Klodt", "Thomas Brox", "Selim Esedoglu", "Daniel Cremers"], "b": "In this work, we introduce a robust energy model for mul- tiview 3D reconstruction that fuses silhouette- and stereo-based image information. It allows to cope with significant amounts of noise with- out manual pre-segmentation of the input images. Moreover, we suggest a method that can globally optimize this energy up to the visibility constraint. While similar global optimization has been", "cn": 17, "i": 4255390, "k": ["3d reconstruction", "Continuous Optimization", "Global Optimization", "Graph Cut"], "p": ["http://www.springerlink.com/content/rh4u57107q136044", "http://www.springerlink.com/index/rh4u57107q136044.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/emmcvpr/emmcvpr2007.html#KolevKBEC07", "http://dx.doi.org/10.1007/978-3-540-74198-5_34", "http://www.math.lsa.umich.edu/~esedoglu/Papers_Preprints/emmcvpr2007.pdf", "http://www.info.unicaen.fr/M2-AMI/articles-2008-2009/kolev.pdf"], "t": "Continuous Global Optimization in Multiview 3D Reconstruction", "v": "EMMCVPR", "y": 2007, "rn": 30}, {"a": ["Kalin Kolev", "Daniel Cremers"], "b": "We propose a convex framework for silhouette and stereo fusion in 3D reconstruction from multiple images. The key idea is to show that the reconstruction problem can be cast as one of minimizing a convex functional where the exact silhouette consistency is imposed as a convex constraint that restricts the domain of admissible functions. As a consequence, we can retain", "cn": 15, "i": 4253669, "k": ["3d reconstruction", "Convex Domain", "Convex Function", "Convex Optimization", "Cost Function", "Numerical Scheme", "Parallel Implementation", "Surface Area", "Visual Hull"], "p": ["http://cvpr.in.tum.de/pub/pub/KC-08.pdf", "http://www.springerlink.com/content/w2j622661q37166p", "http://dx.doi.org/10.1007/978-3-540-88682-2_57", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2008-1.html#KolevC08"], "t": "Integration of Multiview Stereo and Silhouettes Via Convex Functionals on Convex Domains", "v": "ECCV", "y": 2008, "rn": 24}, {"a": ["Alexander Hornung", "Leif Kobbelt"], "b": "\n Estimating photo-consistency is one of the most important ingredients for any 3D stereo reconstruction technique that is based\n on a volumetric scene representation. This paper presents a new, illumination invariant photo-consistency measure for high\n quality, volumetric 3D reconstruction from calibrated images. In contrast to current standard methods such as normalized cross-correlation\n it supports unconstrained camera setups and non-planar surface approximations.", "cn": 14, "i": 2427410, "k": ["3d reconstruction", "Consistent Estimator", "Graphics Processors", "Hardware Accelerator", "Illumination Invariance", "Normalized Cross Correlation", "Surface Approximation"], "p": ["http://www.springerlink.com/index/v076h7n83374733w.pdf", "http://www.springerlink.com/content/v076h7n83374733w", "http://dx.doi.org/10.1007/11744047_14", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2006-2.html#HornungK06"], "t": "Robust and Efficient Photo-Consistency Estimation for Volumetric 3D Reconstruction", "v": "ECCV", "y": 2006, "rn": 19}, {"a": ["Alejandro Troccoli", "Sing Kang", "Steven Seitz"], "b": "Multi-view stereo algorithms typically rely on same-exposure images as inputs due to the brightness constancy assumption. While state-of-the-art depth results are excellent, they do not produce high-dynamic range textures required for high-quality view reconstruction. In this paper, we propose a technique that adapts multi-view stereo for different exposure inputs to simultaneously recover reliable dense depth and high dynamic range textures.", "cn": 9, "i": 2412695, "k": ["High Dynamic Range", "multi-view stereo", "Response Function"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4155812", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04155812", "http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2006.html#TroccoliKS06", "http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.98"], "t": "Multi-View Multi-Exposure Stereo", "v": "3DPVT", "y": 2006, "rn": 15}, {"a": ["Yuri Boykov", "Victor Lempitsky"], "b": "Our work was inspired by recent advances in image segmentation where flux- based functionals significantly improved alignment of obje ct boundaries. We propose a novel photoflux functional for multi-view 3D reconstruction that is closely related to properties of photohulls. Our photohull prior can be combined with regularization. Thus, this work unifies two ma jor groups of multiview stereo techniques: \"space", "cn": 9, "i": 4113369, "k": ["3d reconstruction", "Deformable Model", "Image Segmentation", "Optimal Method"], "p": ["http://www.macs.hw.ac.uk/bmvc2006/papers/398.pdf", "http://www.bmva.org/bmvc/2006/papers/398.pdf", "http://www.csd.uwo.ca/faculty/yuri/Papers/bmvc06.pdf", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/2006/papers/398.pdf", "http://www.bmva.ac.uk/bmvc/2006/papers/398.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2006.html#BoykovL06"], "t": "From Photohulls to Photoflux Optimization", "v": "BMVC", "y": 2006, "rn": 26}, {"a": ["Yu-Pao Tsai", "Cheng-Hung Ko", "Yi-Ping Hung", "Zen-Chung Shih"], "b": "Image-based rendering has been successfully used to display 3-D objects for many applications. A well-known example is the object movie, which is an image-based 3-D object composed of a collection of 2-D images taken from many different viewpoints of a 3-D object. In order to integrate image-based 3-D objects into a chosen scene (e.g., a panorama), one has to meet", "cn": 8, "i": 4412817, "k": ["Graph Cut", "Image Based Rendering", "Image Segmentation", "Indexing Terms", "Medial Axis", "Reconstruction Algorithm", "Shape Priors", "Markov Random Field"], "p": ["http://ippr.csie.ntu.edu.tw/Publication/journal/2005-2007/2007/Background%20Removal%20of%20Multi-View%20Images.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4303155", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04303155", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4303155", "http://www.informatik.uni-trier.de/~ley/db/journals/tip/tip16.html#TsaiKHS07", "http://ir.lib.nctu.edu.tw/bitstream/987654321/1429/1/020106001.pdf", "http://dx.doi.org/10.1109/TIP.2007.904465", "http://kiosk.csie.ntu.edu.tw/Publication%5Cjournal%5C2005-2007%5C2007%5CBackground%20Removal%20of%20Multi-View%20Images.pdf", "http://adsabs.harvard.edu/abs/2007ITIP...16.2607T"], "t": "Background Removal of Multiview Images by Learning Shape Priors", "v": "", "y": 2007, "rn": 28}, {"a": ["Tianli Yu", "Narendra Ahuja", "Wei-chao Chen"], "b": "We show that the approaches to 3D reconstruction that use volumetric graph cuts to minimize a cost function over the object surface have two types of biases, the minimal sur- face bias and the discretization bias. These biases make it difficult to recover surface extrusions and other details, es- pecially when a non-lambertian photo-consistency measure is used. To reduce these", "cn": 7, "i": 2167296, "k": ["3d reconstruction", "Cost Function", "Distance Transform", "Graph Cut", "Minimal Surface"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1641031", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01641031", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-2.html#YuAC06", "http://research.nokia.com/files/wchen_CVPR06.pdf", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.267"], "t": "SDG Cut: 3D Reconstruction of Non-lambertian Objects Using Graph Cuts on Surface Distance Grid", "v": "CVPR", "y": 2006, "rn": 17}, {"a": ["Frank Schmidt", "Eno T\u00f6ppe", "Daniel Cremers"], "b": "We present a fast graph cut algorithm for planar graphs. It is based on the graph theoretical work (2) and leads to an efficient method that we apply on shape matching and im- age segmentation. In contrast to currently used methods in Computer Vision, the presented approach provides an upper bound for its runtime behavior that is almost linear. In", "cn": 6, "i": 5891263, "k": ["Computer Vision", "Graph Cut", "Planar Graph", "Shape Matching", "Upper Bound"], "p": ["http://www-cvpr.iai.uni-bonn.de/pub/pub/schmidt_et_al_cvpr09.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2009.html#SchmidtTC09", "http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206863", "http://wwwcremers.in.tum.de/pub/pub/schmidt_et_al_cvpr09.pdf"], "t": "Efficient planar graph cuts with applications in Computer Vision", "v": "CVPR", "y": 2009, "rn": 21}, {"a": ["Gang Zeng", "Sylvain Paris", "Long Quan", "Fran\u00e7ois Sillion"], "b": "Abstract, We introduce a new surface representation method, called patchwork, to extend three-dimensional surface reconstruction capabilities from multiple images. A patchwork is the combination of several patches that are built one by one. This design potentially allows for the reconstruction of an object with arbitrarily large dimensions while preserving a fine level of detail. We formally demonstrate that this strategy", "cn": 6, "i": 2512396, "k": ["Image Sequence", "Optimization Technique", "Surface Reconstruction", "Surface Representation", "Three Dimensional", "Time Complexity", "Level of Detail"], "p": ["http://publications.csail.mit.edu/tmp/MIT-CSAIL-TR-2005-076.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami29.html#ZengPQS07", "http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.4", "http://people.csail.mit.edu/sparis/publi/2007/pami/Zeng_07_Accurate_and_Scalable.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4016556", "http://people.csail.mit.edu/sparis/publi/2005/tr/Zeng_05_Patchwork_MIT_TR.pdf", "http://publications.csail.mit.edu/lcs/pubs/pdf/MIT-LCS-TR-1011.pdf"], "t": "Accurate and Scalable Surface Representation and Reconstruction from Images", "v": "PAMI", "y": 2007, "rn": 73}, {"a": ["Yunda Sun", "Pushmeet Kohli", "Matthieu Bray", "Philip Torr"], "b": "This paper addresses the problem of obtaining an accurate 3D recon- struction from multiple views. Taking inspiration from the recent successes of using strong prior knowledge for image segmentation, we propose a framework for 3D reconstruction which uses such priors to overcome the ambiguity inherent in this problem. Our framework is based on an object-specific Markov Random Field (MRF)(10). It", "cn": 6, "i": 2444726, "k": ["3d reconstruction", "Efficient Estimation", "Graph Cut", "Image Segmentation", "Multiple Views", "Object Reconstruction", "Parametric Model", "Prior Knowledge", "Shape Priors", "Markov Random Field", "Visual Hull"], "p": ["http://eprints.pascal-network.org/archive/00002299/01/strongPrior.pdf", "http://www.springerlink.com/content/603g486qt27k4501", "http://dx.doi.org/10.1007/11949619_79", "http://www.informatik.uni-trier.de/~ley/db/conf/icvgip/icvgip2006.html#SunKBT06", "http://research.microsoft.com/en-us/um/people/pkohli/papers/icvgip06a.pdf", "https://research.microsoft.com/en-us/um/people/pkohli/papers/icvgip06a.pdf"], "t": "Using Strong Shape Priors for Stereo", "v": "ICVGIP", "y": 2006, "rn": 16}, {"a": ["Olivier Juan", "Yuri Boykov"], "b": "Capacity scaling is a hierarchical approach to graph representation that can improve theoretical complexity and practical efficiency of max-flow/min-cut algorithms. Intro- duced by Edmonds, Karp, and Dinic (7, 6) in 1972, capac- ity scaling is well known in the combinatorial optimization community. Surprisingly, this major performance improv- ing technique is overlooked in computer vision where graph cut methods typically solve", "cn": 4, "i": 4271494, "k": ["Approximate Solution", "Combinatorial Optimization", "Computer Vision", "Energy Function", "Energy Minimization", "Energy Optimization", "Global Optimization", "Graph Cut", "Graph Representation", "Higher Dimensions", "Image Analysis", "Local Minima", "Performance Improvement", "Time Complexity"], "p": ["http://www.csd.uwo.ca/~yuri/Papers/iccv07_cap_scaling.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04408970", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4408970", "http://dx.doi.org/10.1109/ICCV.2007.4408970", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2007.html#JuanB07", "http://www.csd.uwo.ca/faculty/yuri/Papers/iccv07_cap_scaling.pdf"], "t": "Capacity Scaling for Graph Cuts in Vision", "v": "ICCV", "y": 2007, "rn": 17}, {"a": ["Frank Schmidt", "E. Toppe", "D. Cremers"], "b": "We present a fast graph cut algorithm for planar graphs. It is based on the graph theoretical work and leads to an efficient method that we apply on shape matching and image segmentation. In contrast to currently used methods in computer vision, the presented approach provides an upper bound for its runtime behavior that is almost linear. In particular, we", "cn": 3, "i": 50783115, "k": ["Computer Vision", "Graph Cut", "Image Segmentation", "Planar Graph", "Shape Matching", "Upper Bound"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206863", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05206863"], "t": "Efficient planar graph cuts with applications in Computer Vision", "v": "CVPR", "y": 2009, "rn": 19}, {"a": ["Ali Shahrokni", "Christopher Mei", "Philip Torr", "Ian Reid"], "b": "In this paper we show how online images can be automatically exploited for scene visualization and reconstruction starting from a mere visual query provided by the user. A visual query is used to retrieve images of a landmark place using a visual search engine. These images are used to reconstruct ro- bust 3-D features and camera poses in projective space.", "cn": 3, "i": 5957618, "k": ["Projective Space", "Visual Search"], "p": ["http://www.personal.rdg.ac.uk/~tt900645/index_files/papers/shahrokni_etal_bmvc08.pdf", "http://www.bmva.org/bmvc/2008/papers/195.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2008.html#ShahrokniMTR08"], "t": "From Visual Query to Visual Portrayal", "v": "BMVC", "y": 2008, "rn": 15}, {"a": ["Jaeil Choi", "Andrzej Szymczak", "Greg Turk", "Irfan Essa"], "b": "We present a new method of fitting an element-free vol- umetric model to a sequence of deforming surfaces of a moving object. Given a sequence of visual hulls, we iter- atively fit an element-free elastic model to the visual hull in order to extract the optimal pose of the captured vol- ume. The fitting of the volumetric model is acheived", "cn": 3, "i": 2167386, "k": ["Distance Measure", "Moving Object", "Point Cloud", "Potential Energy", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01641028", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1641028", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2006-2.html#ChoiSTE06", "http://doi.ieeecomputersociety.org/10.1109/CVPR.2006.110", "http://www.cc.gatech.edu/gvu/perception/projects/VolumeFitting/cvpr06_efem.pdf"], "t": "Element-Free Elastic Models for Volume Fitting and Capture", "v": "CVPR", "y": 2006, "rn": 28}, {"a": ["Pushmeet Kohli"], "b": "", "cn": 3, "i": 4141148, "k": ["Energy Function", "Graph Cut", "Higher Order"], "p": [], "t": "Minimizing Dynamic and Higher Order Energy Functions using Graph Cuts", "y": 0, "rn": 119}, {"a": ["Victor Lempitsky"], "b": "A number of 3D shape reconstruction algorithms, in particular 3D image segmentation methods, produce their results in the form of binary volumes, where a binary value indicates whether a voxel is associated with the interior or the exterior. For visualization purpose, it is often desirable to convert a binary volume into a surface representation. Straightforward extraction of the median isosurfaces", "cn": 2, "i": 5860254, "k": ["3d imaging", "3d shape reconstruction", "Convex Optimization", "Isosurface Extraction", "Marching Cube", "Surface Representation", "Time Consistency", "Visual Quality", "Higher Order"], "p": ["https://research.microsoft.com/pubs/79956/BinVolumes.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539832", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539832", "http://research.microsoft.com/pubs/79956/BinVolumes.pdf", "http://dx.doi.org/10.1109/CVPR.2010.5539832", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#Lempitsky10"], "t": "Surface extraction from binary volumes with higher-order smoothness", "v": "CVPR", "y": 2010, "rn": 28}, {"a": ["Yongsub Lim", "Kyomin Jung", "Pushmeet Kohli"], "b": "\n Many computer vision problems such as object segmentation or reconstruction can be formulated in terms of labeling a set of\n pixels or voxels. In certain scenarios, we may know the number of pixels or voxels which can be assigned to a particular label.\n For instance, in the reconstruction problem, we may know size of the object to be reconstructed. Such", "cn": 2, "i": 13995243, "k": ["Approximate Solution", "Computer Vision", "Energy Function", "Energy Minimization", "Image Segmentation", "Maximum Flow", "Object Segmentation"], "p": ["http://www.springerlink.com/content/575782152341033x", "http://www.springerlink.com/index/575782152341033x.pdf", "http://dx.doi.org/10.1007/978-3-642-15552-9_39", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2010-2.html#LimJK10"], "t": "Energy Minimization under Constraints on Label Counts", "v": "ECCV", "y": 2010, "rn": 24}, {"a": ["Chih-Yuan Chung", "Homer Chen"], "b": "Video object segmentation is a critical task in multimedia analysis and editing. Normally, the user provides some hints of foreground and background, then the target object is extracted from the video sequence. Most previous methods are either computation-expensive or labor-intensive, and approaches that assume static background have limited applications. In this letter, we propose a novel video segmentation system that", "cn": 2, "i": 14401196, "k": ["Graph Cut", "Image Segmentation", "User Interaction", "Video Object Segmentation", "Video Segmentation", "Markov Random Field", "Video Object"], "p": ["http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5159426", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05159426", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5159426", "http://dx.doi.org/10.1109/TCSVT.2009.2026823", "http://www.informatik.uni-trier.de/~ley/db/journals/tcsv/tcsv20.html#ChungC10"], "t": "Video Object Extraction via MRF-Based Contour Tracking", "v": "TCSV", "y": 2010, "rn": 24}, {"a": ["E. Larsen", "Philippos Mordohai", "Mordohai Pollefeys", "Henry Fuchs"], "b": "Abstract We address multiple-view reconstruction under an optimization approach,based on belief propagation. A novel formulation of belief propagation that operates in 3-D is proposed to facilitate a true multi-image processing scheme that takes visibility into account and thus is applicable to scenes that contain significant occlusions. Visibility is not approximated,but is estimated and used in a modified plane sweep stereo", "cn": 2, "i": 2412779, "k": ["a priori knowledge", "Belief Propagation", "Image Processing", "Multiple Views"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4155746", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04155746", "http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2006.html#LarsenMPF06", "http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.129"], "t": "Simplified Belief Propagation for Multiple View Reconstruction", "v": "3DPVT", "y": 2006, "rn": 21}, {"a": ["Xin Liu", "Hongxun Yao", "Xilin Chen", "Wen Gao"], "b": "In this paper, we present a visual hull embossment algo- rithm which works on the base of a visual hull to reconstruct a precise model from calibrated color images. The algorithm uses the geometry of the visual hull to compute voxel nor- mals and visibilities. Then a photometric consistency field (PCF) is computed, which describes the photometric consis- tency score", "cn": 2, "i": 2440191, "k": ["Color Image", "Energy Minimization", "Geometric Model", "Graph Cut", "Indexing Terms", "Machine Vision", "Visual Hull"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/icip/icip2006.html#LiuYCG06", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4107002", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04107002", "http://dx.doi.org/10.1109/ICIP.2006.312978", "http://www-video.eecs.berkeley.edu/Proceedings/ICIP2006/pdfs/0002205.pdf"], "t": "Visual Hull Embossment by Graph Cuts", "v": "ICIP", "y": 2006, "rn": 15}, {"a": ["Cheng-hung Ko", "Yu-pao Tsai", "Zen-chung Shih", "Yi-ping Hung"], "b": "This paper proposes a new object movie (OM) segmentation method that incorporates shape priors into the segmentation algorithm. The shape prior introduced into every image of the OM is learned from the 3D model reconstructed by the volumetric graph cuts. Here, the constraint derived from the discrete medial axis is used to improve the reconstruction algorithm. Our segmentation method requires", "cn": 2, "i": 2442612, "k": ["3d model", "3d reconstruction", "Graph Cut", "Image Segmentation", "Medial Axis", "Reconstruction Algorithm", "Shape Priors"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01698898", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1698898", "http://www.informatik.uni-trier.de/~ley/db/conf/icpr/icpr2006-1.html#KoTSH06", "http://doi.ieeecomputersociety.org/10.1109/ICPR.2006.119"], "t": "A New Image Segmentation Method for Removing Background of Object Movies by Learning Shape Priors", "v": "ICPR", "y": 2006, "rn": 9}, {"a": ["Fred Nicolls", "Philip Torr"], "b": "Graph cuts have proven useful for image segmentation and for volumetric reconstruction in multiple view stereo. However, solutions are biased: the cost function tends to favour either a short boundary (in 2D) or a boundary with a small area (in 3D). This bias can be avoided by instead minimising the cut ratio, which normalises the cost by a measure of", "cn": 1, "i": 39261534, "k": ["Cost Function", "Curves and Surfaces", "Discrete Differential Geometry", "Global Optimization", "Graph Cut", "Image Segmentation", "Multiple Views", "Linear Program"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539892", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539892", "http://dx.doi.org/10.1109/CVPR.2010.5539892", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#NicollsT10"], "t": "Discrete minimum ratio curves and surfaces", "v": "CVPR", "y": 2010, "rn": 16}, {"a": ["Arjun Jain", "Christian Kurz", "Thorsten Thorm\u00e4hlen", "Hans-Peter Seidel"], "b": "Given a set of 2D images, we propose a novel approach for the reconstruction of straight 3D line segments that represent the underlying geometry of static 3D objects in the scene. Such an algorithm is especially useful for the automatic 3D reconstruction of man-made environments. The main contribution of our approach is the generation of an improved reconstruction by imposing", "cn": 1, "i": 39261610, "k": ["3d reconstruction", "Ground Truth"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5539781", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05539781", "http://dx.doi.org/10.1109/CVPR.2010.5539781", "http://www.informatik.uni-trier.de/~ley/db/conf/cvpr/cvpr2010.html#JainKTS10"], "t": "Exploiting global connectivity constraints for reconstruction of 3D line segments from images", "v": "CVPR", "y": 2010, "rn": 10}, {"a": ["Tobias Feldmann", "Lars Die\u00dfelberg", "Annika W\u00f6rner"], "b": "We present a novel approach for adaptive foreground/background segmentation in non-static environments using multiview silhouette\n fusion. Our focus is on coping with moving objects in the background and influences of lighting conditions. It is shown, that\n by integrating 3d scene information, background motion can be compensated to achieve a better segmentation and a less error\n prone 3d reconstruction of the", "cn": 1, "i": 6032484, "k": ["3d reconstruction", "Error Analysis", "Feedback System", "Moving Object", "Foreground Background"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/dagm/dagm2009.html#FeldmannDW09", "http://www.springerlink.com/index/m736qv4733175874.pdf", "http://www.springerlink.com/content/m736qv4733175874", "http://dx.doi.org/10.1007/978-3-642-03798-6_53", "http://adsabs.harvard.edu/abs/2009LNCS.5748..522F"], "t": "Adaptive Foreground/Background Segmentation Using Multiview Silhouette Fusion", "v": "", "y": 2009, "rn": 15}, {"a": ["Junchi Yan", "Yin Li", "EnLiang Zheng", "Yuncai Liu"], "b": "\n In this paper, we propose an automated and markless human motion tracking system, including voxel acquisition and motion tracking.\n We first explore the problem of voxel reconstruction under a complex environment. Specifically, the procedure of the voxel\n acquisition is conducted under cluttered background, which makes the high quality silhouette unavailable. An accelerated Bayesian\n sensor fusion framework combining the information of", "cn": 1, "i": 13264281, "k": ["High Dimensionality", "Human Motion", "Motion Capture", "Motion Tracking", "Sensor Fusion", "Tracking System", "Ground Truth", "Region of Interest"], "p": ["http://www.springerlink.com/index/l065386998w07712.pdf", "http://www.springerlink.com/content/l065386998w07712", "http://dx.doi.org/10.1007/978-3-642-12304-7_30"], "t": "An Accelerated Human Motion Tracking System Based on Voxel Reconstruction under Complex Environments", "v": "ACCV", "y": 2009, "rn": 24}, {"a": ["Zhouyu Fu", "Antonio Robles-kelly"], "b": "In this paper, we propose a novel approach to graph regularisation based on energy minimisation. Our method hinges in the\n use of a Ginzburg-Landau functional whose extremum is achieved efficiently by a gradient descend optimisation process. As\n a result of the treatment given in this paper to the regularisation problem, constraints can be enforced in a straightforward\n manner. This provides", "cn": 1, "i": 4255377, "k": ["Image Segmentation", "Pattern Recognition", "Photometric Stereo", "ginzburg landau"], "p": ["http://www.springerlink.com/index/3q433348323118j3.pdf", "http://www.springerlink.com/content/3q433348323118j3", "http://www.informatik.uni-trier.de/~ley/db/conf/emmcvpr/emmcvpr2007.html#FuR07", "http://dx.doi.org/10.1007/978-3-540-74198-5_6"], "t": "An Energy Minimisation Approach to Attributed Graph Regularisation", "v": "EMMCVPR", "y": 2007, "rn": 35}, {"a": ["Timo Stich", "Art Tevs", "Marcus Magnor"], "b": "Using Epipolar Image Analysis in the context of the corre- spondence finding problem in depth reconstruction has sev- eral advantages. One is the elegant incorporation of prior knowledge about the scene or the surface reflection prop- erties into the reconstruction process. The proposed frame- work in conjunction with graph cut optimization is able to reconstruct also highly specular surfaces. The", "cn": 1, "i": 2412716, "k": ["Graph Cut", "Graphics Hardware", "Image Analysis", "Prior Knowledge"], "p": ["http://www.cg.tu-bs.de/publications/3dpvt06.pdf", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04155820", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4155820", "http://www.informatik.uni-trier.de/~ley/db/conf/3dpvt/3dpvt2006.html#StichTM06", "http://www.cg.cs.tu-bs.de/publications/3dpvt06.pdf", "http://doi.ieeecomputersociety.org/10.1109/3DPVT.2006.69", "http://graphics.tu-bs.de/people/magnor/publications/3dpvt06.pdf", "http://graphics.tu-bs.de/publications/3dpvt06.pdf", "http://www.cg.cs.tu-bs.de/people/magnor/publications/3dpvt06.pdf"], "t": "Global Depth from Epipolar Volumes--A General Framework for Reconstructing Non-Lambertian Surfaces", "v": "3DPVT", "y": 2006, "rn": 17}, {"a": ["Yuri Boykov", "Victor Lempitsky"], "b": "Our work was inspired by recent advances in image segmentation where flux- based functionals significantly improved alignment of obje ct boundaries. We propose a novel photoflux functional for multi-view 3D reconstruction that is closely related to properties of photohulls. Our photohull prior can be combined with regularization. Thus, this work unifies two ma jor groups of multiview stereo techniques: \"space", "cn": 1, "i": 12866503, "k": ["3d reconstruction", "Deformable Model", "Image Segmentation", "Optimal Method"], "p": [], "t": "Photoflux Maximizing Shapes", "y": 0, "rn": 34}, {"a": ["Pushmeet Kohli", "Victor Lempitsky", "Carsten Rother"], "b": "This paper proposes a new multi-scale energy minimiza- tion algorithm which can be used to efficiently solve large scale labelling problems in computer vision. The basic modus operandi of any multi-scale method involves the con- struction of a smaller problem which can be solved effi- ciently. The solution of this problem is used to obtain a partial labelling of the", "cn": 1, "i": 13213199, "k": ["Computer Vision", "Energy Function", "Energy Minimization", "Fine Structure", "Interactive Image Segmentation", "Large Scale", "Object Segmentation"], "p": ["http://research.microsoft.com/en-us/um/people/pkohli/papers/klr_tr2010.pdf"], "t": "Uncertainty Driven Multi-scale Energy Minimization", "y": 0, "rn": 24}, {"a": ["Ondrej Danek", "Pavel Matula"], "b": "\n Boykov and Kolmogorov showed that it is possible to find globally minimal contours and surfaces via graph cuts by embedding\n an appropriate metric approximation into the graph edge weights and derived the requisite formulas for Euclidean and Riemannian\n metrics [3]. In [9] we have proposed an improved Euclidean metric approximation that is invariant under (horizontal and vertical)\n mirroring, applicable to", "cn": 0, "i": 39262043, "k": ["Approximation Error", "Graph Cut", "Image Segmentation", "riemannian metric", "Stereo Matching", "Theory and Practice"], "p": ["http://www.springerlink.com/index/g64286w402h4v1p6.pdf", "http://www.springerlink.com/content/g64286w402h4v1p6", "http://dx.doi.org/10.1007/978-3-642-19867-0_6", "http://www.informatik.uni-trier.de/~ley/db/conf/dgci/dgci2011.html#DanekM11"], "t": "An Improved Riemannian Metric Approximation for Graph Cuts", "v": "DGCI", "y": 2011, "rn": 15}, {"a": ["Kensuke Hisatomi", "Miwa Katayama", "Kimihiro Tomiyama", "Yuichi Iwadate"], "b": "We developed a 3D archive system for Japanese traditional performing arts. The system generates sequences of 3D actor models\n of the performances from multi-view video by using a graph-cuts algorithm and stores them with CG background models and related\n information. The system can show a scene from any viewpoint as follows; the 3D actor model is integrated with the background", "cn": 0, "i": 39321385, "k": ["3d reconstruction", "Background Modeling", "Energy Minimization", "Graph Cut", "Integrable Model", "Performing Art", "Visual Hull"], "p": ["http://www.springerlink.com/index/j16l7r1775w37504.pdf", "http://www.springerlink.com/content/j16l7r1775w37504", "http://dx.doi.org/10.1007/s11263-011-0434-2", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv94.html#HisatomiKTI11"], "t": "3D Archive System for Traditional Performing Arts - Application of 3D Reconstruction Method Using Graph-cuts", "v": "IJCV", "y": 2011, "rn": 21}, {"a": ["Pushmeet Kohli", "Philip Torr"], "b": "\n Over the last few years energy minimization has emerged as an indispensable tool in computer vision. The primary reason for\n this rising popularity has been the successes of efficient graph cut based minimization algorithms in solving many low level\n vision problems such as image segmentation, object reconstruction, image restoration and disparity estimation. The scale and\n form of computer vision problems", "cn": 0, "i": 13339078, "k": ["Computer Vision", "Disparity Estimation", "Energy Function", "Energy Minimization", "Graph Cut", "Image Restoration", "Image Segmentation", "Interactive Image Segmentation", "Measurement Uncertainty", "Object Reconstruction", "Polynomial Time", "Pose Estimation", "Similarity Function"], "p": ["http://dx.doi.org/10.1007/978-3-642-12848-6_3", "http://www.springerlink.com/index/n2w3156x7092045j.pdf", "http://www.springerlink.com/content/n2w3156x7092045j", "http://www.informatik.uni-trier.de/~ley/db/series/sci/sci285.html#KohliT10"], "t": "Dynamic Graph Cuts and Their Applications in Computer Vision", "y": 2010, "rn": 76}, {"a": ["Javier Bejarano", "Jos\u00e9 Pozo", "Jos\u00e9 Campo"], "b": "Rock glacier is a rare case of study for 3D modelling. This type of models has particular properties which make it a special application for multi-view stereo reconstruction algorithms. In this work we analyze different types of methods for dense reconstruction from wide base-line views. Besides that we select a method which was adapted and implemented for the specific case", "cn": 0, "i": 50819987, "k": ["3d modelling", "Computer Vision", "Depth Estimation", "multi-view stereo", "Reconstruction Algorithm", "Rock Glacier", "Sierra Nevada"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5306016", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=05306016"], "t": "A Multi-view Dense Reconstruction for Rock Glacier Modelling", "v": "VSMM", "y": 2009, "rn": 10}, {"a": ["Ping Li", "Rene Gunnewiek"], "b": "Multi-view scene reconstruction from multiple uncalibrated images can be solved by two stages of processing: first, a sparse\n reconstruction using Structure From Motion (SFM), and second, a surface reconstruction using optimization of Markov random\n field (MRF). This paper focuses on the second step, assuming that a set of sparse feature points have been reconstructed and\n the cameras have been calibrated", "cn": 0, "i": 4230887, "k": ["Content Adaptation", "Content Analysis", "Energy Function", "Graph Cut", "Image Segmentation", "Problem Solving", "Scene Reconstruction", "Structure From Motion", "Surface Reconstruction", "Triangular Mesh", "Markov Random Field"], "p": ["http://www.springerlink.com/content/n5747g2lq6k83071", "http://www.springerlink.com/index/n5747g2lq6k83071.pdf", "http://dx.doi.org/10.1007/978-3-540-88458-3_79", "http://www.informatik.uni-trier.de/~ley/db/conf/acivs/acivs2008.html#LiGW08"], "t": "Scene Reconstruction Using MRF Optimization with Image Content Adaptive Energy Functions", "v": "ACIVS", "y": 2008, "rn": 16}, {"a": ["R. Guerchouche", "O. Bernier", "T. Zaharia"], "b": "Within the framework of collaborative interactions with 3D numerical copies of real objects inserted in virtual environments,\n this paper tackles the issue of 3D object reconstruction from multiple calibrated cameras. After examining the various constraints\n related to collaborative systems, we propose comprehensive, state of the art 3D reconstruction techniques. The main families\n of approaches are here identified, described, and discussed", "cn": 0, "i": 27488385, "k": ["3d reconstruction", "Collaborative System", "Interactive Application", "Object Reconstruction", "Virtual Environment"], "p": ["http://www.springerlink.com/index/f0671672h2657626.pdf", "http://www.springerlink.com/content/f0671672h2657626", "http://www.springerlink.com/index/10.1134/S1054661808040147"], "t": "Multiresolution volumetric 3D object reconstruction for collaborative interactions", "v": "", "y": 2008, "rn": 50}, {"a": ["Thorsten Thorm\u00e4hlen", "Hans-Peter Seidel"], "b": "A semi-automatic approach is presented that enables the generation of a high-quality 3D model of a static object from an image sequence that was taken by a moving, uncalibrated consumer camera. A bounding box is placed around the object, and orthographic projections onto the sides of the bounding box are automatically generated out of the image sequence. These ortho-images can", "cn": 0, "i": 39243831, "k": ["3d model", "Automatic Generation", "Image Based Rendering", "Image Generation", "Image Sequence", "Laser Scanner", "Structure From Motion"], "p": ["http://portal.acm.org/citation.cfm?id=1360685", "http://portal.acm.org/ft_gateway.cfm?id=1360685&type=pdf&CFID=29576336&CFTOKEN=51534192"], "t": "3D-modeling by ortho-image generation from image sequences", "y": 2008, "rn": 9}, {"a": ["T. Matsuyama", "S. Nobuhara", "T. Mukasa", "A. Miyamoto", "K. Fujimoto"], "b": "The development of 3D video in recent years realizes 3D surface capturing of human in motion as is. In this paper, we introduce 3D human sensing algorithms based on 3D video. Since 3D video capturing does not require the object to attach special markers, we can capture the original information such as body motion or viewing directions without any disturbance", "cn": 0, "i": 50645532, "k": ["3d video", "Eye Detection", "Human Motion"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04460466", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4460466"], "t": "3D Human Sensing", "y": 2008, "rn": 8}, {"a": ["Bo Shu", "Xianjie Qiu", "Zhaoqi Wang"], "b": "In this paper, we present a combined camera calibration and image based modeling method using an iterative optimization of shape from silhouette under circular motion. By minimizing the difference between the projections of reconstructed visual hull and the silhouette images using graphics hardware, the optimization can finally converge to accurate camera parameters and realistic visual hull efficiently and robustly. Using", "cn": 0, "i": 50660597, "k": ["3d model", "3d modelling", "Camera Calibration", "Graphics Hardware", "image-based modeling", "Shape From Silhouette", "Visual Hull"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4563093", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04563093"], "t": "Hardware-based camera calibration and 3D modelling under circular motion", "v": "CVPR", "y": 2008, "rn": 21}, {"a": ["Antonio Gallego", "Rafael Molina", "Patricia Compa\u00f1", "Carlos Villagr\u00e1"], "b": "In this paper a new method for reconstructing 3D scenes from stereo images is presented, as well as an algorithm for environment\n mapping, as an application of the previous method. In the reconstruction process a geometrical rectification filter is used\n to remove the conical perspective of the images. It is essential to recover the geometry of the scene (with real", "cn": 0, "i": 4239142, "k": ["3d reconstruction", "Environment Maps"], "p": ["http://dx.doi.org/10.1007/978-3-540-75555-5_30", "http://www.springerlink.com/content/176022q892u33885", "http://www.springerlink.com/index/176022q892u33885.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bvai/bvai2007.html#GallegoMCV07"], "t": "3D Reconstruction and Mapping from Stereo Pairs with Geometrical Rectification", "v": "BVAI", "y": 2007, "rn": 13}, {"a": ["Antonio Gallego", "Rafael Molina", "Carlos Villagr\u00e1"], "b": "The reconstruction and mapping of real scenes is a crucial element in several fields such as robot navigation. Stereo vision\n can be a powerful solution. However the perspective effect arises, as well as other problems, when the reconstruction is tackled\n using depth maps obtained from stereo images. A new approach is proposed to avoid the perspective effect, based on a", "cn": 0, "i": 4239612, "k": ["Depth Map", "Robot Navigation", "Stereo Vision", "Vanishing Point"], "p": ["http://dx.doi.org/10.1007/978-3-540-74272-2_18", "http://www.springerlink.com/content/h5047525717603v2", "http://www.springerlink.com/index/h5047525717603v2.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/caip/caip2007.html#GallegoMCV07"], "t": "Rectified Reconstruction from Stereo Pairs and Robot Mapping", "v": "CAIP", "y": 2007, "rn": 11}, {"a": ["Timothy Smith", "David Redmill", "Cedric Canagarajah", "David Bull"], "b": "Traditional volumetric scene reconstruction algorithms involve the evalua- tion of many millions of voxels which is highly time consuming. This paper presents an efficient algorithm based of future frame prediction that can dra- matically reduce the number of voxels to be evaluated in time varying scenes. The new prediction method, combining scene flow and morphological dila- tions, is evaluated against", "cn": 0, "i": 4457687, "k": ["Efficient Algorithm", "Prediction Method", "Scene Reconstruction", "Optical Flow", "Time Varying"], "p": ["http://www.bmva.org/bmvc/2007/papers/paper-146.pdf", "http://www.dcs.warwick.ac.uk/bmvc2007/proceedings/CD-ROM/papers/paper-146.pdf", "http://www.comp.leeds.ac.uk/bmvc2008/proceedings/2007/papers/paper-146.pdf", "http://www.informatik.uni-trier.de/~ley/db/conf/bmvc/bmvc2007.html#SmithRCB07"], "t": "Time Varying Volumetric Scene Reconstruction Using Scene Flow", "v": "BMVC", "y": 2007, "rn": 18}, {"a": ["Gang Zeng", "Long Quan", "F. Sillion"], "b": "We introduce a new surface representation method, called patchwork, to extend three-dimensional surface reconstruction capabilities from multiple images. A patchwork is the combination of several patches that are built one by one. This design potentially allows for the reconstruction of an object with arbitrarily large dimensions while preserving a fine level of detail. We formally demonstrate that this strategy leads", "cn": 0, "i": 51172318, "k": ["Computer Vision", "Graph Cut", "Image Sequence", "Level Set", "Optimization Technique", "Surface Reconstruction", "Surface Representation", "Three Dimensional", "Time Complexity", "Level of Detail"], "p": ["http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4016556", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=04016556"], "t": "Accurate and Scalable Surface Representation and Reconstruction from Images", "v": "PAMI", "y": 2007, "rn": 58}, {"a": ["Carlos Hernandez"], "b": "We present a new formulation to multi-view stereo that treats the problem as probabilistic 3D segmentation. Pre- vious work has used the stereo photo-consistency criterion as a detector of the boundary between the 3D scene and the surrounding empty space. Here we show how the same criterion can also provide a foreground/background model that can predict if a 3D location", "cn": 0, "i": 10406055, "k": ["3d segmentation", "Graph Cut", "multi-view stereo", "Foreground Background", "Multi Resolution"], "p": ["http://carlos-hernandez.org/papers/hernandez_cvpr07.pdf", "http://george-vogiatzis.org/publications/cvpr2007.pdf", "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2007-CVPR-Hernandez-stereo.pdf"], "t": "Probabilistic visibility for multi-view stereo", "y": 0, "rn": 21}, {"a": ["O. Bernier", "T. Zaharia"], "b": "This article proposes a new method for 3D reconstruction of real world objects using a low number of views. The method uses a hierarchical octree representation of a 3D voxel space. An iterative algorithm is used : starting from a coarse resolution, precise 3D models are obtained. The contributions of this paper concern a new algorithm for estimating voxels visibility", "cn": 0, "i": 10907254, "k": ["3d model", "3d reconstruction", "Iterative Algorithm", "Object Reconstruction"], "p": ["http://perso.rd.francetelecom.fr/bernier/publications/rfia_rg08_light.pdf"], "t": "Multiresolution Volumetric 3D Object Reconstruction", "y": 0, "rn": 29}, {"a": ["Carlos Hern", "Francis Schmitt", "Roberto Cipolla"], "b": "", "cn": 0, "i": 11196153, "k": [], "p": ["http://mi.eng.cam.ac.uk/~cipolla/archive/Publications/inproceedings/2006-ARIF-Hernandez.pdf", "http://mi.eng.cam.ac.uk/~cipolla/publications/inproceedings/2006-ARIF-Hernandez.pdf"], "t": "elisation d'objets 3D a partir d'images non-calibr\u00b7 ees", "y": 0, "rn": 31}, {"a": ["Hiroshi Ishikawa", "Kenichi Kanatani", "Yasushi Kanazawa", "Yasushi Makihara", "Jun Miura"], "b": "", "cn": 0, "i": 11280841, "k": ["Computer Vision"], "p": ["http://www.suri.cs.okayama-u.ac.jp/~kanatani/papers/eccv06rep.pdf", "http://www.suri.it.okayama-u.ac.jp/~kanatani/papers/eccv06rep.pdf"], "t": "Report on the 9th European Conference on Computer Vision (ECCV2006)", "y": 0, "rn": 60}, {"a": ["E. Scott", "Larsen Philippos", "Mordohai Pollefeys", "Henry Fuchs"], "b": "We address multiple-view reconstruction under an opti- mization approach based on belief propagation. A novel formulation of belief propagation that operates in 3-D is proposed to facilitate a true multi-image processing scheme that takes visibility into account and thus is applicable to scenes that contain significant occlusions. Visibility is not approximated but is estimated and used in a modified plane", "cn": 0, "i": 11909520, "k": ["Belief Propagation", "Image Processing", "Multiple Views"], "p": [], "t": "Simplified Belief Propagation for Multiple View Reconstruction", "y": 0, "rn": 22}, {"a": ["Philip Torr\u00e1", "Ian Reid\u00dc"], "b": "In this paper we show how online images can be automatically exploited for scene visualization and reconstruction starting from a mere visual query provided by the user. A visual query is used to retrieve images of a landmark place using a visual search engine. These images are used to reconstruct ro- bust 3\u00f1D features and camera poses in projective space.", "cn": 0, "i": 12269417, "k": ["Projective Space", "Visual Search"], "p": ["http://www.comp.leeds.ac.uk/bmvc2008/proceedings/papers/195.pdf", "http://www.bmva.org/bmvc/2008/papers/195.pdf"], "t": "From Visual Query to Visual Portrayal", "y": 0, "rn": 15}, {"a": [], "b": "", "cn": 0, "i": 12906793, "k": [], "p": [], "t": "Sparse Wide-Baseline Virtual View Generation", "y": 0, "rn": 13}, {"a": ["Vladimir Kolmogorov", "Ramin Zabih"], "b": "In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in com- puter vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet because these graph constructions are complex and highly specific to a particular en- ergy function, graph", "cn": 842, "i": 119729, "k": ["Energy Function", "Energy Minimization", "Graph Cut", "Image Restoration", "Minimum Cut", "Computer Vision", "Graph Algorithm", "Indexing Terms", "Maximum Flow", "Scene Reconstruction", "Software Implementation", "Markov Random Field"], "p": ["http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2002-3.html#KolmogorovZ02", "http://www.springerlink.com/content/8c6ju5u2yug2ulbh", "http://www.springerlink.com/index/8c6ju5u2yug2ulbh.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1262177", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01262177", "http://www.cs.cornell.edu/%7Erdz/Papers/KZ-PAMI04.pdf", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1262177", "http://www.wisdom.weizmann.ac.il/~mica/CVspring06/papers/optimization_I/Kolmogorov%20what%20energy%20functions%20can%20be%20minimized%20via%20graph%20cuts.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami26.html#KolmogorovZ04", "http://www.cs.cornell.edu/rdz/Papers/KZ-ECCV02-graphcuts.pdf", "http://csdl.computer.org/comp/trans/tp/2004/02/i0147abs.htm", "http://www.cs.cornell.edu/rdz/papers/graph_cuts_pami.pdf", "http://www.cs.cornell.edu/~rdz/papers/kz-eccv02-graphcuts.pdf", "http://ecommons.library.cornell.edu/bitstream/1813/5842/1/2001-1857.pdf", "http://webdocs.cs.ualberta.ca/~nray1/CMPUT605/track2_papers/Kolmogorov2004.pdf"], "t": "What Energy Functions Can Be Minimized via Graph Cuts?", "v": "ECCV", "y": 2002, "rn": 54}, {"a": ["Laurent Cohen", "Isaac Cohen"], "b": "enhancements of the model introduced in (12) for curves to the surface model applications given here. In (12), we introduced a modification, using \"balloons,'' in order to apply the method of deformable models to stacks of images comprising a 3-D data set for an application in segmentation. Our use of deformable models in (12) was limited to the extraction of", "cn": 799, "i": 799549, "k": ["Active Contour Model", "Deformable Model", "Difference Scheme", "Edge Elements", "Finite Difference", "Finite Element Method", "Image Analysis", "Magnetic Resonance Image", "Partial Differential Equation", "Satisfiability", "Surface Model", "Three Dimensional"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00244675", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=244675", "http://iris.usc.edu/~icohen/pdf/pami93.pdf", "http://www.computer.org/tpami/tp1993/i1131abs.htm", "http://www.ceremade.dauphine.fr/~cohen/mypapers/CohenCohenPAMI93.pdf"], "t": "Finite-Element Methods for Active Contour Models and Balloons for 2-D and 3-D Images", "v": "PAMI", "y": 1993, "rn": 36}, {"a": ["Laurent Cohen", "Isaac Cohen"], "b": " The use of energy-minimizing curves, known as &amp;quot;snakes&amp;quot; to extract features of interest in images has been introduced by Kass, Witkin and Terzopoulos [23]. A balloon model was introduced in [12] as a way to generalize and solve some of the problems encountered with the original method. We present a 3D generalization of the balloon model as a 3D deformable", "cn": 471, "i": 268093, "k": ["3d imaging", "Active Contour Model", "Energy Minimization", "Finite Element Method"], "p": [], "t": "Finite Element Methods for Active Contour Models and Balloons for 2D and 3D Images", "v": "PAMI", "y": 1991, "rn": 13}, {"a": ["Jian Sun", "Nan-Ning Zheng", "Heung-yeung Shum"], "b": "In this paper, we formulate the stereo matching problem as a Markov network and solve it using Bayesian belief propagation. The stereo Markov network consists of three coupled Markov random fields that model the following: a smooth field for depth/disparity, a line process for depth discontinuity and a binary process for occlusion. After eliminating the line process and the binary", "cn": 361, "i": 800914, "k": ["bayesian inference", "Belief Propagation", "Image Segmentation", "Map Estimation", "Markov Network", "Stereo Matching", "Stereoscopic Vision", "Visual Cues", "Markov Random Field"], "p": ["http://csdl.computer.org/comp/trans/tp/2003/07/i0787abs.htm", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1206509", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01206509", "http://www.informatik.uni-trier.de/~ley/db/journals/pami/pami25.html#SunZS03", "http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1206509", "http://www.cs.sfu.ca/fas-info/cs/CC/821/li/material/source/BP-stereo-PAMI-03.pdf", "http://research.microsoft.com/apps/pubs/default.aspx?id=64220", "http://research.microsoft.com/pubs/64220/stereo_pami.pdf"], "t": "Stereo Matching Using Belief Propagation", "v": "PAMI", "y": 2003, "rn": 41}, {"a": ["Jian Sun", "Heung-yeung Shum", "Nan-Ning Zheng"], "b": "In this paper, we formulate the stereo matching problem as a Markov network consisting of three coupled Markov random fields (MRF's). These three MRF's model a smooth field for depth/disparity, a line process for depth discontinuity and a binary process for occlusion, respectively. After eliminating the line process and the binary process by introducing two robust functions, we obtain the", "cn": 305, "i": 509735, "k": ["Belief Propagation", "Image Segmentation", "Map Estimation", "Markov Network", "Stereo Matching", "Visual Cues", "Markov Random Field"], "p": ["http://www.springerlink.com/index/dyyt9ma8evf7h97b.pdf", "http://www.springerlink.com/content/dyyt9ma8evf7h97b", "http://link.springer.de/link/service/series/0558/bibs/2351/23510510.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/eccv/eccv2002-2.html#SunSZ02", "http://cat.middlebury.edu/stereo/papers/BPStereo_ECCV02.pdf", "http://reference.kfupm.edu.sa/content/s/t/stereo_matching_using_belief_propagation_81359.pdf", "https://research.microsoft.com/en-us/um/people/jiansun/papers/Stereo_ECCV02.pdf", "http://research.microsoft.com/en-us/um/people/jiansun/papers/Stereo_ECCV02.pdf"], "t": "Stereo Matching Using Belief Propagation", "v": "ECCV", "y": 2002, "rn": 39}, {"a": ["Yuri Boykov", "Vladimir Kolmogorov"], "b": "Geodesic active contours and graph cuts are two stan- dard image segmentation techniques. We introduce a new segmentation method combining some of their benefits. Our main intuition is that any cut on a graph embedded in some continuous space can be interpreted as a contour (in 2D) or a surface (in 3D). We show how to build a grid graph", "cn": 140, "i": 1796367, "k": ["Boundary Condition", "Combinatorial Optimization", "Differential Geometry", "Geodesic Active Contour", "Graph Cut", "Graph Embedding", "Image Segmentation", "Integral Geometry", "Minimal Surface", "riemannian metric"], "p": ["http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=01238310", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1238310", "http://www.csd.uwo.ca/faculty/yuri/Papers/iccv03.pdf", "http://www.csee.wvu.edu/~tmcgraw/cs593spring2006/BK-ICCV03.pdf", "http://lear.inrialpes.fr/people/triggs/events/iccv03/cdrom/iccv03/0026_boykov.pdf", "http://www.cs.cornell.edu/People/vnk/papers/BK-ICCV03.pdf", "http://csdl.computer.org/comp/proceedings/iccv/2003/1950/01/195010026abs.htm", "http://www.informatik.uni-trier.de/~ley/db/conf/iccv/iccv2003-1.html#BoykovK03", "http://reference.kfupm.edu.sa/content/c/o/computing_geodesics_and_minimal_surfaces_33230.pdf", "http://www.csd.uwo.ca/~yuri/Papers/iccv03.pdf"], "t": "Computing Geodesics and Minimal Surfaces via Graph Cuts", "v": "ICCV", "y": 2003, "rn": 33}, {"a": ["Dan Snow", "Paul Viola", "Ramin Zabih"], "b": "Voxel occupancy is one approach for reconstructing the 3-dimensional shape of an object from multiple views. In voxel occupancy, the task is to produce a binary labeling of a set of voxels, that determines which voxels are filled and which are empty. In this paper, we give an energy minimization formulation of the voxel occupancy problem. The global minimum of", "cn": 111, "i": 204601, "k": ["Energy Function", "Energy Minimization", "Graph Cut", "Multiple Views", "3 dimensional"], "p": ["http://www.ai.mit.edu/projects/ntt/projects/9807-28/documents/NTT-TR01.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=855839", "http://research.microsoft.com/en-us/um/people/viola/pubs/mit/ntt-tr01.pdf", "https://research.microsoft.com/en-us/um/people/viola/Pubs/MIT/snowZabih.pdf", "http://research.microsoft.com/en-us/um/people/viola/pubs/mit/snowzabih.pdf", "http://www.cs.cornell.edu/~rdz/Papers/SVZ-CVPR00.pdf"], "t": "Exact voxel occupancy with graph cuts", "v": "CVPR", "y": 2000, "rn": 20}, {"a": ["Hiroshi Ishikawa", "Davi Geiger"], "b": "We propose a method for segmenting gray-value images. By segmentation, we mean a map from the set of pixels to a small set of levels such that each connected component of the set of pixels with the same level forms a relatively large and \"meaningful\" region. The method finds a set of levels with associated gray values by first finding", "cn": 97, "i": 326313, "k": ["Computer Vision", "Connected Component", "Energy Function", "Global Optimization", "Maximum Flow", "Polynomial Time"], "p": ["http://www.nsc.nagoya-cu.ac.jp/~hi/segment.pdf", "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=698598", "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=00698598"], "t": "Segmentation by Grouping Junctions", "v": "CVPR", "y": 1998, "rn": 20}, {"a": ["Sylvain Paris", "Fran\u00e7ois Sillion", "Long Quan"], "b": "Surface reconstruction from multiple calibrated images has been mainly approached using local methods, either as a continuous\n optimization problem driven by level sets, or by discrete volumetric methods such as space carving. We propose a direct surface\n reconstruction approach which starts from a continuous geometric functional that is minimized up to a discretization by a\n global graph-cut algorithm operating on", "cn": 50, "i": 2503324, "k": ["3d reconstruction", "Continuous Optimization", "Embedded Graph", "Graph Cut", "High Resolution", "Level Set", "Surface Geometry", "Surface Reconstruction", "Approximate Solution"], "p": ["http://artis.inrialpes.fr/Publications/2004/PSQ04/graph_cut.pdf", "http://www.springerlink.com/content/60425l308j785225", "http://www.springerlink.com/index/60425l308j785225.pdf", "http://people.csail.mit.edu/sparis/publi/2004/accv/Paris_04_Surface_Reconstruction.pdf", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Conference@11b363a3c60_1a6a606/graph_cut.pdf", "http://artis.imag.fr/Publications/2006/PSQ06/graph_cut.pdf", "http://artis.imag.fr/Publications/2004/PSQ04/graph_cut.pdf", "http://www.informatik.uni-trier.de/~ley/db/journals/ijcv/ijcv66.html#ParisSQ06", "http://www-ljk.imag.fr/Publications/Basilic/com.lmc.publi.PUBLI_Article@1172c0fd434_4528a3/graph_cut.pdf", "http://rivit.cs.byu.edu/750/W06/GraphCutStereo.pdf", "http://dx.doi.org/10.1007/s11263-005-3953-x", "http://artis.inrialpes.fr/Publications/2006/PSQ06/graph_cut.pdf", "http://people.csail.mit.edu/sparis/publi/2006/ijcv/Paris_06_Graph-cut.pdf", "https://artis.imag.fr/Publications/2004/PSQ04/graph_cut.pdf", "http://webdocs.cs.ualberta.ca/~jag/papersVis2/modelrec/Paris_IJCV06cut.pdf", "http://www.springerlink.com/index/10.1007/s11263-005-3953-x", "http://www.springerlink.com/index/pdf/10.1007/s11263-005-3953-x"], "t": "A Surface Reconstruction Method Using Global Graph Cut Optimization", "v": "IJCV", "y": 2006, "rn": 45}, {"a": ["O. Faugeras", "J. Gomes", "R. Keriven"], "b": "", "cn": 4, "i": 4061214, "k": ["Variational Principle"], "p": [], "t": "Variational principles in computational stereo", "y": 2003, "rn": 0}]